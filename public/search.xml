<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>人生感悟</title>
      <link href="/2023/11/13/%E4%BA%BA%E7%94%9F%E6%84%9F%E6%82%9F/%E4%BA%BA%E7%94%9F%E6%84%9F%E6%82%9F/"/>
      <url>/2023/11/13/%E4%BA%BA%E7%94%9F%E6%84%9F%E6%82%9F/%E4%BA%BA%E7%94%9F%E6%84%9F%E6%82%9F/</url>
      
        <content type="html"><![CDATA[<p>转载一篇非常不错的文章，是一位工作近20年的技术总裁写的，具有独特的见解和经验，跟大家一起分享学习~<br>一、关于工作与生活</p><p>我有个有趣的观察，外企公司多的是25-35岁的白领，40岁以上的员工很少，二三十岁的外企员工是意气风发的，但外企公司40岁附近的经理人是很尴尬的。我见过的40岁附近的外企经理人大多在一直跳槽，最后大多跳到民企，比方说，唐骏。外企员工的成功很大程度上是公司的成功，并非个人的成功，西门子的确比国美大，但并不代表西门子中国经理比国美的老板强，甚至可以说差得很远。而进外企的人往往并不能很早理解这一点，把自己的成功90％归功于自己的能力，实际上，外企公司随便换个中国区总经理并不会给业绩带来什么了不起的影响。好了问题来了，当这些经理人40多岁了，他们的薪资要求变得很高，而他们的才能其实又不是那么出众，作为外企公司的老板，你会怎么选择？有的是只要不高薪水的，要出位的精明强干精力冲沛的年轻人，有的是，为什么还要用你？</p><p>从上面这个例子，其实可以看到我们的工作轨迹，二三十岁的时候，生活的压力还比较小，身体还比较好，上面的父母身体还好，下面又没有孩子，不用还房贷，也没有孩子要上大学，当个外企小白领还是很光鲜的，挣得不多也够花了。但是人终归要结婚生子，终归会老，到了40岁，父母老了，要看病要吃药，要有人看护，自己要还房贷，要过基本体面的生活，要养小孩……那个时候需要挣多少钱才够花才重要。所以，看待工作，眼光要放远一点，一时的谁高谁低并不能说明什么。</p><p>从这个角度上来说，我不太赞成过于关注第一份工作的薪水，更没有必要攀比第一份工作的薪水，这在刚刚出校园的学生中间是很常见的。正常人大概要工作 35年，这好比是一场马拉松比赛，和真正的马拉松比赛不同的是，这次比赛没有职业选手，每个人都只有一次机会。要知道，有很多人甚至坚持不到终点，大多数人最后是走到终点的，只有少数人是跑过终点的，因此在刚开始的时候，去抢领先的位置并没有太大的意义。刚进社会的时候如果进500强公司，大概能拿到3k -6k&#x2F;月的工资，有些特别技术的人才可能可以到8k&#x2F;月，可问题是，5年以后拿多少？估计5k-10k了不起了。起点虽然高，但增幅有限，而且，后面的年轻人追赶的压力越来越大。</p><p>我前两天问我的一个销售，你会的这些东西一个新人2年就都学会了，但新人所要求的薪水却只是你的一半，到时候，你怎么办？</p><p>职业生涯就像一场体育比赛，有初赛、复赛、决赛。初赛的时候大家都刚刚进社会，大多数都是实力一般的人，这时候努力一点认真一点很快就能让人脱颖而出，于是有的人二十多岁做了经理，有的人迟些也终于赢得了初赛，三十多岁成了经理。然后是复赛，能参加复赛的都是赢得初赛的，每个人都有些能耐，在聪明才智上都不成问题，这个时候再想要胜出就不那么容易了，单靠一点点努力和认真还不够，要有很强的坚忍精神，要懂得靠团队的力量，要懂得收服人心，要有长远的眼光……</p><p>看上去赢得复赛并不容易，但，还不是那么难。因为这个世界的规律就是给人一点成功的同时让人骄傲自满，刚刚赢得初赛的人往往不知道自己赢得的仅仅是初赛，有了一点小小的成绩大多数人都会骄傲自满起来，认为自己已经懂得了全部，不需要再努力再学习了，他们会认为之所以不能再进一步已经不是自己的原因了。虽然他们仍然不好对付，但是他们没有耐性，没有容人的度量，更没有清晰长远的目光。就像一只愤怒的斗牛，虽然猛烈，最终是会败的，而赢得复赛的人则象斗牛士一样，不急不躁，跟随着自己的节拍，慢慢耗尽对手的耐心和体力。赢得了复赛以后，大约已经是一位很了不起的职业经理人了，当上了中小公司的总经理，大公司的副总经理，主管着每年几千万乃至几亿的生意。</p><p>最终的决赛来了，说实话我自己都还没有赢得决赛，因此对于决赛的决胜因素也只能凭自己的猜测而已，这个时候的输赢或许就像武侠小说里写得那样，大家都是高手，只能等待对方犯错了，要想轻易击败对手是不可能的，除了使上浑身解数，还需要一点运气和时间。世界的规律依然发挥着作用，赢得复赛的人已经不只是骄傲自满了，他们往往刚愎自用，听不进去别人的话，有些人的脾气变得暴躁，心情变得浮躁，身体变得糟糕，他们最大的敌人就是他们自己，在决赛中要做的只是不被自己击败，等着别人被自己击败。这和体育比赛是一样的，最后高手之间的比赛，就看谁失误少谁就赢得了决赛。</p><p>二、 根源 </p><p>你工作快乐么？你的工作好么？</p><p>有没有觉得干了一段时间以后工作很不开心？有没有觉得自己入错了行？有没有觉得自己没有得到应有的待遇？有没有觉得工作像一团乱麻每天上班都是一种痛苦？有没有很想换个工作？有没有觉得其实现在的公司并没有当初想象得那么好？有没有觉得这份工作是当初因为生存压力而找的，实在不适合自己？你从工作中得到你想要得到的了么？你每天开心么？</p><p>网络上愤怒的人很多，你有没有想过，你为什么不快乐？你为什么愤怒？</p><p>其实，你不快乐的根源，是因为你不知道要什么！你不知道要什么，所以你不知道去追求什么，你不知道追求什么，所以你什么也得不到。</p><p>我总觉得，职业生涯首先要关注的是自己，自己想要什么？大多数人大概没想过这个问题，唯一的想法只是——我想要一份工作，我想要一份不错的薪水，我知道所有人对于薪水的渴望，可是，你想每隔几年重来一次找工作的过程么？你想每年都在这种对于工作和薪水的焦急不安中度过么？不想的话，就好好想清楚。饮鸩止渴，不能因为口渴就拼命喝毒药。越是焦急，越是觉得自己需要一份工作，越饥不择食，越想不清楚，越容易失败，你的经历越来越差，下一份工作的人看着你的简历就皱眉头。于是你越喝越渴，越渴越喝，陷入恶性循环。最终只能哀叹世事不公或者生不逢时，只能到网络上来发泄一把，在失败者的共鸣当中寻求一点心理平衡罢了。大多数人都有生存压力，我也是，有生存压力就会有很多焦虑，积极的人会从焦虑中得到动力，而消极的人则会因为焦虑而迷失方向。所有人都必须在压力下做出选择，这就是世道，你喜欢也罢不喜欢也罢。</p><p>一般我们处理的事情分为重要的事情和紧急的事情，如果不做重要的事情就会常常去做紧急的事情。比如锻炼身体保持健康是重要的事情，而看病则是紧急的事情。如果不锻炼身体保持健康，就会常常为了病痛烦恼。又比如防火是重要的事情，而救火是紧急的事情，如果不注意防火，就要常常救火。找工作也是如此，想好自己究竟要什么是重要的事情，找工作是紧急的事情，如果不想好，就会常常要找工作。往往紧急的事情给人的压力比较大，迫使人们去赶紧做，相对来说重要的事情反而没有那么大的压力，大多数人做事情都是以压力为导向的，压力之下，总觉得非要先做紧急的事情，结果就是永远到处救火，永远没有停歇的时候。（很多人的工作也像是救火队一样忙碌痛苦，也是因为工作中没有做好重要的事情。）那些说自己活在水深火热为了生存顾不上那么多的朋友，今天找工作困难是当初你们没有做重要的事情，是结果不是原因。如果今天你们还是因为急于要找一份工作而不去思考，那么或许将来要继续承受痛苦找工作的结果。</p><p>我始终觉得我要说的话题，沉重了点，需要很多思考，远比唐笑打武警的话题来的枯燥乏味，但是，天下没有轻松的成功，成功，要付代价。请先忘记一切的生存压力，想想这辈子你最想要的是什么？所以，最要紧的事情，先想好自己想要什么。</p><p>三、什么是好工作</p><p>当初微软有个唐骏，很多大学里的年轻人觉得这才是他们向往的职业生涯，我在清华bbs里发的帖子被这些学子们所不屑，那个时候学生们只想出国或者去外企，不过如今看来，我还是对的，唐骏去了盛大，陈天桥创立的盛大，一家民营公司。一个高学历的海归在500强的公司里拿高薪水，这大约是很多年轻人的梦想，问题是，每年毕业的大学生都在做这个梦，好的职位却只有500个。</p><p>人都是要面子的，也是喜欢攀比的，即使在工作上也喜欢攀比，不管那是不是自己想要的。大家认为外企公司很好，可是好在哪里呢？好吧，他们在比较好的写字楼，这是你想要的么？他们出差住比较好的酒店，这是你想要的么？别人会羡慕一份外企公司的工作，这是你想要的么？那一切都是给别人看的，你干吗要活得那么辛苦给别人看？另一方面，他们薪水福利一般，并没有特别了不起，他们的晋升机会比较少，很难做到很高阶的主管，他们虽然厌恶常常加班，却不敢不加班，因为“你不干有得是人干”，大部分情况下会找个台湾人香港人新加坡人来管你，而这些人又往往有些莫名其妙的优越感。你想清楚了么？500强一定好么？找工作究竟是考虑你想要什么，还是考虑别人想看什么？</p><p>我的大学同学们大多数都到美国了，甚至毕业这么多年了，还有人最近到国外去了。出国真的有那么好么？我的大学同学们，大多数还是在博士、博士后、访问学者地挣扎着，至今只有一个正经在一个美国大学里拿到个正式的教职。国内的教授很难当么？我有几个表亲也去了国外了，他们的父母独自在国内，没有人照顾，有好几次人在家里昏倒都没人知道，出国，真的这么光彩么？就像有人说的“很多事情就像看A片，看的人觉得很爽，做的人未必。”</p><p>人总想找到那个最好的，可是，什么是最好的？你觉得是最好的那个，是因为你的确了解，还是因为别人说他是最好的？即使他对于别人是最好的，对于你也一定是最好的么？</p><p>对于自己想要什么，自己要最清楚，别人的意见并不是那么重要。很多人总是常常被别人的意见所影响，亲戚的意见，朋友的意见，同事的意见……问题是，你究竟是要过谁的一生？人的一生不是父母一生的续集，也不是儿女一生的前传，更不是朋友一生的外篇，只有你自己对自己的一生负责，别人无法也负不起这个责任。自己做的决定，至少到最后，自己没什么可后悔。对于大多数正常智力的人来说，所做的决定没有大的对错，无论怎么样的选择，都是可以尝试的。比如你没有考自己上的那个学校，没有入现在这个行业，这辈子就过不下去了？就会很失败？不见得。</p><p>我想，好工作，应该是适合你的工作，具体点说，应该是能给你带来你想要的东西的工作，你或许应该以此来衡量你的工作究竟好不好，而不是拿公司的大小，规模，外企还是国企，是不是有名，是不是上市公司来衡量。小公司，未必不是好公司，赚钱多的工作，也未必是好工作。你还是要先弄清楚你想要什么，如果你不清楚你想要什么，你就永远也不会找到好工作，因为你永远只看到你得不到的东西，你得到的，都是你不想要的。</p><p>可能，最好的，已经在你的身边，只是，你还没有学会珍惜。人们总是盯着得不到的东西，而忽视了那些已经得到的东西。</p><p>四、普通人</p><p>我发现中国人的励志和国外的励志存在非常大的不同，中国的励志比较鼓励人立下大志愿，卧薪尝胆，有朝一日成富成贵。而国外的励志比较鼓励人勇敢面对现实生活，面对普通人的困境，虽然结果也是成富成贵，但起点不一样，相对来说，我觉得后者在操作上更现实，而前者则需要用999个失败者来堆砌一个成功者的故事。</p><p>我们都是普通人，普通人的意思就是，概率这件事是很准的。因此，我们不会买彩票中500万，我们不会成为比尔盖茨或者李嘉诚，我们不会坐飞机掉下来，我们当中很少的人会创业成功，我们之中有30％的人会离婚，我们之中大部分人会活过65岁……</p><p>所以请你在想自己要什么的时候，要得“现实”一点，你说我想要做李嘉诚，抱歉，我帮不上你。成为比尔盖茨或者李嘉诚这种人，是靠命的，看我写的这篇文章绝对不会让你成为他们，即使你成为了他们，也绝对不是我这篇文章的功劳。“王侯将相宁有种乎”但真正当皇帝的只有一个人，王侯将相，人也不多。目标定得高些对于喜欢挑战的人来说有好处，但对于大多数普通人来说，反而比较容易灰心沮丧，很容易就放弃了。</p><p>回过头来说，李嘉诚比你有钱大致50万倍，他比你更快乐么？或许。有没有比你快乐50万倍，一定没有。他比你最多也就快乐一两倍，甚至有可能还不如你快乐。寻找自己想要的东西不是和别人比赛，比谁要得更多更高，比谁的目标更远大。虽然成为李嘉诚这个目标很宏大，但你并不见得会从这个目标以及追求目标的过程当中获得快乐，而且基本上你也做不到。你必须听听你内心的声音，寻找真正能够使你获得快乐的东西，那才是你想要的东西。</p><p>你想要的东西，或者我们把它称之为目标，目标其实并没有高低之分，你不需要因为自己的目标没有别人远大而不好意思，达到自己的目标其实就是成功，成功有大有小，快乐却是一样的。我们追逐成功，其实追逐的是成功带来的快乐，而非成功本身。职业生涯的道路上，我们常常会被攀比的心态蒙住眼睛，忘记了追求的究竟是什么，忘记了是什么能使我们更快乐。</p><p>社会上一夜暴富的新闻很多，这些消息，总会在我们的心里面掀起很多涟漪，涟漪多了就变成惊涛骇浪，心里的惊涛骇浪除了打翻承载你目标的小船，并不会使得你也一夜暴富。“只见贼吃肉，不见贼挨揍。”我们这些普通人既没有当贼的勇气，又缺乏当贼的狠辣绝决，虽然羡慕吃肉，却更害怕挨揍，偶尔看到几个没挨揍的贼就按奈不住，或者心思活动，或者大感不公，真要叫去做贼，却也不敢。</p><p>我还是过普通人的日子，要普通人的快乐，至少，晚上睡得着觉。</p><p>五、跳槽与积累 </p><p>首先要说明，工作是一件需要理智的事情，所以不要在工作上耍个性，天涯上或许会有人觉得你很有个性而叫好，煤气公司电话公司不会因为觉得你很有个性而免了你的帐单。当你很帅地炒掉了你的老板，当你很酷地挖苦了一番招聘的HR，账单还是要照付，只是你赚钱的时间更少了，除了你自己，没人受损失。</p><p>我并不反对跳槽，但跳槽决不是解决问题的办法，而且频繁跳槽的后果是让人觉得没有忠诚度可言，而且不能安心工作。现在很多人从网上找工作，很多找工作的网站常常给人出些馊主意，要知道他们是盈利性企业，当然要从自身盈利的角度来考虑，大家越是频繁跳槽频繁找工作他们越是生意兴隆，所以鼓动人们跳槽是他们的工作。所以他们会常常告诉你，你拿的薪水少了，你享受的福利待遇差了，又是“薪情快报”又是“赞叹自由奔放的灵魂”。至于是否会因此让你不能安心，你跳了槽是否解决问题，是否更加开心，那个，他们管不着。</p><p>要跳槽肯定是有问题，一般来说问题发生了，躲是躲不开的，很多人跳槽是因为这样或者那样的不开心，如果这种不开心，在现在这个公司不能解决，那么在下一个公司多半也解决不掉。你必须相信，90%的情况下，你所在的公司并没有那么烂，你认为不错的公司也没有那么好。就像围城里说的，“城里的人拼命想冲出来，而城外的人拼命想冲进去。”每个公司都有每个公司的问题，没有问题的公司是不存在的。换个环境你都不知道会碰到什么问题，与其如此，不如就在当下把问题解决掉。很多问题当你真的想要去解决的时候，或许并没有那么难。有的时候你觉得问题无法解决，事实上，那只是“你觉得”。</p><p>人生的曲线应该是曲折向上的，偶尔会遇到低谷但大趋势总归是曲折向上的，而不是象脉冲波一样每每回到起点，我见过不少面试者，30多岁了，四五份工作经历，每次多则3年，少则1年，30多岁的时候回到起点从一个初级职位开始干起，拿基本初级的薪水，和20多岁的年轻人一起竞争，不觉得有点辛苦么？这种日子好过么？</p><p>我非常不赞成在一个行业超过3年以后换行业，基本上，35岁以前我们的生存资本靠打拼，35岁以生存的资本靠的就是积累，这种积累包括人际关系，经验，人脉，口碑……如果常常更换行业，代表几年的积累付之东流，一切从头开始，如果换了两次行业，35岁的时候大概只有5年以下的积累，而一个没有换过行业的人至少有了10年的积累，谁会占优势？工作到2-3年的时候，很多人觉得工作不顺利，好像到了一个瓶颈，心情烦闷，就想辞职，乃至换一个行业，觉得这样所有一切烦恼都可以抛开，会好很多。其实这样做只是让你从头开始，到了时候还是会发生和原来行业一样的困难，熬过去就向上跨了一大步，要知道每个人都会经历这个过程，每个人的职业生涯中都会碰到几个瓶颈，你熬过去了而别人没有熬过去你就领先了。跑长跑的人会知道，开始的时候很轻松，但是很快会有第一次的难受，但过了这一段又能跑很长一段，接下来会碰到第二次的难受，坚持过了以后又能跑一段，如此往复，难受一次比一次厉害，直到坚持不下去了。大多数人第一次就坚持不了了，一些人能坚持到第二次，第三次虽然大家都坚持不住了，可是跑到这里的人也没几个了，这点资本足够你安稳活这一辈子了。</p><p>一份工作到两三年的时候，大部分人都会变成熟手，这个时候往往会陷入不断的重复，有很多人会觉得厌倦，有些人会觉得自己已经搞懂了一切，从而懒得去寻求进步了。很多时候的跳槽是因为觉得失去兴趣了，觉得自己已经完成比赛了。其实这个时候比赛才刚刚开始，工作两三年的人，无论是客户关系，人脉，手下，和领导的关系，在业内的名气……还都是远远不够的，但稍有成绩的人总是会自我感觉良好的，每个人都觉得自己跟客户关系铁得要命，觉得自己在业界的口碑好得很。其实可以肯定地说，一定不是，这个时候，还是要拿出前两年的干劲来，稳扎稳打，积累才刚刚开始。</p><p>你足够了解你的客户吗？你知道他最大的烦恼是什么吗？你足够了解你的老板么？你知道他最大的烦恼是什么吗？你足够了解你的手下么？你知道他最大的烦恼是什么吗？如果你不知道，你凭什么觉得自己已经积累够了？如果你都不了解，你怎么能让他们帮你的忙，做你想让他们做的事情？如果他们不做你想让他们做的事情，你又何来的成功？</p><p>六、等待</p><p>这是个浮躁的人们最不喜欢的话题，本来不想说这个话题，因为会引起太多的争论，而我又无意和人争论这些，但是考虑到对于职业生涯的长久规划，这是一个躲避不了的话题，还是决定写一写，不爱看的请离开吧。</p><p>并不是每次穿红灯都会被汽车撞，并不是每个罪犯都会被抓到，并不是每个错误都会被惩罚，并不是每个贪官都会被枪毙，并不是你的每一份努力都会得到回报，并不是你的每一次坚持都会有人看到，并不是你每一点付出都能得到公正的回报，并不是你的每一个善意都能被理解……这个，就是世道。好吧，世道不够好，可是，你有推翻世道的勇气么？如果没有，你有更好的解决办法么？有很多时候，人需要一点耐心，一点信心。每个人总会轮到几次不公平的事情，而通常，安心等待是最好的办法。</p><p>有很多时候我们需要等待，需要耐得住寂寞，等待属于你的那一刻。周润发等待过，刘德华等待过，周星驰等待过，王菲等待过，张艺谋也等待过……看到了他们如今的功成名就的人，你可曾看到当初他们的等待和耐心？你可曾看到金马奖影帝在街边摆地摊？你可曾看到德云社一群人在剧场里给一位观众说相声？你可曾看到周星驰的角色甚至连一句台词都没有？每一个成功者都有一段低沉苦闷的日子，我几乎能想象得出来他们借酒浇愁的样子，我也能想象得出他们为了生存而挣扎的窘迫。在他们一生最中灿烂美好的日子里，他们渴望成功，但却两手空空，一如现在的你。没有人保证他们将来一定会成功，而他们的选择是耐住寂寞。如果当时的他们总念叨着“成功只是属于特权阶级的”，你觉得他们今天会怎样？</p><p>曾经我也不明白有些人为什么并不比我有能力却要坐在我的头上，年纪比我大就一定要当我的领导么？为什么有些烂人不需要努力就能赚钱？为什么刚刚改革开放的时候的人能那么容易赚钱，而轮到我们的时候，什么事情都要正规化了？有一天我突然想，我还在上学的时候他们就在社会里挣扎奋斗了，他们在社会上奋斗积累了十几二十年，我们新人来了，他们有的我都想要，我这不是在要公平，我这是在要抢劫。因为我要得太急，因为我忍不住寂寞。二十多岁的男人，没有钱，没有事业，却有蓬勃的欲望。</p><p>人总是会遇到挫折的，人总是会有低潮的，人总是会有不被人理解的时候的，人总是有要低声下气的时候，这些时候恰恰是人生最关键的时候，因为大家都会碰到挫折，而大多数人过不了这个门槛，你能过，你就成功了。在这样的时刻，我们需要耐心等待，满怀信心地去等待，相信，生活不会放弃你，机会总会来的。至少，你还年轻，你没有坐牢，没有生治不了的病，没有欠还不起的债。比你不幸的人远远多过比你幸运的人，你还怕什么？路要一步步走，虽然到达终点的那一步很激动人心，但大部分的脚步是平凡甚至枯燥的，但没有这些脚步，或者耐不住这些平凡枯燥，你终归是无法迎来最后的那些激动人心。</p><p>逆境，是上帝帮你淘汰竞争者的地方。要知道，你不好受，别人也不好受，你坚持不下去了，别人也一样，千万不要告诉别人你坚持不住了，那只能让别人获得坚持的信心，让竞争者看着你微笑的面孔，失去信心，退出比赛。胜利属于那些有耐心的人。</p><p>在最绝望的时候，我会去看电影《The Pursuit of Happyness》《JerryMaguire》，让自己重新鼓起勇气，因为，无论什么时候，我们总还是有希望。当所有的人离开的时候，我不失去希望，我不放弃。每天下班坐在车里，我喜欢哼着《隐形的翅膀》看着窗外，我知道，我在静静等待，等待属于我的那一刻。</p><p>原贴里伊吉网友的话我很喜欢，抄录在这里：</p><p>每个人都希望，自己是独一无二的特殊者</p><p>含着金匙出生、投胎到好家庭、工作安排到电力局拿1w月薪这样的小概率事件，当然最好轮到自己</p><p>红军长征两万五、打成右派反革命、胼手胝足牺牲尊严去奋斗，最好留给祖辈父辈和别人</p><p>自然，不是每个吃过苦的人都会得到回报</p><p>但是，任何时代，每一个既得利益者身后，都有他的祖辈父辈奋斗挣扎乃至流血付出生命的身影</p><p>羡慕别人有个好爸爸，没什么不可以</p><p>问题是，你的下一代，会有一个好爸爸吗？</p><p>至于问到为什么不能有同样的赢面概率？我只能问：为什么物种竞争中，人和猴子不能有同样的赢面概率？</p><p>物竞天择。猴子的灵魂不一定比你卑微，但你身后有几十万年的类人猿进化积淀。</p><p>七、入对行跟对人</p><p>在中国，大概很少有人是一份职业做到底的，虽然如此，第一份工作还是有些需要注意的地方，有两件事情格外重要，第一件是入行，第二件事情是跟人。第一份工作对人最大的影响就是入行，现代的职业分工已经很细，我们基本上只能在一个行业里成为专家，不可能在多个行业里成为专家。很多案例也证明即使一个人在一个行业非常成功，到另外一个行业，往往完全不是那么回事情，“你想改变世界，还是想卖一辈子汽水？”是乔布斯邀请百事可乐总裁约翰·斯考利加盟苹果时所说的话，结果这位在百事非常成功的约翰，到了苹果表现平平。其实没有哪个行业特别好，也没有哪个行业特别差，或许有报道说哪个行业的平均薪资比较高，但是他们没说的是，那个行业的平均压力也比较大。看上去很美的行业一旦进入才发现很多地方其实并不那么完美，只是外人看不见。</p><p>说实话，我自己都没有发大财，所以我的建议只是让人快乐工作的建议，不是如何发大财的建议，我们只讨论一般普通打工者的情况。我认为选择什么行业并没有太大关系，看问题不能只看眼前。比如，从前年开始，国家开始整顿医疗行业，很多医药公司开不下去，很多医药行业的销售开始转行。其实医药行业的不景气是针对所有公司的，并非针对一家公司，大家的日子都不好过，这个时候跑掉是非常不划算的，大多数正规的医药公司即使不做新生意撑个两三年总是能撑的，大多数医药销售靠工资撑个两三年也是可以撑的，国家不可能永远捏着医药行业不放的，两三年以后光景总归还会好起来的，那个时候别人都跑了而你没跑，那时的日子应该会好过很多。有的时候觉得自己这个行业不行了，问题是，再不行的行业，做得人少了也变成了好行业，当大家都觉得不好的时候，往往却是最好的时候。大家都觉得金融行业好，金融行业门槛高不说，有多少人削尖脑袋要钻进去，竞争激励，进去以后还要时时提防，一个疏忽，就被后来的人给挤掉了，压力巨大，又如何谈得上快乐？也就未必是“好”工作了。</p><p>太阳能这个东西至今还不能进入实际应用的阶段，但是中国已经有7家和太阳能有关的公司在纽交所上市了，国美苏宁永乐其实是贸易型企业，也能上市，鲁泰纺织连续10年利润增长超过50%，卖茶的一茶一座，卖衣服的海澜之家都能上市……其实选什么行业真的不重要，关键是怎么做。事情都是人做出来的，关键是人。</p><p>有一点是需要记住的，这个世界上，有史以来直到我们能够预见得到的未来，成功的人总是少数，有钱的人总是少数，大多数人是一般的，普通的，不太成功的。因此，大多数人的做法和看法，往往都不是距离成功最近的做法和看法。因此大多数人说好的东西不见得好，大多数人说不好的东西不见得不好。大多数人都去炒股的时候说明跌只是时间问题，大家越是热情高涨的时候，跌的日子越近。大多数人买房子的时候，房价不会涨，而房价涨的差不多的时候，大多数人才开始买房子。不会有这样一件事情让大家都变成功，发了财，历史上不曾有过，将来也不会发生。有些东西即使一时运气好得到了，还是会在别的时候别的地方失去的。</p><p>年轻人在职业生涯的刚开始，尤其要注意的是，要做对的事情，不要让自己今后几十年的人生总是提心吊胆，更不值得为了一份工作赔上自己的青春年华。我的公司是个不行贿的公司，以前很多人不理解，甚至自己的员工也不理解，不过如今，我们是同行中最大的企业，客户乐意和我们打交道，尤其是在国家打击腐败的时候，每个人都知道我们做生意不给钱的名声，都敢于和我们做生意。而勇于给钱的公司，不是倒了，就是跑了，要不就是每天睡不好觉，人还是要看长远一点。很多时候，看起来最近的路，其实是最远的路，看起来最远的路，其实是最近的路。</p><p>跟对人是说，入行后要跟个好领导好老师，刚进社会的人做事情往往没有经验，需要有人言传身教。对于一个人的发展来说，一个好领导是非常重要的。所谓“好”的标准，不是他让你少干活多拿钱，而是以下三个。</p><p>首先，好领导要有宽广的心胸，如果一个领导每天都会发脾气，那几乎可以肯定他不是个心胸宽广的人，能发脾气的时候却不发脾气的领导，多半是非常厉害的领导。中国人当领导最大的毛病是容忍不了能力比自己强的人，所以常常可以看到的一个现象是，领导很有能力，手下一群庸才或者手下一群闲人。如果看到这样的环境，还是不要去的好。</p><p>其次，领导要愿意从下属的角度来思考问题，这一点其实是从面试的时候就能发现的，如果这位领导总是从自己的角度来考虑问题，几乎不听你说什么，这就危险了。从下属的角度来考虑问题并不代表同意下属的说法，但他必须了解下属的立场，下属为什么要这么想，然后他才有办法说服你，只关心自己怎么想的领导往往难以获得下属的信服。</p><p>第三，领导敢于承担责任，如果出了问题就把责任往下推，有了功劳就往自己身上揽，这样的领导不跟也罢。选择领导，要选择关键时刻能抗得住的领导，能够为下属的错误买单的领导，因为这是他作为领导的责任。</p><p>有可能，你碰不到好领导，因为，中国的领导往往是屁股决定脑袋的领导，因为他坐领导的位置，所以他的话就比较有道理，这是传统观念官本位的误区，可能有大量的这种无知无能的领导，只是，这对于你其实是好事，如果将来有一天你要超过他，你希望他比较聪明还是比较笨？相对来说这样的领导其实不难搞定，只是你要把自己的身段放下来而已。多认识一些人，多和比自己强的人打交道，同样能找到好的老师，不要和一群同样郁闷的人一起控诉社会，控诉老板，这帮不上你，只会让你更消极。和那些比你强的人打交道，看他们是怎么想的，怎么做的，学习他们，然后跟更强的人打交道。</p><p>八、选择</p><p>我们每天做的最多的事情，其实是选择，因此在谈职业生涯的时候不得不提到这个话题。</p><p>我始终认为，在很大的范围内，我们究竟会成为一个什么样的人，决定权在我们自己，每天我们都在做各种各样的选择，我可以不去写这篇文章，去别人的帖子拍拍砖头，也可以写下这些文字，帮助别人的同时也整理自己的思路，我可以多注意下格式让别人易于阅读，也可以写成一堆，我可以就这样发上来，也可以在发以前再看几遍，你可以选择不刮胡子就去面试，也可以选择出门前照照镜子……每天，每一刻我们都在做这样那样的决定，我们可以漫不经心，也可以多花些心思，成千上万的小选择累计起来，就决定了最终我们是个什么样的人。</p><p>从某种意义上来说我们的未来不是别人给的，是我们自己选择的，很多人会说我命苦啊，没得选择阿，如果你认为“去微软还是去IBM”“上清华还是上北大”“当销售副总还是当厂长”这种才叫选择的话，的确你没有什么选择，大多数人都没有什么选择。但每天你都可以选择是否为客户服务更周到一些，是否对同事更耐心一些，是否把工作做得更细致一些，是否把情况了解得更清楚一些，是否把不清楚的问题再弄清楚一些……你也可以选择在是否在痛苦中继续坚持，是否抛弃掉自己的那些负面的想法，是否原谅一个人的错误，是否相信我在这里写下的这些话，是否不要再犯同样的错误……生活每天都在给你选择的机会，每天都在给你改变自己人生的机会，你可以选择赖在地上撒泼打滚，也可以选择咬牙站起来。你永远都有选择。有些选择不是立杆见影的，需要累积，比如农民可以选择自己常常去浇地，也可以选择让老天去浇地，诚然你今天浇水下去苗不见得今天马上就长出来，但常常浇水，大部分苗终究会长出来的，如果你不浇，收成一定很糟糕。</p><p>每天生活都在给你机会，他不会给你一叠现金也不会拱手送你个好工作，但实际上，他还是在给你机会。我的家庭是一个普通的家庭，没有任何了不起的社会关系，我的父亲在大学毕业以后就被分配到了边疆，那个小县城只有一条马路，他们那一代人其实比我们更有理由抱怨，他们什么也没得到，年轻的时候那<em>个_ 年</em>代，书都没得读，支援边疆插队落户，等到老了，却要给年轻人机会了。他有足够的理由象成千上万那样的青年一样坐在那里抱怨生不逢时，怨气冲天。然而在分配到边疆的十年之后，国家恢复招研究生，他考回了原来的学校。研究生毕业，他被分配到了安徽一家小单位里，又是3年以后，国家第一届招收博士生，他又考回了原来的学校，成为中国第一代博士，那时的他比现在的我年纪还大。生活并没有放弃他，他也没有放弃生活。10年的等待，他做了他自己的选择，他没有放弃，他没有破罐子破摔，所以时机到来的时候，他改变了自己的人生。你最终会成为什么样的人，就决定在你的每个小小的选择之间。</p><p>你选择相信什么？你选择和谁交朋友？你选择做什么？你选择怎么做？……我们面临太多的选择，而这些选择当中，意识形态层面的选择又远比客观条件的选择来得重要得多，比如选择做什么产品其实并不那么重要，而选择怎么做才重要。选择用什么人并不重要，而选择怎么带这些人才重要。大多数时候选择客观条件并不要紧，大多数关于客观条件的选择并没有对错之分，要紧的是选择怎么做。一个大学生毕业了，他要去微软也好，他要卖猪肉也好，他要创业也好，他要做游戏代练也好，只要不犯法，不害人，都没有什么关系，要紧的是，选择了以后，怎么把事情做好。</p><p>除了这些，你还可以选择时间和环境，比如，你可以选择把这辈子最大的困难放在最有体力最有精力的时候，也可以走一步看一步，等到了40岁再说，只是到了40多岁，那正是一辈子最脆弱的时候，上有老下有小，如果在那个时候碰上了职业危机，实在是一件很苦恼的事情。与其如此不如在20多岁30多岁的时候吃点苦，好让自己脆弱的时候活得从容一些。你可以选择在温室里成长，也可以选择到野外磨砺，你可以选择在办公室吹冷气的工作，也可以选择40度的酷热下，去见你的客户，只是，这一切最终会累积起来，引导你到你应得的未来。</p><p>我不敢说所有的事情你都有得选择，但是绝大部分事情你有选择，只是往往你不把这当作一种选择。认真对待每一次选择，才会有比较好的未来。</p><p>九、选择职业 </p><p>职业的选择，总的来说，无非就是销售、市场、客服、物流、行政、人事、财务、技术、管理几个大类，有个有趣的现象就是，500强的CEO当中最多的是销售出身，第二多的人是财务出身，这两者加起来大概超过95％。现代IT行业也有技术出身成为老板的，但实际上，后来他们还是从事了很多销售和市场的工作，并且表现出色，公司才获得了成功，完全靠技术能力成为公司老板的，几乎没有。这是有原因的，因为销售就是一门跟人打交道的学问，而管理其实也是跟人打交道的学问，这两者之中有很多相通的东西，他们的共同目标就是“让别人去做某件特定的事情。”而财务则是从数字的层面了解生意的本质，从宏观上看待生意的本质，对于一个生意是否挣钱，是否可以正常运作有着最深刻的认识。</p><p>公司小的时候是销售主导公司，而公司大的时候是财务主导公司，销售的局限性在于只看人情不看数字，财务的局限性在于只看数字不看人情。公司初期，运营成本低，有订单就活得下去，跟客户也没有什么谈判的条件，别人肯给生意做已经谢天谢地了，这个时候订单压倒一切，客户的要求压倒一切，所以当然要顾人情。公司大了以后，一切都要规范化，免得因为不规范引起一些不必要的风险，同时运营成本也变高，必须提高利润率，把有限的资金放到最有产出的地方。对于上市公司来说，股东才不管你客户是不是最近出国，最近是不是那个省又在搞严打，到了时候就要把业绩拿出来，拿不出来就抛股票，这个时候就是数字压倒一切。</p><p>前两天听到有人说一句话觉得很有道理，开始的时候我们想“能做什么？”，等到公司做大了有规模了，我们想“不能做什么。”很多人在工作中觉得为什么领导这么保守，这也不行那也不行，错过很多机会。很多时候是因为，你还年轻，你想的是“能做什么”，而作为公司领导要考虑的方面很多，他比较关心“不能做什么”。</p><p>我并非鼓吹大家都去做销售或者财务，究竟选择什么样的职业，和你究竟要选择什么样的人生有关系，有些人就喜欢下班按时回家，看看书听听音乐，那也挺好，但就不适合找个销售的工作了，否则会是折磨自己。有些人就喜欢出风头，喜欢成为一群人的中心，如果选择做财务工作，大概也干不久，因为一般老板不喜欢财务太积极，也不喜欢财务话太多。先想好自己要过怎样的人生，再决定要找什么样的职业。有很多的不快乐，其实是源自不满足，而不满足，很多时候是源自于心不定，而心不定则是因为不清楚究竟自己要什么，不清楚要什么的结果就是什么都想要，结果什么都没得到。</p><p>我想，我们还是因为生活而工作，不是因为工作而生活，生活是最要紧的，工作只是生活中的一部分。我总是觉得生活的各方方面都是相互影响的，如果生活本身一团乱麻，工作也不会顺利。所以要有娱乐、要有社交、要锻炼身体，要有和睦的家庭……最要紧的，要开心，我的两个销售找我聊天，一肚子苦水，我问他们， 2年以前，你什么都没有，工资不高，没有客户关系，没有业绩，处于被开的边缘，现在的你比那时条件好了很多，为什么现在却更加不开心了？如果你做得越好越不开心，那你为什么还要工作？首先的首先，人还是要让自己高兴起来，让自己心态好起来，这种发自内心的改变会让你更有耐心，更有信心，更有气质，更能包容……否则，看看镜子里的你，你满意么？</p><p>有人会说，你说得容易，我每天加班，不加班老板就会把我炒掉，每天累得要死，哪有时间娱乐、社交、锻炼？那是人们把目标设定太高的缘故，如果你还在动不动就会被老板炒掉的边缘，那么你当然不能设立太高的目标，难道你还想每天去打高尔夫？你没时间去健身房锻炼身体，但是上下班的时候多走几步可以吧，有楼梯的时候走走楼梯不走电梯可以吧？办公的间隙扭扭脖子拉拉肩膀做做fu<strong>wo</strong>撑可以吧？谁规定锻炼就一定要拿出每天2个小时去健身房？你没时间社交，每月参加郊游一次可以吧，周末去参加个什么音乐班，绘画班之类的可以吧，去尝试认识一些同行，和他们找机会交流交流可以吧？开始的时候总是有些难的，但迈出这一步就会向良性循环的方向发展。而每天工作得很苦闷，剩下的时间用来咀嚼苦闷，只会陷入恶性循环，让生活更加糟糕。</p><p>虽然离开惠普仅有十五天，但感觉上惠普已经离我很远。我的心思更多放在规划自己第二阶段的人生，这并非代表我对惠普没有任何眷恋，主要还是想以此驱动自己往前走。</p><p>万科王石登珠穆朗玛峰的体验给我很多启发，虽然在出发时携带大量的物资，但是登顶的过程中，必须不断减轻负荷，最终只有一个氧气瓶和他登上峰顶。登山如此，漫长的人生又何尝不是。</p><p>我宣布退休后，接到同事朋友同学的祝贺。大部分人都认为我能够在这样的职位上及年龄选择退休，是一种勇气，也是一种福气。</p><p>还有一部分人怀疑我只是借此机会换个工作，当然还有一些人说我在HP做不下去了，趁此机会离开。</p><p>我多年来已经习惯别人对我的说三道四，但对于好友，我还是挺关心大家是否真正理解我的想法，这也是写这篇文章的目的。</p><p>由于受我父亲早逝的影响，我很早就下定决心，要在有生之年实现自己的愿望，我不要像我父亲一样，为家庭生活忙碌一辈子，临终前感伤，懊恼自己有很多没有实现的理想。</p><p>一本杂志的文章提到我们在生前就应该思考自己的墓志铭，因为那代表你自己对完美人生的定义，我们应该尽可能在有生之年去实现它。</p><p>我希望我的墓志铭上除了与家人及好友有关的内容外，是这样写着：</p><p>1.这个人曾经服务于一家全球最大的IT公司（HP）25年，和她一起经历过数次重大的变革，看着她从以电子仪表为主要的业务变革成全球最大的IT公司。</p><p>2.这个人曾经在全球发展最快的国家（中国）工作16年，并担任HP中国区总裁7年，见证及经历过中国改革开放的关键最新突破阶段，与中国一起成长。</p><p>3.这个人热爱飞行，曾经是一个有执照的飞行员，累积飞行时数超过X小时，曾经在X个机场起降过。</p><p>4.这个人曾经获得管理硕士学位，在领导管理上特别关注中国企业的组织行为及绩效，并且在这个领域上获得中国企业界的认可。</p><p>我费时25年才总结1和2两项成果，我不知还要费时多久才能达成3和4的愿望，特别是第4个愿望需要经历学术的训练，才能将我的经验总结成知识。</p><p>否则我的经验将无法有效影响及传授他人。因此重新进入学校学习，拿一个管理学位是有必要的，更何况这是我一个非常重要的愿望。</p><p>另一方面，我25年的时间都花在运营(operation)的领域，兢兢业业的做好职业人士的工作，它是一份好工作，特别是在HP，这份工作也帮助我建立财务的基础，支持家庭的发展。</p><p>但是我不想终其一生，都陷入在运营的领域，我想象企业家一样，有机会靠一些点子(ideas)赚钱，虽然风险很高，但是值得一试，即使失败，也不枉走一回，这也是第4个愿望其中的一部份。</p><p>Carly Fiorina曾经对我说过“这个世界上有好想法的人很多，但有能力去实现的人很少”，2007年5月21日在北大演讲时，有人问起那些书对我影响较大，我想对我人生观有影响的其中一本书叫“TriggerPoint”，它的主要观点是：人生最需要的不是规划，而是在适当的时机掌握机会，采取行动。</p><p>我这些愿望在我心中已经酝酿一段很长的时间，开始的时候，也许一年想个一两次，过了也就忘掉，但逐渐的，这个心中的声音，愈来愈大，出现的频率也愈来愈高，当它几乎每一个星期都会来与我对话时，我知道时机已经成熟。</p><p>但和任何人一样，要丢掉自己现在所拥有的，所熟悉的环境及稳定的收入，转到一条自己未曾经历过，存在未知风险的道路，需要绝大的勇气，家人的支持和好友的鼓励。有舍才有得，真是知易行难，我很高兴自己终于跨出了第一步。</p><p>我要感谢HP的EER提前退休优惠政策，它是其中一个关键的TriggerPoints,另一个关键因素是在去年五六月发生的事。</p><p>当时我家老大从大学毕业，老二从高中毕业，在他们继续工作及求学前，这是一个黄金时段，让我们全家可以相聚一段较长的时间，我为此很早就计划休一个长假，带着他们到各地游玩。</p><p>但这个计划因为工作上一件重要的事情（Mark Hurd访华）不得不取消。这个事件刺激了我必须严肃的去对待那心中的声音，我会不会继续不断的错失很多关键的机会?</p><p>我已经年过50，我会不会走向和我父亲一样的道路？人事部老总Charles跟我说，很多人在所有对他有利的星星都排成一列时，还是错失时机。</p><p>我知道原因，因为割舍及改变对人是多么的困难，我相信大部分的人都有自己人生的理想，但我也相信很多人最终只是把这些理想当成是幻想，然后不断的为自己寻找不能实现的藉口，南非前总统曼德拉曾经说过，“与改变世界相比，改变自己更困难”，真是一针见血。</p><p>什么是快乐及有意义的人生？我相信每一个人的定义都不一样，对我来说，能实现我墓志铭上的内容就是我的定义。</p><p>在中国惠普总裁的位置上固然可以吸引很多的关注及眼球，但是我太太及较亲近的好友，都知道那不是我追求的，那只是为扮演好这个角色必须尽力做好的地方。</p><p>做一个没有名片的人士，虽然只有十多天的时间，但我发现我的脑袋里已经空出很多空间及能量，让我可以静心的为我ChapterII的新生活做细致的调研及规划。</p><p>我预订以两年的时间来完成转轨的准备工作，并且花多点时间与家人共处。这两年的时间我希望拿到飞行执照，拿到管理有关的硕士学位，提升英文的水平，建立新的网络，多认识不同行业的人，保持与大陆的联系。希望两年后，我可以顺利回到大陆去实现我第四个愿望。</p><p>毫不意外，在生活上，我发现很多需要调整的地方。</p><p>二十多年来，我生活的步调及节奏，几乎完全被公司及工作所左右，不断涌出的deadline及任务驱动我每天的安排，一旦离开这样的环境，第一个需要调整的就是要依靠自己的自律及意志力来驱动每天的活动，睡觉睡到自然醒的态度绝对不正确，放松自己，不给事情设定目标及时间表，或者对错失时间目标无所谓，也不正确，没有年度，季度，月及周计划也不正确。</p><p>担任高层经理多年，已经养成交待事情的习惯，自己的时间主要花在思考，决 策及追踪项目的进展情况，更多是依靠一个庞大的团队来执行具体的事项及秘书来处理很多协调及繁琐的事情。</p><p>到美国后，很多事情需要打800号电话联系，但这些电话很忙，常让你在waitingline上等待很长的时间，当我在等待时，我可以体会以前秘书工作辛苦的地方，但同时也提醒我自己，在这个阶段要改变态度，培养更大的耐性及自己动手做的能力。</p><p>生活的内容也要做出很大的调整，多出时间锻炼身体，多出时间关注家人，多出时间关注朋友，多出时间体验不同的休闲活动及飞行，一步步的，希望生活逐步调整到我所期望的轨道上，期待这两年的生活既充实又充满乐趣及意义。</p><p>第一个快乐的体验就是准备及参加大儿子的订婚礼，那种全心投入，不需担忧工作数字的感觉真好。同时我也租好了公寓，买好了家具及车子，陪家人在周末的时候到Reno及Lake Tahoe玩了一趟，LakeTahoe我去了多次，但这次的体验有所不同，我从心里欣赏到它的美丽。</p><p>但同时我也在加紧调研的工作，为申请大学及飞行学校做准备，这段时间也和在硅谷的朋友及一些风险投资公司见面，了解不同的产业。</p><p>我的人生观是“完美的演出来自充分的准备”，“勇于改变自己，适应不断变化的环境，机会将不断出现”，“快乐及有意义的人生来自于实现自己心中的愿望，而非外在的掌声”。</p><p>我离开时，有两位好朋友送给我两个不同的祝语，Baron的是“多年功过化烟尘”，杨华的是“莫春者，风乎舞雩，咏而归”，它们分别代表了我离开惠普及走向未来的心情。</p><p>我总结人生有三个阶段，一个阶段是为现实找一份工作，一个阶段是为现实，但可以选择一份自己愿意投入的工作，一个阶段是为理想去做一些事情。</p><p>我珍惜我的福气，感激HP及同事、好朋友给我的支持，鼓励及协助，这篇文字化我心声的文章与好友分享。</p>]]></content>
      
      
      <categories>
          
          <category> 人生感悟 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人生感悟 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PromQL全解析</title>
      <link href="/2023/11/09/kubernetes/promql/"/>
      <url>/2023/11/09/kubernetes/promql/</url>
      
        <content type="html"><![CDATA[<p>PromQL（Prometheus Query Language）为Prometheus tsdb的查询语言。是结合grafana进行数据展示和告警规则的配置的关键部分。<br>本文默认您已了解Prometheus的四种指标类型：</p><ul><li>counter（计数器）</li><li>gauge （仪表类型）</li><li>histogram（直方图类型）</li><li>summary （摘要类型）<br>便于读者实践，本文大部分样本数据target：</li><li>Prometheus</li><li>node_exporter</li></ul><h2 id="表达式数据类型"><a href="#表达式数据类型" class="headerlink" title="表达式数据类型"></a>表达式数据类型</h2><p>PromQL查询语句即表达式，实现的四种数据类型：</p><h3 id="Instant-vector"><a href="#Instant-vector" class="headerlink" title="Instant vector"></a>Instant vector</h3><p>Instance vector（瞬时向量）表示一个时间序列的集合，但是每个时序只有最近的一个点，而不是线。<br><img src="/image-132.png" alt="Alt text"></p><h3 id="Range-vector"><a href="#Range-vector" class="headerlink" title="Range vector"></a>Range vector</h3><p>Range vector（范围向量）表示一段时间范围里的时序，每个时序可包含多个点<br><img src="/image-133.png" alt="Alt text"><br>sources：<a href="https://satyanash.net/software/2021/01/04/understanding-prometheus-range-vectors.html">Understanding Prometheus Range Vectors</a></p><h3 id="Scalar"><a href="#Scalar" class="headerlink" title="Scalar"></a>Scalar</h3><p>Scalar（标量）通常为数值，可以将只有一个时序的Instance vector转换成Scalar。</p><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>简单字符串值，目前未被使用。</p><h2 id="选择器"><a href="#选择器" class="headerlink" title="选择器"></a>选择器</h2><h3 id="标签选择器"><a href="#标签选择器" class="headerlink" title="标签选择器"></a>标签选择器</h3><p>查询Prometheus http状态码为400的请求数量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=&quot;400&quot;&#125;</span><br></pre></td></tr></table></figure><p>标签匹配运算符:</p><ul><li>&#x3D; ：与字符串匹配</li><li>!&#x3D; ：与字符串不匹配</li><li>&#x3D;~ ：与正则匹配</li><li>!~ ：与正则不匹配</li></ul><p>查询Prometheus http状态码为4xx或5xx并且handler为&#x2F;api&#x2F;v1&#x2F;query的请求数量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=~&quot;4.*|5.*&quot;,handler=&quot;/api/v1/query&quot;&#125;</span><br></pre></td></tr></table></figure><p>内部标签__name__用来匹配指标名称，下面的表达式与上一条等价</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;code=~&quot;4.*|5.*&quot;,handler=&quot;/api/v1/query&quot;,__name__=&quot;prometheus_http_requests_total&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="范围选择器"><a href="#范围选择器" class="headerlink" title="范围选择器"></a>范围选择器</h3><p>查询过去5分钟Prometheus健康检查的采样记录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;,handler=&quot;/-/healthy&quot;&#125;[5m]</span><br></pre></td></tr></table></figure><p>单位：ms、s、m、h、d、w、y</p><p>时间串联：[1h5m]一小时5分钟</p><h2 id="时间偏移"><a href="#时间偏移" class="headerlink" title="时间偏移"></a>时间偏移</h2><h3 id="通过offset"><a href="#通过offset" class="headerlink" title="通过offset"></a>通过offset</h3><p>通过offset将时间倒退5分钟，即查询5分钟之前的数据。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125; offset 5m </span><br></pre></td></tr></table></figure><p>同样支持查询range vector</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125;[3m] offset 5m</span><br></pre></td></tr></table></figure><h3 id="修饰符"><a href="#修饰符" class="headerlink" title="@修饰符"></a>@修饰符</h3><p>还可以通过@ 直接跳转到某个uinx时间戳，需开启启动参数–enable-feature&#x3D;promql-at-modifier</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125; @ 1646089826</span><br></pre></td></tr></table></figure><h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><p>Prometheus中的运算符与各类编程语言中的基本一致。</p><h3 id="数学运算符"><a href="#数学运算符" class="headerlink" title="数学运算符"></a>数学运算符</h3><p>Prometheus 中存在以下数学运算符：</p><ul><li>+（加法）</li><li>-（减法）</li><li>*（乘法）</li><li>&#x2F;（除法）</li><li>%（取模）</li><li>^（幂）<br>两个标量之间的计算<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10/3</span><br></pre></td></tr></table></figure>瞬时向量与标量计算，由于计算后值意义与原指标名有差异，Prometheus很贴心的帮我们移除了指标名称。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_http_response_size_bytes_sum / 1024</span><br></pre></td></tr></table></figure>两个瞬时向量间的计算，如下计算node的内存使用率<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(</span><br><span class="line">1 -</span><br><span class="line">node_memory_MemAvailable_bytes&#123;job=&quot;node&quot;,instance=&quot;localhost:9100&quot;&#125; </span><br><span class="line">/ node_memory_MemTotal_bytes&#123;job=&quot;node&quot;,instance=&quot;localhost:9100&quot;&#125;</span><br><span class="line">)</span><br><span class="line">* 100</span><br></pre></td></tr></table></figure>如果两个瞬时向量标签不一致可通过ignoring忽略多余标签<br>输入示例：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  24</span><br><span class="line">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6</span><br><span class="line"></span><br><span class="line">method:http_requests:rate5m&#123;method=&quot;get&quot;&#125;  600</span><br><span class="line">method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120</span><br></pre></td></tr></table></figure>查询示例：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">method_code:http_errors:rate5m&#123;code=&quot;500&quot;&#125; / ignoring(code) method:http_requests:rate5m</span><br></pre></td></tr></table></figure>结果示例：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;method=&quot;get&quot;&#125;  0.04            //  24 / 600</span><br><span class="line">&#123;method=&quot;post&quot;&#125; 0.05            //   6 / 120</span><br></pre></td></tr></table></figure>如果两个瞬时向量数量不一致时可通过group_left、group_right指定以那一侧为准<br>输入示例：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  24</span><br><span class="line">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125;  30</span><br><span class="line">method_code:http_errors:rate5m&#123;method=&quot;put&quot;, code=&quot;501&quot;&#125;  3</span><br><span class="line">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6</span><br><span class="line">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 21</span><br><span class="line"></span><br><span class="line">method:http_requests:rate5m&#123;method=&quot;get&quot;&#125;  600</span><br><span class="line">method:http_requests:rate5m&#123;method=&quot;del&quot;&#125;  34</span><br><span class="line">method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120</span><br></pre></td></tr></table></figure>查询示例：</li></ul><p>group_left以左侧为准</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m</span><br></pre></td></tr></table></figure><p>结果示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  0.04            //  24 / 600</span><br><span class="line">&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125;  0.05            //  30 / 600</span><br><span class="line">&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 0.05            //   6 / 120</span><br><span class="line">&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 0.175           //  21 / 120</span><br></pre></td></tr></table></figure><h3 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h3><p>Prometheus 中存在以下比较运算符：</p><ul><li>&#x3D;&#x3D;（相等）</li><li>!&#x3D;（不相等）</li><li>&gt;（大于）</li><li>&lt;（小于）</li><li>&gt;&#x3D;（大于或等于）</li><li>&lt;&#x3D;（小于或等于）</li></ul><p>两个标量之间比较，在运算符后跟bool修饰，结果0( false) 或1 ( true)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10 &lt; bool 5</span><br></pre></td></tr></table></figure><p><img src="/image-134.png" alt="Alt text"><br>瞬时向量与标量比较，查询node状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up&#123;job=&quot;node&quot;&#125; ==  bool 1</span><br></pre></td></tr></table></figure><p>两个瞬时向量比较，查看消息队列容量状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus_notifications_queue_length &lt; bool prometheus_notifications_queue_capacity</span><br></pre></td></tr></table></figure><p><img src="/image-135.png" alt="Alt text"></p><h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><p>Prometheus 中存在以下逻辑运算符：</p><ul><li>and（与）</li><li>or（或）</li><li>unless（非）</li></ul><p>逻辑运算仅适用于向量</p><p>如下我们有4个target，进行相应的逻辑运算，实现和标签选择相似效果。<br><img src="/image-136.png" alt="Alt text"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up&#123;instance!=&quot;192.168.1.123:9091&quot;&#125; and up&#123;job!=&quot;alertmanager&quot;&#125;</span><br></pre></td></tr></table></figure><p><img src="/image-137.png" alt="Alt text"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up&#123;instance=&quot;192.168.1.123:9091&quot;&#125; or up&#123;job=&quot;alertmanager&quot;&#125; </span><br></pre></td></tr></table></figure><p><img src="/image-138.png" alt="Alt text"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up unless up&#123;job=&quot;alertmanager&quot;&#125; </span><br></pre></td></tr></table></figure><p><img src="/image-139.png" alt="Alt text"><br>Prometheus 中二元运算符的优先级，从高到低。</p><ol><li>^</li><li>*, &#x2F;, %,atan2</li><li>+,-</li><li>&#x3D;&#x3D;, !&#x3D;, &lt;&#x3D;, &lt;, &gt;&#x3D;,&gt;</li><li>and,unless</li><li>or</li></ol><p>相同优先级的运算符是左结合的<br>相同优先级的运算符（+ 和 -）是左结合的。这意味着在表达式中，加法和减法运算将按照从左到右的顺序进行。</p><p>例如，考虑以下PromQL表达式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a + b - c</span><br></pre></td></tr></table></figure><p>在这个表达式中，加法运算符（+）和减法运算符（-）具有相同的优先级。根据左结合的规则，这个表达式将首先执行加法运算，然后再执行减法运算。换句话说，计算顺序将是先计算”a + b”，然后将结果与”c”相减。</p><p>PromQL中的atan2函数用于计算两个数值的反正切值。它接受两个参数，并返回一个介于-π&#x2F;2和π&#x2F;2之间的值，表示从原点到点(y, x)的角度。</p><p>具体来说，atan2(y, x)返回的角度是满足以下条件的唯一角度θ：</p><p>θ在-π&#x2F;2和π&#x2F;2之间；<br>点(x, y)位于以原点为圆心、半径为1的圆上；<br>点(x, y)与极坐标中的点(1, θ)对应。<br>与atan函数不同的是，atan2考虑了y和x的值之间的比例关系，因此能够更准确地描述角度的变化。在处理二维空间中的角度计算时，atan2函数通常比atan函数更常用。</p><p>以下是一个PromQL中使用atan2函数的示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(rate(vector_field[1m])) * 100 / atan2(1, 1)</span><br></pre></td></tr></table></figure><p>这个示例中，使用rate函数计算了一个名为vector_field的时间序列的1分钟平均值，并将其乘以100。然后，通过使用atan2函数将结果除以1和1之间的反正切值，得到一个归一化的结果。</p><h3 id="聚合运算符"><a href="#聚合运算符" class="headerlink" title="聚合运算符"></a>聚合运算符</h3><p>Prometheus 支持以下内置聚合运算符，可用于聚合单个瞬时向量，生成新的向量：</p><ul><li>sum（总和）</li><li>min（最小）</li><li>max（最大）</li><li>avg（平均值）</li><li>group（分组）</li><li>stddev（标准偏差）</li><li>stdvar（标准方差）</li><li>count（计算向量中的元素个数）</li><li>count_values（计算具有相同值的元素个数）</li><li>bottomk（样本值的最小 k 个元素）</li><li>topk（按样本值计算的最大 k 个元素）</li><li>quantile（分位数计算 φ-quantile (0 ≤ φ ≤ 1)</li></ul><p>聚合运算符可通过 without、by 根据标签扩展</p><p>sum、min、max、avg：</p><p>计算http请求的总和，最大、最小请求的url的数量，平均数量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><p><img src="/image-140.png" alt="Alt text"><br>通过状态码分别统计<br><img src="/image-141.png" alt="Alt text"><br>group:</p><p>类uniq的用法<br><img src="/image-142.png" alt="Alt text"></p><p>stddev、stdvar：</p><p>反映一组数据离散程度，用以衡量数据值偏离算术平均值的程度。标准偏差为方差的开平方，标准偏差越小，这些值偏离平均值就越少，反之亦然。</p><p>通过标准差来反映网络波动</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stddev(rate(node_network_transmit_bytes_total[5m]))</span><br></pre></td></tr></table></figure><p>rate计算某段时间的速率<br><img src="/image-143.png" alt="Alt text"><br>count、count_values:</p><p>统计总共有几个时序</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">count(prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><p><img src="/image-144.png" alt="Alt text"><br>计算每个value的数量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">count_values(&quot;value&quot;,prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><p><img src="/image-145.png" alt="Alt text"></p><p>bottomk、topk</p><p>计算value中最小的5个时序</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bottomk(5,prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><p><img src="/image-146.png" alt="Alt text"></p><p>quantile:求数据的分位数</p><p>我们现在要找出K8s集群中所有node节点的内存使用率的分布情况:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">quantile</span><br><span class="line">(0.8,</span><br><span class="line">(</span><br><span class="line">1 -</span><br><span class="line">node_memory_MemAvailable_bytes&#123;job=&quot;kubernetes-service-endpoints&quot;&#125; </span><br><span class="line">/ node_memory_MemTotal_bytes&#123;job=&quot;kubernetes-service-endpoints&quot;&#125;</span><br><span class="line">)</span><br><span class="line">* 100</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><img src="/image-147.png" alt="Alt text"></p><p>直接可以看出80%的节点内存使用率在68%以下</p><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="值取整"><a href="#值取整" class="headerlink" title="值取整"></a>值取整</h3><h4 id="ceil"><a href="#ceil" class="headerlink" title="ceil()"></a>ceil()</h4><p>ceil(v instant-vector)样本数据向上取整。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceil(node_load1)  #1.2--&gt;2</span><br></pre></td></tr></table></figure><h4 id="floor"><a href="#floor" class="headerlink" title="floor()"></a>floor()</h4><p>floor(v instant-vector)与ceil()相反，floor()样本值向下取整。</p><h4 id="round"><a href="#round" class="headerlink" title="round()"></a>round()</h4><p>round(v instant-vector, to_nearest&#x3D;1 scalar) 对样本值四舍五入取整。to_nearest参数是可选的,默认为 1,表示样本返回的是最接近 1 的整数倍的值，参数可以为分数。</p><p>取整</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">round(prometheus_engine_query_duration_seconds_sum)</span><br></pre></td></tr></table></figure><p>取整到最近的5的倍数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">round(prometheus_engine_query_duration_seconds_sum,5)</span><br></pre></td></tr></table></figure><h3 id="值截取"><a href="#值截取" class="headerlink" title="值截取"></a>值截取</h3><h4 id="clamp"><a href="#clamp" class="headerlink" title="clamp()"></a>clamp()</h4><p>clamp(v instant-vector, min scalar, max scalar) 截取所有元素的样本值在 [min,max]集合内的样本,如果min&gt;max返回NaN</p><p>放回样本值在10到20的样本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clamp(prometheus_http_requests_total,10,20)</span><br></pre></td></tr></table></figure><h4 id="clamp-max"><a href="#clamp-max" class="headerlink" title="clamp_max()"></a>clamp_max()</h4><p>clamp_max(v instant-vector, max scalar) 同clamp()，不过只限定样本最大值</p><h4 id="clamp-min"><a href="#clamp-min" class="headerlink" title="clamp_min()"></a>clamp_min()</h4><p>clamp_min(v instant-vector, min scalar) 同clamp()，不过只限定样本最小值</p><h3 id="值变化统计"><a href="#值变化统计" class="headerlink" title="值变化统计"></a>值变化统计</h3><h4 id="changes"><a href="#changes" class="headerlink" title="changes()"></a>changes()</h4><p>changes(v range-vector)返回某段时间内样本值改变的次数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">changes(node_load1[1m])</span><br></pre></td></tr></table></figure><h3 id="复位统计"><a href="#复位统计" class="headerlink" title="复位统计"></a>复位统计</h3><h4 id="resets"><a href="#resets" class="headerlink" title="resets()"></a>resets()</h4><p>resets(v range-vector) 返回样本范围时间内的复位次数。与counter使用，两个连续样本之间值如有减少则被视为计数器复位。</p><p>查看上下文交换次数计数器在5分钟内复位次数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">resets(node_context_switches_total[5m])</span><br></pre></td></tr></table></figure><h3 id="日期与时间管理"><a href="#日期与时间管理" class="headerlink" title="日期与时间管理"></a>日期与时间管理</h3><h4 id="day-of-month"><a href="#day-of-month" class="headerlink" title="day_of_month()"></a>day_of_month()</h4><p>day_of_month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份中的日期（1-31）</p><p>v&#x3D;vector(time()) 为默认参数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">day_of_month(node_boot_time_seconds)</span><br></pre></td></tr></table></figure><h4 id="day-of-week"><a href="#day-of-week" class="headerlink" title="day_of_week()"></a>day_of_week()</h4><p>day_of_week(v&#x3D;vector(time()) instant-vector)同上，如果样本值是utc时间，则返回这个时间所属星期几（0-6）</p><h4 id="days-in-month"><a href="#days-in-month" class="headerlink" title="days_in_month()"></a>days_in_month()</h4><p>days_in_month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份的天数（28-31）</p><h4 id="hour"><a href="#hour" class="headerlink" title="hour()"></a>hour()</h4><p>hour(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属一天中的第几个小时（1-13）</p><h4 id="minute"><a href="#minute" class="headerlink" title="minute()"></a>minute()</h4><p>minute(v&#x3D;vector(time()) instant-vector) 如果样本值是utc时间，则返回这个时间所属小时中的第几分钟（1-59）</p><h4 id="month"><a href="#month" class="headerlink" title="month()"></a>month()</h4><p>month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的月份（1-12）</p><h4 id="year"><a href="#year" class="headerlink" title="year()"></a>year()</h4><p>year(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的年份</p><h4 id="time"><a href="#time" class="headerlink" title="time()"></a>time()</h4><p>返回自1970 年 1 月 1 日 UTC 以来的秒数，不是系统时间，而是表达式计算时那一刻的时间。</p><h4 id="timestamp"><a href="#timestamp" class="headerlink" title="timestamp()"></a>timestamp()</h4><p>timestamp(v instant-vector)返回每个样本值的时间戳，自 1970 年 1 月 1 日 UTC 以来的秒数。</p><h3 id="直方图分位数"><a href="#直方图分位数" class="headerlink" title="直方图分位数"></a>直方图分位数</h3><h4 id="histogram-quantile"><a href="#histogram-quantile" class="headerlink" title="histogram_quantile()"></a>histogram_quantile()</h4><p>histogram_quantile(φ float, b instant-vector) 从 bucket 类型的向量 b 中计算 φ (0 ≤ φ ≤ 1) 分位数的样本的最大值，与聚合运算符quantile相似。</p><p>计算80%请求的持续时间最大值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">histogram_quantile(0.8,rate(prometheus_http_request_duration_seconds_bucket[1d]))</span><br></pre></td></tr></table></figure><h3 id="差异与增长率"><a href="#差异与增长率" class="headerlink" title="差异与增长率"></a>差异与增长率</h3><h4 id="delta"><a href="#delta" class="headerlink" title="delta()"></a>delta()</h4><p>delta(v range-vector)计算范围向量中每个时间序列元素的第一个值和最后一个值之间的差。与指标类型gauge一起使用</p><p>计算一天内内存可用量的变化</p><p>delta(node_memory_MemAvailable_bytes[1d])</p><h4 id="idelta"><a href="#idelta" class="headerlink" title="idelta()"></a>idelta()</h4><p>idelta(v range-vector)计算范围向量中最后两个样本之间的差异。与指标类型gauge一起使用</p><p>idelta(node_memory_MemAvailable_bytes[1m])</p><h4 id="increase"><a href="#increase" class="headerlink" title="increase()"></a>increase()</h4><p>increase(v range-vector) 计算时间范围内的增量，与counter一起使用。它是速率rate(v)乘以时间范围内秒数的语法糖，主要用于人类可读性。</p><p>计算10分钟内请求增长量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">increase(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure><h4 id="rate"><a href="#rate" class="headerlink" title="rate()"></a>rate()</h4><p>rate(v range-vector)计算范围向量中时间序列的平均每秒增长率。</p><p>过去10分钟请求平均每秒增长率，与counter一起使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rate(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure><h4 id="irate"><a href="#irate" class="headerlink" title="irate()"></a>irate()</h4><p>irate(v range-vector) 通过时间范围的最后两个点来计算每秒瞬时增长率。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">irate(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure><h3 id="label管理"><a href="#label管理" class="headerlink" title="label管理"></a>label管理</h3><h4 id="label-join"><a href="#label-join" class="headerlink" title="label_join()"></a>label_join()</h4><p>label_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, …)为每个时间序列添加一个label，值为指定旧label的value连接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">label_join(up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;,&quot;new_label&quot;,&quot;-&quot;,&quot;instance&quot;,&quot;job&quot;)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;, new_label=&quot;localhost:9100-node&quot;&#125;   1</span><br></pre></td></tr></table></figure><h4 id="label-replace"><a href="#label-replace" class="headerlink" title="label_replace()"></a>label_replace()</h4><p>label_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string)从源label中获取value元素用于添加新的label</p><p>$1 获取正则匹配，匹配值添加到hello标签中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">label_replace(up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;,&quot;hello&quot;,&quot;$1&quot;,&quot;job&quot;,&quot;(.*)&quot;)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up&#123;hello=&quot;node&quot;, instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;       1</span><br></pre></td></tr></table></figure><h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><h4 id="predict-linear"><a href="#predict-linear" class="headerlink" title="predict_linear()"></a>predict_linear()</h4><p>predict_linear(v range-vector, t scalar) 通过简单线性回归预测t秒后的样本值，与gauge一起使用。</p><p>根据过去1小时的文件系统剩余空间量，预测1小时之后的剩余空间</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_linear(node_filesystem_free_bytes[1h],3600)</span><br></pre></td></tr></table></figure><h3 id="转换"><a href="#转换" class="headerlink" title="转换"></a>转换</h3><h4 id="absent"><a href="#absent" class="headerlink" title="absent()"></a>absent()</h4><p>absent(v instant-vector)如果向量有元素，则返回一个空向量；如果向量没有元素，则返回值为 1。</p><p>设置如下告警表达式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">absent(up&#123;job=&quot;node&quot;&#125; == 1)</span><br></pre></td></tr></table></figure><p>由于up{job&#x3D;”node”}不存在或值不为1则告警表达式的值为1 产生告警</p><h4 id="absent-over-time"><a href="#absent-over-time" class="headerlink" title="absent_over_time()"></a>absent_over_time()</h4><p>absent_over_time(v range-vector)如果范围向量有元素，则返回一个空向量；如果范围向量没有元素，则返回值为 1。</p><p>如果up{job&#x3D;”node1”}在某段时间不存在则返回1</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">absent_over_time(up&#123;job=&quot;node1&quot;&#125;[1h])</span><br></pre></td></tr></table></figure><h4 id="scalar"><a href="#scalar" class="headerlink" title="scalar()"></a>scalar()</h4><p>scalar(v instant-vector)以标量形式返回该单元素的样本值,如果输入向量不是正好一个元素，scalar将返回NaN.</p><h4 id="vector"><a href="#vector" class="headerlink" title="vector()"></a>vector()</h4><p>vector(s scalar)将标量作为没有标签的向量返回。</p><h4 id="sgn"><a href="#sgn" class="headerlink" title="sgn()"></a>sgn()</h4><p>sgn(v instant-vector)返回一个向量，其中所有样本值都转换为1或-1或0</p><p>定义如下：</p><p>如果 v 为正，则为 1</p><p>如果 v 为负，则为 -1</p><p>如果 v 等于 0，则为 0。</p><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><h4 id="sort"><a href="#sort" class="headerlink" title="sort()"></a>sort()</h4><p>sort(v instant-vector)返回按样本值升序排序的向量元素。</p><h4 id="sort-desc"><a href="#sort-desc" class="headerlink" title="sort_desc()"></a>sort_desc()</h4><p>与sort()相反，按降序排序。</p><h4 id="over-time"><a href="#over-time" class="headerlink" title="_over_time()"></a>_over_time()</h4><p>下面的函数列表允许传入一个范围向量，返回一个带有聚合的瞬时向量：</p><ul><li>avg_over_time(range-vector): 区间向量内每个度量指标的平均值。</li><li>min_over_time(range-vector): 区间向量内每个度量指标的最小值。</li><li>max_over_time(range-vector): 区间向量内每个度量指标的最大值。</li><li>sum_over_time(range-vector): 区间向量内每个度量指标的求和值。</li><li>count_over_time(range-vector): 区间向量内每个度量指标的样本数据个数。</li><li>quantile_over_time(scalar, range-vector): 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)</li><li>stddev_over_time(range-vector): 区间向量内每个度量指标的总体标准偏差。</li><li>stdvar_over_time(range-vector): 区间向量内每个度量指标的总体标准方差</li></ul><h3 id="数学函数"><a href="#数学函数" class="headerlink" title="数学函数"></a>数学函数</h3><h4 id="abs"><a href="#abs" class="headerlink" title="abs()"></a>abs()</h4><p>abs(v instant-vector)返回样本的绝对值。</p><h4 id="sqrt"><a href="#sqrt" class="headerlink" title="sqrt()"></a>sqrt()</h4><p>sqrt(v instant-vector)计算样本值的平方根。</p><h4 id="deriv"><a href="#deriv" class="headerlink" title="deriv()"></a>deriv()</h4><p>deriv(v range-vector) 使用简单线性回归计算时间序列在范围向量中的每秒导数。与指标类型gauge一起使用</p><h4 id="exp"><a href="#exp" class="headerlink" title="exp()"></a>exp()</h4><p>exp(v instant-vector)计算样本值的指数函数。</p><p>特殊情况：</p><ul><li>Exp(+Inf) &#x3D; +Inf</li><li>Exp(NaN) &#x3D; NaN</li></ul><h4 id="ln-、log2-、log10"><a href="#ln-、log2-、log10" class="headerlink" title="ln()、log2()、log10()"></a>ln()、log2()、log10()</h4><p>ln&#x2F;log2&#x2F;log10(v instant-vector) 计算样本值对数</p><p>特殊情况（同适用于log2&#x2F;log10）：</p><ul><li>ln(+Inf) &#x3D; +Inf</li><li>ln(0) &#x3D; -Inf</li><li>ln(x &lt; 0) &#x3D; NaN</li><li>ln(NaN) &#x3D; NaN</li></ul><h4 id="holt-winters"><a href="#holt-winters" class="headerlink" title="holt_winters()"></a>holt_winters()</h4><p>holt_winters(v range-vector, sf scalar, tf scalar)基于访问向量v，生成时间序列数据平滑数据值。平滑因子sf越低, 对旧数据越重要。趋势因子tf越高，更关心趋势数据。0&lt;sf,tf&lt;&#x3D;1。 与gauge一起使用</p><h3 id="三角函数、弧度"><a href="#三角函数、弧度" class="headerlink" title="三角函数、弧度"></a>三角函数、弧度</h3><ul><li>acos(v instant-vector)</li><li>acosh(v instant-vector)</li><li>asin(v instant-vector)</li><li>asinh(v instant-vector)</li><li>atan(v instant-vector)</li><li>atanh(v instant-vector)</li><li>cos(v instant-vector)</li><li>cosh(v instant-vector)</li><li>sin(v instant-vector)</li><li>sinh(v instant-vector)</li><li>tan(v instant-vector)</li><li>tanh(v instant-vector)</li></ul><h3 id="角度、弧度转化"><a href="#角度、弧度转化" class="headerlink" title="角度、弧度转化"></a>角度、弧度转化</h3><ul><li>deg(v instant-vector)</li><li>pi()</li><li>rad(v instant-vector)</li></ul><p>原文地址: <a href="https://zhuanlan.zhihu.com/p/477177336">https://zhuanlan.zhihu.com/p/477177336</a></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PromQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SNAT和DNAT</title>
      <link href="/2023/11/03/kubernetes/snat-dnat/"/>
      <url>/2023/11/03/kubernetes/snat-dnat/</url>
      
        <content type="html"><![CDATA[<p>1.SNAT和DNAT都是网络地址转换技术，有什么不同？<br>SNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。<br>DNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。<br>总的来说，SNAT和DNAT都是网络地址转换技术，但它们的作用不同。SNAT主要用于隐藏内部网络的真实IP地址，增强网络的安全性；DNAT主要用于将外部网络的请求路由到内部网络的某个主机上，实现网络服务的访问。</p><p>2.SNAT也能解决路由的问题吧？例如源地址为内网ip，通过转换为外部ip，实现对外部资源的访问？<br>SNAT也可以解决路由的问题。当内部网络的主机需要访问外部网络的资源时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就可以将数据包路由回内部网络的主机。通过这种方式，SNAT可以实现内部网络主机对外部资源的访问。<br>在这种情况下，SNAT的作用类似于一个代理服务器。内部网络的主机将数据包发送到代理服务器，代理服务器将数据包的源IP地址修改为一个公共IP地址，然后将数据包发送到外部网络。外部网络将数据包路由回代理服务器，代理服务器再将数据包的源IP地址修改为内部网络的真实IP地址，最终将数据包发送到内部网络的主机。<br>需要注意的是，SNAT只能实现单向的路由，即内部网络主机访问外部资源。如果外部网络的主机需要访问内部网络的资源，就需要使用DNAT技术将外部网络的请求路由到内部网络的某个主机上。</p><p>3.DNAT也是可以解决访问的问题，作为回包路由转换？<br>DNAT也可以解决访问的问题。当外部网络的主机需要访问内部网络的资源时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。通过这种方式，DNAT可以实现外部网络主机对内部资源的访问。<br>在这种情况下，DNAT的作用类似于一个端口映射。外部网络的主机将数据包发送到DNAT设备，DNAT设备将数据包的目标IP地址修改为内部网络的某个主机的IP地址，然后将数据包发送到内部网络。内部网络将数据包的回复发送到DNAT设备，DNAT设备再将数据包的目标IP地址修改为外部网络的真实IP地址，最终将数据包发送到外部网络的主机。<br>需要注意的是，DNAT只能实现单向的路由，即外部网络主机访问内部网络资源。如果内部网络的主机需要访问外部网络的资源，就需要使用SNAT技术将数据包的源IP地址修改为一个公共IP地址，从而实现数据包的路由。</p><p>4.SNAT和DNAT，仅仅时转化ip的区别吗？<br>SNAT和DNAT的区别不仅仅是转换IP地址的不同，它们的作用和应用场景也不同。<br>SNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。同时，SNAT还可以实现负载均衡功能，将网络流量分配到多个服务器上，提高网络的性能和可靠性。</p><p>DNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。同时，DNAT还可以实现端口映射功能，将外部网络的请求映射到内部网络的某个端口上，提高网络的灵活性和可扩展性。</p><p>因此，虽然SNAT和DNAT都是网络地址转换技术，但它们的作用和应用场景不同，不能简单地认为它们只是转换IP地址的区别。<br>————————————————<br>版权声明：本文为CSDN博主「NTZ5bzZKdUw」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/qq_41152046/article/details/130029737">https://blog.csdn.net/qq_41152046/article/details/130029737</a></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络（1-3层）详解</title>
      <link href="/2023/11/03/kubernetes/internet-1-3/"/>
      <url>/2023/11/03/kubernetes/internet-1-3/</url>
      
        <content type="html"><![CDATA[<p>计算机被发明出来使用很长时间，都是作为一个独立的个体来使用的，直到后来美国国防部的高级研究计划局（ARPA）计划建设一个军用网，叫做“阿帕网”（ARPAnet），阿帕网于1969年正式启用，当时仅连接了4台计算机，供科学家们进行计算机联网实验使用，直到那时候才开始出现计算机网络的概念。</p><p>今天我们就来聊聊计算机组网的那点事儿</p><p>第一层（物理层）</p><p>从计算机组网的角度来说，将两台计算机通过网线相连，就是一个简单的网络结构，如图所示：</p><p><img src="/image-120.png" alt="Alt text"><br>但是在实际网络环境中，接入网络的计算机不可能只有两台，那么在有很多台计算机的情况下，我们该如何连接呢？</p><p>为此我们发明了一个中间设备，将计算机的网线都插到这个设备上，由这个设备做转发，这样彼此之间就可以通信了。</p><p>这个中间设备的名子就叫集线器（俗称HUB）,它的功能非常简单，仅仅是将任意一个接口接受到的电信号转发到所有出口（广播），不做任何处理，因此将他定位为物理层设备。</p><p>但是这种转发方式会引起一个新的问题，由于转发到了所有出口，那接在集线器下的其他设备都能接受到数据，那么怎么判断数据是不是发给自己的。</p><p><img src="/image-121.png" alt="Alt text"><br>这儿就引入一个新的名词，MAC地址，正常情况下MAC地址是全局唯一的标识，全世界独一无二，给每一个设备都配一个MAC地址，这样，A 在发送数据包给 B 时，只要在头部拼接一个源目MAC地址就可以解决此问题了。B 在收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包的确是发给自己的，于是便收下。其他的计算机收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包并不是发给自己的，于是便丢弃。虽然集线器使整个网络布局简单明了，但会出现一个新的问题，原来我只要发给电脑B的消息，现在却要发给连接到集线器中的所有电脑，这样既不安全，又浪费宝贵带宽资源。</p><p>第二层（数据链路层）</p><p>在第一层中，我们最后虽然解决了多台计算机的组网需求，但最后却留下了问题，即集线器的使用不仅有安全隐患，而且浪费有限的带宽资源。那第二层的主要目标就是解决安全隐患以及带宽浪费的问题，把这个集线器弄得更智能一些，想要将数据发送到那一台设备，就只发给目标 MAC 地址指向的那台电脑，就好了。<br><img src="/image-122.png" alt="Alt text"></p><p>所以一个全新的设备出现了，这东西就叫做交换机。它能够实现你将数据发送到指定的设备而不会转发到所有出口（广播）的情况，因此将他定位为数据链路层设备。每一台交换机内部维护一张 MAC 地址表，记录着每一个设备的 MAC 地址，连接在其哪一个端口上。</p><table><thead><tr><th align="left">MAC 地址</th><th align="left">端口</th></tr></thead><tbody><tr><td align="left">bb-bb-bb-bb-bb-bb</td><td align="left">1</td></tr><tr><td align="left">cc-cc-cc-cc-cc-cc</td><td align="left">3</td></tr><tr><td align="left">aa-aa-aa-aa-aa-aa</td><td align="left">4</td></tr><tr><td align="left">dd-dd-dd-dd-dd-dd</td><td align="left">5</td></tr></tbody></table><p>这种情况下，假如你仍然要发给 B 一个数据包，构造了如下的数据结构从网口出去。<br><img src="/image-123.png" alt="Alt text"></p><p>到达交换机时，交换机内部通过自己维护的 MAC 地址表，发现目标机器 B 的 MAC 地址 bb-bb-bb-bb-bb-bb 映射到了端口 1 上，于是把数据从 1 号端口发给了 B，一次数据转发完成。而以这样传输方式组成的小范围的网络，叫做以太网。当然刚开始的时候，MAC 地址表是空的，那MAC地址表是如何建立起来的呢？假如刚开始交换机 MAC 地址表是空的，你给 B 发送了如下数据：</p><p><img src="/image-124.png" alt="Alt text"><br>由于这个包从端口 4 进入的交换机，所以此时交换机就可以在 MAC地址表记录第一条数据：</p><table><thead><tr><th align="left">MAC 地址</th><th align="left">端口</th></tr></thead><tbody><tr><td align="left">aa-aa-aa-aa-aa-aa-aa</td><td align="left">4</td></tr></tbody></table><p>交换机看目标 MAC 地址（bb-bb-bb-bb-bb-bb）在地址表中并没有映射关系，于是将此包发给了所有端口，即广播发送。之后，只有机器 B 收到了确实是发给自己的包，于是做出了响应，响应数据从端口 1 进入交换机，于是交换机此时在地址表中更新了第二条数据：</p><table><thead><tr><th align="left">MAC 地址</th><th align="left">端口</th></tr></thead><tbody><tr><td align="left">aa-aa-aa-aa-aa-aa-aa</td><td align="left">4</td></tr><tr><td align="left">bb-bb-bb-bb-bb-bb</td><td align="left">1</td></tr></tbody></table><p>经过该网络中的机器不断通信，交换机最终将 MAC 地址表建立完毕~</p><p>最直观的展示过程：<br><img src="/image-125.png" alt="Alt text"></p><p>通过此种方法我们就成功的建立了一个相对安全，也比较智能的局域互联网络，通过此网络我们可以在几台计算机之间分享数据，但是很快新的问题又出现了。随着机器数量越多，一台交换机的端口不够了，我们能想到的最简单的办法，就是将多个交换机连接起来，解决这 个问题，事实上还真的可以，但是这样真的没有问题吗？<br><img src="/image-126.png" alt="Alt text"></p><p>需要注意的是，上面那根红色的线，最终在 MAC 地址表中可不是一条记录，而是要把 EFGH 这四台机器与该端口（端口6）的映射全部记录在表中。最终，两个交换机将分别记录 A ~ H 所有机器的映射记录。</p><p>左边的交换机</p><table><thead><tr><th align="left">MAC 地址</th><th align="left">端口</th></tr></thead><tbody><tr><td align="left">bb-bb-bb-bb-bb-bb</td><td align="left">1</td></tr><tr><td align="left">cc-cc-cc-cc-cc-cc</td><td align="left">3</td></tr><tr><td align="left">aa-aa-aa-aa-aa-aa</td><td align="left">4</td></tr><tr><td align="left">dd-dd-dd-dd-dd-dd</td><td align="left">5</td></tr><tr><td align="left">ee-ee-ee-ee-ee-ee</td><td align="left">6</td></tr><tr><td align="left">ff-ff-ff-ff-ff-ff</td><td align="left">6</td></tr><tr><td align="left">gg-gg-gg-gg-gg-gg</td><td align="left">6</td></tr><tr><td align="left">hh-hh-hh-hh-hh-hh</td><td align="left">6</td></tr></tbody></table><p>右边的交换机</p><table><thead><tr><th align="left">MAC 地址</th><th align="left">端口</th></tr></thead><tbody><tr><td align="left">bb-bb-bb-bb-bb-bb</td><td align="left">1</td></tr><tr><td align="left">cc-cc-cc-cc-cc-cc</td><td align="left">1</td></tr><tr><td align="left">aa-aa-aa-aa-aa-aa</td><td align="left">1</td></tr><tr><td align="left">dd-dd-dd-dd-dd-dd</td><td align="left">1</td></tr><tr><td align="left">ee-ee-ee-ee-ee-ee</td><td align="left">2</td></tr><tr><td align="left">ff-ff-ff-ff-ff-ff</td><td align="left">3</td></tr><tr><td align="left">gg-gg-gg-gg-gg-gg</td><td align="left">4</td></tr><tr><td align="left">hh-hh-hh-hh-hh-hh</td><td align="left">6</td></tr></tbody></table><p>这种设计方式，在计算机数量不多的情况下是可以正常使用的，但是当接入的计算机数量太多，交换机就无法维护如此巨大的表了。</p><p>第三层（网络层）</p><p>在第二层中问题的根本在于，连出去的那根红色的网线，后面不知道有多少个设备不断地连接进来，从而使得地址表越来越大。<br><img src="/image-127.png" alt="Alt text"></p><p>解决的办法就是，再接入一个新的设备，这个设备有自己独立的 MAC 地址同时还能把所有流经的数据包做一次转发，这个设备就是路由器，并将它定在了网络层。现在交换机的 MAC 地址表中，只需要多出一条 MAC 地址 ABAB 与其端口的映射关系，就可以成功把数据包转交给路由器了，而后由路由器转发到其他设备。但是这儿由出现了一个新的问题，那就是如何做到将发送的数据先发送给路由器呢？</p><p>为了解决这个问题，我们又发明了一个新的工具，IP 地址。现在每一台电脑，同时有自己的 MAC 地址，又有自己的 IP 地址，只不过 IP 地址是软件层面上的，可以随时修改，MAC 地址一般是无法修改的。这样一个可以随时修改的 IP 地址，就可以根据你规划的网络拓扑结构来调整了。<br><img src="/image-128.png" alt="Alt text"></p><p>如上图所示，假如我想要发送数据包给 ABCD 其中一台设备，不论哪一台，我都可以这样描述，”将 IP 地址为 192.168.0 开头的全部发送给到路由器，之后再怎么转发，交给它！那交给路由器之后，路由器又是怎么把数据包准确转发给指定设备的呢？</p><p>我们先给上面的组网方式中的每一台设备，加上自己的 IP 地址</p><p><img src="/image-129.png" alt="Alt text"><br>现在两个设备之间传输，除了加上数据链路层的头部之外，还要再增加一个网络层的头部。假如 A 给 B 发送数据，由于它们直接连着交换机，所以 A 直接发出数据包即可，网络层的功能没有体现出作用。但假如 A 给 C 发送数据，A 就需要先转交给路由器，然后再由路由器转交给 C。由于最底层的传输仍然需要依赖以太网，所以数据包是分成两段的。</p><p>A-路由器这段的包如下：<br><img src="/image-130.png" alt="Alt text"></p><p>路由器-C这段的包如下：</p><p><img src="/image-131.png" alt="Alt text"><br>A 给 C 发数据包，首先判断源 IP与目的IP是否处于一个子网，如果处于同一个子网，直接将包通过交换机发出，如果源 IP 与目的 IP 不处于一个子网，就交给路由器去处理，这里又有一个新的问题，那就是A 如何知道，哪个设备是路由器呢？答案就是你提前需要在 A 上设置路由器的地址，而这个地址我们叫他默认网关。现在数据已经可以成功发到路由器这里了，最后一个问题就是，路由器如何知道，收到的这个数据包，该从自己的哪个端口出去，才能直接（或间接）地最终到达目的地 C 呢。</p><p>这儿就又出现了一张新的表，叫做路由表。至于这个路由表是怎么出来的，可以通过手动的方式指定，也可以通过路由算法自动生成，本文不展开讲述，因为这又是一个庞大的体系。不同于 MAC 地址表的是，路由表并不是一对一这种明确关系，我们下面看一个路由表的结构。</p><table><thead><tr><th align="left">目的地址</th><th align="left">子网掩码</th><th align="left">下一跳</th><th align="left">端口</th></tr></thead><tbody><tr><td align="left">192.168.0.0</td><td align="left">255.255.255.0</td><td align="left"></td><td align="left">0</td></tr><tr><td align="left">192.168.0.254</td><td align="left">255.255.255.255</td><td align="left"></td><td align="left">0</td></tr><tr><td align="left">192.168.1.0</td><td align="left">255.255.255.0</td><td align="left"></td><td align="left">1</td></tr><tr><td align="left">192.168.1.254</td><td align="left">255.255.255.255</td><td align="left"></td><td align="left">1</td></tr></tbody></table><p>上表表示，<a href="http://192.168.0.xxx/">http://192.168.0.xxx</a> 这个子网下的，都转发到 0 号端口，<a href="http://192.168.1.xxx/">http://192.168.1.xxx</a> 这个子网下的，都转发到 1 号端口。但是这儿又有一个新的麻烦出现了。</p><p>现在我们知道要发送数据的目标主机IP地址，但发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？又出现一个新的名词arp，在网络层，我需要把 IP 地址对应的 MAC 地址找到， 这种方式就是 arp 协议，同时电脑每一台电脑里面也会有一张 arp 缓存表，表中记录着 IP 与 MAC 地址的对应关系。</p><table><thead><tr><th align="left">IP 地址</th><th align="left">MAC 地址</th></tr></thead><tbody><tr><td align="left">192.168.0.2</td><td align="left">BBBB</td></tr></tbody></table><p>刚开始的时候这个表是空的，电脑 A 为了知道电脑 B的 MAC 地址，将会广播一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个响应。此时 A 便更新了自己的 arp 表。这样通过大家不断广播 arp 请求，最终所有电脑里面都将 arp 缓存表更新完整。</p><p>至此一个数据成功的从一个网段转发到另一个网段，复杂的网络是由一个个小型的网络组合而成的，将N个局域网连接到一起可不就是互联网嘛。</p><p>原文地址:<a href="https://zhuanlan.zhihu.com/p/433393781">https://zhuanlan.zhihu.com/p/433393781</a></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VXLAN 基础教程：VXLAN 协议原理介绍</title>
      <link href="/2023/11/03/kubernetes/vxlan/"/>
      <url>/2023/11/03/kubernetes/vxlan/</url>
      
        <content type="html"><![CDATA[<p>VXLAN（Virtual eXtensible Local Area Network，虚拟可扩展局域网），是一种虚拟化隧道通信技术。它是一种 Overlay（覆盖网络）技术，通过三层的网络来搭建虚拟的二层网络。</p><p>简单来讲，VXLAN 是在底层物理网络（underlay）之上使用隧道技术，借助 UDP 层构建的 Overlay 的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。它对原有的网络架构几乎没有影响，不需要对原网络做任何改动，即可架设一层新的网络。也正是因为这个特性，很多 CNI 插件（Kubernetes 集群中的容器网络接口，这个大家应该都知道了吧，如果你不知道，现在你知道了）才会选择 VXLAN 作为通信网络。</p><p>VXLAN 不仅支持一对一，也支持一对多，一个 VXLAN 设备能通过像网桥一样的学习方式学习到其他对端的 IP 地址，还可以直接配置静态转发表。</p><p>一个典型的数据中心 VXLAN 网络拓扑图如图所示：</p><p><img src="/image-114.png" alt="Alt text"><br>其中 VM 指的是虚拟机，Hypervisor 指的是虚拟化管理器。</p><h2 id="1-为什么需要-VXLAN？"><a href="#1-为什么需要-VXLAN？" class="headerlink" title="1.  为什么需要 VXLAN？"></a>1.  为什么需要 VXLAN？</h2><p>与 VLAN 相比，VXLAN 很明显要复杂很多，再加上 VLAN 的先发优势，已经得到了广泛的支持，那还要 VXLAN 干啥？</p><h3 id="VLAN-ID-数量限制"><a href="#VLAN-ID-数量限制" class="headerlink" title="VLAN ID 数量限制"></a>VLAN ID 数量限制</h3><p>VLAN tag 总共有 4 个字节，其中有 12 bit 用来标识不同的二层网络（即 LAN ID），故而最多只能支持 $2^{12}$，即 4096 个子网的划分。而虚拟化（虚拟机和容器）的兴起使得一个数据中心会有成千上万的机器需要通信，这时候 VLAN 就无法满足需求了。而 VXLAN 的报文 Header 预留了 24 bit 来标识不同的二层网络（即 VNI，VXLAN Network Identifier），即 3 个字节，可以支持 $2^{24}$ 个子网。</p><h3 id="交换机-MAC-地址表限制"><a href="#交换机-MAC-地址表限制" class="headerlink" title="交换机 MAC 地址表限制"></a>交换机 MAC 地址表限制</h3><p>对于同网段主机的通信而言，报文到底交换机后都会查询 MAC 地址表进行二层转发。数据中心虚拟化之后，VM 的数量与原有的物理机相比呈数量级增长，而应用容器化之后，容器与 VM 相比也是呈数量级增长。。。而交换机的内存是有限的，因而 MAC 地址表也是有限的，随着虚拟机（或容器）网卡 MAC 地址数量的空前增加，交换机表示压力山大啊！</p><p>而 VXLAN 就厉害了，它用 VTEP（后面会解释）将二层以太网帧封装在 UDP 中，一个 VTEP 可以被一个物理机上的所有 VM（或容器）共用，一个物理机对应一个 VTEP。从交换机的角度来看，只是不同的 VTEP 之间在传递 UDP 数据，只需要记录与物理机数量相当的 MAC 地址表条目就可以了，一切又回到了和从前一样。</p><h3 id="虚机或容器迁移范围受限"><a href="#虚机或容器迁移范围受限" class="headerlink" title="虚机或容器迁移范围受限"></a>虚机或容器迁移范围受限</h3><p>VLAN 与物理网络融合在一起，不存在 Overlay 网络，带来的问题就是虚拟网络不能打破物理网络的限制。举个例子，如果要在 VLAN 100 部署虚拟机（或容器），那只能在支持 VLAN 100 的物理设备上部署。</p><p>VLAN 其实也有解决办法，就是将所有的交换机 Trunk 连接起来，产生一个大的二层，这样带来的问题就是广播域过分扩大，也包括更多未知的单播和多播，即 BUM（Broadcast，Unknown Unicast，Multicast），同时交换机 MAC 地址表也会有承受不住的问题。</p><p>而 VXLAN 将二层以太网帧封装在 UDP 中（上面说过了），相当于在三层网络上构建了二层网络。这样不管你物理网络是二层还是三层，都不影响虚拟机（或容器）的网络通信，也就无所谓部署在哪台物理设备上了，可以随意迁移。</p><p>总的来说，传统二层和三层的网络在应对这些需求时变得力不从心，虽然很多改进型的技术比如堆叠、SVF、TRILL 等能够增加二层的范围，努力改进经典网络，但是要做到对网络改动尽可能小的同时保证灵活性却非常困难。为了解决这些问题，有很多方案被提出来，Overlay 就是其中之一，而 VXLAN 是 Overlay 的一种典型的技术方案。下面就对 Overlay 做一个简要的介绍。</p><h2 id="2-Overlay-是个啥？"><a href="#2-Overlay-是个啥？" class="headerlink" title="2. Overlay 是个啥？"></a>2. Overlay 是个啥？</h2><p>Overlay 在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于 IP 的基础网络技术为主。</p><p>IETF 在 Overlay 技术领域提出 VXLAN、NVGRE、STT 三大技术方案。大体思路均是将以太网报文承载到某种隧道层面，差异性在于选择和构造隧道的不同，而底层均是 IP 转发。VXLAN 和 STT 对于现网设备而言对流量均衡要求较低，即负载链路负载分担适应性好，一般的网络设备都能对 L2-L4 的数据内容参数进行链路聚合或等价路由的流量均衡，而 NVGRE 则需要网络设备对 GRE 扩展头感知并对 flow ID 进行 HASH，需要硬件升级；STT 对于 TCP 有较大修改，隧道模式接近 UDP 性质，隧道构造技术属于革新性，且复杂度较高，而 VXLAN 利用了现有通用的 UDP 传输，成熟性极高。</p><p>总体比较，VLXAN 技术具有更大优势，而且当前 VLXAN 也得到了更多厂家和客户的支持，已经成为 Overlay 技术的主流标准。</p><h2 id="3-VXLAN-协议原理"><a href="#3-VXLAN-协议原理" class="headerlink" title="3. VXLAN 协议原理"></a>3. VXLAN 协议原理</h2><p>VXLAN 有几个常见的术语：</p><ul><li>VTEP（VXLAN Tunnel Endpoints，VXLAN 隧道端点）</li></ul><p>VXLAN 网络的边缘设备，用来进行 VXLAN 报文的处理（封包和解包）。VTEP 可以是网络设备（比如交换机），也可以是一台机器（比如虚拟化集群中的宿主机）。</p><ul><li>VNI（VXLAN Network Identifier，VXLAN 网络标识符）</li></ul><p>VNI 是每个 VXLAN 段的标识，是个 24 位整数，一共有 $2^{24} &#x3D; 16777216$（一千多万），一般每个 VNI 对应一个租户，也就是说使用 VXLAN 搭建的公有云可以理论上可以支撑千万级别的租户。</p><ul><li>Tunnel（VXLAN 隧道）</li></ul><p>隧道是一个逻辑上的概念，在 VXLAN 模型中并没有具体的物理实体向对应。隧道可以看做是一种虚拟通道，VXLAN 通信双方认为自己是在直接通信，并不知道底层网络的存在。从整体来说，每个 VXLAN 网络像是为通信的虚拟机搭建了一个单独的通信通道，也就是隧道。<br><img src="/image-115.png" alt="Alt text"><br>上图所示为 VXLAN 的工作模型，它创建在原来的 IP 网络（三层）上，只要是三层可达（能够通过 IP 相互通信）的网络就能部署 VXLAN。在 VXLAN 网络的每个端点都有一个 VTEP 设备，负责 VXLAN 协议报文的解包和封包，也就是在虚拟报文上封装 VTEP 通信的报文头部。</p><p>物理网络上可以创建多个 VXLAN 网络，可以将这些 VXLAN 网络看成一个隧道，不同节点上的虚拟机&#x2F;容器能够通过隧道直连。通过 VNI 标识不同的 VXLAN 网络，使得不同的 VXLAN 可以相互隔离。</p><p>VXLAN 的报文结构如下图所示：</p><p><img src="/image-116.png" alt="Alt text"></p><ul><li><p>VXLAN Header : 在原始二层帧的前面增加 8 字节的 VXLAN 的头部，其中最主要的是 VNID，占用 3 个字节（即 24 bit），类似 VLAN ID，可以具有 $2^{24}$ 个网段。</p></li><li><p>UDP Header : 在 VXLAN 和原始二层帧的前面使用 8 字节 UDP 头部进行封装（MAC IN UDP），目的端口号缺省使用 4789，源端口按流随机分配（通过 MAC，IP，四层端口号进行 hash 操作）， 这样可以更好的做 ECMP。</p></li></ul><p>IANA（Internet As-signed Numbers Autority）分配了 4789 作为 VXLAN 的默认目的端口号。</p><p>在上面添加的二层封装之后，再添加底层网络的 IP 头部（20 字节）和 MAC 头部（14 字节），这里的 IP 和 MAC 是宿主机的 IP 地址和 MAC 地址。</p><p>同时，这里需要注意 MTU 的问题，传统网络 MTU 一般为 1500，这里加上 VXLAN 的封装多出的（36+14&#x2F;18，对于 14 的情况为 access 口，省去了 4 字节的 VLAN Tag）50 或 54 字节，需要调整 MTU 为 1550 或 1554，防止频繁分包。<br><img src="/image-117.png" alt="Alt text"></p><h3 id="VXLAN-的-Flood-与-Learn"><a href="#VXLAN-的-Flood-与-Learn" class="headerlink" title="VXLAN 的 Flood 与 Learn"></a>VXLAN 的 Flood 与 Learn</h3><p>总的来说，VXLAN 报文的转发过程就是：原始报文经过 VTEP，被 Linux 内核添加上 VXLAN 头部以及外层的 UDP 头部，再发送出去，对端 VTEP 接收到 VXLAN 报文后拆除外层 UDP 头部，并根据 VXLAN 头部的 VNI 把原始报文发送到目的服务器。但这里有一个问题，第一次通信前双方如何知道所有的通信信息？这些信息包括：</p><p>哪些 VTEP 需要加到一个相同的 VNI 组？<br>发送方如何知道对方的 MAC 地址？<br>如何知道目的服务器在哪个节点上（即目的 VTEP 的地址）？<br>第一个问题简单，VTEP 通常由网络管理员来配置。要回答后面两个问题，还得回到 VXLAN 协议的报文上，看看一个完整的 VXLAN 报文需要哪些信息：</p><ul><li><p>内层报文 : 通信双方的 IP 地址已经明确，只需要 VXLAN 填充对方的 MAC 地址，因此需要一个机制来实现 ARP 功能。</p></li><li><p>VXLAN 头部 : 只需要知道 VNI。一般直接配置在 VTEP 上，要么提前规划，要么根据内层报文自动生成。</p></li><li><p>UDP 头部 : 需要知道源端口和目的端口，源端口由系统自动生成，目的端口默认是 4789。</p></li><li><p>IP 头部 : 需要知道对端 VTEP 的 IP 地址，这个是最关键的部分。</p></li></ul><p>实际上，VTEP 也会有自己的转发表，转发表通过泛洪和学习机制来维护，对于目标 MAC 地址在转发表中不存在的未知单播，广播流量，都会被泛洪给除源 VTEP 外所有的 VTEP，目标 VTEP 响应数据包后，源 VTEP 会从数据包中学习到 MAC，VNI 和 VTEP 的映射关系，并添加到转发表中，后续当再有数据包转发到这个 MAC 地址时，VTEP 会从转发表中直接获取到目标 VTEP 地址，从而发送单播数据到目标 VTEP。<br><img src="/image-118.png" alt="Alt text"></p><p>VTEP 转发表的学习可以通过以下两种方式：</p><p>多播<br>外部控制中心（如 Flannel、Cilium 等 CNI 插件）</p><ul><li>MAC 头部 : 确定了 VTEP 的 IP 地址，后面就好办了，MAC 地址可以通过经典的 ARP 方式获取。</li></ul><h2 id="4-Linux-的-VXLAN"><a href="#4-Linux-的-VXLAN" class="headerlink" title="4. Linux 的 VXLAN"></a>4. Linux 的 VXLAN</h2><p>Linux 对 VXLAN 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，可能会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 VXLAN。</p><p>到了 kernel 3.12 版本，Linux 对 VXLAN 的支持已经完备，支持单播和组播，IPv4 和 IPv6。利用 man 查看 ip 的 link 子命令，可以查看是否有 VXLAN type：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ man ip-link</span><br></pre></td></tr></table></figure><p>搜索 VXLAN，可以看到如下描述：<br><img src="/image-119.png" alt="Alt text"></p><h3 id="管理-VXLAN-接口"><a href="#管理-VXLAN-接口" class="headerlink" title="管理 VXLAN 接口"></a>管理 VXLAN 接口</h3><ol><li>Linux VXLAN 接口的基本管理如下：<br>创建点对点的 VXLAN 接口：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip link add vxlan0 type vxlan id 4100 remote 192.168.1.101 local 192.168.1.100 dstport 4789 dev eth0</span><br></pre></td></tr></table></figure>其中 id 为 VNI，remote 为远端主机的 IP，local 为你本地主机的 IP，dev 代表 VXLAN 数据从哪个接口传输。</li></ol><p>在 VXLAN 中，一般将 VXLAN 接口（本例中即 vxlan0）叫做 VTEP。<br>2. 创建多播模式的 VXLAN 接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip link add vxlan0 type vxlan id 4100 group 224.1.1.1 dstport 4789 dev eth0</span><br></pre></td></tr></table></figure><p>多播组主要通过 ARP 泛洪来学习 MAC 地址，即在 VXLAN 子网内广播 ARP 请求，然后对应节点进行响应。group 指定多播组的地址。</p><ol start="3"><li>查看 VXLAN 接口详细信息：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip -d link show vxlan0</span><br></pre></td></tr></table></figure></li></ol><h4 id="FDB-表"><a href="#FDB-表" class="headerlink" title="FDB 表"></a>FDB 表</h4><p>FDB（Forwarding Database entry，即转发表）是 Linux 网桥维护的一个二层转发表，用于保存远端虚拟机&#x2F;容器的 MAC地址，远端 VTEP IP，以及 VNI 的映射关系，可以通过 bridge fdb 命令来对 FDB 表进行操作：</p><ul><li>条目添加：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bridge fdb add &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt; dst &lt;remote_host_ip&gt;</span><br></pre></td></tr></table></figure></li><li>条目删除：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bridge fdb del &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt;</span><br></pre></td></tr></table></figure></li><li>条目更新：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bridge fdb replace &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt; dst &lt;remote_host_ip&gt;</span><br></pre></td></tr></table></figure></li><li>条目查询：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bridge fdb show</span><br></pre></td></tr></table></figure></li></ul><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>本文通过介绍 VXLAN 出现的时代背景、VXLAN 的概念和网络模型、VXLAN 报文结构，让你对 VXLAN 有了初步的认识；通过介绍 VXLAN 转发表的泛洪和学习，让你知道了通信双方如何感知对方；最后介绍了 Linux 中 VXLAN 的基本配置，让你进一步了解如何在 Linux 中玩转 VXLAN。下一篇文章将会通过实战来说明如何搭建基于 VXLAN 的 Overlay 网络，顺便展开解读上文提到的多播和外部控制中心的工作原理。</p><p>原文地址: <a href="https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82">https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82</a></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VXLAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网关技术详解及常见网关对比</title>
      <link href="/2023/11/02/kubernetes/gateway/"/>
      <url>/2023/11/02/kubernetes/gateway/</url>
      
        <content type="html"><![CDATA[<p>原文地址: <a href="https://blog.csdn.net/huangjinjin520/article/details/126863371">https://blog.csdn.net/huangjinjin520/article/details/126863371</a></p><h2 id="什么是网关"><a href="#什么是网关" class="headerlink" title="什么是网关"></a>什么是网关</h2><p>网关，很多地方将网关比如成门， 没什么问题， 但是需要区分网关与网桥的区别，</p><p>网桥 工作在数据链路层，在不同或相同类型的LAN之间存储并转发数据帧，必要时进行链路层上的协议转换。可连接两个或多个网络，在其中传送信息包。</p><p>网关 是一个大概念，不具体特指一类产品，只要连接两个不同的网络都可以叫网关，网桥一般只转发信息，而网关可能进行包装。</p><h2 id="网关通俗理解"><a href="#网关通俗理解" class="headerlink" title="网关通俗理解"></a>网关通俗理解</h2><p>根据网关的特性，举个例子:</p><p>假如你要去找集团老板(这儿只是举个例子)， 大家都知道老板肯定不是谁想见就能见的， 也怕坏人嘛， 那么你去老板所在的办公楼，假如是集团总部， 大楼这个门就充当了网关的角色， 大门一般都有看门员 ，看门员会做哪些事情呢?</p><p>首先所有想见老板的人肯定都得从这个门进(统一入口 )， 这个门相当于将办公室和外界隔离了，主要为了保护里面的安全以及正常工作， 来到这个门之后， 门卫肯定会让你出示相关证件(鉴权检验 )， 意思就是判断你要见老板这个请求是否合理， 如果不合理直接就拒绝了， 让你回家等消息 ， 如果鉴权之后， 发现你找老板其实只是为了和他谈谈两元店的生意， 门卫会跟你说这个用不着找老板， 你去集团投资部就行了(动态路由 ， 将请求路由到不同的后端集群中)， 此时会对你进行一些包装 ，例如给你出具一个访问证类似的，然后告诉你路该怎么走，等等。</p><p>你看看，网关的作用是不是就是这三个， 最终目的就是减少你与集团的耦合，具体到计算机上就是减少客户端与服务端的耦合，如果没有网关意味着所有请求都会直接调用服务器上的资源，这样耦合太强了，服务器出了问题，客户端会直接报错， 例如老板换工作的地方了，如果没有网关你直接去原来的地方找， 肯定会被告知老板不在这儿。</p><h2 id="为什么需要网关"><a href="#为什么需要网关" class="headerlink" title="为什么需要网关"></a>为什么需要网关</h2><p>当使用单体应用程序架构时，客户端（Web 或移动端）通过向后端应用程序发起一次 REST 调用来获取数据。负载均衡器将请求路由给 N 个相同的应用程序实例中的一个。然后应用程序会查询各种数据库表，并将响应返回给客户端。微服务架构下，单体应用被切割成多个微服务，如果将所有的微服务直接对外暴露，势必会出现安全方面的各种问题，另外内外耦合严重。</p><p>客户端可以直接向每个微服务发送请求，其问题主要如下：</p><p>客户端需求和每个微服务暴露的细粒度 API 不匹配。</p><p>部分服务使用的协议不是Web友好协议。可能使用 Thrift 二进制 RPC，也可能使用 AMQP 消息传递协议。</p><p>微服务难以重构。如果合并两个服务，或者将一个服务拆分成两个或更多服务，这类重构就非常困难了。</p><p>服务端的各个服务直接暴露给客户端调用势必会引起各种问题。同时，服务端的各个服务可扩展和伸缩性很差。API 网关是微服务架构中的基础组件，位于接入层之下和业务服务层之上，如前所述的这些功能适合在 API 网关实现。</p><h2 id="网关与服务器集群"><a href="#网关与服务器集群" class="headerlink" title="网关与服务器集群"></a>网关与服务器集群</h2><p>回到我们服务器上，下面图介绍了网关(Gateway)作用，可知 Gateway 方式下的架构，可以细到为每一个服务的实例配置一个自己的 Gateway，也可以粗到为一组服务配置一个，甚至可以粗到为整个架构配置一个接入的 Gateway。于是，整个系统架构的复杂度就会变得简单可控起来。</p><p><img src="/image-104.png" alt="Alt text"></p><p>这张图展示了一个多层 Gateway 架构，其中有一个总的 Gateway 接入所有的流量(流量网关 )，并分发给不同的子系统，还有第二级 Gateway 用于做各个子系统的接入 Gateway(业务网关 )。可以看到，网关所管理的服务粒度可粗可细。通过网关，我们可以把分布式架构组织成一个星型架构，由网络对服务的请求进行路由和分发。下面来聊聊好的网关应该具备哪些功能，也就是网关设计模式。</p><h2 id="网关设计思路"><a href="#网关设计思路" class="headerlink" title="网关设计思路"></a>网关设计思路</h2><p>一个网关需要有以下的功能:</p><h3 id="1-请求路由"><a href="#1-请求路由" class="headerlink" title="1. 请求路由"></a>1. 请求路由</h3><p>网关一定要有请求路由的功能。这样一来，对于调用端来说，也是一件非常方便的事情。因为调用端不需要知道自己需要用到的其它服务的地址，全部统一地交给 Gateway 来处理。</p><h3 id="2-服务注册"><a href="#2-服务注册" class="headerlink" title="2. 服务注册"></a>2. 服务注册</h3><p>为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些 API 接口。比如，HTTP 的 Restful 请求，可以注册相应 API 的 URI、方法、HTTP 头。这样，Gateway 就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。</p><h3 id="3-负载均衡"><a href="#3-负载均衡" class="headerlink" title="3. 负载均衡"></a>3. 负载均衡</h3><p>因为一个网关可以接收多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单点就是直接 Round-Robin 轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到 session 粘连。</p><h3 id="4-弹力设计"><a href="#4-弹力设计" class="headerlink" title="4. 弹力设计"></a>4. 弹力设计</h3><p>网关还可以把弹力设计中的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去。这样，同样可以像 Service Mesh 那样，让应用服务只关心自己的业务逻辑（或是说数据面上的事）而不是控制逻辑（控制面）。</p><h3 id="5-安全方面"><a href="#5-安全方面" class="headerlink" title="5. 安全方面"></a>5. 安全方面</h3><p>SSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。错误处理越靠前的位置就是越好，所以，网关可以做到一个全站的接入组件来对后端的服务进行保护。当然，网关还可以做更多更有趣的事情，比如：灰度发布、API聚合、API编排。</p><h4 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h4><p>网关完全可以做到对相同服务不同版本的实例进行导流，还可以收集相关的数据。这样对于软件质量的提升，甚至产品试错都有非常积极的意义。</p><h4 id="API-聚合"><a href="#API-聚合" class="headerlink" title="API 聚合"></a>API 聚合</h4><p>使用网关可以将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。于是，我们可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）。</p><h4 id="API-编排"><a href="#API-编排" class="headerlink" title="API 编排"></a>API 编排</h4><p>同样在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。</p><h2 id="网关设计重点"><a href="#网关设计重点" class="headerlink" title="网关设计重点"></a>网关设计重点</h2><p>网关设计重点主要是三个， 高性能、高可用、高扩展:</p><h3 id="1-高性能"><a href="#1-高性能" class="headerlink" title="1. 高性能"></a>1. 高性能</h3><p>在技术设计上，网关不应该也不能成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务一定要使用异步非阻塞的 I&#x2F;O 来确保后端延迟不会导致应用程序中出现性能问题。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I&#x2F;O Completion Port 的异步 IO 模型，Java 下如 Netty、Spring Reactor 的 NIO 框架。</p><h3 id="2-高可用"><a href="#2-高可用" class="headerlink" title="2. 高可用"></a>2. 高可用</h3><p>因为所有的流量或调用经过网关，所以网关必须成为一个高可用的技术组件，它的稳定直接关系到了所有服务的稳定。网关如果没有设计，就会成变一个单点故障。因此，一个好的网关至少要做到以下几点。</p><p>集群化 。网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。</p><p>服务化 。网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置。</p><p>持续化 。比如重启，就是像 Nginx 那样优雅地重启。有一个主管请求分发的主进程。当我们需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。</p><h3 id="3-高扩展"><a href="#3-高扩展" class="headerlink" title="3. 高扩展"></a>3. 高扩展</h3><p>因为网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。而我们都知道，业务逻辑是多变和不确定的。比如，需要在网关上加入一些和业务相关的东西。因此，一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。</p><p>另外，在运维方面 ，网关应该有以下几个设计原则。</p><ul><li><p>业务松耦合，协议紧耦合 。在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。</p></li><li><p>应用监视，提供分析数据 。网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用 Tracing ID 实施分布式链路跟踪，并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。</p></li><li><p>用弹力设计保护后端服务 。网关上一定要实现熔断、限流、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据。你可以考虑一下这样的设计。</p></li><li><p>DevOps 。因为网关这个组件太关键了，所以需要 DevOps 这样的东西，将其发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。</p></li></ul><h2 id="网关设计注意事项"><a href="#网关设计注意事项" class="headerlink" title="网关设计注意事项"></a>网关设计注意事项</h2><ol><li><p>不要在网关中的代码里内置聚合后端服务的功能，而应考虑将聚合服务放在网关核心代码之外。可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。</p></li><li><p>网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。这里多说一句，网关处理的静态内容应该靠近用户（应该放到 CDN 上），而网关和此时的动态服务应该靠近后端服务。</p></li><li><p>网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过 DNS 轮询的方式实现，要么通过 CDN 来做流量调度，或者通过更为底层的性能更高的负载均衡设备。</p></li><li><p>对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都去查一下相关的服务所在的地方。当然，如果你的系统不复杂，可以考虑把服务发现的功能直接集成进网关中。</p></li><li><p>为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。</p></li></ol><p>另外，因为网关是为用户请求和后端服务的桥接装置，所以需要考虑一些安全方面的事宜。具体如下：</p><ul><li><p>加密数据 。可以把 SSL 相关的证书放到网关上，由网关做统一的 SSL 传输管理。</p></li><li><p>校验用户的请求 。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。但是，我们需要权衡一下，网关是否需要校验用户的输入。因为这样一来，网关就需要从只关心协议头，到需要关心协议体。而协议体中的东西一方面不像协议头是标准的，另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能。对此，我想说的是，看具体需求，一方面如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。</p></li><li><p>检测异常访问 。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；还比如，同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击。</p></li></ul><h2 id="流量网关"><a href="#流量网关" class="headerlink" title="流量网关"></a>流量网关</h2><p>流量网关，顾名思义就是控制流量进入集群的网关，有很多工作需要在这一步做，对于一个服务集群，势必有很多非法的请求或者无效的请求，这时候要将请求拒之门外，降低集群的流量压力。<br><img src="/image-105.png" alt="Alt text"><br>定义全局性的、跟具体的后端业务应用和服务完全无关的策略网关就是上图所示的架构模型——流量网关。流量网关通常只专注于全局的Api管理策略，比如全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等，有点类似防火墙。Kong 就是典型的流量网关。</p><p>下面是kong的架构图，来自官网：<a href="https://konghq.com/">https://konghq.com</a><br><img src="/image-106.png" alt="Alt text"><br>这里需要补充一点的是，业务网关一般部署在流量网关之后、业务系统之前，比流量网关更靠近业务系统。通常API网指的是业务网关。有时候我们也会模糊流量网关和业务网关，让一个网关承担所有的工作，所以这两者之间并没有严格的界线。</p><h2 id="业务网关"><a href="#业务网关" class="headerlink" title="业务网关"></a>业务网关</h2><p>当一个单体应用被拆分成许许多多的微服务应用后，也带来了一些问题。一些与业务非强相关的功能，比如权限控制、日志输出、数据加密、熔断限流等，每个微服务应用都需要，因此存在着大量重复的代码实现。而且由于系统的迭代、人员的更替，各个微服务中这些功能的实现细节出现了较大的差异，导致维护成本变高。另一方面，原先单体应用下非常容易做的接口管理，在服务拆分后没有了一个集中管理的地方，无法统计已存在哪些接口、接口定义是什么、运行状态如何。</p><p>网关就是为了解决上述问题。作为微服务体系中的核心基础设施，一般需要具备接口管理、协议适配、熔断限流、安全防护等功能，各种开源的网关产品（比如 zuul）都提供了优秀高可扩展性的架构、可以很方便的实现我们需要的一些功能、比如鉴权、日志监控、熔断限流等。</p><p>与流量网关相对应的就是业务网关，业务网关更靠近我们的业务，也就是与服务器应用层打交道，那么有很多应用层需要考虑的事情就可以依托业务网关，例如在线程模型、协议适配、熔断限流，服务编排等。下面看看业务网关体系结构:<br><img src="/image-107.png" alt="Alt text"><br>从这个途中可以看出业务网关主要职责以及所做的事情， 目前业务网关比较成熟的 API 网关框架产品有三个 分别是:Zuul1、Zuul2 和 SpringCloud Gateway， 后面再进行对比。</p><h2 id="常见网关对比"><a href="#常见网关对比" class="headerlink" title="常见网关对比"></a>常见网关对比</h2><p>既然对比，就先宏观上对各种网关有一个了解，后面再挑一些常用的或者说应用广泛的详细了解。</p><p>目前常见的开源网关大致上按照语言分类有如下几类：</p><p>Nginx+lua ：OpenResty、Kong、Orange、Abtesting gateway 等</p><p>Java ：Zuul&#x2F;Zuul2、Spring Cloud Gateway、Kaazing KWG、gravitee、Dromara soul 等</p><p>Go ：Janus、fagongzi、Grpc-gateway</p><p>Dotnet ：Ocelot</p><p>NodeJS ：Express Gateway、Micro Gateway</p><p>按照使用数量、成熟度等来划分，主流的有 5个：</p><p>OpenResty</p><p>Kong</p><p>Zuul、Zuul2</p><p>Spring Cloud Gateway</p><h3 id="1-OpenResty"><a href="#1-OpenResty" class="headerlink" title="1. OpenResty"></a>1. OpenResty</h3><p>OpenResty是一个流量网关，根据前面对流量网关的介绍就可以知道流量网关的指责。</p><p>OpenResty基于 Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。</p><p>通过揉和众多设计良好的 Nginx 模块，OpenResty 有效地把 Nginx 服务器转变为一个强大的 Web 应用服务器，基于它开发人员可以使用 Lua 编程语言对 Nginx 核心以及现有的各种 Nginx C 模块进行脚本编程，构建出可以处理一万以上并发请求的极端高性能的 Web 应用</p><p>OpenResty 最早是顺应 OpenAPI 的潮流做的，所以 Open 取自“开放”之意，而Resty便是 REST 风格的意思。虽然后来也可以基于 ngx_openresty 实现任何形式的 web service 或者传统的 web 应用。</p><p>也就是说 Nginx 不再是一个简单的静态网页服务器，也不再是一个简单的反向代理了。第二代的 openresty 致力于通过一系列 nginx 模块，把nginx扩展为全功能的 web 应用服务器。</p><p>ngx_openresty 是用户驱动的项目，后来也有不少国内用户的参与，从 openresty.org 的点击量分布上看，国内和国外的点击量基本持平。</p><p>ngx_openresty 目前有两大应用目标：</p><p>通用目的的 web 应用服务器。在这个目标下，现有的 web 应用技术都可以算是和 OpenResty 或多或少有些类似，比如 Nodejs， PHP 等等。ngx_openresty 的性能（包括内存使用和 CPU 效率）算是最大的卖点之一。</p><p>Nginx 的脚本扩展编程，用于构建灵活的 Web 应用网关和 Web 应用防火墙。有些类似的是 NetScaler。其优势在于 Lua 编程带来的巨大灵活性。</p><h3 id="2-Kong"><a href="#2-Kong" class="headerlink" title="2. Kong"></a>2. Kong</h3><p>Kong基于OpenResty开发，也是流量层网关， 是一个云原生、快速、可扩展、分布式的Api 网关。继承了OpenResty的高性能、易扩展性等特点。Kong通过简单的增加机器节点，可以很容易的水平扩展。同时功能插件化，可通过插件来扩展其能力。而且在任何基础架构上都可以运行。具有以下特性：</p><p>提供了多样化的认证层来保护Api。</p><p>可对出入流量进行管制。</p><p>提供了可视化的流量检查、监视分析Api。</p><p>能够及时的转换请求和相应。</p><p>提供log解决方案</p><p>可通过api调用Serverless 函数。</p><h4 id="Kong解决了什么问题"><a href="#Kong解决了什么问题" class="headerlink" title="Kong解决了什么问题"></a>Kong解决了什么问题</h4><p>当我们决定对应用进行微服务改造时，应用客户端如何与微服务交互的问题也随之而来，毕竟服务数量的增加会直接导致部署授权、负载均衡、通信管理、分析和改变的难度增加。</p><p>面对以上问题，API GATEWAY是一个不错的解决方案，其所提供的访问限制、安全、流量控制、分析监控、日志、请求转发、合成和协议转换功能，可以解放开发者去把精力集中在具体逻辑的代码，而不是把时间花费在考虑如何解决应用和其他微服务链接的问题上。</p><p>图片来自Kong官网:</p><p><img src="/image-108.png" alt="Alt text"><br>可以看到Kong解决的问题。专注于全局的Api管理策略，全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等。</p><h4 id="Kong的优点以及性能"><a href="#Kong的优点以及性能" class="headerlink" title="Kong的优点以及性能"></a>Kong的优点以及性能</h4><p>在众多 API GATEWAY 框架中，Mashape 开源的高性能高可用API网关和API服务管理层——KONG（基于 NGINX+Lua）特点尤为突出，它可以通过插件扩展已有功能，这些插件（使用 lua 编写）在API请求响应循环的生命周期中被执行。于此同时，KONG本身提供包括 HTTP 基本认证、密钥认证、CORS、TCP、UDP、文件日志、API请求限流、请求转发及 NGINX 监控等基本功能。目前，Kong 在 Mashape 管理了超过 15，000 个 API，为 200，000 开发者提供了每月数十亿的请求支持。</p><h4 id="Kong架构"><a href="#Kong架构" class="headerlink" title="Kong架构"></a>Kong架构</h4><p>Kong提供一些列的服务，这就不得不谈谈内部的架构:<br><img src="/image-109.png" alt="Alt text"><br>首先最底层是基于Nginx， Nginx是高性能的基础层， 一个良好的负载均衡、反向代理器，然后在此基础上增加Lua脚本库，形成了OpenResty，拦截请求， 响应生命周期，可以通过Lua编写脚本，所以插件比较丰富。</p><p>关于Kong的一些插件库以及如何配置，可以参考简书:开源API网关系统（Kong教程）入门到精通：<a href="https://www.jianshu.com/p/a68e45bcadb6">https://www.jianshu.com/p/a68e45bcadb6</a></p><h3 id="3-Zuul1-0"><a href="#3-Zuul1-0" class="headerlink" title="3. Zuul1.0"></a>3. Zuul1.0</h3><p>Zuul是所有从设备和web站点到Netflix流媒体应用程序后端请求的前门。作为一个边缘服务应用程序，Zuul被构建来支持动态路由、监视、弹性和安全性。它还可以根据需要将请求路由到多个Amazon自动伸缩组。</p><p>Zuul使用了一系列不同类型的过滤器，使我们能够快速灵活地将功能应用到服务中。</p><h4 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h4><p>过滤器是Zuul的核心功能。它们负责应用程序的业务逻辑，可以执行各种任务。</p><p>Type ：通常定义过滤器应用在哪个阶段</p><p>Async ：定义过滤器是同步还是异步</p><p>Execution Order ：执行顺序</p><p>Criteria ：过滤器执行的条件</p><p>Action ：如果条件满足，过滤器执行的动作</p><p>Zuul提供了一个动态读取、编译和运行这些过滤器的框架。过滤器之间不直接通信，而是通过每个请求特有的RequestContext共享状态。</p><p>下面是Zuul的一些过滤器:</p><h4 id="Incoming"><a href="#Incoming" class="headerlink" title="Incoming"></a>Incoming</h4><p>Incoming过滤器在请求被代理到Origin之前执行。这通常是执行大部分业务逻辑的地方。例如:认证、动态路由、速率限制、DDoS保护、指标。</p><h4 id="Endpoint"><a href="#Endpoint" class="headerlink" title="Endpoint"></a>Endpoint</h4><p>Endpoint过滤器负责基于incoming过滤器的执行来处理请求。Zuul有一个内置的过滤器（ProxyEndpoint），用于将请求代理到后端服务器，因此这些过滤器的典型用途是用于静态端点。例如:健康检查响应，静态错误响应，404响应。</p><h4 id="Outgoing"><a href="#Outgoing" class="headerlink" title="Outgoing"></a>Outgoing</h4><p>Outgoing过滤器在从后端接收到响应以后执行处理操作。通常情况下，它们更多地用于形成响应和添加指标，而不是用于任何繁重的工作。例如:存储统计信息、添加&#x2F;剥离标准标题、向实时流发送事件、gziping响应。</p><h4 id="过滤器类型"><a href="#过滤器类型" class="headerlink" title="过滤器类型"></a>过滤器类型</h4><p>下面是与一个请求典型的生命周期对应的标准的过滤器类型：</p><p>PRE ：路由到Origin之前执行</p><p>ROUTING ：路由到Origin期间执行</p><p>POST ：请求被路由到Origin之后执行</p><p>ERROR ：发生错误的时候执行</p><p>这些过滤器帮助我们执行以下功能：</p><p>身份验证和安全性 ：识别每个资源的身份验证需求，并拒绝不满足它们的请求</p><p>监控 ：在边缘跟踪有意义的数据和统计数据，以便给我们一个准确的生产视图</p><p>动态路由 ：动态路由请求到不同的后端集群</p><p>压力测试 ：逐渐增加集群的流量，以评估性能</p><p>限流 ：为每种请求类型分配容量，并丢弃超过限制的请求</p><p>静态响应处理 ：直接在边缘构建一些响应，而不是将它们转发到内部集群</p><h4 id="Zuul-1-0-请求生命周期"><a href="#Zuul-1-0-请求生命周期" class="headerlink" title="Zuul 1.0 请求生命周期"></a>Zuul 1.0 请求生命周期</h4><p><img src="/image-110.png" alt="Alt text"><br>Netflix宣布了通用API网关Zuul的架构转型。Zuul原本采用同步阻塞架构，转型后叫作Zuul2，采用异步非阻塞架构。Zuul2和Zuul1在架构方面的主要区别在于，Zuul2运行在异步非阻塞的框架上，比如Netty。Zuul1依赖多线程来支持吞吐量的增长，而Zuul 2使用的Netty框架依赖事件循环和回调函数。</p><h3 id="4-Zuul2-0"><a href="#4-Zuul2-0" class="headerlink" title="4. Zuul2.0"></a>4. Zuul2.0</h3><p>Zuul 2.0 架构图<br><img src="/image-111.png" alt="Alt text"><br>上图是Zuul2的架构，和Zuul1没有本质区别，两点变化：</p><p>前端用Netty Server代替Servlet，目的是支持前端异步。后端用Netty Client代替Http Client，目的是支持后端异步。</p><p>过滤器换了一下名字，用Inbound Filters代替Pre-routing Filters，用Endpoint Filter代替Routing Filter，用Outbound Filters代替Post-routing Filters。</p><p>Inbound Filters ：路由到 Origin 之前执行，可以用于身份验证、路由和装饰请求</p><p>Endpoint Filters ：可用于返回静态响应，否则内置的ProxyEndpoint过滤器将请求路由到Origin</p><p>Outbound Filters ：从Origin那里获取响应后执行，可以用于度量、装饰用户的响应或添加自定义header</p><p>有两种类型的过滤器：sync 和 async。因为Zuul是运行在一个事件循环之上的，因此从来不要在过滤中阻塞。如果你非要阻塞，可以在一个异步过滤器中这样做，并且在一个单独的线程池上运行，否则可以使用同步过滤器。</p><p>上文提到过Zuul2开始采用了异步模型</p><p>优势 是异步非阻塞模式启动的线程很少，基本上一个CPU core上只需启一个事件环处理线程，它使用的线程资源就很少，上下文切换(Context Switch)开销也少。非阻塞模式可以接受的连接数大大增加，可以简单理解为请求来了只需要进队列，这个队列的容量可以设得很大，只要不超时，队列中的请求都会被依次处理。</p><p>不足 ，异步模式让编程模型变得复杂。一方面Zuul2本身的代码要比Zuul1复杂很多，Zuul1的代码比较容易看懂，Zuul2的代码看起来就比较费劲。另一方面异步模型没有一个明确清晰的请求-&gt;处理-&gt;响应执行流程(call flow)，它的流程是通过事件触发的，请求处理的流程随时可能被切换断开，内部实现要通过一些关联id机制才能把整个执行流再串联起来，这就给开发调试运维引入了很多复杂性，比如你在IDE里头调试异步请求流就非常困难。另外ThreadLocal机制在这种异步模式下就不能简单工作，因为只有一个事件环线程，不是每个请求一个线程，也就没有线程局部的概念，所以对于CAT这种依赖于ThreadLocal才能工作的监控工具，调用链埋点就不好搞(实际可以工作但需要进行特殊处理)。</p><p>总体上，异步非阻塞模式比较适用于IO密集型(IO bound)场景，这种场景下系统大部分时间在处理IO，CPU计算比较轻，少量事件环线程就能处理。</p><h4 id="Zuul-与-Zuul-2-性能对比"><a href="#Zuul-与-Zuul-2-性能对比" class="headerlink" title="Zuul 与 Zuul 2 性能对比"></a>Zuul 与 Zuul 2 性能对比</h4><p><img src="/image-112.png" alt="Alt text"><br>Netflix给出了一个比较模糊的数据，大致Zuul2的性能比Zuul1好20%左右 ，这里的性能主要指每节点每秒处理的请求数。为什么说模糊呢？因为这个数据受实际测试环境，流量场景模式等众多因素影响，你很难复现这个测试数据。即便这个20%的性能提升是确实的，其实这个性能提升也并不大，和异步引入的复杂性相比，这20%的提升是否值得是个问题。Netflix本身在其博文22和ppt11中也是有点含糊其词，甚至自身都有一些疑问的。</p><h3 id="5-Spring-Cloud-Gateway"><a href="#5-Spring-Cloud-Gateway" class="headerlink" title="5. Spring Cloud Gateway"></a>5. Spring Cloud Gateway</h3><p>SpringCloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。</p><p>SpringCloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 2.0之前的非Reactor模式的老版本。而为了提升网关的性能，SpringCloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。</p><p>Spring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控&#x2F;指标，和限流。</p><p>Spring Cloud Gateway 底层使用了高性能的通信框架Netty 。</p><p>SpringCloud Gateway 特征</p><p>SpringCloud官方，对SpringCloud Gateway 特征介绍如下：</p><p>（1）基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0</p><p>（2）集成 Hystrix 断路器</p><p>（3）集成 Spring Cloud DiscoveryClient</p><p>（4）Predicates 和 Filters 作用于特定路由，易于编写的 Predicates 和 Filters</p><p>（5）具备一些网关的高级功能：动态路由、限流、路径重写</p><p>从以上的特征来说，和Zuul的特征差别不大。SpringCloud Gateway和Zuul主要的区别，还是在底层的通信框架上。</p><p>简单说明一下上文中的三个术语：</p><h4 id="Filter-（过滤器）"><a href="#Filter-（过滤器）" class="headerlink" title="Filter （过滤器）"></a>Filter （过滤器）</h4><p>和Zuul的过滤器在概念上类似，可以使用它拦截和修改请求，并且对上游的响应，进行二次处理。过滤器为org.springframework.cloud.gateway.filter.GatewayFilter类的实例。</p><h4 id="Route-（路由）"><a href="#Route-（路由）" class="headerlink" title="Route （路由）"></a>Route （路由）</h4><p>网关配置的基本组成模块，和Zuul的路由配置模块类似。一个Route模块 由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。</p><h4 id="Predicate-（断言）："><a href="#Predicate-（断言）：" class="headerlink" title="Predicate （断言）："></a>Predicate （断言）：</h4><p>这是一个 Java 8 的 Predicate，可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。断言的 输入类型是一个 ServerWebExchange。</p><h3 id="几种网关的对比"><a href="#几种网关的对比" class="headerlink" title="几种网关的对比"></a>几种网关的对比</h3><p><img src="/image-113.png" alt="Alt text"><br>作者：等不到的口琴</p><p>来源：&#x2F;&#x2F;<a href="http://www.cnblogs.com/Courage129/p/14446586.html">www.cnblogs.com/Courage129/p/14446586.html</a></p><p>版权申明：内容来源网络，仅供分享学习，版权归原创者所有。除非无法确认，我们都会标明作者及出处，如有侵权烦请告知，我们会立即删除并表示歉意。谢谢!</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gateway </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubeovn underlay 相关概念</title>
      <link href="/2023/11/02/kubernetes/kube-ovn-underlay/"/>
      <url>/2023/11/02/kubernetes/kube-ovn-underlay/</url>
      
        <content type="html"><![CDATA[<p>在计算机网络中，Provider Network（提供商网络）是一个由服务提供商或网络管理员管理的网络，它为用户提供网络连接和服务。Provider Network通常包含多个VLAN（虚拟局域网）和Subnet（子网）。</p><p>VLAN是一种逻辑上的局域网，它可以将物理网络中的设备划分为不同的逻辑组，以便进行管理和访问控制。在Provider Network中，VLAN通常用于将用户设备划分为不同的逻辑子网，以便提供更好的隔离和管理。</p><p>Subnet是IP网络的一部分，它使用子网掩码来划分网络地址空间。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。在Provider Network中，Subnet通常用于将不同的用户设备分配到不同的IP子网中，以便进行路由和访问控制。</p><p>Provider Network、VLAN和Subnet之间的关系和作用如下：</p><p>Provider Network是整个网络的框架，它提供了用户设备与外部网络或服务之间的连接。<br>VLAN在Provider Network中起到了逻辑隔离的作用，它将用户设备划分为不同的逻辑子网，以便更好地管理和控制网络流量。<br>Subnet是IP网络的一部分，它在Provider Network中定义了IP地址的分配范围和子网掩码。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。<br>VLAN和Subnet之间存在一定的关联。一个VLAN可以包含多个Subnet，每个Subnet都是IP网络的一部分。在Provider Network中，VLAN和Subnet的组合使用可以更好地管理网络流量和控制访问权限。<br>总之，Provider Network、VLAN和Subnet之间的关系是相互依存的。Provider Network提供了整个网络的框架和连接能力，VLAN起到了逻辑隔离的作用，而Subnet则定义了IP地址的分配范围和子网掩码。这些技术的组合使用可以提供更好的网络管理和控制能力。</p>]]></content>
      
      
      
        <tags>
            
            <tag> kubeovn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>看完这篇，成为Grafana高手</title>
      <link href="/2023/10/31/kubernetes/grafana-dashboard/"/>
      <url>/2023/10/31/kubernetes/grafana-dashboard/</url>
      
        <content type="html"><![CDATA[<p>看完这篇，成为Grafana高手<br>原创 huhuli 腾讯VATeam 2022-09-30 14:08 发表于广东<br><a href="https://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ">https://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ</a></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>QQ直播前端团队接入腾讯云前端性能监控（RUM）后，对目前的监控能力以及上报数据进行了梳理， 并着手进行了前端性能监控的专项建设，其中监控数据大盘建设是不可或缺的一环。<br>可视化的监控大盘可以清晰明了的观察到各项目运行情况，宏观上能快速进行项目间的横向对比，也可以非常便捷的进行项目各数据维度的详细展示，纵向的分析各指标数据的统计。</p><p><img src="/image-30.png" alt="Alt text"></p><p>通过对数据大盘支持能力的调研，我们采用Grafana进行了数据大盘的建设。通过搭建Grafana服务，然后添加监控上报数据，最终使得【QQ直播前端监控数据大盘】得以建设完成。</p><p>那么什么是Grafana？</p><p>Grafana 是一款开源的数据可视化工具，使用Grafana可以非常轻松的将数据转成图表(如下图)的展现形式来做到数据监控以及数据统计。</p><p>Grafana官方提供Linux，Windows，MacOS，Docker版本</p><p>下载链接:  <a href="https://grafana.com/get/">https://grafana.com/get/</a></p><p>本文将依托建设数据大盘的经验，重点介绍一下Grafana的使用，助力小伙伴们成为Grafana高手。</p><h1 id="数据与图表"><a href="#数据与图表" class="headerlink" title="数据与图表"></a>数据与图表</h1><p>数据的可视化都是通过图表为载体的，不同的图表可以将数据进行不同侧重点的展现，要进行数据大盘的建设，首先要对图表有一个简单的了解，这样才能在数据大盘搭建过程中选择合适的图表，合理的进行可视化效果的展示。</p><p>认识Grafana的图表<br>✦</p><p>Grafana 的图表的选择路径都是 在 Visualization 类目下进行图表的选择</p><p><img src="/image-31.png" alt="Alt text"></p><h2 id="1-折线图"><a href="#1-折线图" class="headerlink" title="1. 折线图"></a>1. 折线图</h2><p><img src="/image-32.png" alt="Alt text">           </p><p>示例图表：Time series</p><p>图表配置：Graph styles</p><p>a. style: Lines</p><p>b. Fill opacity: 3</p><p>c. Gradient mode: scheme</p><h2 id="2-柱状图"><a href="#2-柱状图" class="headerlink" title="2. 柱状图"></a>2. 柱状图</h2><p><img src="/image-39.png" alt="Alt text">         </p><p>示例图表：Time series</p><p>图表配置：Graph styles</p><p>a. style: Bars</p><p>b. Fill opacity: 3</p><p>c. Gradient mode: scheme</p><h2 id="3-点状图"><a href="#3-点状图" class="headerlink" title="3. 点状图"></a>3. 点状图</h2><p><img src="/image-33.png" alt="Alt text">        </p><p>示例图表：Time series</p><p>图表配置：Graph styles</p><p>a. style: Points</p><p>b. Point size: 5</p><p>c. Stack series: Normal</p><h2 id="4-饼状图"><a href="#4-饼状图" class="headerlink" title="4. 饼状图"></a>4. 饼状图</h2><p><img src="/image-34.png" alt="Alt text">          </p><p>示例图表：Pie chart</p><h2 id="5-单一状态图"><a href="#5-单一状态图" class="headerlink" title="5. 单一状态图"></a>5. 单一状态图</h2><p><img src="/image-35.png" alt="Alt text">          </p><p>示例图表：Stat</p><p>图表配置：Graph styles</p><p>a. style: Bars</p><p>b. Fill opacity: 3</p><p>c. Gradient mode: scheme</p><h2 id="6-仪表盘"><a href="#6-仪表盘" class="headerlink" title="6. 仪表盘"></a>6. 仪表盘</h2><p><img src="/image-36.png" alt="Alt text">        </p><p>示例图表：Gauge</p><h2 id="7-表格"><a href="#7-表格" class="headerlink" title="7. 表格"></a>7. 表格</h2><p><img src="/image-37.png" alt="Alt text">         </p><p>示例图表：Table</p><h2 id="8-文本"><a href="#8-文本" class="headerlink" title="8. 文本"></a>8. 文本</h2><p><img src="/image-38.png" alt="Alt text">           </p><p>示例图表：Text（支持Markdown 和 HTML两种格式）</p><h2 id="9-…"><a href="#9-…" class="headerlink" title="9. …"></a>9. …</h2><h1 id="数据与图表的搭配"><a href="#数据与图表的搭配" class="headerlink" title="数据与图表的搭配"></a>数据与图表的搭配</h1><h2 id="按照数据格式区分"><a href="#按照数据格式区分" class="headerlink" title="按照数据格式区分"></a>按照数据格式区分</h2><p>✦</p><p>柱状图， 折线图， 饼状图的图表都需要数据具有时间序列，用于展示在一定的时间区间或者是连续的时间范围内，单一数据或者多种分类数据的变化趋势，或者是数量占比。</p><p>状态图， 表格数据，仪表盘等则对数据没有时间序列要求，状态图，仪表盘可用于进行一些总结性的数据展示，例如速度，温度，进度，完成度等， 表格数据则更适合展示复杂数据或者多维度数据</p><h2 id="按照使用意图区分"><a href="#按照使用意图区分" class="headerlink" title="按照使用意图区分"></a>按照使用意图区分</h2><p>✦</p><p>数据比较：柱状图，折线图比较合适，可以实现单数据，多种类数据的比较，能清晰看到变化趋势</p><p>占比分类：饼图，仪表盘， 单一状态图等比较合适，可以清晰的看到每个数据整体性的占比</p><p>趋势比较：折线图，面积图(折线可设置覆盖面积) 等比较合适，能直观展现数据变化</p><p>分布类：饼图， 散点图 等比较合适</p><h2 id="其他-✦"><a href="#其他-✦" class="headerlink" title="其他      ✦"></a>其他      ✦</h2><p>文字类图表就如同名字含义一样，可用于展示文字相关信息，并且个性化定制程度，灵活性排布支持都非常高（得益于Markdown 和 HTML的强大灵活性）</p><p>表格对于日志类型，或者是其他多维度数据展示较为合适，适用于整体性给出一个报表，并且具备排序等公共功能，方便数据快速比较。</p><h2 id="数据与图表的添加与扩展"><a href="#数据与图表的添加与扩展" class="headerlink" title="数据与图表的添加与扩展"></a>数据与图表的添加与扩展</h2><p>数据源与图表的扩展Grafana都采用插件的形式，因此我们想要扩展某个类型的数据源或者图表时，都需要先在Grafana插件市场找到目标插件，然后进行安装，如下图代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM grafana/grafana:8.3.1</span><br><span class="line">USER root</span><br><span class="line">RUN grafana-cli plugins install grafana-clickhouse-datasource //数据源插件</span><br><span class="line">RUN grafana-cli plugins install auxmoney-waterfall-panel //图表插</span><br></pre></td></tr></table></figure><h2 id="数据源添加"><a href="#数据源添加" class="headerlink" title="数据源添加"></a>数据源添加</h2><p>✦</p><p>打开Grafana平台，点击左侧”设置”图标，进入DataSource管理面板。</p><p><img src="/image-40.png" alt="Alt text">               </p><p>在“Add data source”面板中选择合适的数据源，并配置数据库信息。下图以Promethrus为例，添加数据源需要进行必要的配置，例如数据源的ip，port以及鉴权信息等。</p><p><img src="/image-41.png" alt="Alt text">         </p><p><img src="/image-42.png" alt="Alt text">        </p><h2 id="图表插件添加"><a href="#图表插件添加" class="headerlink" title="图表插件添加"></a>图表插件添加</h2><p>✦</p><ol><li>打开Grafana平台，点击左侧”设置”图标，进入Plugins管理面板</li></ol><p> <img src="/image-43.png" alt="Alt text">          </p><ol start="2"><li>在tab 栏筛选已经安装的插件，就可以看到已经安装可以使用的插件</li></ol><p><img src="/image-44.png" alt="Alt text"></p><ol start="3"><li>图表面板已经安装，可以直接在创建面板的时候指定类型使用</li></ol><p><img src="/image-45.png" alt="Alt text">       </p><h1 id="Grafana入门使用"><a href="#Grafana入门使用" class="headerlink" title="Grafana入门使用"></a>Grafana入门使用</h1><p>这里需要区分两个概念：</p><p>看板（dashboard）: 一个或多个数据图表形成的集合</p><p>面板（panel）：组成看板的其中一个图表</p><h2 id="创建一个看板-dashboard"><a href="#创建一个看板-dashboard" class="headerlink" title="创建一个看板 (dashboard)"></a>创建一个看板 (dashboard)</h2><p>✦</p><p>创建一个数据可视化看板的前提是需要有数据源的接入， 具体具体接入方法见数据与图表的添加与扩展</p><ol><li>打开Grafana平台，点击左侧”加号”，点击Create类目下的Dashboard 按钮，新创建一个空表的看板， 会默认弹出四个添加panel的选项</li></ol><p><img src="/image-46.png" alt="Alt text"><br><img src="/image-47.png" alt="Alt text"></p><p>a.添加一个空白面板</p><p>b. 添加一个新的行，用于面板的分类</p><p>c. 从面板库添加一个面板</p><p>d. 从剪贴板添加一个面板，可以用来快速复制一个已有的面板</p><ol start="2"><li>点击看板右上角保存看板。<br><img src="/image-48.png" alt="Alt text"><br>a. 输入看板名称</li></ol><p>b. 输入简单描述文字</p><p>c. 选择看板所属目录（用来分类管理看板）</p><p>d. 可选为看板设置Tag，标记看板的特征，后期可根据Tag来筛选看板</p><p>e. 其他选项可按需自主定义</p><h2 id="创建面板-panel"><a href="#创建面板-panel" class="headerlink" title="创建面板 (panel)"></a>创建面板 (panel)</h2><p>✦</p><p><img src="/image-50.png" alt="Alt text">         </p><p>点击上图所示的图表，会弹出创建面板的四种选择，可以根据自己的需求自主创建，下面我们以创建空白面板为例</p><p>点击Add a new panel 按钮， 你就会创建一个空白数据的图表面板，如下图</p><p><img src="/image-51.png" alt="Alt text"></p><h2 id="面板数据的获取"><a href="#面板数据的获取" class="headerlink" title="面板数据的获取"></a>面板数据的获取</h2><p>前文已经提到， 创建一个数据可视化看板的前提是需要有数据源的接入，因此，我们想要获取数据，必须要进行数据源的接入</p><ol><li><p>选择数据源（Data source）<br><img src="/image-52.png" alt="Alt text"><br> 配置选择自己接入的数据源后，后续才能进行相关数据获取的语法编写，这里不同的数据源之前需要的语法也不一样，因此大家可以自己根据自己的条件自主选择， 因为QQ直播接入的数据源是influxdb, 因此后面的例子将会以influxdb语法为例。</p></li><li><p>SQL语句的编写</p></li></ol><p>Grafana的面板语法编辑有两种形式， 简易模式与高级模式</p><p>Grafana 一个面板支持多条SQL语句</p><p>a. 简易模式：简易模式数据的获取主要通过下拉框的形式选择具体的指标以及判断条件， 支持添加多个条件</p><p><img src="/image-53.png" alt="Alt text">   </p><p>高级模式：通过点击编辑图标可以进行编辑模式的切换，高级模式下为全部的SQL语句的编书写，此模式对于语法有一定的要求，但是获取数据会更加的灵活</p><p><img src="/image-54.png" alt="Alt text"></p><h2 id="面板的基础配置"><a href="#面板的基础配置" class="headerlink" title="面板的基础配置"></a>面板的基础配置</h2><p>在编辑完成数据获取的SQL语句之后，面板上应该已经有了相关数据的展示，此时可以根据自己的数据格式，以及展示诉求来选择对应的图表，图表具体选择参考上文数据与图表的搭配</p><p>我们以默认的Time series的折线图为例，简述一下面板的基础配置</p><p><img src="/image-55.png" alt="Alt text"></p><ol><li>面板的基础信息</li></ol><p><img src="/image-56.png" alt="Alt text">      </p><p>在通过SQL语句选择加载完成数据后，图表会有默认的样式给到我们，此时如果对面板无其他要求，只需配置一下面板的基础信息就可完成Grafana的看板配置</p><p>基础信息包括</p><p>a. 标题</p><p>b. 描述</p><p>c. 背景是否透明</p><ol start="2"><li>数据提示</li></ol><p><img src="/image-57.png" alt="Alt text">        </p><p>Tootip配置项用于配置当鼠标经过（hover）图表数据点的时候的提示信息， 可选为Single单个提醒， All显示所有数据， Hidden都不显示</p><p><img src="/image-58.png" alt="Alt text"></p><ol start="3"><li>图例（legend）显示设置</li></ol><p><img src="/image-59.png" alt="Alt text"></p><p>图例显示模式有三种</p><p>a. List (默认)， 图例数据横向依次展示</p><p>b. Table， 图例数据会按照表格形式展示</p><p>c. Hidden, 不展示图例</p><p>图例的位置</p><p>a. Bottom, 陈列在图表底部</p><p>b. Right, 陈列在图表的右侧</p><p> 图例值展示</p><p><img src="/image-60.png" alt="Alt text">      </p><p>此处会有一个下拉列表供我们选择图例的显示数据，默认不展示，用户也可以选择数据展示形式，例如最大值，最小值，平均值等</p><ol start="4"><li>坐标轴（Axis）配置</li></ol><p><img src="/image-61.png" alt="Alt text">         </p><p>坐标轴的基础配置一般只需要设置一下坐标轴的名称（Label）即可，其余的设置可以按照默认值不用修改，下面简述一下配置的含义</p><p>a. Width选项可以选择设置坐标轴（Label）的占比宽度</p><p>b. Soft min 以及 Soft max 用来设置纵坐标的显示的最大值最小值</p><p>c. Show gride lines 可以设置是否显示背景的网格线</p><p>d. Scale 用来设置是否进行数据的放大，目的是让数据对比更加清晰</p><p>通过以上对一个图表面板的基础配置，我们的一个图表基本上已经成型，可以达到数据可视化的正常显示目的，剩下的就是加强对自己数据格式类型的分析以及基于自己的可视化诉求来进行合适的图表面板的配置选择，就可以通过多个图表的添加来完成自己初版的数据可视化看板。</p><h1 id="Grafana进阶使用"><a href="#Grafana进阶使用" class="headerlink" title="Grafana进阶使用"></a>Grafana进阶使用</h1><p>当我们选择一个图表插件进行数据可视化的时候，图表的一些属性会帮我们设置好了默认值，但是基于兼容性更广的特性，这些默认值也许并不是我们选择图表最合适的展示效果，因此为了进一步提升图表的展示性，我们可以通过以下属性来进行面板的进一步美化。</p><h2 id="图表属性配置-Standard-options"><a href="#图表属性配置-Standard-options" class="headerlink" title="图表属性配置 (Standard options)"></a>图表属性配置 (Standard options)</h2><p>✦</p><p><img src="/image-62.png" alt="Alt text">              </p><p>此选项框中的属性配置，可以使得我们的数据展示更加的准确，例如纵坐标的单位，我们不想采用通用意义上的在Label上进行命名标注单位例如耗时（ms）, 那么就可以选择此处的单位属性（Unit）进行更精确的展示</p><ol><li>单位（Unit）</li></ol><p><img src="/image-63.png" alt="Alt text">              </p><p>在单位选项中， 你可以进行非常精细化的选择，选项框中几乎包含了所有品类用到的单位属性，例如百分比，长度单位，时间单位，角度单位等等</p><ol start="2"><li>显示范围（Min, Max）</li></ol><p>在Min, Max 选项中，允许用户输入一个数字进行显示范围的限制，那么图表上在显示范围之外的数据将不会在图表中显示，例如我将耗时限制在0~3000范围，那么3000以外的数据将会被隐藏</p><p><img src="/image-64.png" alt="Alt text"></p><ol start="3"><li><p>Decimals 选项可以用来设置纵坐标数据的小数点范围</p></li><li><p>Display Name 选项则可以用来设置图例显示名字，但是由于限制，只能在只有一类数据时比较适用，如果数据类别较多，单纯在此处设置会将全部图例数据覆盖，因此图例的名称最好在SQL语句编写的时候就做好展示。当然后面也会讲有别的方法进行多种图例数据别名的单独设置</p></li><li><p>图表颜色配置（Color scheme）</p></li></ol><p>一般图表颜色的展示都会有默认值，不过我们想要改变现在图表曲线的颜色分类可以在此处进行设置。</p><p><img src="/image-65.png" alt="Alt text"></p><p>我们可以选择整体图表的颜色走向或者是颜色分布，但是一般曲线展示的颜色还是会根据数据自己适配，因此如果我们想要改变某一条曲线的颜色，可以直接点击图例前面的颜色icon,进行颜色选择。我们可以根据提供选项进行选择，也可以自定义设置颜色。</p><p><img src="/image-66.png" alt="Alt text"></p><h2 id="阈值设置-Thresholds"><a href="#阈值设置-Thresholds" class="headerlink" title="阈值设置 (Thresholds)"></a>阈值设置 (Thresholds)</h2><p>✦</p><p>有些图表插件是支持设置阈值的， 阈值的设置可以使得我们对数据的合规程度有清晰的对比，能够直观的衡量出当前数据的质量，因此阈值设置也是面板美化展示的一个重要部分</p><p><img src="/image-67.png" alt="Alt text">              </p><p>如上图示例，我们设置对耗时的图表设置了两个阈值，上图的意义是：</p><ul><li><p>在3000ms和5000ms设置阈值</p></li><li><p>3000ms以下将视为健康，颜色标记为绿色</p></li><li><p>3000ms~5000ms视为亚健康，颜色标记黄色</p></li><li><p>5000ms以上视为警示，颜色标记为红色</p></li></ul><p>阈值的模式有两种选择</p><ol><li><p>绝对值, 即按照标记的阈值数据进行比较</p></li><li><p>百分比, 阈值为相对于最大值的占比</p></li></ol><p>阈值展示的形式有四种：</p><ol><li><p>不展示 （off）</p></li><li><p>只展示阈值线 （as lines）</p></li><li><p>只展示区域 （as filled regions）</p></li><li><p>同时展示阈值线和区域 （as filled regions and lines）</p></li></ol><p>下图为我们选择绝对值模式下，展示线和区域的阈值示例图， 由图可以看出数据在不同阈值区间的分布，以及与阈值的对比，因此我们能直观的评估出数据的质量</p><p><img src="/image-68.png" alt="Alt text">            </p><h2 id="数值映射-Value-mappings"><a href="#数值映射-Value-mappings" class="headerlink" title="数值映射 (Value mappings)"></a>数值映射 (Value mappings)</h2><p>✦</p><p><img src="/image-69.png" alt="Alt text">            </p><p>图表的展示都是由许多的值来组成的一个个点，连线，反过来讲，图表就是数据值的展现，在图表中， 有时候有些数据并不是我们理想的数值，或者说我们想特异性的让某些值显示为其他值（写SQL语句也可以实现）， 这时候可以使用数值映射选项</p><p><img src="/image-70.png" alt="Alt text"></p><p>数值映射的形式可以有以下四种</p><p>1 单纯的某个值映射</p><ol start="2"><li><p>一段范围区间映射</p></li><li><p>正则表达式映射</p></li><li><p>针对某类值映射</p></li></ol><p>例如在示例中，假如我们健康波段数据具体值不关心， 只是关心整体的数据波动范围是否在健康范围之内，我们可以把0~3000ms的范围映射为健康，那么再具体显示的时候，不再会有具体值给到我们，统一会展示健康，如下图：</p><p><img src="/image-71.png" alt="Alt text"></p><p>这个功能更加适用于表格数据，例如我们明确的将空数据映射为空或0的场景，如下图</p><p><img src="/image-72.png" alt="Alt text"></p><h2 id="数据覆盖-Overrides"><a href="#数据覆盖-Overrides" class="headerlink" title="数据覆盖 (Overrides)"></a>数据覆盖 (Overrides)</h2><p>✦</p><p>数据覆盖允许我们对之前已经设置好的图表进行个性化设置，它相当于图表更高级的设置，覆盖的范围可以是整个SQL语句获取的数据，也可以是数据中某一类图例数据</p><p><img src="/image-73.png" alt="Alt text">         </p><p>具体覆盖的数据类别：</p><p>1 某一类数据</p><ol start="2"><li><p>正则匹配到的数据</p></li><li><p>某些类型的数据</p></li><li><p>整个SQL查询的数据</p></li></ol><p>在设置了一个Override 之后，就可以进一步进行子项的配置，子项里面的属性几乎与上文介绍的图表属性一致</p><p><img src="/image-74.png" alt="Alt text">          </p><p>我们通过覆盖属性的配置，可以让修改到之前我们已经在整体设置好的图标样式</p><p>例如我们现在经过SQL查询，已经获取到了js_ready和css_ready的耗时数据，但是我们想让这两种数据对比更加明确，既能够清晰的看到整体的趋势，也能看到某类数据单独的变化，这时我们可以通过override属性进行配置，让两个数据的纵坐标分别在左右两边，并且数据展示用折线和柱状图分别表示。</p><p>具体override配置属性如下图：</p><p><img src="/image-75.png" alt="Alt text">              </p><p>对css_ready 数据配置：</p><ol><li><p>图表展示为柱状图， 柱状图数据点居中</p></li><li><p>纵坐标数据靠右展示，颜色为浅绿色</p></li><li><p>标题设置为CSS耗时（ms）</p></li></ol><p>对js_ready数据配置：</p><ol><li><p>默认基础配置折线图</p></li><li><p>默认纵坐标靠左展示</p></li><li><p>设置颜色红色</p></li><li><p>标题设置为JS耗时（ms）</p></li></ol><p>最终结果如下图：<br><img src="/image-76.png" alt="Alt text"></p><h2 id="变量与模板"><a href="#变量与模板" class="headerlink" title="变量与模板"></a>变量与模板</h2><p>✦</p><p>在Grafana里面，学会使用变量，会发现打开了新世界的大门，用好变量，可能你的工作量就会缩减一半，甚至更多。</p><p>变量的使用场景有很多，例如我们编写SQL语句中的时间选项（$__interval），就是内置的一个变量，通过这个时间变量，可以控制多个图表在不同时间范围内的展示情况，因此一个好的变量的使用，可以让我们只配置一个图表，达到展示不同条件下的数据的目的，而不用去为每一种情况设置一个图表。</p><p>模板在Grafana中最简单的含义就是任何一条包含变量的查询（query)。</p><p>【变量的设置】</p><p>变量的设置是基于看板的，看板内设置的变量，对看板内的所有面板是共享的</p><p>点击看板设置，进入变量设置页面</p><p><img src="/image-77.png" alt="Alt text"></p><p><img src="/image-78.png" alt="Alt text">            </p><p>【变量的种类】</p><p> <img src="/image-79.png" alt="Alt text">              </p><p>在添加一个变量的可选下拉框中，可以选择添加的变量类型，共计有以下几种变量可以选择</p><table><thead><tr><th align="left">变量类型</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">query</td><td align="left">查询变量允许编写可以返回指标名称、标签值或键列表的数据源查询。例如，查询变量可能会返回服务器名称, ID 或数据中心的列表。变量值随着数据源查询动态获取选项而变化。</td></tr><tr><td align="left">custom</td><td align="left">手动定义变量选项,使用逗号分隔的列表</td></tr><tr><td align="left">text box</td><td align="left">显示具有可选默认值的自由文本输入字段</td></tr><tr><td align="left">constant</td><td align="left">设置一个常量</td></tr><tr><td align="left">data source</td><td align="left">快速添加一个数据源的变量</td></tr><tr><td align="left">interval</td><td align="left">代表时间跨度的变量</td></tr><tr><td align="left">ad hoc filters</td><td align="left">自动添加到数据源的所有指标查询的键&#x2F;值过滤器（仅限 InfluxDB、Prometheus 和 Elasticsearch）</td></tr></tbody></table><p>添加变量的其他输入框选项可以直接根据英文的意义非常直白的看出，例如设置面标签信息，描述信息，以及设置是否在看板中隐藏，对于某些变量类型还可以设置是否可以多选或者是否包含所有的值的选项等等，这些设置可以根据自己的需求来选择。</p><p>【变量的使用】</p><p>设置完成变量之后，变量的使用有两种形式</p><p>$varname， 这是最直接的方式， 但是这种语法会有限制，就是不能在一个词的中间使用例如：apps.frontend.$varname.requests.count</p><ol><li>${var_name}， 如果想要在表达式中间插入变量，请使用此语法，另外这种语法还有一些高级用法，${var_name:<format>}，这种格式可以更好地控制 Grafana 如何插入值，具体的用法可以参考官方文档</li></ol><p>【变量简单使用示例】</p><p>沿用上文的数据，我们创建一个简单的自定义变量，url_event,如下图</p><p><img src="/image-80.png" alt="Alt text"></p><p>获取数据的时候,sql 语法就可以写成如下</p><p><img src="/image-81.png" alt="Alt text"></p><p>这样，我们只建立了一个图表面板，由于使用了变量，因此可以只用变量的切换就实现看板数据的变化，如下</p><p>变量选择 js_ready<br><img src="/image-82.png" alt="Alt text"><br>变量选择css_ready</p><p><img src="/image-83.png" alt="Alt text"></p><h2 id="Link的使用"><a href="#Link的使用" class="headerlink" title="Link的使用"></a>Link的使用</h2><p>✦</p><p>在Grafana中，可以使用链接来进行看板的跳转以及外链的跳转，并且link的使用也非常灵活。</p><p>在一个数据面板的设置中，link可以的设置主要有两种方式</p><ol><li>整个面板设置链接</li></ol><p><img src="/image-84.png" alt="Alt text">              </p><p>在数据面板的设置中，前文我们没有细讲link的选项，这里其实是为整个数据面板设置跳转链接的入口，通过此处设置link，可以在面板上增加一个icon, 实现我们在点击的时候进行跳转, 具体效果如下图</p><p><img src="/image-85.png" alt="Alt text">              </p><ol start="2"><li>为具体数据设置link(data links)</li></ol><p>data links属性设置一般只在柱状图、折线图、表格面板里才有，并且，如果没有搭配override属性进行个性化设置的话，默认每个数据点都会设置上跳转的链接，效果如下图</p><p><img src="/image-86.png" alt="Alt text"></p><p>这样的设置其实和整个面板设置link类似，因此不同的data links 最好和override属性搭配，来进行个性化的数据链接跳转，以达到不通数据跳转不同链接的目的。</p><h2 id="Link与变量的搭配"><a href="#Link与变量的搭配" class="headerlink" title="Link与变量的搭配"></a>Link与变量的搭配</h2><p>✦</p><p>Grafana的link设置非常灵活，在link设置中，可以直接使用已经设置的看板变量以及系统的变量来进行链接的组合。</p><p>甚至在data links的设置中，还可以直接使用SQL语句查询到的结果来进行链接的组合，这样也可达到不同数值设置不同的跳转链接的功能</p><p>在添加链接的时候，如果想查看可用变量列表，可以直接在数据链接URL字段中键入 $ 来查看变量列表，效果如下图：</p><p><img src="/image-87.png" alt="Alt text"></p><p>变量列表里的变量主要可以分为三个类型</p><p>a. 全局内建的变量，例如时间变量的 from, to</p><p>b. 用户创建的模板变量，例如上文示例创建的 url_event</p><p>c. 基于SQL语句查询出来的数据，一般都在fields字段下</p><p>通过引用变量来创建图表面板的跳转链接，可以较为灵活的实现基于数据的外链跳转以及更为高级的数据看板的之间的联动，下文要讲到的数据下钻就是基于data links 与变量的搭配来实现。</p><h1 id="Grafana高级使用"><a href="#Grafana高级使用" class="headerlink" title="Grafana高级使用"></a>Grafana高级使用</h1><h2 id="妙用Transform"><a href="#妙用Transform" class="headerlink" title="妙用Transform"></a>妙用Transform</h2><p>✦</p><p>前面讲的一些Grafana的使用，都是以SQL语句查询到的数据为基础，在图表可视化上进行的设置与操作，而Transform的功能，大部分是更底层的操作，直接对数据的操作，来达到改变图表展示的目的，是数据可视化之前的操作。</p><p>tranform 可以实现将我们查询到的数据进行进一步加工，例如可以进行数据筛选，计算，重命名，排序以及控制隐藏等功能。</p><p><img src="/image-88.png" alt="Alt text"></p><p>本文以几个较为典型的功能简单介绍一下</p><ol><li>通过计算添加数据（Add field from calculation）</li></ol><p><img src="/image-89.png" alt="Alt text">              </p><p>数据的计算有两种模式：</p><p>a. Reduce row： 分别对选择的特定字段数据的每一行进行聚合计算</p><p>b. Binary option： 选定的两个字段的值进行数学运算例如加减乘除</p><ol start="2"><li>转换数据的类型(Convert field type)</li></ol><p>可以将选择的特定字段的值的类型指定为固定的数据类型</p><p><img src="/image-90.png" alt="Alt text">              </p><ol start="3"><li>根据名称筛选数据展示(Filter data by name)</li></ol><p>a. 可以将SQL语句查询出的字段名称陈列，并且自定义数据的展示与否</p><p>b. 也可以直接根据正则表达式进行数据筛选</p><p><img src="/image-91.png" alt="Alt text"></p><ol start="4"><li>数据合并（Merge）</li></ol><p>类似sql中的join，根据时间序列来进行合并不同的字段数据成为个数据表</p><p><img src="/image-92.png" alt="Alt text"></p><ol start="5"><li>重命名（Rename by regex）</li></ol><p>可以使用这个功能来进行查询结果名称的转换，允许我们使用正则表达式来进行重命名内容的匹配</p><p><img src="/image-93.png" alt="Alt text">          </p><p>transform 还有很多实用的功能，这里就不一一陈列，如果有需要用到操作数据的功能，可以考虑transform功能，全部的功能可以直接看官方文档</p><h2 id="面板的Repeat"><a href="#面板的Repeat" class="headerlink" title="面板的Repeat"></a>面板的Repeat</h2><p>✦</p><p>面板的repeat 也是需要搭配变量功能来使用，图表面板会根据用户选择的变量个数来进行分别加载，因此，此功能使用的前提是变量的值要大于1个，并且设置了允许多个变量可选，见下图示例</p><p><img src="/image-94.png" alt="Alt text"></p><p>当前提条件满足后，可以在面板的repeat属性进行设置</p><p>repeat 可选加载的方向是横向还是纵向，并且可以设置最大的重复个数，来避免造成加载展示问题以及性能问题。</p><p>当设置完成后，并不会马上生效，需要保存然后退出此图表面板然后重新加载一下数据看板，然后数据图表就会根据我们选择的变量的个数来进行分别的展示。</p><p>以上文的示例设置之后，效果如图：</p><p><img src="/image-95.png" alt="Alt text"></p><h2 id="数据下钻"><a href="#数据下钻" class="headerlink" title="数据下钻"></a>数据下钻</h2><p>✦</p><p>要实现一个数据下钻，需要link搭配变量来进行看板之间的联动，主要的思路大体如下：</p><ol><li><p>模板看板B中设置好需要的变量</p></li><li><p>模板看板B查询数据时引用变量</p></li><li><p>在源图表面板A中设置跳转到模板看板B的链接，链接上引用我们设置或者是查询的变量内容</p></li><li><p>跳转至目标模板数据看板B时，模板看板B获取从link上带过来的变量值</p></li><li><p>变量赋值，模板看板B根据变量值刷新数据查询</p></li></ol><p>经过上面的步骤，那么一个数据看板之间的联动就完成了，剩下的步骤就是丰富变量的设置以及看板内图表面板的内容了。</p><p>那么如何从跳转过来的link上获取到携带过来的变量的值呢？</p><p>在上文我们设置变量来控制数据面板repeat的时候，我们设置了一个变量 url_event</p><p>当控制变量为 js_ready的时候，看板的整体URL是</p><p><img src="/image-96.png" alt="Alt text"></p><p>当控制变量为 css_ready的时候，看板的整体URL是</p><p><img src="/image-97.png" alt="Alt text"></p><p>因此我们可以看到，当我们看板设置变量并且使用的时候，变量的内容是以query的格式显示在URL上的，并且命名的格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var-&#123;your_var_name&#125; = &#123;your_var_value&#125;</span><br></pre></td></tr></table></figure><p>当变量在url上面显式的标记的时候，Grafana会主动获取链接上面声明的变量的值并赋值给模板变量。</p><p>因此根据上面的格式，我们可以在link上面构造上述的数据query格式，为模板的看板变量赋值。</p><p>于是实现一个的数据下钻整体流程都变得清晰了，下面我们还是以上文的例子来构造一个简单的数据下钻的例子</p><ol><li>构造一个整体的page render 数据看板 A</li></ol><p>将数据格式以table的形式展现，整体性的展示当天项目的render过程的各个事件平均耗时情况，如下图：</p><p><img src="/image-98.png" alt="Alt text"></p><ol start="2"><li>设置一个详细指标数据的模板看板 B</li></ol><p>新建另一个数据详情的看板，然后建立一个事件的变量</p><p><img src="/image-99.png" alt="Alt text"></p><p>编写具体事件详细数据的查询SQL语句，并引用变量</p><p><img src="/image-100.png" alt="Alt text"></p><ol start="3"><li>通过link实现看板之间的联动</li></ol><p>配置数据看板A的data link, 使得每一行数据可以进行下钻详情展示</p><p><img src="/image-101.png" alt="Alt text"></p><p>经过上述步骤，就完成可一个简单的数据下钻，实现可一个项目page render过程的整体数据的可视化，并且可以点击具体加载事件查看该事件详细的数据分布趋势</p><p>效果如下:<br><img src="/image-103.png" alt="Alt text"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Grafana是一款非常优秀的开源可视化工具，能非常方便的将数据进行可视化，非常适合数据大盘建设，以及做数据监控和数据统计的工作。</p><p>本文基于实际业务中建设监控数据大盘的经验，介绍了Grafana基本的一些图表概念和使用方法，并对不同的数据类型选取合适的可视化图表提供了一些建议和思考。</p><p>通过三个阶段的介绍，总结了Grafana进行数据可视化入门教程以及一些进阶使用技巧，希望能在未来你的业务中，数据大盘的建设过程中提供一些便利和思路。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> grafana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>chrony参数及常用命令介绍</title>
      <link href="/2023/10/27/linux/chrony/"/>
      <url>/2023/10/27/linux/chrony/</url>
      
        <content type="html"><![CDATA[<p>​</p><h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h1><p>在Kubernetes集群中，如果各节点的时间不一致，可能会带来以下影响：</p><p>资源调度问题：Kubernetes使用资源调度器来分配任务和计算资源。如果各个节点的时间不一致，可能会导致调度器无法准确判断任务的截止时间，从而影响任务的执行和资源的分配。<br>服务一致性问题：对于有状态的服务（如数据库），如果各个节点的时间不一致，可能会导致数据一致性问题。例如，如果在某个节点上写入了一条数据，然后在另一个时间不一致的节点上读取数据，可能会读取到过期的数据。<br>日志分析问题：在Kubernetes集群中，所有的日志都是按照时间顺序排列的。如果各个节点的时间不一致，可能会导致日志分析出现问题，如时间戳不匹配、事件顺序错误等。<br>容器同步问题：Kubernetes使用容器来运行任务。如果各个节点的时间不一致，可能会导致容器同步出现问题，如容器启动和停止的时间不一致等。<br>网络通信问题：Kubernetes集群中的各个节点通过网络进行通信。如果节点之间的时间不一致，可能会导致网络通信出现问题，如消息延迟、丢包等。<br>监控和报警问题：如果各个节点的时间不一致，可能会导致监控和报警系统出现问题。例如，报警阈值设置错误、监控数据不准确等。<br>采用chrony进行集群节点间时间同步。</p><p>#2. chrony配置文件介绍<br>ubuntu系统下chrony配置文件路径为&#x2F;etc&#x2F;chrony&#x2F;chrony.conf ，内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># Welcome to the chrony configuration file. See chrony.conf(5) for more</span><br><span class="line">server 192.168.0.206 iburst  #选择集群中一个节点作为服务器，这在集群无法连接外网是保证所有节点时间一直，其余所有节点从该节点获取时间同步。</span><br><span class="line">server ntp.aliyun.com iburst #外网ntp server</span><br><span class="line">server time1.cloud.tencent.com iburst</span><br><span class="line"># information about usuable directives.</span><br><span class="line"></span><br><span class="line"># This will use (up to):</span><br><span class="line"># - 4 sources from ntp.ubuntu.com which some are ipv6 enabled</span><br><span class="line"># - 2 sources from 2.ubuntu.pool.ntp.org which is ipv6 enabled as well</span><br><span class="line"># - 1 source from [01].ubuntu.pool.ntp.org each (ipv4 only atm)</span><br><span class="line"># This means by default, up to 6 dual-stack and up to 2 additional IPv4-only</span><br><span class="line"># sources will be used.</span><br><span class="line"># At the same time it retains some protection against one of the entries being</span><br><span class="line"># down (compare to just using one of the lines). See (LP: #1754358) for the</span><br><span class="line"># discussion.</span><br><span class="line">#</span><br><span class="line"># About using servers from the NTP Pool Project in general see (LP: #104525).</span><br><span class="line"># Approved by Ubuntu Technical Board on 2011-02-08.</span><br><span class="line"># See http://www.pool.ntp.org/join.html for more information.</span><br><span class="line">pool ntp.ubuntu.com        iburst maxsources 4</span><br><span class="line">pool 0.ubuntu.pool.ntp.org iburst maxsources 1</span><br><span class="line">pool 1.ubuntu.pool.ntp.org iburst maxsources 1</span><br><span class="line">pool 2.ubuntu.pool.ntp.org iburst maxsources 2</span><br><span class="line"></span><br><span class="line"># This directive specify the location of the file containing ID/key pairs for</span><br><span class="line"># NTP authentication.</span><br><span class="line">keyfile /etc/chrony/chrony.keys</span><br><span class="line"></span><br><span class="line"># This directive specify the file into which chronyd will store the rate</span><br><span class="line"># information.</span><br><span class="line">driftfile /var/lib/chrony/chrony.drift</span><br><span class="line"></span><br><span class="line"># Uncomment the following line to turn logging on.</span><br><span class="line">#log tracking measurements statistics</span><br><span class="line"></span><br><span class="line"># Log files location.</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line"># Stop bad estimates upsetting machine clock.</span><br><span class="line">maxupdateskew 100.0</span><br><span class="line"></span><br><span class="line"># This directive enables kernel synchronisation (every 11 minutes) of the</span><br><span class="line"># real-time clock. Note that it can’t be used along with the &#x27;rtcfile&#x27; directive.</span><br><span class="line">rtcsync</span><br><span class="line"></span><br><span class="line"># Step the system clock instead of slewing it if the adjustment is larger than</span><br><span class="line"># one second, but only in the first three clock updates.</span><br><span class="line">makestep 1 3 #此出可以设置为：makestep 3 -1 当误差大于三秒时执行步进调整，而不用等待微调</span><br><span class="line"></span><br><span class="line">allow all #允许所有ip访问本时间服务器</span><br><span class="line"></span><br><span class="line">local stratum 10 #即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端</span><br></pre></td></tr></table></figure><h1 id="3-常用命令"><a href="#3-常用命令" class="headerlink" title="3. 常用命令"></a>3. 常用命令</h1><p>timedatectl set-time “2023-10-27 12:30:50” ：修改时间<br>chronyc tracking： 服务当前同步状态的快照<br>chronyc sources -v：查看时间同步源<br>chronyc makestep：立即执行步进调整<br>systemctl status chronyd： 查看chronyd服务状态<br>systemctl restart chronyd: 重启chronyd服务</p><p>​</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> chrony </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>deepflow dashboard</title>
      <link href="/2023/10/18/kubernetes/deepflow-dashboard/"/>
      <url>/2023/10/18/kubernetes/deepflow-dashboard/</url>
      
        <content type="html"><![CDATA[<ol><li>Application-Service List<br>此dashboard包含两个部分，分别是Service List和EndPoint List。展示了服务时延，请求速率，成功率等信息。<br>1.2 Service List<br><img src="/image.png" alt="Alt text"><br>● Data Source： 数据源为DeepFlow<br>● auto_service： 筛选指定的service<br>● app_service:  筛选app_service<br>● signal_source: 筛选信号源<br>Auto Service<br>App Service<br>Signal Source<br>Request Rate<br>Delay Avg<br>Delay P75<br>Client Error Ratio<br>Server Error Ratio<br>对应k8s中service name</li></ol><p>分为三种类型信号源：<br>Packet (cBPF)、eBPF、OTel来自不同信号源数据有细微差距。<br>请求速率<br>平均时延<br>75%的请求时延时间段<br>客户端异常比例，通过客户端异常 &#x2F; 响应计算得，即 client_error &#x2F; response<br>服务端异常比例，通过服务端异常 &#x2F; 响应计算得，即 server_error &#x2F; response<br>1.3 Endpoint List<br><img src="/image-1.png" alt="Alt text"><br>服务端点时延信息。<br>2. Application - Cloud Host<br>此dashboard主要以kubernetes节点的角度展示了请求成功率时延等信息。<br><img src="/image-2.png" alt="Alt text"><br>● vm: 筛选指定节点<br>● protocol: 筛选指定协议<br>chost<br>Protocol<br>Request<br>Client error<br>Server error<br>Latency<br>云节点名<br>网络协议类型<br>请求速率<br>客户端错误百分比<br>服务端错误百分比<br>平均时延<br>3. Application - Cloud Host Map<br>此dashboard主要通过Map展示，当节点作为server，和当节点作为client两种角色情况下，请求时延，请求速率，客户端错误百分比，服务端百分比等信息。<br>3.1 当节点上服务作为服务端时：<br><img src="/image-3.png" alt="Alt text"><br>3.2 当节点上服务作为客户端时：<br><img src="/image-4.png" alt="Alt text"><br>4. Application - DNS Monitoring<br>该dashbord主要展示了dns协议请求信息，包括请求总数，客户端错误率，客户端错误数量，服务端错误率，服务段错误数量，DNS Topo，请求时延等等信息，可用于分析DNS解析相关错误。</p><p>4.1 Total Request、DNS Topo、Delay Distribution、Error<br><img src="/image-5.png" alt="Alt text"><br>这部分面板展示了DNS请求总数，客户端及服务端错误数量和错误率，DNS亲求拓扑，在Client Error(by client)面板中展示了客户端错误数量列表。<br>4.2 Server Error Ratio、Time Out、Delay<br><img src="/image-6.png" alt="Alt text"><br>这部分面板展示了DNS服务端错误百分比，服务端超时数量及按客户端统计列表；服务端时延，客户端时延等信息。<br>4.3 Request、Log Analysis、Request log Delay Distribution、Request Log<br><img src="/image-7.png" alt="Alt text"><br>● Request: 展示DNS服务请求速率、客户端请求数量和所占百分比。<br>● Log Analysis: 展示请求日志数量列表，可按服务端、客户端、成功或错误进行筛选。如图展示了失败的DNS请求客户端和请求域名列表及对应数量，通过Request Log（by response desc）可以看出错误都是Non-Existent Domain。通过Request Log Delay Distribution可看出请求日志时延。Reqeust Log展示例如请求日志列表。<br>5. Dubbo Monitoring - K8S<br><img src="/image-8.png" alt="Alt text"></p><p>Dubbo微服务监控。展示请求总数，服务连接，时延、错误、请求日志分析等内容。<br>6. Application - K8s Ingress<br><img src="https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/31b5dcc3-e80c-44df-b008-63f844c2fba3.png" alt="Alt text"></p><p>Ingress服务监控。展示请求、时延、错误、吞吐量等内容。<br>7. Application - K8s Pod<br>此dashboard展示了各个pod作为客户端和服务端发送请求的速率，错误率，时延等信息。<br><img src="/image-10.png" alt="Alt text"><br>我们以部署的测试服务deepflow-ebpf-spring-demo为例：<br>● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。<br>● workload：筛选工作负载。<br>● protocol：筛选网络协议。<br>7.1 Request面板<br>以redis-master-0 Redis为例，在此面板中可以看到名为redis-master-0的pod，网络协议Redis的最小请求速率（Min）为0.667 req&#x2F;s, 平均请求速率（Mean）为1.26 req&#x2F;s，最大请求速率1.33 req&#x2F;s。<br>7.2 Server error面板<br>展示了各pod指定网络协议的服务端错误百分比。<br>7.3 Latency面板<br>展示了各pod指定协议时延信息。<br>7.4 Pod List面板<br>指定pod,指定协议的请求速率，客户端错误百分比，服务端错误百分比，平均时延列表。<br>8. Application - K8s Pod Map<br>此dashboard展示了pod请求map,请求速率，服务段错误百分比，客户端错误百分比，时延等信息。<br>我们以部署的测试服务deepflow-ebpf-spring-demo为例：<br>● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。<br>● workload：筛选工作负载。<br>● protocol：筛选网络协议。<br>8.1 Show client<br><img src="/image-11.png" alt="Alt text"><br>此时展示指定namespace中所有pod作为服务端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。<br>8.2 Show server<br><img src="/image-12.png" alt="Alt text"><br>此时展示指定namespace中所有pod作为客户端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。<br>9. Application - Redis Monitoring - Cloud<br>此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。<br><img src="/image-13.png" alt="Alt text"><br>● Cloud Host: 按节点筛选redis服务<br>● IP: 按IP筛选redis服务<br>10. Application - Redis Monitoring - K8S<br>此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。<br><img src="https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/7a2ab804-36f5-4ef2-a9fc-dc4a477851c7.png" alt="Alt text"><br>● cluster： 筛选指定集群<br>● Redis Service: 筛选指定redis服务<br>● redis willdCard：通配符匹配<br>● Tap Side： 可选择不同的数据采集点，获取不同的指标，例如查看客户端网卡吞吐量，服务端网卡吞吐量等。</p><ol><li>Application - Request Log<br>此dashboard展示了请求日志相关数据。<br><img src="/image-15.png" alt="Alt text"><br>● 筛选条件：可根据cluster（集群名）、namespace（命名空间）、workload（工作负载名）、protocol（网络协议）、request_type（请求类型）、reqeust_resource（请求资源）、status（响应状态）进行数据筛选。<br>● Summary count: 请求数量摘要。以一分钟区间统计请求数量。<br>● Error Count: 请求错误数量。<br>● Latency histogram: 请求时延直方图。<br>● Request log: 请求日志，包括Start time(请求开始时间)，Client(客户端)、Server(服务端)、Tap Side(数据采集点)、Protocol(网络协议)、App Protocol(应用协议)、Request type(请求类型)、Request domain(请求域名)、Request resource(请求资源)、Response Status(响应状态)、Response Code(响应码)、Response Delay(响应时延)。</li><li>Application - Request Log - Cloud</li></ol><p><img src="/image-16.png" alt="Alt text"><br>此dashborad也是展示请求日志，与Application - Request Log展示内容相同，筛选条件不同：<br>● vm: 根据节点筛选<br>● protocol: 根据网络协议筛选<br>● request_type: 根据请求类型筛选<br>● reqeust_resource：根据请求资源筛选<br>● status：根据响应状态筛选<br>13. Application - SQL Monitoring - Cloud<br><img src="/image-18.png" alt="Alt text"><br>此dashboar展示了mysql相关数据库监控信息。<br>● 筛选条件：可根据client(客户端)、DB Host(数据库所在节点)、DB IP(数据库IP)、Client For SQL Analysis（需要SQL分析的客户端匹配.<br>● 展示内容：请求总数、客户端列表、topo概览、客户端服务端错误百分比及错误数及列表、连接数、平均活跃连接数、时延、时延客户端列表、SQL执行分析（SQL Statement、Request Type、响应状态、时延、AffectedRows、执行数量）、吞吐量、分布式追踪、SQL语句时延列表。<br>14. Application - SQL Monitoring - K8S<br><img src="/image-19.png" alt="Alt text"><br>此dashboar也是展示了mysql相关数据库监控信息。展示数据内容与SQL Monitoring - Cloud相同，筛选角度不同：<br>● client: 根据客户端筛选<br>● DB Cluster: 根据数据库所在集群筛选<br>● DB Service:  根据数据可服务筛选<br>● DB Wildcard: 根据数据库通配符筛选<br>● Tap Side: 根据数据采集点筛选<br>● Client For SQL Analysis：根据需要SQL分析的客户端匹配筛选<br>15. Distributed Tracing<br><img src="/image-20.png" alt="Alt text"><br>此dashboard展示了分布式调用追踪，可选择一个调用进行例如点击Request中的_id，就会显示其调用的Flame Graph(火焰图)。Service List展示了调用在各个Service所花费的时间和百分比。Request Log展示了请求体制数据，Related Data展示了相关数据。<br>● N： 通过 BPF 从网络流量中提取的 Span<br>● S:  通过 eBPF 从系统或应用函数调用中提取的 Span<br>Span 是分布式跟踪的基本构建块。分布式跟踪中的单个跟踪由一系列标记的时间间隔组成,称为跨度。跨度表示完成用户请求或事务的逻辑工作单元。在分布式链路跟踪中有两个重要的概念：跟踪（trace）和 跨度（ span）。trace 是请求在分布式系统中的整个链路视图，span 则代表整个链路中不同服务内部的视图，span 组合在一起就是整个 trace 的视图。<br>16. Distributed Tracing - Cloud<br><img src="/image-21.png" alt="Alt text"><br>此dashboard也展示了分布式调用追踪，与Distributed Tracing展示内容相同，筛选条件不同：<br>● vm: 根据节点筛选<br>● trace_id： 根据tarceID进行筛选，traceID是一个唯一标识符，用于跟踪整个分布式系统中的请求。它可以帮助我们追踪请求在整个系统中所经过的所有服务和操作，并且可以帮助我们在出现问题时快速定位问题。<br>● span_id：根据SpanID进行筛选，traceid 在请求的整个调用链中始终保持不变，所以在日志中可以通过 traceid 查询到整个请求期间系统记录下来的所有日志。请求到达每个服务后，服务都会为请求生成spanid，而随请求一起从上游传过来的上游服务的 spanid 会被记录成parent-spanid或者叫 pspanid。当前服务生成的 spanid 随着请求一起再传到下游服务时，这个spanid 又会被下游服务当做 pspanid 记录。<br>● request_resource：请求资源。<br>17. Network - Cloud Host<br><img src="/image-22.png" alt="Alt text"><br>此dashboard展示了各节点网络性能指标。可根据Vm(节点)进行筛选。<br>● Throught(bps): 展示了节点吞吐量，包括最小值、平均值、最大值。<br>● Retrans rate: 展示包重传率，包括最小值、平均值、最大值。<br>● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。<br>● TCP conn. establishment latency：TCP连接建立延迟指的是从客户端向服务器发起TCP连接请求，到服务器成功响应这个请求并建立起TCP连接所需的时间。这个延迟时间通常由网络延迟、服务器处理能力和其他因素决定。在高性能网络和服务器环境中，TCP连接建立延迟应该尽可能低。如果延迟时间过长，可能会导致用户体验不佳或者网络应用程序性能下降。<br>● Cloud Host List：展示节点网络性能详情列表。<br>chost<br>Throughput(bps)<br>Throughput(pps)<br>TCP new conn.<br>TCP retrans rate<br>TCP conn. establishment fail rate<br>TCP conn. establishment latency<br>TCP&#x2F;UDP data latency<br>节点名<br>是吞吐量的单位，表示每秒传输的比特数（bits per second）<br>是网络吞吐量的一种单位，表示每秒发送的分组数据包数量<br>TCP新建连接数<br>包重传率<br>TCP连接建立失败率<br>TCP连接建立延迟<br>TCP或UDP协议下数据传输的延迟时间。<br>TCP&#x2F;UDP data latency指的是TCP或UDP协议下数据传输的延迟时间。这是从数据发送端到接收端的时间，包括在网络中传输以及在发送和接收端的处理时间。这个延迟可能会受到网络拥堵、硬件性能、协议效率等因素的影响。一般来说，低延迟的通信对于实时性要求高的应用非常重要。<br>18. Network - Cloud Host Map<br>此dashboard展示了各节点，网络性能拓扑图。可根据VM(节点)，进行筛选。<br>18.1 Show Client<br><img src="https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/f5dfef4b-f7e9-4182-86b4-7dcd565b362c.png"><br>展示了指定节点作为服务短时，网络性能指标，通过拓扑图可以点至查看指定客户端服务端之间的数据传输速率。<br>在Cloud Host Path列表中展示的数据与Network - Cloud Host相比多了以下数据：<br>● CLient: 客户端名。<br>● Server: 服务端。<br>● Tap side: 数据采样点。<br>● Protocol: 网络协议。<br>● Server port: 服务端口。<br>18.2 Show Server<br><img src="https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/8fa5d9e2-859d-42c7-9d3d-a1e1edabcb96.png"><br>与show client展示内容相同，角度不同，此时展示当指定节点作为客户端时相关网络性能指标。<br>19.  Network - Flow Log<br><img src="/image-25.png" alt="Alt text"><br>此dashboard展示了网络流日志内容。<br>可根据cluster(集群)、namespace(命名空间)、workload(工作负载)进行筛选。<br>● Summary count: 日志总量摘要。<br>● Error count: 错误数量。<br>● TCP est.conn latency distribution：连接建立（establishment）延迟时间分布。<br>● TCP data latency distribution： 指的是在TCP协议下，数据传输延迟时间分布。<br>● Flow log：网络流日志列表，内容包括 start time(开始时间)、client(客户端)、server(服务端)、tap side(数据才采集点)、protocol(网络协议)、client port(客户端端口)、server port(服务端端口)、status(状态，由 close_type（流结束类型）与 protocol（协议）决定：正常结束&#x2F;周期性上报&#x2F;非TCP超时&#x3D;正常，客户端XX&#x3D;客户端异常，服务端XX&#x2F;TCP超时&#x3D;服务端异常，其他结束方式&#x3D;未知。)、Byte TX(发送字节数)、Byte RX(接收字节数)、TCP Client Retransmission(TCP客户端重传)、TCP Server Retransmission(TCP服务端重传)、Avg TCP Est. Delay(连接建立平均时延)、Avg Data Delay（数据传输平均时延）。<br>20. Network - Flow Log - Cloud<br><img src="https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/cbf20764-c8a8-48b3-a0c2-a023923ef515.png" alt="Alt text"><br>此dashboard展示的网络流日志内容与Flow Log相同，区别是筛选条件不同，此dashboard提供根据VM(节点)进行筛选，查看各节点上工作流日志。<br>21. Network - K8s Pod<br><img src="https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/334e9637-7366-4397-a79c-c61ec162c7f3.png"><br>此dashboard展示了pod的网络性能相关指标，可根据cluster、namespace、workload进行筛选。<br>● Throught(bps): 展示了pod网络吞吐量，包括最小值、平均值、最大值。<br>● Retrans rate: 展示pod包重传率，包括最小值、平均值、最大值。<br>● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。<br>● TCP conn. establishment latency：TCP连接建立延迟。<br>● Pod List： pod网络性能列表。<br>22.  Network - K8s Pod Map<br><img src="https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/85fd8ca0-bea9-43e3-8a12-1a9b82cac676.png"><br>网络性能全景图，点击路径可查看相关指标，包括bps、retrans_ratio(TCP 重传比例：TCP 重传比例，通过TCP 重传 &#x2F; 所有的包计算得，即 retrans &#x2F; packet)、tcp_establish_fail_ratio（建连-失败比例：建连-失败比例，通过 TCP 建连-失败次数 &#x2F; 所有的关闭连接计算得，即 tcp_establish_fail &#x2F; close_flow）、rtt(平均 TCP 建连时延,统计周期内，所有 TCP 建连时延的平均值)、art(平均数据时延:统计周期内，所有数据时延的平均值，数据时延包含 TCP&#x2F;UDP)等。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deepflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kibana create ILM</title>
      <link href="/2023/09/05/kubernetes/kibana-ilm/"/>
      <url>/2023/09/05/kubernetes/kibana-ilm/</url>
      
        <content type="html"><![CDATA[<h1 id="kibana设置ILM"><a href="#kibana设置ILM" class="headerlink" title="kibana设置ILM"></a>kibana设置ILM</h1><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><p>kibana version: v7.9.3</p><h2 id="2-设置ILM"><a href="#2-设置ILM" class="headerlink" title="2. 设置ILM"></a>2. 设置ILM</h2><h3 id="2-1-创建索引生命周期策略"><a href="#2-1-创建索引生命周期策略" class="headerlink" title="2.1 创建索引生命周期策略"></a>2.1 创建索引生命周期策略</h3><h4 id="2-1-1-热阶段"><a href="#2-1-1-热阶段" class="headerlink" title="2.1.1 热阶段"></a>2.1.1 热阶段</h4><p>首先需要先创建索引生命周期策略，在索引模板中可以引用创建好的索引生命周期策略。</p><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm01.png"></p><ul><li><p>策略名称： 引用该策略是需要用，例如设置为：filebeat-index-ilm</p></li><li><p>最大索引大小：设置单个索引最大字节数，此处为50千兆字节，即50G.</p></li><li><p>最大文档数：设置单个索引所内容乃的最大文档数，超过该数则创建新的索引。</p></li><li><p>最大存在时间： 指的是索引在温热阶段中可以存在的最长时间。一旦索引达到这个时间限制，它将被自动转移到冷却阶段，并最终被归档或删除。</p><p>“最大存在时间”是一个可选的参数，你可以根据实际需求来决定是否设置这个参数。如果你没有设置这个参数，索引将会一直保持在温热阶段，直到你手动将其转移到冷却阶段或删除。</p><p>在设置”最大存在时间”时，你可以选择一个固定的时间长度，例如30天。这意味着索引在温热阶段中最多存在30天，之后它将被自动转移到冷却阶段。这个参数可以帮助你控制索引的生命周期，避免过多的旧索引占用存储空间和资源。</p><p>需要注意的是，具体的索引生命周期策略还受到其他参数的影响，例如滚动布署的频率、索引模板、索引生命周期策略等。因此，在实际应用中，需要根据具体的业务需求和数据量来调整和优化这些参数。</p></li></ul><h4 id="2-1-2-温阶段和冷阶段"><a href="#2-1-2-温阶段和冷阶段" class="headerlink" title="2.1.2 温阶段和冷阶段"></a>2.1.2 温阶段和冷阶段</h4><p>温阶段和冷阶段不再设置，解释一下这两个阶段：</p><p>在 Kibana 中创建索引生命周期策略时，warm phase和Cold phase的存在有意义，它们适用于不同的场景。</p><ol><li>Warm phase（温阶段）：<br>  Warm phase是索引生命周期的中间阶段，适用于处理活跃但不再频繁更改的数据。在这个阶段，索引被用于的搜索和查询操作较多，因此需要保持良好的搜索性能。在温阶段，索引可以被滚动更新，以保持其当前的索引结构、映射和设置。</li></ol><p>  温阶段适用于以下场景：</p><ul><li>数据检索：如果您的应用程序需要从历史数据中检索信息，并且这些数据已经过了一段时间但仍然活跃，那么可以将索引设置为在温阶段。</li><li>数据归档和分析：如果您的应用程序需要将数据存储一段时间以便进行进一步的分析、报告或可视化，那么可以将索引设置为在温阶段。</li></ul><ol start="2"><li>Cold phase（冷阶段）：<br>  Cold phase是索引生命周期的后期阶段，适用于处理不再活跃的数据。在这个阶段，索引被用于的搜索和查询操作较少，因此可以降低存储成本和索引维护开销。在冷阶段，索引可以被归档和压缩，以进一步降低存储成本。</li></ol><p>  冷阶段适用于以下场景：</p><ul><li>数据归档：如果您的应用程序需要长期存储数据，并且这些数据不再被频繁地搜索和查询，那么可以将索引设置为在冷阶段。</li><li>数据保留策略：如果您的应用程序需要保留某些数据一段时间后将其删除，那么可以将索引设置为在冷阶段，并在达到保留期限时自动删除索引。</li></ul><p>  综上所述，温阶段和冷阶段的存在意义在于进一步优化索引生命周期的管理。通过将索引分阶段管理，可以更好地平衡性能、存储成本和维护开销，以满足不同的业务需求。</p><h4 id="2-1-3-删除阶段"><a href="#2-1-3-删除阶段" class="headerlink" title="2.1.3 删除阶段"></a>2.1.3 删除阶段</h4><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm03.png"></p><ul><li>删除倒计时： 设置日志多久之后删除。</li></ul><h3 id="2-2-创建索引模板"><a href="#2-2-创建索引模板" class="headerlink" title="2.2 创建索引模板"></a>2.2 创建索引模板</h3><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template01.png"></p><ul><li><p>名称：索引模板名</p></li><li><p>索引模式： 用来匹配应用于哪些索引，例如匹配filebeat-开头的索引;filebeat-*</p></li><li><p>优先级：是一个整数值，用于确定索引模板的优先级。较高的优先级值表示该索引模板具有更高的优先级。当多个索引模板匹配到同一个索引时，优先级最高的索引模板将被应用。</p></li><li><p>版本：是一个整数值，用于跟踪索引模板的版本号。你可以根据需要为每个索引模板设置一个唯一的版本号。当索引模板需要更新时，你可以增加版本号以确保新版本的索引模板被应用。</p></li><li><p>_meta 字段：_meta 字段是一个 JSON 对象，用于存储与索引模板相关的元数据。你可以在 _meta 字段中添加自定义的键值对，例如索引模板的创建时间、作者等信息。这些元数据可以在使用 Elasticsearch API 管理索引模板时进行访问和操作。</p></li></ul><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template02.png"></p><ul><li>选择组件： 引用已经创建好的组件模板</li></ul><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template03.png"></p><ul><li>索引设置: 图中设置了生命周期相关内容，lifecycle：指的就是索引的生命周期，这里就是我们之前创建的索引生命周期；rollover_alias：滚动别名，当我们配置了索引大小，超过这个大小后，会以这个名称命名。</li></ul><ol><li>映射字段：<br>  映射字段是指将文档中的字段与特定的数据类型和属性进行映射。在创建索引模板时，可以手动添加映射字段，以便在索引文档时将字段映射为指定的数据类型和属性。例如，可以添加一个名为 “message” 的映射字段，将其映射为文本类型，并设置其分析器为 “standard”。</li></ol><p>映射字段适用于以下场景：</p><ul><li><p>数据类型已知且固定的场景：当文档中的字段类型固定且已知时，可以手动添加映射字段，以确保索引的准确性和性能。</p></li><li><p>需要自定义数据类型的场景：当文档中存在自定义的数据类型时，可以手动添加映射字段，并将其映射为相应的数据类型，以便在查询和聚合时能够正确地处理数据。</p></li></ul><ol start="2"><li>动态模板：<br>  动态模板是指根据文档中的字段名、数据类型等动态地设定字段类型。在创建索引模板时，可以定义动态模板规则，以便根据文档的实际情况动态地设定字段类型。例如，可以定义一个名为 “text” 的动态模板，将所有以 “message” 开头的字段映射为文本类型。</li></ol><p>动态模板适用于以下场景：</p><ul><li><p>数据类型未知或动态变化的场景：当文档中的字段类型未知或动态变化时，可以使用动态模板来自动识别字段类型，并将其映射为相应的数据类型。</p></li><li><p>需要灵活处理不同数据类型的场景：当文档中存在多种数据类型时，可以使用动态模板来根据字段名、数据类型等信息动态设定字段类型，以便在查询和聚合时能够正确地处理数据。</p></li></ul><ol start="3"><li>高级选项：<br>  高级选项是指在创建索引模板时可以配置的一些高级设置，例如索引分片数、索引副本数、分析器等。这些设置可以优化索引的性能和存储效率。</li></ol><p>高级选项适用于以下场景：</p><ul><li>需要优化索引性能的场景：可以通过配置索引分片数和索引副本数来优化索引的性能，提高查询和聚合的速度。</li><li>需要优化存储效率的场景：可以通过配置存储设置和分析器来优化索引的存储效率，减少存储空间的使用.。</li></ul><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template05.png"></p><ul><li><p>设置索引别名</p><ol><li>方便对多个索引进行查询：如果你有许多索引并且经常需要同时查询这些索引，使用别名可以方便地将这些索引组合在一起进行查询。</li><li>简化索引引用：在查询时，只需要引用别名，而不需要写出完整的索引名称，这使得查询语句更加简洁。</li><li>方便索引的版本控制：如果你在系统中对索引进行更新或替换，使用别名可以使得对已有查询的影响最小化。例如，你可以创建一个别名，使其始终映射到最新的索引版本，这样在更新索引时，不需要更改所有查询。</li></ol><p>在 Elasticsearch 中创建别名的方法是通过使用 “alias” API。例如，如果你有一个索引 “test-20190120”，并想为其创建一个别名 “test”，你可以使用以下的请求：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT /_aliases  &#123;    <span class="string">&quot;actions&quot;</span>: [      &#123;        <span class="string">&quot;add&quot;</span>: &#123;          <span class="string">&quot;index&quot;</span>: <span class="string">&quot;test-20190120&quot;</span>,          <span class="string">&quot;alias&quot;</span>: <span class="string">&quot;test&quot;</span>        &#125;      &#125;    ]  &#125;</span><br></pre></td></tr></table></figure><p>在上述请求中，”add” 动作告诉 Elasticsearch 将别名 “test” 添加到索引 “test-20190120” 上。之后，你可以使用别名 “test” 来查询该索引的内容。</p></li></ul><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template06.png"></p><p>完成模板创建。</p><h2 id="3-生效"><a href="#3-生效" class="headerlink" title="3. 生效"></a>3. 生效</h2><p>创建索引生命周期之前的创建的索引不会受索引生命周期影响，之后创建的索引会进入到索引生命周期的策略管理中。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kibana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubevirt expose vm by svc</title>
      <link href="/2023/09/01/kubernetes/kubevirt-vm-expose/"/>
      <url>/2023/09/01/kubernetes/kubevirt-vm-expose/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>存在kubevit存在的三个虚机：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ubuntu-4tlg7   7d22h   Running   True</span><br><span class="line">ubuntu-7kgrk   7d22h   Running   True</span><br><span class="line">ubuntu-94kg2   7d22h   Running   True</span><br></pre></td></tr></table></figure><p>网络没有做透传，pod也不是underlay网络想要通过NodePort方式暴露虚机22端口进行远程登录。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><ol><li>修改vm资源实例，在spec.template.metada下添加labels设置,已存在的则不用添加。例如如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  runStrategy: RerunOnFailure</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        kubevirtvm01: kubevirtvm01</span><br></pre></td></tr></table></figure></li><li>重启虚机</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtctl -n wyl-vm restart ubuntu-4tlg7</span><br></pre></td></tr></table></figure><ol start="3"><li><p>暴露端口</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtctl expose vm ubuntu-4tlg7 --name ubuntu-4tlg7-ssh --port 22 --target-port 22 --type NodePort -n wyl-vm</span><br></pre></td></tr></table></figure></li><li><p>查看svc</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME               TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">ubuntu-4tlg7-ssh   NodePort   10.96.23.17   &lt;none&gt;        22:32581/TCP   14m</span><br></pre></td></tr></table></figure><p>使用节点ip地址加svc nodeport即可访问虚机。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubevirt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>grafana how to create alert rule</title>
      <link href="/2023/08/31/kubernetes/grafana-create-alert-rule/"/>
      <url>/2023/08/31/kubernetes/grafana-create-alert-rule/</url>
      
        <content type="html"><![CDATA[<h1 id="1-部署grafana的配置文件修改"><a href="#1-部署grafana的配置文件修改" class="headerlink" title="1. 部署grafana的配置文件修改"></a>1. 部署grafana的配置文件修改</h1><p>因为要采用发送邮件的方式通知告警内容所以，在部署grafana时要先配置好SMTP &#x2F; Emailing的内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[smtp]</span><br><span class="line">enabled = true # 开启smtp</span><br><span class="line">host = smtp.mxhichina.com:465  #设置邮箱服务器地址</span><br><span class="line">user = test@test.com  #设置邮箱用户</span><br><span class="line">password = test123456 #设置邮箱密码或授权码</span><br><span class="line">from_address = test@test.com #设置邮箱发送方地址</span><br><span class="line">from_name = Grafana #设置邮箱发送name</span><br></pre></td></tr></table></figure><h1 id="2-配置contact-points-告警通道"><a href="#2-配置contact-points-告警通道" class="headerlink" title="2. 配置contact points(告警通道)"></a>2. 配置contact points(告警通道)</h1><p>使用contact points定义在告警发生时如何通知联系人。包括创建message template和contact points。</p><h2 id="2-1-创建message-template-消息模板"><a href="#2-1-创建message-template-消息模板" class="headerlink" title="2.1 创建message template(消息模板)"></a>2.1 创建message template(消息模板)</h2><p>grafana的消息模板基于go语言的模板系统。如下模板数据表列出了可用于模板的变量</p><table><thead><tr><th>Name</th><th>Type</th><th>Notes</th></tr></thead><tbody><tr><td>Receiver</td><td>string</td><td>Name of the contact point that the notification is being sent to.</td></tr><tr><td>Status</td><td>string</td><td><code>firing</code> if at least one alert is firing, otherwise <code>resolved</code>.</td></tr><tr><td>Alerts</td><td>Alert</td><td>List of alert objects that are included in this notification (see below).</td></tr><tr><td>GroupLabels</td><td>KeyValue</td><td>Labels these alerts were grouped by.</td></tr><tr><td>CommonLabels</td><td>KeyValue</td><td>Labels common to all the alerts included in this notification.</td></tr><tr><td>CommonAnnotations</td><td>KeyValue</td><td>Annotations common to all the alerts included in this notification.</td></tr><tr><td>ExternalURL</td><td>string</td><td>Back link to the Grafana that sent the notification. If using external Alertmanager, back link to this Alertmanager.</td></tr></tbody></table><p>Alerts类型是一个过滤告警的函数：</p><ul><li><code>Alerts.Firing</code> returns a list of firing alerts.</li><li><code>Alerts.Resolved</code> returns a list of resolved alerts.</li></ul><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-message-template.png" alt="template"></p><p>define用来设置模板名，是可选的，如果不设置默认采用Template name,最佳实践时与Template name 保持一致。</p><h2 id="2-2-创建-contact-point"><a href="#2-2-创建-contact-point" class="headerlink" title="2.2 创建 contact point"></a>2.2 创建 contact point</h2><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-contact-point.png" alt="point"></p><p>创建name和不同类型的contact，包括邮箱，钉钉等，同一个name下可以添加多个contact。详细说一下邮箱类型的tact：</p><ul><li><p>Addresses: 接收通知的邮件地址，可以写多个，用英文分号（;)隔开。</p></li><li><p>Single email: 勾选表示发送一个邮件给所有的接受者。</p></li><li><p>message: 可以通过模板变量引用前面创建的模板：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;template &quot;alert message&quot; .&#125;&#125;</span><br></pre></td></tr></table></figure></li><li><p>Disable resloved message: 是否关闭告警解决通知。</p></li></ul><h1 id="3-创建通知策略（Notification-policies）"><a href="#3-创建通知策略（Notification-policies）" class="headerlink" title="3. 创建通知策略（Notification policies）"></a>3. 创建通知策略（Notification policies）</h1><p>通知策略通过label配置告警，通知指定 contact point设置接收告警通知的对象。</p><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/n-p.png" alt="np"></p><ul><li><p>matching labels： 添加指定的匹配label用于匹配alerts。</p></li><li><p>contact point: 设置创建好的指定的contact point.</p></li><li><p>Continue matching subsequent sibling nodes: 是否继续匹配嵌套策略。</p></li><li><p>Override grouping：是一种告警策略设置，可用于覆盖默认的告警分组工作方式。默认情况下，Grafana根据告警规则的标签对告警进行分组。但是，对于某些特殊情况，用户可能希望以不同的方式进行告警分组，这时就可以使用Override grouping来实现。</p><p>使用Override grouping，用户可以通过自定义指标和筛选条件来定义告警的分组方式。这样可以根据特定的业务需求，将相关的告警归为一组，便于在仪表盘中统一管理和查看。</p><p>Override grouping的设置涉及以下几个重要的概念：</p><ol><li>可聚合的字段：定义用于分组的字段，可以是任意的标签或指标。</li><li>聚合器：确定了要使用哪种方法来聚合分组，如平均值、最大值、最小值等。</li><li>时间范围：告警分组的时间范围，可以是一个固定的时间段或相对于当前时间的一段时间。</li></ol><p>用户可以根据具体情况选择合适的聚合字段、聚合器和时间范围来定义告警的分组方式。通过Override grouping，用户可以更加灵活地管理和控制告警的分组行为，从而更好地满足业务需求。</p></li><li><p>Override general timings（覆盖一般定时）：用来覆盖通用的重复和间隔定时。</p><p>具体来说，Grafana的告警策略中，可以设置一个重复间隔时间（Repeat interval），用于确定告警规则检查条件的重复间隔。默认情况下，这个间隔会使用Grafana的全局设置。</p><p>然而，有时候我们希望针对特定的告警规则使用不同的重复间隔时间，这就可以使用Override general timings（覆盖一般定时）来实现。通过勾选此选项，并设置相应的重复间隔时间，可以覆盖全局设置，使特定的告警规则使用不同的重复间隔时间。</p><p>这样做的好处是，可以根据特定的告警规则的需求，灵活地定义重复间隔时间，以更加精确和准确地监控和警告系统的状态变化。这对于保证系统的稳定性、性能和安全性非常有帮助。</p><ol><li><p>Group wait: 为传入警报创建的新组发送初始通知之前的等待时间。</p></li><li><p>Group interval: 发送第一个通知后为该组发送一批新警报的等待时间。</p></li><li><p>Repeat interval: 成功发送警报后重新发送警报的等待时间。</p></li></ol></li></ul><h1 id="4-创建告警规则（rule"><a href="#4-创建告警规则（rule" class="headerlink" title="4. 创建告警规则（rule)"></a>4. 创建告警规则（rule)</h1><p>rule有三种类型：</p><ul><li><p>Cortex or Loki managed alerting rule：创建由Cortex或者Loki管理的rule；需要对Prometheus或者其他数据源有读写权限。</p><p>Cortex和Loki都是与Grafana密切相关的工具。</p><p>Cortex是一个可扩展、多租户、分布式的时间序列数据库。它能够接收和存储大规模的指标数据，并提供高速查询、聚合和处理数据的能力。Cortex的设计目标是能够处理海量的时间序列数据，并且具有可水平扩展性和高可用性。Cortex允许用户通过内置的查询语言PromQL来查询和分析指标数据，并支持数据的可视化和报表功能。Cortex还提供了横向扩展的能力，可以轻松地增加存储容量和查询吞吐量。因此，Cortex适用于大规模监控系统中需要存储和查询大量指标数据的场景。</p><p>Loki是一个用于日志聚合和存储的系统。它可以接收多个来源的日志数据，并将它们存储为可搜索和可查询的格式。与传统的日志存储系统相比，Loki采用了一种高效的存储和索引方法，可以充分利用现代存储技术和硬件，以提供更高的性能和可扩展性。Loki支持使用标准的日志查询语言PromQL来查询和分析日志数据，并且与Cortex集成，可以实现和指标数据的混合查询和分析。此外，Loki还提供了强大的数据可视化和报表功能，可以方便地展示和监控系统的日志信息。</p><p>综上所述，Cortex和Loki是Grafana监控和可视化平台的两个重要组成部分。Cortex用于存储和查询大规模的指标数据，而Loki则用于存储和查询系统的日志数据。它们都具有高性能、可扩展性和易于使用的特点，能够满足大规模监控系统中对指标和日志数据的存储、查询和分析需求。</p></li><li><p>Cortex or Loki managed recording rule：创建recording类型的rule。</p></li><li><p>Grafana managed alerting rule：创建grafana管理的告警规则，我们主要介绍这个类型的规则。</p></li></ul><h2 id="4-2-Grafana-managed-alerting-rule"><a href="#4-2-Grafana-managed-alerting-rule" class="headerlink" title="4.2 Grafana managed alerting rule"></a>4.2 Grafana managed alerting rule</h2><p><img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-1.png"></p><ul><li><p>rule name: 告警规则名。</p></li><li><p>rule type: 告警规则类型。</p></li><li><p>Folder: 选择所属的Folder。</p></li><li><p>创建告警规则语句：</p><ol><li><p>选择数据源为Prometheus</p></li><li><p>查询展示的最近10分钟的数据。</p></li><li><p>Metrics browser: 设定数据查询的语句使用PromQL语法。</p></li><li><p>Legend: 根据查询出的数据变量设置显示指标名。</p></li><li><p>Min step: 最小步长表示图形里每两个点的最小数据间隔是多少，例如：这里我设置了 200，那表示图形上每隔 200 个单位才会有一个点。</p></li><li><p>Resolution： 这表示其数据精度是怎样的，是 1 比 1 的精度，还是原有的 1&#x2F;2，还是 1&#x2F;3 等等。如果是 1&#x2F;2 的话，那么就是原本 1 个单位显示一个点，现在 2 个单位合并起来显示成一个点了，那么其精度就变低了。</p></li><li><p>Format： 表示你的数据格式是什么，这里有：Time series、Table、Heap Map 三个选项。Time series 表示是时间序列数据，即随着时间的流动有源源不断的数据。Table 表示是一个表格数据。Heap Map 表示是热力图数据。</p></li><li><p>instant: 勾选时查询只在指定的单个时间点上执行，这对于需要聚合或对单个时间点数据感兴趣的场景非常有用。面板的时间选择器将被禁用，因为查询仅在一个固定时间点上执行。不勾选时：查询将返回一个时间范围内的数据，这对于需要在一段时间内进行数据分析或比较的情况非常有用。面板的时间选择器将启用，可以选择查询的时间范围。</p></li></ol><p>  <img src="https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-2.png"></p><p>  创建Expression（表达式）：</p><ul><li><p>classic condition:</p><ol><li><p><code>avg()</code>: 用于计算一段时间内的平均值。适用于告警需要基于平均值的场景。例如，如果需要在CPU平均负载超过阈值时触发告警，可以使用<code>avg()</code>函数。</p></li><li><p><code>last()</code>: 用于获取时间段内最后一个数据点的值。适用于告警需要基于最后一个数据点的场景。例如，如果需要在最后一个数据点超过阈值时触发告警，可以使用<code>last()</code>函数。</p></li><li><p><code>max()</code>: 用于计算一段时间内的最大值。适用于告警需要基于最大值的场景。例如，如果需要在CPU负载的最大值超过阈值时触发告警，可以使用<code>max()</code>函数。</p></li><li><p><code>min()</code>: 用于计算一段时间内的最小值。适用于告警需要基于最小值的场景。例如，如果需要在CPU负载的最小值低于阈值时触发告警，可以使用<code>min()</code>函数。</p></li><li><p><code>sum()</code>: 用于计算一段时间内的总和。适用于告警需要基于总和的场景。例如，如果需要在一段时间内的请求数总和超过阈值时触发告警，可以使用<code>sum()</code>函数。</p></li><li><p><code>count()</code>: 用于计算一段时间内的数据点数量。适用于告警需要基于数据点数量的场景。例如，如果需要在一段时间内的请求数量超过阈值时触发告警，可以使用<code>count()</code>函数。</p></li></ol><p>Define alert conditions: 定义告警状态：</p><ul><li><p>condition: 选择基于哪个query或者表达式进行告警。</p></li><li><p>Evaluate: 设置多久评估一次告警条件，</p></li><li><p>For： 满足条件持续多久触发告警，改变告警状态到firing.</p></li><li><p>Configure no data and error handling: 设定无数错和错误处理：</p><table><thead><tr><th>No Data Option</th><th>Description</th></tr></thead><tbody><tr><td>No Data</td><td>Create a new alert <code>DatasourceNoData</code> with the name and UID of the alert rule, and UID of the datasource that returned no data as labels.</td></tr><tr><td>Alerting</td><td>Set alert rule state to <code>Alerting</code>.</td></tr><tr><td>Ok</td><td>Set alert rule state to <code>Normal</code>.</td></tr></tbody></table><table><thead><tr><th>Error or timeout option</th><th>Description</th></tr></thead><tbody><tr><td>Alerting</td><td>Set alert rule state to <code>Alerting</code></td></tr><tr><td>OK</td><td>Set alert rule state to <code>Normal</code></td></tr><tr><td>Error</td><td>Create a new alert <code>DatasourceError</code> with the name and UID of the alert rule, and UID of the datasource that returned no data as labels.</td></tr></tbody></table></li></ul><p>Add details for your alert： 添加其他额外的alert信息。</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> grafana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>install metrics-server</title>
      <link href="/2023/08/25/kubernetes/metrics-server/"/>
      <url>/2023/08/25/kubernetes/metrics-server/</url>
      
        <content type="html"><![CDATA[<p>使用kubectl top命名需要安装metrics-server,否则会报错: error: Metrics API not available<br>使用如下yaml文件安装metrics-server:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">    <span class="attr">rbac.authorization.k8s.io/aggregate-to-admin:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">rbac.authorization.k8s.io/aggregate-to-edit:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">rbac.authorization.k8s.io/aggregate-to-view:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">system:aggregated-metrics-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">metrics.k8s.io</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nodes</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">system:metrics-server</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nodes/metrics</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nodes</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server-auth-reader</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">extension-apiserver-authentication-reader</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server:system:auth-delegator</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">system:auth-delegator</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">system:metrics-server</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">system:metrics-server</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--cert-dir=/tmp</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--secure-port=4443</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kubelet-use-node-status-port</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--metric-resolution=15s</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kubelet-insecure-tls</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.6.4</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">livenessProbe:</span></span><br><span class="line">          <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">          <span class="attr">httpGet:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/livez</span></span><br><span class="line">            <span class="attr">port:</span> <span class="string">https</span></span><br><span class="line">            <span class="attr">scheme:</span> <span class="string">HTTPS</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">4443</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="attr">readinessProbe:</span></span><br><span class="line">          <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">          <span class="attr">httpGet:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/readyz</span></span><br><span class="line">            <span class="attr">port:</span> <span class="string">https</span></span><br><span class="line">            <span class="attr">scheme:</span> <span class="string">HTTPS</span></span><br><span class="line">          <span class="attr">initialDelaySeconds:</span> <span class="number">20</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">runAsNonRoot:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">runAsUser:</span> <span class="number">1000</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">tmp-dir</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">priorityClassName:</span> <span class="string">system-cluster-critical</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">metrics-server</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line">        <span class="attr">name:</span> <span class="string">tmp-dir</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiregistration.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">APIService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">v1beta1.metrics.k8s.io</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">metrics.k8s.io</span></span><br><span class="line">  <span class="attr">groupPriorityMinimum:</span> <span class="number">100</span></span><br><span class="line">  <span class="attr">insecureSkipTLSVerify:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">service:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">metrics-server</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1beta1</span></span><br><span class="line">  <span class="attr">versionPriority:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f metrics-server.yaml</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EFK</title>
      <link href="/2023/08/24/kubernetes/efk/"/>
      <url>/2023/08/24/kubernetes/efk/</url>
      
        <content type="html"><![CDATA[<p>要在Kubernetes中部署Filebeat、Elasticsearch和Kibana来采集容器日志，可以按照以下步骤进行:</p><ol><li><p>部署Elasticsearch:<br>在Kubernetes集群上创建一个Elasticsearch的Deployment，这个Deployment将用于存储和索引日志数据。可以使用以下示例配置文件创建Deployment:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">elasticsearch</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">elasticsearch:7.12.1</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9200</span></span><br></pre></td></tr></table></figure><p>运行<code>kubectl apply -f elasticsearch.yaml</code>命令来创建Deployment。</p></li><li><p>部署Kibana:<br>在Kubernetes集群上创建一个Kibana的Deployment，这个Deployment将用于可视化和查询日志数据。可以使用以下示例配置文件创建Deployment:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">kibana:7.12.1</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">0.5</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5601</span></span><br></pre></td></tr></table></figure><p>运行<code>kubectl apply -f kibana.yaml</code>命令来创建Deployment。</p></li><li><p>部署Filebeat:<br>在Kubernetes集群上创建一个Filebeat DaemonSet，这个DaemonSet将在每个节点上运行一个Filebeat实例来收集容器日志。可以使用以下示例配置文件创建DaemonSet:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">filebeat</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">filebeat</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">filebeat</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">filebeat</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">filebeat</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">docker.elastic.co/beats/filebeat:7.12.1</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/docker/containers</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlogpod</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log/pods</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varrun</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/run</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibkubelet</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/kubelet</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlognode</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log/node</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlogcontainersnew</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log/containersnew</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dockersocket</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/run/docker.sock</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/filebeat/filebeat.yml</span></span><br><span class="line">          <span class="attr">subPath:</span> <span class="string">filebeat.yml</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">K8S_NODE_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">spec.nodeName</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NODE_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">spec.nodeName</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FILEBEAT_HOST</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">status.hostIP</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FILEBEAT_CONFIG_CHECK_FREQUENCY</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;5s&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">OUTPUT_TYPE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">elasticsearch</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ELASTICSEARCH_HOST</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">elasticsearch:9200</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ELASTICSEARCH_USERNAME</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;&lt;ELASTICSEARCH_USERNAME&gt;&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ELASTICSEARCH_PASSWORD</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;&lt;ELASTICSEARCH_PASSWORD&gt;&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ELASTICSEARCH_INDEX</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;filebeat-<span class="template-variable">%&#123;[agent.version]&#125;</span>-<span class="template-variable">%&#123;+yyyy.MM.dd&#125;</span>&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ELASTICSEARCH_PIPELINE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;&lt;ELASTICSEARCH_PIPELINE&gt;&quot;</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">100Mi</span></span><br><span class="line">        <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">        <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirstWithHostNet</span></span><br><span class="line">        <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br><span class="line">        <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/lib/docker/containers</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/log</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlogpod</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/log/pods</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varrun</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/run</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibkubelet</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/lib/kubelet</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlognode</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/log/node</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlogcontainersnew</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/log/containersnew</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dockersocket</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/run/docker.sock</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">filebeat-config</span></span><br><span class="line">    <span class="attr">updateStrategy:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">     <span class="attr">rollingUpdate:</span></span><br><span class="line">        <span class="attr">maxUnavailable:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>创建一个ConfigMap来存储Filebeat的配置文件(filebeat.yml)，示例配置文件可以参考以下内容:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">filebeat.config:</span></span><br><span class="line">  <span class="attr">modules:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">$&#123;path.config&#125;/modules.d/*.yml</span></span><br><span class="line">    <span class="attr">reload.enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="attr">filebeat.modules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">module:</span> <span class="string">system</span></span><br><span class="line">  <span class="attr">syslog:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">auth:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">package:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">coredns:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">output.elasticsearch:</span></span><br><span class="line">  <span class="attr">hosts:</span> [<span class="string">&#x27;elasticsearch:9200&#x27;</span>]</span><br><span class="line">  <span class="attr">username:</span> <span class="string">&#x27;&lt;ELASTICSEARCH_USERNAME&gt;&#x27;</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">&#x27;&lt;ELASTICSEARCH_PASSWORD&gt;&#x27;</span></span><br><span class="line">  <span class="attr">pipeline:</span> <span class="string">&#x27;&lt;ELASTICSEARCH_PIPELINE&gt;&#x27;</span></span><br></pre></td></tr></table></figure><p>运行<code>kubectl create configmap filebeat-config --from-file=filebeat.yml</code>命令来创建ConfigMap。</p><p>然后，运行<code>kubectl apply -f filebeat.yaml</code>命令来创建DaemonSet。</p></li><li><p>日志采集:<br>当Filebeat启动后，它将开始采集Kubernetes集群中所有容器的日志数据，并将其发送到Elasticsearch进行存储和索引。您可以使用Kibana来可视化和查询这些日志数据。</p></li></ol><p>这是一个简单的部署Filebeat、Elasticsearch和Kibana来采集Kubernetes集群中容器日志的示例配置。根据您的实际需求，可能还需要进行一些其他的配置和调整。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logging </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fluent Bit和Fluentd之间的联系及区别</title>
      <link href="/2023/08/24/kubernetes/fluent_Bit_Fluentd/"/>
      <url>/2023/08/24/kubernetes/fluent_Bit_Fluentd/</url>
      
        <content type="html"><![CDATA[<p>Fluent Bit和Fluentd是两个流行的开源日志收集工具，并且它们有一些共同的设计目标，但也有一些区别。</p><ol><li>Fluent Bit（轻量型的日志收集器）<br>Fluent Bit是一个轻量级和高性能的日志收集器，由Treasure Data公司开发。它专注于收集、过滤和转发日志，具有低内存占用和低性能开销的特点。Fluent Bit设计用于嵌入式系统和容器环境中，可以作为提供日志数据的终端。</li></ol><p>使用场景：</p><ul><li>IoT设备：Fluent Bit作为嵌入式日志收集器，适用于在资源有限的物联网设备上收集日志数据。</li><li>容器环境：Fluent Bit能够与Docker等容器平台无缝集成，并快速收集、聚合和转发容器日志。</li><li>边缘计算：部署在边缘节点的Fluent Bit能够实时收集和传输边缘设备上的日志数据。</li></ul><p>使用方式：</p><ul><li>配置管理：通过配置文件定义输入源、过滤规则和输出目标。</li><li>轻量级部署：由于其低资源消耗，Fluent Bit适合在嵌入式设备和容器中部署。</li><li>插件支持：提供多种插件，如输入、过滤和输出插件，可根据需求扩展功能。</li></ul><ol start="2"><li>Fluentd（全能型的日志收集引擎）<br>Fluentd是一个功能强大的开源日志收集和流数据处理引擎，也是由Treasure Data公司开发。它设计用于处理大规模和复杂的数据流，提供了更丰富的功能和灵活性。</li></ol><p>使用场景：</p><ul><li>日志聚合：收集来自多个源（文件、系统日志、应用程序日志等）的日志数据，并将其聚合到一处进行分析和存储。</li><li>实时大数据处理：通过Fluentd的插件生态系统，可以将数据发送到Hadoop、Elasticsearch等数据处理和存储平台。</li><li>日志路由和转换：Fluentd支持对日志数据进行过滤、标准化和转换，以便在不同目标之间进行路由。</li></ul><p>使用方式：</p><ul><li>插件生态系统：拥有丰富的插件生态系统，可用于收集、处理和转发各种类型的数据。</li><li>高度可配置：通过配置文件进行配置，可以定义输入源、过滤器和输出目标，并自定义数据流的处理逻辑。</li><li>部署灵活：Fluentd可以以独立进程或守护进程的形式部署，也可以在容器中运行。</li></ul><p>联系与区别：</p><ul><li>它们都是由Treasure Data公司开发的开源日志收集工具，具有类似的设计目标。</li><li>Fluent Bit更注重轻量级和高性能，适用于嵌入式和容器环境中的日志收集，而Fluentd则更适合处理大规模和复杂的数据流。</li><li>Fluent Bit的功能相对较少，专注于基本的日志收集、过滤和转发，而Fluentd具有更丰富的功能和插件生态系统。</li><li>Fluent Bit和Fluentd可以在同一系统中共存，实现多层次的日志收集和处理。</li></ul><p>总结：<br>Fluent Bit和Fluentd都是用于日志收集的工具，但根据应用场景和需求的不同，可以选择适合的工具。如果你需要一个轻量级的解决方案，以及在嵌入式设备和容器中高效收集和转发日志，可以选择Fluent Bit。而如果你面对复杂的数据流和需要更多功能和灵活性的场景，可以选择Fluentd。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logging </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>golang模板语法及预定义函数</title>
      <link href="/2023/08/23/golang/go_template/"/>
      <url>/2023/08/23/golang/go_template/</url>
      
        <content type="html"><![CDATA[<p>在Go语言中，使用模板可以通过<code>text/template</code>或者<code>html/template</code>包来实现。这两个包的主要区别是，<code>html/template</code>包会自动对输出进行转义，以防止跨站点脚本攻击。</p><p>下面是<code>text/template</code>和<code>html/template</code>包中常用的模板语法和示例：</p><ol><li><p>注释：</p><p>可以使用<code>&#123;&#123;/* 注释内容 */&#125;&#125;</code>语法添加注释。注释可以在模板执行时忽略。</p><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;/* This is a comment */&#125;&#125;</span><br></pre></td></tr></table></figure></li><li><p>输出变量值：</p><p>使用<code>&#123;&#123;.&#125;&#125;</code>语法输出当前的上下文变量值。</p><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;.&#125;&#125;  // 输出当前上下文的变量值</span><br></pre></td></tr></table></figure></li><li><p>条件语句：</p><p>使用<code>&#123;&#123;if .Condition&#125;&#125; ... &#123;&#123;else&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法进行条件判断。</p><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;if .Condition&#125;&#125;</span><br><span class="line">    True Block</span><br><span class="line">&#123;&#123;else&#125;&#125;</span><br><span class="line">    False Block</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure></li><li><p>循环语句：</p><p>使用<code>&#123;&#123;range .Slice&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法进行循环迭代。</p><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;range .Slice&#125;&#125;</span><br><span class="line">    &#123;&#123;.&#125;&#125;  // .表示当前迭代的元素</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure></li><li><p>定义和使用变量：</p><p>使用<code>&#123;&#123;with .Variable&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法定义和使用临时变量。</p><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;with .Variable&#125;&#125;</span><br><span class="line">    &#123;&#123;.&#125;&#125;  // 使用临时变量</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure></li><li><p>函数调用：</p><p>使用<code>&#123;&#123;函数名 参数1 参数2 ...&#125;&#125;</code>语法调用内置或自定义函数。</p><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;len .String&#125;&#125;  // 调用len函数返回字符串的长度</span><br></pre></td></tr></table></figure></li><li><p>嵌套模板：</p><p>使用<code>&#123;&#123;template "模板名称" .数据&#125;&#125;</code>语法在模板中嵌套另一个模板。</p><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;template &quot;header&quot; .PageTitle&#125;&#125;  // 嵌套名为&quot;header&quot;的模板，并传入.PageTitle参数</span><br></pre></td></tr></table></figure></li></ol><p>这些是常用的模板语法和示例，通过这些语法可以实现动态生成文本或者HTML代码的功能。具体使用方法可以参考Go语言文档中的模板包说明：<a href="https://golang.org/pkg/html/template/">https://golang.org/pkg/html/template/</a></p><p>在Go语言的模板中，可以通过在模板中调用预定义的全局函数来进行一些常用的操作。Go语言的模板引擎提供了一些内置函数，这些函数可以在模板中直接使用，而不需要额外的导入。</p><p>以下是一些常用的预定义全局函数：</p><ol><li><p><code>and</code>：接受任意数量的布尔值作为参数，并返回它们的与运算结果。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;and true true&#125;&#125;  // true</span><br><span class="line">&#123;&#123;and true false&#125;&#125; // false</span><br></pre></td></tr></table></figure></li><li><p><code>or</code>：接受任意数量的布尔值作为参数，并返回它们的或运算结果。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;or true true&#125;&#125;  // true</span><br><span class="line">&#123;&#123;or true false&#125;&#125; // true</span><br></pre></td></tr></table></figure></li><li><p><code>not</code>：接受布尔值作为参数，并返回它的否定值。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;not true&#125;&#125;  // false</span><br><span class="line">&#123;&#123;not false&#125;&#125; // true</span><br></pre></td></tr></table></figure></li><li><p><code>eq</code>：用于比较两个值是否相等。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;eq 10 10&#125;&#125;   // true</span><br><span class="line">&#123;&#123;eq &quot;abc&quot; &quot;def&quot;&#125;&#125; // false</span><br></pre></td></tr></table></figure></li><li><p><code>ne</code>：用于比较两个值是否不相等。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;ne 10 20&#125;&#125;   // true</span><br><span class="line">&#123;&#123;ne &quot;abc&quot; &quot;abc&quot;&#125;&#125; // false</span><br></pre></td></tr></table></figure></li><li><p><code>lt</code>：用于比较两个值是否左边小于右边。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;lt 10 20&#125;&#125;   // true</span><br><span class="line">&#123;&#123;lt &quot;abc&quot; &quot;def&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure></li><li><p><code>le</code>：用于比较两个值是否左边小于等于右边。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;le 20 20&#125;&#125;   // true</span><br><span class="line">&#123;&#123;le &quot;abc&quot; &quot;def&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure></li><li><p><code>gt</code>：用于比较两个值是否左边大于右边。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;gt 20 10&#125;&#125;   // true</span><br><span class="line">&#123;&#123;gt &quot;def&quot; &quot;abc&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure></li><li><p><code>ge</code>：用于比较两个值是否左边大于等于右边。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;ge 20 20&#125;&#125;   // true</span><br><span class="line">&#123;&#123;ge &quot;def&quot; &quot;abc&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure></li><li><p><code>len</code>：返回一个字符串或数组的长度。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;len &quot;hello&quot;&#125;&#125;  // 5</span><br><span class="line">&#123;&#123;len .slice&#125;&#125;   // 数组或切片的长度</span><br></pre></td></tr></table></figure></li></ol><p>以上就是一些常用的预定义全局函数的使用方法和示例。使用这些函数可以在模板中进行一些基本的逻辑操作和比较。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>uninstall docker</title>
      <link href="/2023/08/23/docker/uninstall_docker/"/>
      <url>/2023/08/23/docker/uninstall_docker/</url>
      
        <content type="html"><![CDATA[<p>要在CentOS 7上干净地卸载Docker，可以执行以下步骤：</p><ol><li>停止Docker服务：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop docker</span><br></pre></td></tr></table></figure><ol start="2"><li>移除所有Docker容器和镜像。这将删除所有相关数据，包括容器、镜像以及存储卷等。请注意，这将不可逆转地删除数据。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -rf /var/lib/docker</span><br></pre></td></tr></table></figure><ol start="3"><li>卸载Docker软件包。可以使用以下命令之一，根据Docker的安装方式选择相应的命令：</li></ol><ul><li>如果Docker是通过<code>yum</code>进行安装的：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum remove docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure><ul><li>如果Docker是通过<code>dnf</code>进行安装的：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dnf remove docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure><ul><li>如果Docker是通过RPM包进行手动安装的，可以使用以下命令之一：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rpm -e docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure><ol start="4"><li>删除相关配置文件：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -rf /etc/docker</span><br><span class="line">sudo rm -rf /etc/systemd/system/docker.service.d</span><br></pre></td></tr></table></figure><ol start="5"><li>删除用户组和用户（可选）：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo groupdel docker</span><br><span class="line">sudo userdel docker</span><br></pre></td></tr></table></figure><p>完成以上步骤后，Docker将被完全卸载。</p>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>install nodejs</title>
      <link href="/2023/08/22/nodejs/install_nodejs/"/>
      <url>/2023/08/22/nodejs/install_nodejs/</url>
      
        <content type="html"><![CDATA[<p>要在Ubuntu上安装Node.js和NPM，你可以按照以下步骤进行操作：</p><ol><li><p>首先，打开终端。</p></li><li><p>更新系统软件包列表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure></li><li><p>安装Node.js：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install nodejs</span><br></pre></td></tr></table></figure><p>这将安装最新版本的Node.js。</p></li><li><p>安装npm：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install npm</span><br></pre></td></tr></table></figure><p>这将安装最新版本的npm。</p></li><li><p>检查Node.js和npm的安装版本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nodejs --version</span><br><span class="line">npm --version</span><br></pre></td></tr></table></figure><p>在命令行上将显示Node.js和npm的版本号。</p></li></ol><p>如果你希望安装特定版本的Node.js和npm，可以使用nvm（Node Version Manager）工具。</p><ol><li><p>安装nvm：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash</span><br></pre></td></tr></table></figure><p>这将下载并运行nvm的安装脚本。</p></li><li><p>重新打开终端，或者在当前终端中运行以下命令以启用nvm：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></li><li><p>安装所需版本的Node.js：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvm install 18.17.1</span><br></pre></td></tr></table></figure><p>这将安装Node.js v18.17.1。</p></li><li><p>使用所需版本的Node.js：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvm use 18.17.1</span><br></pre></td></tr></table></figure><p>这将在当前终端会话中使用Node.js v18.17.1。</p></li><li><p>安装所需版本的npm：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g npm@9.6.7</span><br></pre></td></tr></table></figure><p>这将安装npm v9.6.7。</p></li><li><p>检查Node.js和npm的安装版本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node --version</span><br><span class="line">npm --version</span><br></pre></td></tr></table></figure><p>在命令行上将显示Node.js v18.17.1和npm v9.6.7的版本号。</p></li></ol><p>请注意，使用nvm安装的Node.js版本仅在您的当前终端会话中有效。如果您希望在其他终端会话中使用相同的Node.js版本，您需要运行相应的<code>nvm use</code>命令。</p>]]></content>
      
      
      
        <tags>
            
            <tag> nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>uninstall containerd</title>
      <link href="/2023/08/22/kubernetes/uninstall_cintainerd/"/>
      <url>/2023/08/22/kubernetes/uninstall_cintainerd/</url>
      
        <content type="html"><![CDATA[<p>要彻底清除 Kubernetes 集群节点上的 containerd，可以按照以下步骤进行：</p><p>Step 1: 停止并移除所有运行的容器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crictl ps -a | awk &#x27;&#123;if(NR&gt;1) print $1&#125;&#x27; | xargs -I &#123;&#125; crictl rm &#123;&#125;</span><br></pre></td></tr></table></figure><p>这将停止并删除节点上所有正在运行的容器。</p><p>Step 2: 停止并禁用 containerd 服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop containerd</span><br><span class="line">$ systemctl disable containerd</span><br></pre></td></tr></table></figure><p>这将停止并禁用 containerd 服务。</p><p>Step 3: 卸载 containerd 软件包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum remove containerd -y</span><br></pre></td></tr></table></figure><p>根据你的系统，可能需要使用适当的软件包管理器（如apt、dnf）来移除 containerd 软件包。</p><p>Step 4: 删除 containerd 配置目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ rm -rf /etc/containerd</span><br></pre></td></tr></table></figure><p>这将删除 containerd 的配置文件。</p><p>Step 5: 删除 containerd 数据目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ rm -rf /var/lib/containerd</span><br></pre></td></tr></table></figure><p>这将删除 containerd 的数据目录。</p><p>Step 6: 清理 containerd 相关的 iptables 规则</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -F</span><br><span class="line">$ iptables -t mangle -F</span><br></pre></td></tr></table></figure><p>这将清除与 containerd 相关的 iptables 规则。</p><p>Step 7: 检查是否有残留的 containerd 配置文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls /etc/systemd/system/containerd*</span><br></pre></td></tr></table></figure><p>如果输出中有任何文件，则手动删除它们：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ rm /etc/systemd/system/containerd*.service</span><br></pre></td></tr></table></figure><p>现在，你的 Kubernetes 集群节点上的 containerd 已经彻底卸载。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> containerd </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go mod使用最新提交</title>
      <link href="/2023/08/18/golang/last_version_mod/"/>
      <url>/2023/08/18/golang/last_version_mod/</url>
      
        <content type="html"><![CDATA[<p>​<br>例如一个项目在其中依赖了    github.com&#x2F;linuxsuren&#x2F;go-fake-runtime v0.0.1</p><p>go.mod内容：</p><pre><code>github.com/linuxsuren/go-fake-runtime v0.0.1</code></pre><p>修改了github.com&#x2F;linuxsuren&#x2F;go-fake-runtime代码，存在一个最新的commit hash值为25fa814c6232e545f5bce03bd4db04fc37e10250</p><p>修改项目中的go.mod</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">github.com/linuxsuren/go-fake-runtime 25fa814c6232e545f5bce03bd4db04fc37e10250</span><br></pre></td></tr></table></figure><p>然后执行go mod tidy,会看到go.mod中的依赖会更新为最新的提交</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">github.com/linuxsuren/go-fake-runtime v0.0.2-0.20230815071200-25fa814c6232</span><br></pre></td></tr></table></figure><p>至此项目依赖的github.com&#x2F;linuxsuren&#x2F;go-fake-runtime已由v0.0.1版本更为指定的commit。</p><p>​</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>metrics/cadvisor,kube-state-metrics,node-exporter</title>
      <link href="/2023/08/18/kubernetes/monitor/"/>
      <url>/2023/08/18/kubernetes/monitor/</url>
      
        <content type="html"><![CDATA[<h1 id="kubelet的metrics-cadvisor"><a href="#kubelet的metrics-cadvisor" class="headerlink" title="kubelet的metrics&#x2F;cadvisor"></a>kubelet的metrics&#x2F;cadvisor</h1><p>Kubelet是Kubernetes主节点的一个核心组件，负责管理节点上的容器，以及与主控平面进行通信。Kubelet通过提供不同的接口和嵌入式组件来收集和暴露节点和容器的监控指标。</p><ol><li><p>Kubelet监控指标：</p><ul><li>Kubelet启动的Pod数目</li><li>Kubelet已经完成的Pod数目</li><li>Kubelet当前正在运行的Pod数目</li><li>Kubelet拒绝启动的Pod数目</li><li>Kubelet处理错误的Pod数目</li><li>Kubelet未知状态的Pod数目</li><li>Kubelet容器运行时间</li><li>Kubelet容器CPU使用率</li><li>Kubelet容器内存使用率</li><li>Kubelet存储设备使用率</li><li>Kubelet网络上行流量</li><li>Kubelet网络下行流量</li><li>Kubelet容器磁盘使用量</li><li>Kubelet容器文件系统使用率</li><li>Kubelet容器日志记录量</li></ul></li><li><p>cAdvisor监控指标：</p><ul><li>容器的CPU使用率</li><li>容器的内存使用率</li><li>容器的磁盘使用率</li><li>容器的网络上行流量</li><li>容器的网络下行流量</li><li>容器的文件系统使用率</li><li>容器的日志记录量</li><li>容器的进程数</li><li>容器的打开文件数</li><li>容器的线程数</li><li>容器的磁盘I&#x2F;O使用率</li><li>容器的网络延迟</li><li>容器的网络吞吐量</li><li>容器的内存压缩率</li><li>容器的内存丢失</li><li>容器的CPU限制与请求</li></ul></li></ol><p>总体来说，Kubelet和cAdvisor提供了丰富的监控指标，可以用于监视节点和容器的资源使用情况、运行状态及性能状况。这些指标对于在Kubernetes集群中管理和优化容器化应用程序的性能和可靠性非常有帮助。</p><h1 id="kube-state-metrics"><a href="#kube-state-metrics" class="headerlink" title="kube-state-metrics"></a>kube-state-metrics</h1><p>kube-state-metrics（KSM）是一个用于将Kubernetes集群的状态信息转换为Prometheus指标的开源项目。它可以提供丰富的监控指标，用于监控Kubernetes集群中的各种资源和对象。以下是Kube-state-metrics提供的一些主要监控指标：</p><ol><li><p>节点指标（Node Metrics）：包括节点的CPU利用率、内存利用率、磁盘空间利用率等信息。</p></li><li><p>Pod指标（Pod Metrics）：包括Pod的CPU利用率、内存利用率、网络流量等信息。</p></li><li><p>命名空间指标（Namespace Metrics）：包括命名空间中的Pod、Replication Controller、Deployment、DaemonSet等资源的数量和状态信息。</p></li><li><p>服务指标（Service Metrics）：包括服务的连接数、请求流量、响应时间等信息。</p></li><li><p>部署指标（Deployment Metrics）：包括部署的副本数量、可用副本数量、滚动更新状态等信息。</p></li><li><p>容器指标（Container Metrics）：包括容器的CPU利用率、内存利用率、文件系统使用情况等信息。</p></li><li><p>StatefulSet指标（StatefulSet Metrics）：包括StatefulSet的副本数量、可用副本数量、当前状态等信息。</p></li><li><p>守护进程指标（DaemonSet Metrics）：包括DaemonSet的副本数量、可用副本数量、当前状态等信息。</p></li><li><p>任务指标（Job Metrics）：包括任务的运行状态、副本数量、成功和失败的次数等信息。</p></li></ol><p>这些指标可以提供关于Kubernetes集群和其中资源的性能、状态和健康状况的详细信息。使用这些指标，可以进行实时监控、性能优化、故障排除和容量规划，以确保集群的稳定性和可靠性。</p><h1 id="node-exporter"><a href="#node-exporter" class="headerlink" title="node-exporter"></a>node-exporter</h1><p>Node Exporter 是一种用于 Prometheus 的开源代理，用于暴露各种系统级监控指标。它可以在 Linux 系统上工作，并提供以下类型的监控指标：</p><ol><li><p>系统指标：包括 CPU 使用率、内存使用率、磁盘使用率、磁盘 I&#x2F;O 情况、网络流量、文件系统使用率等。这些指标可以帮助管理员了解系统的整体状态和资源利用情况。</p></li><li><p>进程指标：可以获取正在运行的进程数、进程CPU和内存使用情况、进程网络连接数等信息。通过这些指标，可以监控和识别系统中资源占用较多的进程，从而及时调整和优化。</p></li><li><p>网络指标：包括网络接口的带宽利用率、传输速率、丢包率和错误率等。这些指标可以帮助了解网络流量情况，监控网络性能和及时发现问题。</p></li><li><p>磁盘指标：包括磁盘使用率、磁盘读写速度、磁盘IO等。这些指标可以帮助监控磁盘的健康状况、数据读写速度和IO性能。</p></li><li><p>内存指标：包括内存使用量、内存交换情况、内存分页等。这些指标可以帮助了解内存的使用情况和性能。</p></li><li><p>CPU 指标：包括 CPU 使用率、CPU 温度、CPU 核心数等。这些指标可以帮助监控系统的负载情况和CPU性能。</p></li><li><p>运行时间指标：包括系统的运行时间以及系统启动后的负载状况。这些指标可以帮助了解系统的稳定性和运行时间。</p></li></ol><p>除了以上列举的指标，Node Exporter 还提供了其他许多监控指标，以及一些自定义指标的扩展方式。用户可以根据需要选择性地监控和收集这些指标，以满足对系统性能和资源利用的需求。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/08/04/hello-world/"/>
      <url>/2023/08/04/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><p>dependencies:</p><ul><li>node, npm</li><li>sudo npm install -g hexo-cli</li><li>sudo npm install hexo</li><li>npm install hexo-deployer-git –save</li><li>npm install hexo-generator-search –save</li></ul><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
