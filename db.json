{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"themes/butterfly/source/css/index.styl","path":"css/index.styl","modified":1,"renderable":1},{"_id":"themes/butterfly/source/css/var.styl","path":"css/var.styl","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/20230818103122.jpg","path":"img/20230818103122.jpg","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/20230823160932.png","path":"img/20230823160932.png","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/404.jpg","path":"img/404.jpg","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/friend_404.gif","path":"img/friend_404.gif","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/thumbbig-1221433.jpg","path":"img/thumbbig-1221433.jpg","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/tw_cn.js","path":"js/tw_cn.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/search/algolia.js","path":"js/search/algolia.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/search/local-search.js","path":"js/search/local-search.js","modified":1,"renderable":1},{"_id":"source/img/20230818103122.jpg","path":"img/20230818103122.jpg","modified":1,"renderable":0},{"_id":"source/img/20230822143445.jpg","path":"img/20230822143445.jpg","modified":1,"renderable":0}],"Cache":[{"_id":"source/_data/link.yaml","hash":"80576ac894f882f25903e2ab824427b8d11988cd","modified":1692324729920},{"_id":"source/_drafts/draft.md","hash":"b472be5771163e18b109ee34e0cc62ba571bb40d","modified":1692327202494},{"_id":"source/_posts/hello-world.md","hash":"9db9748dfecfc3146a3239035331efaf5cb9cf92","modified":1692774850502},{"_id":"source/about/index.md","hash":"67d4cc7108911b8662a0201bdabf042dbaef7b09","modified":1691119039026},{"_id":"source/categories/index.md","hash":"d77b6f39e85b912ee0a4f6708974edf1677f7c8a","modified":1692324631370},{"_id":"source/link/index.md","hash":"b749372caa351fad232a4420c82ae06acca33d7a","modified":1692324680798},{"_id":"source/tags/index.md","hash":"fbfe43a3c44f87bafe265cc8d0ef3de7acbed1cf","modified":1692324602674},{"_id":"source/_posts/docker/uninstall_docker.md","hash":"fe3044b3520af04ef501894ee9345b302546540f","modified":1692856339606},{"_id":"source/_posts/golang/go_template.md","hash":"576c203bdf37b4a835f657a26c086ef704896acc","modified":1692773723180},{"_id":"source/_posts/golang/last_version_mod.md","hash":"3623367c5fa8c4ff5bc93b1d023e8b8844fe4f7e","modified":1692773729952},{"_id":"source/_posts/kubernetes/deepflow-dashboard.md","hash":"7db65ddc47fbd7bc9346e36fa86c207ce42b8807","modified":1697620707736},{"_id":"source/_posts/kubernetes/efk.md","hash":"07bac5cc6a41a1525479956266d636f71466ed6d","modified":1692866102494},{"_id":"source/_posts/kubernetes/fluent_Bit_Fluentd.md","hash":"aad3274f394baa501e2ac724183f136ec885b562","modified":1692864882291},{"_id":"source/_posts/kubernetes/gateway.md","hash":"33d6f4d6b630bade78902eadbab7343ef296a6d0","modified":1698895775022},{"_id":"source/_posts/kubernetes/grafana-create-alert-rule.md","hash":"4d9b91f9bb146d8dce4abefe7b1c46942b0edc2a","modified":1699324912156},{"_id":"source/_posts/kubernetes/grafana-dashboard.md","hash":"8b194ae66ee614a19bb6c98b234b15d7b1ac4eab","modified":1698720609089},{"_id":"source/_posts/kubernetes/image-1.png","hash":"0bae2d21312c343fd0a9d5e3a08ba0a22a4c740e","modified":1697619448570},{"_id":"source/_posts/kubernetes/image-100.png","hash":"1b0ab0fa5f9b916745de168a908f8378a22f0a16","modified":1698720347392},{"_id":"source/_posts/kubernetes/image-101.png","hash":"94cf0ec9da20ace1bf8c7a14efd7c18b8a08964c","modified":1698720358691},{"_id":"source/_posts/kubernetes/image-102.png","hash":"aeaf8c0f6a8a5b257a9967e248fdf7859f266810","modified":1698720367219},{"_id":"source/_posts/kubernetes/image-103.png","hash":"aeaf8c0f6a8a5b257a9967e248fdf7859f266810","modified":1698720417711},{"_id":"source/_posts/kubernetes/image-105.png","hash":"b7ca1fef4fcecc6a2c4e93419d5d0e158f3fa8ad","modified":1698895034656},{"_id":"source/_posts/kubernetes/image-106.png","hash":"8e66e7149fd5f7c9ab2e655166786d4dd1e29693","modified":1698895082442},{"_id":"source/_posts/kubernetes/image-109.png","hash":"eb6e4e7912a1ced2ced02fb66ae709cf80a7254d","modified":1698895373288},{"_id":"source/_posts/kubernetes/image-110.png","hash":"757dcc40fc32dfe6abd6f6a9858b4a83bd6f19e4","modified":1698895522957},{"_id":"source/_posts/kubernetes/image-111.png","hash":"0480afa59660ab35c6e24937eee69fd0ee8a6e74","modified":1698895582844},{"_id":"source/_posts/kubernetes/image-112.png","hash":"b9770f39e04202cc3b63a911a920619fbcc6cce7","modified":1698895644232},{"_id":"source/_posts/kubernetes/image-120.png","hash":"a1645efb5b06723ed44d59a5b7fee4705428aeee","modified":1698977940741},{"_id":"source/_posts/kubernetes/image-121.png","hash":"c91bc3808d347d3988252d4cc5b5d6764bec15b4","modified":1698977952421},{"_id":"source/_posts/kubernetes/image-123.png","hash":"c91bc3808d347d3988252d4cc5b5d6764bec15b4","modified":1698978077281},{"_id":"source/_posts/kubernetes/image-124.png","hash":"c91bc3808d347d3988252d4cc5b5d6764bec15b4","modified":1698978093731},{"_id":"source/_posts/kubernetes/image-126.png","hash":"7fdb29a5077e634229fd53645f284db295e5807a","modified":1698978184236},{"_id":"source/_posts/kubernetes/image-127.png","hash":"84e97e1728f1894cec9d45f5fa491019160f2392","modified":1698978292856},{"_id":"source/_posts/kubernetes/image-128.png","hash":"daa49fcf3a02feff6a746e3d589a19f29545937e","modified":1698978308341},{"_id":"source/_posts/kubernetes/image-129.png","hash":"16ed05eb451e28f3d804ff8e42bac1b59452a671","modified":1698978318172},{"_id":"source/_posts/kubernetes/image-130.png","hash":"7a6d9accb5df224313f85f3a8a4684ed0c5dc536","modified":1698978327706},{"_id":"source/_posts/kubernetes/image-131.png","hash":"659c24bb41719bbddabc4017e3ce03ca42ee4e54","modified":1698978335257},{"_id":"source/_posts/kubernetes/image-132.png","hash":"980857f2cab2ad4a514fcd744a2fe639473c3a0f","modified":1699496939437},{"_id":"source/_posts/kubernetes/image-133.png","hash":"8ec56f1fd72363621c5449b4d43b41ceb2f4f19c","modified":1699496984669},{"_id":"source/_posts/kubernetes/image-134.png","hash":"6e1a70343f67d30527e4e6666f3a75f0a147facf","modified":1699499008080},{"_id":"source/_posts/kubernetes/image-135.png","hash":"e144254fc6f02fd299dbb5c3cf09f511b6803f15","modified":1699499278378},{"_id":"source/_posts/kubernetes/image-138.png","hash":"ba6846786148d43135dea11bd41844a4f2b0a8d9","modified":1699499541330},{"_id":"source/_posts/kubernetes/image-140.png","hash":"6e033a628523f45208ca02b68077e1c182e8cbfd","modified":1699500936850},{"_id":"source/_posts/kubernetes/image-141.png","hash":"cffe1ea7b569fcc72975979f17b33e8fa9f4a916","modified":1699500970981},{"_id":"source/_posts/kubernetes/image-31.png","hash":"c710557cdd1d1577b40ac61813621f7db4ded7a5","modified":1698718344387},{"_id":"source/_posts/kubernetes/image-36.png","hash":"66e582fcd670a9b49a9de2d20a3e8980257697cf","modified":1698718482688},{"_id":"source/_posts/kubernetes/image-37.png","hash":"743a60f2769fc51649732eaa86d0e41c9d96d27d","modified":1698718500106},{"_id":"source/_posts/kubernetes/image-38.png","hash":"fc4255e93690dff11aaa0526f35a2162001292c9","modified":1698718518781},{"_id":"source/_posts/kubernetes/image-40.png","hash":"0ee3616e66ae359aa2c8b51c28684216c6d1a1ff","modified":1698718737489},{"_id":"source/_posts/kubernetes/image-41.png","hash":"80070fa3e376ac4ff3e571e6bd3a09283a64f420","modified":1698718750712},{"_id":"source/_posts/kubernetes/image-42.png","hash":"4d8880dbbb89155f138cdffeaa8a7a7a9285a2a0","modified":1698718764272},{"_id":"source/_posts/kubernetes/image-43.png","hash":"80f3f58498ce6de8cc546f3300c5fb7f543ef4d0","modified":1698718787263},{"_id":"source/_posts/kubernetes/image-45.png","hash":"77de8ecf4184a9fdfa3819053a23bdf49dae31d5","modified":1698718823126},{"_id":"source/_posts/kubernetes/image-46.png","hash":"f79309cf8e6036a950271750db9ee2b21a8d300b","modified":1698718865688},{"_id":"source/_posts/kubernetes/image-47.png","hash":"afc8fda7d671d3254708cd0e837fe525dce29c46","modified":1698718880940},{"_id":"source/_posts/kubernetes/image-48.png","hash":"cfd5d4d2a49edbb981496e299bd59a5343f8523d","modified":1698718919831},{"_id":"source/_posts/kubernetes/image-49.png","hash":"cfd5d4d2a49edbb981496e299bd59a5343f8523d","modified":1698718935939},{"_id":"source/_posts/kubernetes/image-50.png","hash":"8d7c17c1a7d9875542f6f42e02bf36a29368f399","modified":1698718992397},{"_id":"source/_posts/kubernetes/image-51.png","hash":"fc1c6ab4457134611823b69bcbedb4a57b57ed80","modified":1698719002729},{"_id":"source/_posts/kubernetes/image-52.png","hash":"11b5f7a74d7896af37662fc8e4081d41656b3bd6","modified":1698719030500},{"_id":"source/_posts/kubernetes/image-53.png","hash":"d459219182ffd72c6acdd87c7b8ce7edde574da9","modified":1698719058796},{"_id":"source/_posts/kubernetes/image-54.png","hash":"299d28a04287244f29535b0d7e5318cc6f586ff5","modified":1698719073471},{"_id":"source/_posts/kubernetes/image-56.png","hash":"64e9adf6739255bb2eb40e5755f4f7bdb6a17904","modified":1698719107531},{"_id":"source/_posts/kubernetes/image-57.png","hash":"0eea76a844232b3c4f91de0fd3a53469b4a0cdca","modified":1698719139906},{"_id":"source/_posts/kubernetes/image-59.png","hash":"280d3d4dc238e159245b083fbd54d265087c5ebb","modified":1698719164454},{"_id":"source/_posts/kubernetes/image-60.png","hash":"7fb67366654da7c29ce42e474659d67850c9f6ce","modified":1698719203293},{"_id":"source/_posts/kubernetes/image-61.png","hash":"550775d9d5ceb16ea9c2574eca609634fa71a239","modified":1698719218625},{"_id":"source/_posts/kubernetes/image-62.png","hash":"0165eff4797e7805ec74b8b6147191b958c12a43","modified":1698719257077},{"_id":"source/_posts/kubernetes/image-63.png","hash":"ba2334f015489a3a4c9613ba50993bd7a538c786","modified":1698719273433},{"_id":"source/_posts/kubernetes/image-64.png","hash":"26471faee5fdd35a1fe2f491ed666999525e1eae","modified":1698719285777},{"_id":"source/_posts/kubernetes/image-65.png","hash":"81cd738de264644f461f5170c8abd1e5a91388ce","modified":1698719310709},{"_id":"source/_posts/kubernetes/image-66.png","hash":"fc0505e6cb1699ea429070a6226b626e1d212092","modified":1698719321549},{"_id":"source/_posts/kubernetes/image-67.png","hash":"ead429319262aeab8737e2105650883968d805e4","modified":1698719334386},{"_id":"source/_posts/kubernetes/image-69.png","hash":"e6ed109b2755cfc57a9e61501a411a606f04e750","modified":1698719402798},{"_id":"source/_posts/kubernetes/image-72.png","hash":"9e22c3544c40b9a3db1875da4f476cf7fdf2b301","modified":1698719445694},{"_id":"source/_posts/kubernetes/image-74.png","hash":"971b99ab5c9af871c2f46858b3ff6c3f9725fe87","modified":1698719489934},{"_id":"source/_posts/kubernetes/image-73.png","hash":"840ecc5496b340f9746d98b793150c454f42dc5a","modified":1698719460774},{"_id":"source/_posts/kubernetes/image-75.png","hash":"69b94a0fbb236ca9eb71376bcc9ee9a0faca2a50","modified":1698719501311},{"_id":"source/_posts/kubernetes/image-76.png","hash":"cb33eafaee31dd82f964fe4fcac79a028b6983e2","modified":1698719549287},{"_id":"source/_posts/kubernetes/image-77.png","hash":"7e3d931071d694c7604aa802aaded264af87861e","modified":1698719573263},{"_id":"source/_posts/kubernetes/image-80.png","hash":"a0e9d3bd083ccea3069be3ca3d7e9e430cc87b2e","modified":1698719956142},{"_id":"source/_posts/kubernetes/image-81.png","hash":"27790c1698bb6513f4a4c5487d3f7d1dcaf897e5","modified":1698719965526},{"_id":"source/_posts/kubernetes/image-84.png","hash":"5ff54504162ac13f0387a2b1a30fae513087e9eb","modified":1698720011794},{"_id":"source/_posts/kubernetes/image-85.png","hash":"9f4356dacd84a84c770eba419ebeb488f624f7e8","modified":1698720024338},{"_id":"source/_posts/kubernetes/image-86.png","hash":"980e787ffa567f1169ed4a095f20e70fe1017afd","modified":1698720038142},{"_id":"source/_posts/kubernetes/image-87.png","hash":"c8d2fe0c709fd13ddfe32e3a80db1a54cbb62fbb","modified":1698720058445},{"_id":"source/_posts/kubernetes/image-89.png","hash":"e0c6a0ee95b01c028dc3e1d21aed7af949174e45","modified":1698720106441},{"_id":"source/_posts/kubernetes/image-90.png","hash":"0d4658bb81069c721104b84e71b7228ca61ce092","modified":1698720130509},{"_id":"source/_posts/kubernetes/image-91.png","hash":"c7b34df348cfe2ab0c29b8bdb3d959aec98a4e08","modified":1698720158949},{"_id":"source/_posts/kubernetes/image-92.png","hash":"d053f79d742ddeeb1d0868c8c36d7e241a35b11a","modified":1698720177165},{"_id":"source/_posts/kubernetes/image-93.png","hash":"319f401eba3b9fbb9a096583330228697ef8275e","modified":1698720193173},{"_id":"source/_posts/kubernetes/image-94.png","hash":"09c74a48926b5e6e71acd7e493f118d90ad24a57","modified":1698720207777},{"_id":"source/_posts/kubernetes/image-95.png","hash":"7c25b38935643d75354b5140bdd562a74599fc2f","modified":1698720228868},{"_id":"source/_posts/kubernetes/image-97.png","hash":"c7011a7e56ec64932f723f21fe520289e00be7f2","modified":1698720289320},{"_id":"source/_posts/kubernetes/image-98.png","hash":"4d7ec40ebc0b516072767acc1caf9e74988d16c9","modified":1698720321600},{"_id":"source/_posts/kubernetes/image-99.png","hash":"cf36ac2fccac421ff1b995773d64118f67e6716d","modified":1698720332704},{"_id":"source/_posts/kubernetes/internet-1-3.md","hash":"73bbf1cddca151e687acba49228efd2b42ba0e4a","modified":1698978456246},{"_id":"source/_posts/kubernetes/kibana-ilm.md","hash":"2ce626ddbe9f18a3d0de521fc487200732c8dd1b","modified":1699324912152},{"_id":"source/_posts/kubernetes/kube-ovn-underlay.md","hash":"5ad8e780c11b9b7e71115757917ee1cc7b2c7692","modified":1698891753396},{"_id":"source/_posts/kubernetes/kubevirt-vm-expose.md","hash":"df504cf158ab3119727bdc8edf94fac62eae5b17","modified":1693561138859},{"_id":"source/_posts/kubernetes/metrics-server.md","hash":"72afa48992cda6663acfd8d8be61fb5a044ebc8d","modified":1692930793160},{"_id":"source/_posts/kubernetes/monitor.md","hash":"4ddc99d69c473ffb33b4ad5bed84de4e4a072d3a","modified":1692773744756},{"_id":"source/_posts/kubernetes/promql.md","hash":"f3d8360df664c50cc49eeca7eaf10998e19f0cba","modified":1699586573697},{"_id":"source/_posts/kubernetes/snat-dnat.md","hash":"44a0fa5256f877eef567cb251c1fc07fa298fe36","modified":1698996078064},{"_id":"source/_posts/kubernetes/uninstall_cintainerd.md","hash":"18cfe19dd7d2878fdbf3f37b6420a060227dd464","modified":1692689392616},{"_id":"source/_posts/kubernetes/vxlan.md","hash":"16f8a53829cc264083a9fae98b708135324124e5","modified":1698976924789},{"_id":"source/_posts/nodejs/install_nodejs.md","hash":"46282da1aa96fc8843c1209df2da921cf4727795","modified":1692693367375},{"_id":"source/_posts/linux/chrony.md","hash":"3428f5425df5d51f9c87d98c60f194fc6367d9a1","modified":1698390511967},{"_id":"source/img/20230818103122.jpg","hash":"690b5dbaea6aff4c293708ec80de2ac601b3495c","modified":1692325882489},{"_id":"source/_posts/kubernetes/image-107.png","hash":"1fe0ecbf2d9a49ac93f74a27d7b357b3e2f89618","modified":1698895146731},{"_id":"source/_posts/kubernetes/image-108.png","hash":"1fe0ecbf2d9a49ac93f74a27d7b357b3e2f89618","modified":1698895296694},{"_id":"source/_posts/kubernetes/image-113.png","hash":"2dcbdff3f87791dab52706f0289ff2bdb4075439","modified":1698895754790},{"_id":"source/_posts/kubernetes/image-122.png","hash":"20264a914519bb3c10d7f616509a71e0f4b71d56","modified":1698977965549},{"_id":"source/_posts/kubernetes/image-125.png","hash":"20925ea9a3c1cf510020baed326d7d953330beef","modified":1698978173754},{"_id":"source/_posts/kubernetes/image-142.png","hash":"09842c18d8f4aaea8a55ff19fc0aa94847d8ab9c","modified":1699501000064},{"_id":"source/_posts/kubernetes/image-143.png","hash":"aa53d8a4cd36527a3bfcd7831f7ae60c6ebbb0d8","modified":1699501117261},{"_id":"source/_posts/kubernetes/image-32.png","hash":"f784ed8efe08d7e7eac4185f50d873096c044ab4","modified":1698718360121},{"_id":"source/_posts/kubernetes/image-33.png","hash":"0be6780c63b75bf6dfc0e7f6d4a9dc5aef4fa255","modified":1698718418178},{"_id":"source/_posts/kubernetes/image-34.png","hash":"6a3f1fc8b6d2880992c56b0914c715ef34d6a390","modified":1698718443195},{"_id":"source/_posts/kubernetes/image-39.png","hash":"dbcc6ef1e63b213a286b0fb2f01e3bb78811c156","modified":1698718605335},{"_id":"source/_posts/kubernetes/image-44.png","hash":"230530a1ac2dad9efd45bec20a3a5e61b7ca6859","modified":1698718807434},{"_id":"source/_posts/kubernetes/image-55.png","hash":"600227e9d875d5f7c284f4be146a3e01916d0d2a","modified":1698719095483},{"_id":"source/_posts/kubernetes/image-58.png","hash":"8e687183cbe66e7b0b8b8c64b0508433948a36ca","modified":1698719152030},{"_id":"source/_posts/kubernetes/image-70.png","hash":"42352f9554e114f272d0b2a792e8f0964c31fb55","modified":1698719415906},{"_id":"source/_posts/kubernetes/image-78.png","hash":"687baf5c3e30a642122ef7ee654b23567f7c6653","modified":1698719586791},{"_id":"source/_posts/kubernetes/image-79.png","hash":"d7102328a4c39d2b28fb0cec2b39a3cb9df890b6","modified":1698719603939},{"_id":"source/_posts/kubernetes/image-82.png","hash":"cd35f34f1152f22c98ab8b0e1ab9019bada2af45","modified":1698719977194},{"_id":"source/_posts/kubernetes/image-83.png","hash":"93b5e8165a6578fd835dc4b12f6cf7447b5c4dfe","modified":1698719989946},{"_id":"source/_posts/kubernetes/image-88.png","hash":"cb8c1eb7c10a96753acf1417b92952aa0889441d","modified":1698720090161},{"_id":"source/_posts/kubernetes/image-96.png","hash":"b868a98e911e94366d47ccc89a5dc8c988233dac","modified":1698720280248},{"_id":"source/_posts/kubernetes/image.png","hash":"c00ddad579b17a31ca404ab556135d9d91b6cdf4","modified":1697619408222},{"_id":"source/_posts/kubernetes/image-104.png","hash":"bf7b2f75e4e0a087096c13c405ee1fe023cc906f","modified":1698894565579},{"_id":"source/_posts/kubernetes/image-117.png","hash":"fadaea9d1c585ad3ee7556987d4d2d44eea62b57","modified":1698976124932},{"_id":"source/_posts/kubernetes/image-144.png","hash":"ed800bbab8a1b4b990845aad6f7334a644afbbdf","modified":1699582663533},{"_id":"source/_posts/kubernetes/image-35.png","hash":"b4a832f4b8f401f3bfdf981bd0147a896d7f68fa","modified":1698718456170},{"_id":"source/_posts/kubernetes/image-68.png","hash":"7010b1883062f9f8e3357cc672290f44e9359849","modified":1698719388702},{"_id":"source/_posts/kubernetes/image-71.png","hash":"7b09d11fa959561ebd82b5712611bd2f6a718aa6","modified":1698719439010},{"_id":"source/img/20230822143445.jpg","hash":"3a109901811ca6833fb3223189064fa867653bbf","modified":1692686095318},{"_id":"source/_posts/kubernetes/image-11.png","hash":"f090d32691a601a3a72c857178314feb6f4a4a1e","modified":1697619571328},{"_id":"source/_posts/kubernetes/image-136.png","hash":"1917be8b348b2e3b93265a4444621c5441254495","modified":1699499461434},{"_id":"source/_posts/kubernetes/image-137.png","hash":"fc8a440334d776eb410c7f341c892dfa93af941e","modified":1699499498742},{"_id":"source/_posts/kubernetes/image-139.png","hash":"85cd1be00828084b4b594d2382b3c9b82c3deb7e","modified":1699499578622},{"_id":"source/_posts/kubernetes/image-145.png","hash":"ff5bd5fadb7e2d53e75fb896abf6dd52909fa7fe","modified":1699582700208},{"_id":"source/_posts/kubernetes/image-147.png","hash":"ab69c564e302afdf592598efc52b35c45cab0311","modified":1699582891726},{"_id":"source/_posts/kubernetes/image-23.png","hash":"e1c93d730901898a27860e76a6f84d353fb2101b","modified":1697619695438},{"_id":"source/_posts/kubernetes/image-22.png","hash":"e1c93d730901898a27860e76a6f84d353fb2101b","modified":1697619686062},{"_id":"source/_posts/kubernetes/image-30.png","hash":"5df67fa051c6f27895f2ca5022eeed4c0faa3685","modified":1698718295502},{"_id":"source/_posts/kubernetes/image-10.png","hash":"7d76732ad4527872e296755bdf77e63913403408","modified":1697619561608},{"_id":"source/_posts/kubernetes/image-12.png","hash":"0d05e583a35c37c95401e432d9095adbc3cc01b2","modified":1697619579008},{"_id":"source/_posts/kubernetes/image-2.png","hash":"8cf3b9cff450966ebfb92ce8064a3ff7fc999a1c","modified":1697619496901},{"_id":"source/_posts/kubernetes/image-25.png","hash":"eb6b5a407fe209b16f295dba705c53f81be24d3e","modified":1697619900099},{"_id":"source/_posts/kubernetes/image-26.png","hash":"eb6b5a407fe209b16f295dba705c53f81be24d3e","modified":1697619909607},{"_id":"source/_posts/kubernetes/image-27.png","hash":"eb6b5a407fe209b16f295dba705c53f81be24d3e","modified":1697619925471},{"_id":"source/_posts/kubernetes/image-28.png","hash":"eb6b5a407fe209b16f295dba705c53f81be24d3e","modified":1697619936771},{"_id":"source/_posts/kubernetes/image-29.png","hash":"eb6b5a407fe209b16f295dba705c53f81be24d3e","modified":1697620057858},{"_id":"source/_posts/kubernetes/image-16.png","hash":"7c0981723b4a22b60e2f1e5d2ed85b82735afec7","modified":1697619620123},{"_id":"source/_posts/kubernetes/image-17.png","hash":"7c0981723b4a22b60e2f1e5d2ed85b82735afec7","modified":1697619626943},{"_id":"source/_posts/kubernetes/image-21.png","hash":"bb110c2d27853f867fd2c701783dfc4d7900169e","modified":1697619678634},{"_id":"source/_posts/kubernetes/image-20.png","hash":"aee0b068cfdfc7ca5ee5c7a4571c704f766ef8ee","modified":1697619669930},{"_id":"source/_posts/kubernetes/image-3.png","hash":"a81a8f9bab8435537e5cd0fb019c67e7d6da17ea","modified":1697619509317},{"_id":"source/_posts/kubernetes/image-4.png","hash":"959af5ef59ac3a24e595faf6230f58bf0b33243e","modified":1697619515457},{"_id":"source/_posts/kubernetes/image-6.png","hash":"d872952ad5d1a85c93386637ccee9c518f4789ee","modified":1697619535316},{"_id":"source/_posts/kubernetes/image-7.png","hash":"425ad21cb2c5486d5c20685dfc36c556f34e715a","modified":1697619540588},{"_id":"themes/butterfly/LICENSE","hash":"1128f8f91104ba9ef98d37eea6523a888dcfa5de","modified":1691120115272},{"_id":"themes/butterfly/README.md","hash":"b5d6e7271b88d1a63755386442663af03e36a428","modified":1691120115276},{"_id":"themes/butterfly/README_CN.md","hash":"86569b94949392e9b981608433495f0941d20b0c","modified":1691120115276},{"_id":"themes/butterfly/_config.yml","hash":"be87170c21e91b4eac9ccf9a76eb5adf16f048c3","modified":1692857608301},{"_id":"themes/butterfly/package.json","hash":"1646604798f745ef068852772eb22239985ba731","modified":1691120115284},{"_id":"themes/butterfly/languages/default.yml","hash":"4025c0ba440eb24705dd0293ca9ca84efb3105cc","modified":1691120115276},{"_id":"themes/butterfly/plugins.yml","hash":"d0e179ae31cdc62037062432b0ee7a9008155a73","modified":1691120115284},{"_id":"themes/butterfly/languages/en.yml","hash":"4e9cdb7a3570929bcf082de7a4eac49140dddc73","modified":1691120115276},{"_id":"themes/butterfly/languages/zh-CN.yml","hash":"7dd849c3ba34986c57c764d9e36150b4bfffd2e9","modified":1691120115276},{"_id":"themes/butterfly/languages/zh-TW.yml","hash":"ee01e068f12dc33adfae5733824ea1255deb5ca6","modified":1691120115276},{"_id":"themes/butterfly/layout/archive.pug","hash":"a0c034c2d319320a54046805e80b58dc48b7e233","modified":1691120115276},{"_id":"themes/butterfly/layout/category.pug","hash":"710708cfdb436bc875602abf096c919ccdf544db","modified":1691120115276},{"_id":"themes/butterfly/layout/page.pug","hash":"baf469784aef227e4cc840550888554588e87a13","modified":1691120115284},{"_id":"themes/butterfly/layout/index.pug","hash":"e1c3146834c16e6077406180858add0a8183875a","modified":1691120115284},{"_id":"themes/butterfly/layout/tag.pug","hash":"0440f42569df2676273c026a92384fa7729bc4e9","modified":1691120115284},{"_id":"themes/butterfly/layout/post.pug","hash":"fc9f45252d78fcd15e4a82bfd144401cba5b169a","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/additional-js.pug","hash":"aca0ec7ef69b21d1f242c62fed389468a0f0e1a2","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/404.pug","hash":"cb49f737aca272ccfeb62880bd651eccee72a129","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/footer.pug","hash":"02390a5b6ae1f57497b22ba2e6be9f13cfb7acac","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/layout.pug","hash":"7fa9ae4b70b87fc97e992dde5944681f92b59bea","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/pagination.pug","hash":"4c85de4dea4dca4e5088097a79bd6d7009cbf8ef","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head.pug","hash":"dd9fde431add984330e3178e06a8d74705e7340e","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/rightside.pug","hash":"d15124c488273ea0801a042888feadc9261d0b2f","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/sidebar.pug","hash":"9f0e9e039f304439007460fa0a7c8ac18e0ffd37","modified":1691120115276},{"_id":"themes/butterfly/source/css/index.styl","hash":"755490867fd8afe47d5cce24faea2ca172b0c4dd","modified":1691120115292},{"_id":"themes/butterfly/source/css/var.styl","hash":"30abbb8eed880d51f61f336064d93abd709e0115","modified":1691120115292},{"_id":"themes/butterfly/source/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1691120115292},{"_id":"themes/butterfly/source/img/favicon.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1691120115292},{"_id":"themes/butterfly/source/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1691120115292},{"_id":"themes/butterfly/source/img/thumbbig-1221433.jpg","hash":"8c32ca61f09cf449dee0024a21972a3ad9c26eff","modified":1692857524894},{"_id":"themes/butterfly/source/js/main.js","hash":"0227b5bd233a3c66582e0ee820cdb353ce52ece1","modified":1691120115292},{"_id":"themes/butterfly/source/js/tw_cn.js","hash":"42b106354d72a0ea1fe62587b313a5b7de3cc393","modified":1691120115292},{"_id":"themes/butterfly/source/js/utils.js","hash":"aaaedc207440095da1ffabcad870fc2641befb0e","modified":1691120115292},{"_id":"themes/butterfly/scripts/events/404.js","hash":"83cd7f73225ccad123afbd526ce1834eb1eb6a6d","modified":1691120115284},{"_id":"themes/butterfly/scripts/events/cdn.js","hash":"21fb5aabe043486d095c4c8cce361ed85ba88a26","modified":1691120115284},{"_id":"themes/butterfly/scripts/events/comment.js","hash":"5351e0bc09e6b5b3f6d30f333a2520626a28ca3a","modified":1691120115284},{"_id":"themes/butterfly/scripts/events/init.js","hash":"428b94c7b9e83f7ea36227dee66bfe3c23aee4a8","modified":1691120115284},{"_id":"themes/butterfly/scripts/events/stylus.js","hash":"9819f0996234fbd80d6c50a9e526c56ebf22588d","modified":1691120115284},{"_id":"themes/butterfly/scripts/events/welcome.js","hash":"8ad9911b755cba13dde2cc055c3f857a6b0dd20e","modified":1691120115284},{"_id":"themes/butterfly/scripts/filters/post_lazyload.js","hash":"932df912976261929f809b7dbd4eb473e7787345","modified":1691120115284},{"_id":"themes/butterfly/scripts/filters/random_cover.js","hash":"8d25f47434deae870bbffd07efe528a40363ab4d","modified":1691120115284},{"_id":"themes/butterfly/scripts/helpers/aside_archives.js","hash":"2ec66513d5322f185d2071acc052978ba9415a8e","modified":1691120115284},{"_id":"themes/butterfly/scripts/helpers/aside_categories.js","hash":"e00efdb5d02bc5c6eb4159e498af69fa61a7dbb9","modified":1691120115284},{"_id":"themes/butterfly/scripts/helpers/findArchiveLength.js","hash":"9ea86bd7a3c3fca3324f70b1cd4d9e42f9efb08d","modified":1691120115284},{"_id":"themes/butterfly/scripts/helpers/inject_head_js.js","hash":"4238e06ff448ff2ee717cd4c874f37f04d35da06","modified":1691120115284},{"_id":"themes/butterfly/scripts/helpers/page.js","hash":"ce5d5a3d07b0d76ac5e96e5f9e5783f4b601b6be","modified":1691120115284},{"_id":"themes/butterfly/scripts/helpers/related_post.js","hash":"4677be4175da6800c0b3b8c1614e593f73df8831","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/button.js","hash":"91d954f6e9fe6e571eb8ec9f8996294b2dc3688e","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/flink.js","hash":"ab62919fa567b95fbe14889517abda649991b1ee","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/gallery.js","hash":"950b3dbac0b21717458a8d1769cbfc454d0eff54","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/hide.js","hash":"396c3ab1bcf1c7693ad7e506eadd13016c6769b6","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/inlineImg.js","hash":"a43ee2c7871bdd93cb6beb804429e404570f7929","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/label.js","hash":"03b2afef41d02bd1045c89578a02402c28356006","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/mermaid.js","hash":"531808a290b8bdd66bac2faab211ada8e9646a37","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/note.js","hash":"d51812b43924f1bbf413c67499510dd125022005","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/score.js","hash":"ea679dfe12d0e2290113b4a9d00663ce7a5ee5ad","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/tabs.js","hash":"6c6e415623d0fd39da016d9e353bb4f5cca444f5","modified":1691120115284},{"_id":"themes/butterfly/scripts/tag/timeline.js","hash":"300eb779588bf35a1b687d9f829d866074b707e3","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/head/Open_Graph.pug","hash":"8aa8d799aedbfd811195b84a451bc4b6e2647c12","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/analytics.pug","hash":"67e1c3b48e4ca7ee0b2c76d3ca7476b9883cf105","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/config.pug","hash":"75e7a524af64fbaaaf7b05a1b1922bf6940d7afe","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/config_site.pug","hash":"7df90c8e432e33716517ab918b0a125bc284041b","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/google_adsense.pug","hash":"95a37e92b39c44bcbea4be7e29ddb3921c5b8220","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/noscript.pug","hash":"d16ad2ee0ff5751fd7f8a5ce1b83935518674977","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/preconnect.pug","hash":"a03b3ddc06e7aa9fd07eea0d5f97c8d5addd2315","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/pwa.pug","hash":"3d492cfe645d37c94d30512e0b230b0a09913148","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/head/site_verification.pug","hash":"e2e8d681f183f00ce5ee239c42d2e36b3744daad","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/header/index.pug","hash":"944d6e9dd50df3395f3a2c7ad9db667d50dea4ed","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/header/menu_item.pug","hash":"31346a210f4f9912c5b29f51d8f659913492f388","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/header/nav.pug","hash":"f61659aa457d1a2d1baa3a13157996cfac4d6609","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/header/post-info.pug","hash":"9698f22751778dde063cbfbd01c59ca4462ccd85","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/header/social.pug","hash":"5de9a82032cdad1db3b868b797460921cd775fc2","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/loading/fullpage-loading.pug","hash":"9e8c5788602b29a527ef35fe8a20076a5fa969bd","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/loading/index.pug","hash":"131f344d68b4c241d6e03849b243ee792fcd3cea","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/loading/pace.pug","hash":"6ab4e301c92586505d6cddce1b3ad23b7c79010d","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/mixins/article-sort.pug","hash":"90554c2ca5ba946f4c02e1bc5fe2859cef1b1594","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/mixins/post-ui.pug","hash":"1ed873db25eec869beebb6873f04e19f0b0f4134","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/page/categories.pug","hash":"5276a8d2835e05bd535fedc9f593a0ce8c3e8437","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/page/default-page.pug","hash":"12c65c174d26a41821df9bad26cdf1087ec5b0ca","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/page/flink.pug","hash":"f9ce83978b217a71a2eb8761dc14b09866faa3f4","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/page/tags.pug","hash":"9621991359e22b14049346f1cf87bdedc94edf5a","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/post/post-copyright.pug","hash":"ebecba46a5f4efe1c98a386df06c56e26fbd07b9","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/aplayer.pug","hash":"c7cfade2b160380432c47eef4cd62273b6508c58","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/post/reward.pug","hash":"864869c43fe5b5bb6f4ac6b13dd4bfb16ea47550","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/effect.pug","hash":"6528e86656906117a1af6b90e0349c2c4651d5e1","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/pangu.pug","hash":"0f024e36b8116118233e10118714bde304e01e12","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/pjax.pug","hash":"cde142861edfc7aab435b8a0ebb84d9ba450fb5b","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/prismjs.pug","hash":"ffb9ea15a2b54423cd4cd441e2d061b8233e9b58","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/subtitle.pug","hash":"8044b9c18b34b019ffe26b7383e7e80356b5e4b5","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/widget/card_ad.pug","hash":"60dc48a7b5d89c2a49123c3fc5893ab9c57dd225","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/widget/card_announcement.pug","hash":"ae392459ad401a083ca51ee0b27526b3c1e1faed","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/widget/card_archives.pug","hash":"86897010fe71503e239887fd8f6a4f5851737be9","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/widget/card_author.pug","hash":"03c6afabbf1ac729c7fb21c7ec06da0190b0fdc7","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/widget/card_bottom_self.pug","hash":"13dc8ce922e2e2332fe6ad5856ebb5dbf9ea4444","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/card_categories.pug","hash":"d1a416d0a8a7916d0b1a41d73adc66f8c811e493","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/card_newest_comment.pug","hash":"7834bf7c711e739fd33cfcd0b53d151013b3d449","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/card_post_toc.pug","hash":"3057a2f6f051355e35d3b205121af8735100eacf","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/card_recent_post.pug","hash":"e5aac7b28ed4123d75797263c64e74ac547945bc","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/card_tags.pug","hash":"eceb4420a64c720f0d2741e89d6229bbb3d87353","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/card_top_self.pug","hash":"ae67c6d4130a6c075058a9c1faea1648bcc6f83e","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/card_webinfo.pug","hash":"35ce167c5a275211bfc1fa3d49adfde5b404d98f","modified":1691120115284},{"_id":"themes/butterfly/layout/includes/widget/index.pug","hash":"010e3d548ababca2280c4fc4168d9a4a1ee4f536","modified":1691120115284},{"_id":"themes/butterfly/source/css/_highlight/highlight.styl","hash":"57a19eb0c418d92a88b143f56ccb8cd60e6d7ad0","modified":1691120115284},{"_id":"themes/butterfly/source/css/_highlight/theme.styl","hash":"bcd384c8b2aa0390c9eb69ac1abbfd1240ce1da4","modified":1691120115288},{"_id":"themes/butterfly/source/css/_global/function.styl","hash":"e0de61a059b5e6c7b8ebc7149b4650bdcd69af5e","modified":1691120115284},{"_id":"themes/butterfly/source/css/_global/index.styl","hash":"51868d861c94a9f1ad7c0dbd66d2f475c5d4ea62","modified":1691120115284},{"_id":"themes/butterfly/source/css/_layout/aside.styl","hash":"57adf29a3e36e4ea84384e36c034eb294dffb208","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/chat.styl","hash":"f9a5d3f1fc5ed0ed2ee4c1eaa58ed650d11ddebd","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/comments.styl","hash":"c61dccca690d486c3d9c29cf028d87b777385141","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/footer.styl","hash":"83a7a70eb0532ea9c4267939fe484af915fca01e","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/head.styl","hash":"8cd2aaa32cd68cd1908c9001444a811c3d0f9267","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/loading.styl","hash":"ac2aeee9926f75b2a0098efe1c114126987430f2","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/pagination.styl","hash":"fb9f78bfbb79579f1d752cb73fb6d25c8418e0fd","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/post.styl","hash":"fc9424d9c5def2201ec1d04dc79d0beedc1d2175","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/relatedposts.styl","hash":"d53de408cb27a2e704aba7f7402b7caebe0410d8","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/reward.styl","hash":"c5cfed620708807a48076b5ee59b0ba84e29aa80","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/rightside.styl","hash":"bbc884d6b2158a833b77a1bbc07248e17874b22e","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/sidebar.styl","hash":"631ca35a38bc4ac052e9caf47508ff1f99842fc7","modified":1691120115288},{"_id":"themes/butterfly/source/css/_mode/darkmode.styl","hash":"e4f948b0d4eb5483b2b360e56cbfe3359751b438","modified":1691120115288},{"_id":"themes/butterfly/source/css/_mode/readmode.styl","hash":"c481d1f689a4e6d7ee492a03751bda47a30225ce","modified":1691120115288},{"_id":"themes/butterfly/source/css/_layout/third-party.styl","hash":"5556c9bf4f53a90cb9b4945cd76a8849bd67f3f3","modified":1691120115288},{"_id":"themes/butterfly/source/css/_page/404.styl","hash":"50dbb9e6d98c71ffe16741b8c1b0c1b9771efd2b","modified":1691120115288},{"_id":"themes/butterfly/source/css/_page/archives.styl","hash":"c9e98027f2dd730ce389c2047f62ebb748955fcf","modified":1691120115288},{"_id":"themes/butterfly/source/css/_page/categories.styl","hash":"f01ee74948cedb44e53cd3bb1ef36b7d2778ede7","modified":1691120115288},{"_id":"themes/butterfly/source/css/_page/common.styl","hash":"4e320e16d49bc18085045937681f7331a1e243ca","modified":1691120115288},{"_id":"themes/butterfly/source/css/_page/flink.styl","hash":"98d755b686ee833e9da10afaa40c4ec2bd66c19a","modified":1691120115288},{"_id":"themes/butterfly/source/css/_page/homepage.styl","hash":"b3ea08d9460122751144a3ca835e009a460d6ad3","modified":1691120115288},{"_id":"themes/butterfly/source/css/_page/tags.styl","hash":"580feb7e8b0822a1be48ac380f8c5c53b1523321","modified":1691120115288},{"_id":"themes/butterfly/source/css/_search/algolia.styl","hash":"649a054e73278b6724bd4dd9b94724791ec5c928","modified":1691120115288},{"_id":"themes/butterfly/source/css/_search/index.styl","hash":"20a3134e1302b62bfc881f4ec43f398267111f22","modified":1691120115288},{"_id":"themes/butterfly/source/css/_tags/button.styl","hash":"45f0c32bdea117540f6b14ebac6450d7142bd710","modified":1691120115292},{"_id":"themes/butterfly/source/css/_search/local-search.styl","hash":"a86e4e9198b225b4b73a7a45f04b86cbbed0d231","modified":1691120115288},{"_id":"themes/butterfly/source/css/_tags/gallery.styl","hash":"81ad85acf0e0fe7f9ee23c16a700e7154574d5dd","modified":1691120115292},{"_id":"themes/butterfly/source/css/_tags/hexo.styl","hash":"d76c38adf1d9c1279ef4241835667789f5b736e0","modified":1691120115292},{"_id":"themes/butterfly/source/css/_tags/hide.styl","hash":"ce489ca2e249e2a3cf71584e20d84bdb022e3475","modified":1691120115292},{"_id":"themes/butterfly/source/css/_tags/inlineImg.styl","hash":"df9d405c33a9a68946b530410f64096bcb72560c","modified":1691120115292},{"_id":"themes/butterfly/source/css/_tags/label.styl","hash":"66c59e193d794cdb02cca7bd1dc4aea5a19d7e84","modified":1691120115292},{"_id":"themes/butterfly/source/css/_tags/note.styl","hash":"85ae91c83691ea4511f4277da1194a185251cc78","modified":1691120115292},{"_id":"themes/butterfly/source/css/_tags/tabs.styl","hash":"bf9568444dd54e39dc59b461323dcd38942f27d9","modified":1691120115292},{"_id":"themes/butterfly/source/css/_tags/timeline.styl","hash":"f071156d439556e7463ed4bc61ceee87170d5d08","modified":1691120115292},{"_id":"themes/butterfly/source/css/_third-party/normalize.min.css","hash":"2c18a1c9604af475b4749def8f1959df88d8b276","modified":1691120115292},{"_id":"themes/butterfly/source/js/search/algolia.js","hash":"fd86281d4f0f99ce173e49c1a0df3507fe268d37","modified":1691120115292},{"_id":"themes/butterfly/source/js/search/local-search.js","hash":"8509cbd954ee9e099dcfbbfdafba70893a56e9ae","modified":1691120115292},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/abcjs.pug","hash":"ed6906b7c6aa7046bbad95dfdda9211997be7099","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/index.pug","hash":"f58f1648d2d71311bafca4833f20b605bb5f18c8","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/artalk.pug","hash":"5f86add36eeffbed61d11f08972a13697b4d9437","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/disqus.pug","hash":"d85c3737b5c9548553a78b757a7698df126a52cf","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/fb.pug","hash":"0344477a2cf38698318ead2681c63ac12f01586e","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/index.pug","hash":"b2d274db84ef22fbd6d5ea8f4404821898934209","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/remark42.pug","hash":"001e8be47854b891efe04013c240c38fed4185eb","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/twikoo.pug","hash":"56c028ba0ea8fac19f0125114d765dfc56ce2b48","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/valine.pug","hash":"39427e107230a10790972349c9dd4c4f31d55eb7","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/waline.pug","hash":"d02f3cc9e6183e7d05c7e90e9ae1dee5ce21f297","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/chat/crisp.pug","hash":"2fb098a7aa45010a8cd212dc0bd5308c6e7c63e3","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/chat/chatra.pug","hash":"ddce8352b371a1fb426bdb6c33f587eb37a69647","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/chat/daovoice.pug","hash":"9b57a8e13de8fc51a5f550854e47164fd8ac1be8","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/chat/index.pug","hash":"618e1b7f9204049b07beb9e1363c844a78a9ace3","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/chat/messenger.pug","hash":"e39a9c37adf4cb15a2ba3b2cc65542ffea88650d","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/chat/tidio.pug","hash":"dd61eca6e9a45f63e09bdefba89fe285a81ba096","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/comments/artalk.pug","hash":"5d5d8a0a3a7690d6d01e3feb91c2a36a5cd651b1","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqus.pug","hash":"9ef303da16d180619da18b146ddb9bc35f66bdbf","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqusjs.pug","hash":"6e17b2cea503eabeb328835038812cfa95f15871","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/comments/facebook_comments.pug","hash":"0704efed9079c867ab5f7bee7381a6c869154c73","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/comments/giscus.pug","hash":"5127bc550a2edb1ab9f45416e1964c76e8201544","modified":1691120115276},{"_id":"themes/butterfly/layout/includes/third-party/comments/gitalk.pug","hash":"2fc5627eb63118c83df9422b47c801822e28df98","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/index.pug","hash":"35ae7980f658a349c5956c5699efd435b604b836","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/js.pug","hash":"00ed91c52939b9675b316137f854d13684c895a6","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/livere.pug","hash":"52ea8aa26b84d3ad38ae28cdf0f163e9ca8dced7","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/twikoo.pug","hash":"4d78f6266d0870c06c10eaf47c951bd4d9a7732e","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/remark42.pug","hash":"598790433e3c9be28b0063bff08d257acd0abf75","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/utterances.pug","hash":"2a8d02ed9303092e8816f6489a443e7388102470","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/valine.pug","hash":"e55b9c0f8ced231f47eb88bd7f4ec99f29c5c29d","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/comments/waline.pug","hash":"0a1b8fe95623b095eb7ede3f30ca327684d1e613","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/math/index.pug","hash":"b8ae5fd7d74e1edcef21f5004fc96147e064d219","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/math/katex.pug","hash":"dfcbd9881be569ea420eff1a6b00e4f4dbe2138e","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/math/mathjax.pug","hash":"fc072ac839401174b5d3cf9acd3b694246c23a55","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/math/mermaid.pug","hash":"d0ce1891b042dcc2c93cacc866e38721b94aa4c4","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/artalk.pug","hash":"8c0d9a45bd2d83cc6d0e7bbfe172a09ff33c0178","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/disqus-comment.pug","hash":"4fe8faf77b8420fc031ae1b54f78b2ece9fcc07e","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/github-issues.pug","hash":"0330e3063ccf0ce40e4828b8d4fbef62362e8195","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/index.pug","hash":"4ec0642f2d5444acfab570a6f8c7868e7ff43fde","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/remark42.pug","hash":"aa6061183a32472cd1882fce445a5049108a984b","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"44991d67abb81784c5cdb4337b2b9798fc4361e1","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/valine.pug","hash":"b7b2aa5be4112065d5066c0f066f5f58721153bf","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/waline.pug","hash":"ae1ccd78926cc19399d396b237d5161d7cde44a8","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/search/algolia.pug","hash":"9c3c109a12d2b6916e8b4965cca12f521510ead9","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/search/docsearch.pug","hash":"1c3e101445c5571ba998ce293d3984319df1b3b0","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/search/index.pug","hash":"a99a41334387ee9a46c6f8e8212331a29a10d159","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/search/local-search.pug","hash":"5ebd5e8d39c9f77f5b2d983f6cd6802ccaf98746","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/share/add-this.pug","hash":"2980f1889226ca981aa23b8eb1853fde26dcf89a","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/share/addtoany.pug","hash":"85c92f8a7e44d7cd1c86f089a05be438535e5362","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/share/index.pug","hash":"4c4a9c15215ae8ac5eadb0e086b278f76db9ee92","modified":1691120115280},{"_id":"themes/butterfly/layout/includes/third-party/share/share-js.pug","hash":"c7dd2b2ae9b23aa0a60fffd7df9e9f76ef52033e","modified":1691120115280},{"_id":"themes/butterfly/source/css/_highlight/highlight/diff.styl","hash":"cf1fae641c927621a4df1be5ca4a853b9b526e23","modified":1691120115284},{"_id":"themes/butterfly/source/css/_highlight/highlight/index.styl","hash":"18804c58239d95798fa86d0597f32d7f7dd30051","modified":1691120115284},{"_id":"themes/butterfly/source/css/_highlight/prismjs/diff.styl","hash":"5972c61f5125068cbe0af279a0c93a54847fdc3b","modified":1691120115288},{"_id":"themes/butterfly/source/css/_highlight/prismjs/index.styl","hash":"5dc2e0bcae9a54bfb9bdcc82d02ae5a3cf1ca97d","modified":1691120115288},{"_id":"source/_posts/kubernetes/image-146.png","hash":"c83448b63f59d5bcf17280784981ac870bc2bfa4","modified":1699582789987},{"_id":"source/_posts/kubernetes/image-15.png","hash":"d32f59117d4817866be14e904b370cd265b0f784","modified":1697619614575},{"_id":"source/_posts/kubernetes/image-8.png","hash":"c19eff01c86dff878643104cabd691ad2d6eb2f3","modified":1697619548336},{"_id":"source/_posts/kubernetes/image-9.png","hash":"c19eff01c86dff878643104cabd691ad2d6eb2f3","modified":1697619554620},{"_id":"themes/butterfly/source/css/_highlight/prismjs/line-number.styl","hash":"8970cc1916c982b64a1478792b2822d1d31e276d","modified":1691120115288},{"_id":"themes/butterfly/source/img/20230818103122.jpg","hash":"690b5dbaea6aff4c293708ec80de2ac601b3495c","modified":1692325954425},{"_id":"source/_posts/kubernetes/image-115.png","hash":"ef34d2e823566713582fa399cf006171b6597c95","modified":1698976017278},{"_id":"source/_posts/kubernetes/image-114.png","hash":"0cda72aef6f6e3d7f09138aea6f29dd7318b63f2","modified":1698975837452},{"_id":"source/_posts/kubernetes/image-118.png","hash":"d1148810cbc0e4b17dd0aa5fb2c055bdd52a78a8","modified":1698976191080},{"_id":"source/_posts/kubernetes/image-19.png","hash":"f9c0e4887ce3bcd96ea8a8396d49042bcbee3063","modified":1697619657446},{"_id":"source/_posts/kubernetes/image-24.png","hash":"b6c6757c1d0be6252a3b60d3b96e520f84ff599c","modified":1697619855624},{"_id":"source/_posts/kubernetes/image-116.png","hash":"2ba1fd72e1b324df7a979b197fc7737a6afaf3ed","modified":1698976085519},{"_id":"source/_posts/kubernetes/image-14.png","hash":"f49833ea73f79f8dd1e0b510641d94c7bc79b14c","modified":1697619599783},{"_id":"source/_posts/kubernetes/image-13.png","hash":"f49833ea73f79f8dd1e0b510641d94c7bc79b14c","modified":1697619586691},{"_id":"source/_posts/kubernetes/image-5.png","hash":"c7c05824a660325f6b8ae10ed634158af50a3941","modified":1697619526600},{"_id":"source/_posts/kubernetes/image-18.png","hash":"7f214ee3a7bdfb4a347f5e9d5fb3ac1ea0d448ce","modified":1697619639199},{"_id":"themes/butterfly/source/img/20230823160932.png","hash":"9864346b852cb55c5fb3fdd45b80265e0f64bf20","modified":1692778176057},{"_id":"source/_posts/kubernetes/image-119.png","hash":"810a27aaafc8cbd8120efe089374ccc3fb6adfdd","modified":1698976350403},{"_id":"public/search.xml","hash":"cdc0fe90862f339b59bc2cdbb0bb018e2d8a637b","modified":1699586580008},{"_id":"public/about/index.html","hash":"2057c2f3a2db4aac1fa7e0b311a192362fdd98b6","modified":1699586580008},{"_id":"public/link/index.html","hash":"2c41731e297d1bc0c85ea4bfbf85db1f5340ce0b","modified":1699586580008},{"_id":"public/categories/index.html","hash":"b1c9e92e67a31d68fbf2b6a9e6f835032b47e768","modified":1699586580008},{"_id":"public/tags/index.html","hash":"f026c6a5dd19a1411929bc3b6cf9cc2fe772b9d8","modified":1699586580008},{"_id":"public/2023/11/09/kubernetes/promql/index.html","hash":"a7eaa39302cb44cef2aa65e4107dfb9475e616af","modified":1699586580008},{"_id":"public/2023/11/03/kubernetes/snat-dnat/index.html","hash":"c7fb1d35553ab0635283eadf2a22953e873ee2e3","modified":1699586580008},{"_id":"public/2023/11/03/kubernetes/internet-1-3/index.html","hash":"d5245323bea17e8dc41abc7ffb60978d7e9da8cd","modified":1699586580008},{"_id":"public/2023/11/03/kubernetes/vxlan/index.html","hash":"987533a84130948840d26180e79a3d21ac3bb416","modified":1699586580008},{"_id":"public/2023/11/02/kubernetes/gateway/index.html","hash":"3113853467fd61e58073ecc6902292506d07c9f7","modified":1699586580008},{"_id":"public/2023/11/02/kubernetes/kube-ovn-underlay/index.html","hash":"e83ba03a46ab5b0b07a1750657c42fce542b96d2","modified":1699586580008},{"_id":"public/2023/10/31/kubernetes/grafana-dashboard/index.html","hash":"6d56ead65a2c23ad35112de2b416fa3c89b647a9","modified":1699586580008},{"_id":"public/2023/10/27/linux/chrony/index.html","hash":"36d911da5c6bf1593bad692ffe014f6fa3f9c796","modified":1699586580008},{"_id":"public/2023/10/18/kubernetes/deepflow-dashboard/index.html","hash":"96ac32e0f42d7e511aacadbca4d35bc89ada232f","modified":1699586580008},{"_id":"public/2023/09/05/kubernetes/kibana-ilm/index.html","hash":"20ec932b133afca4c4ff5d7531252e05ecf0a5c9","modified":1699586580008},{"_id":"public/2023/09/01/kubernetes/kubevirt-vm-expose/index.html","hash":"e02b970b3b552016277c6109ca6fad37e1c922a9","modified":1699586580008},{"_id":"public/2023/08/31/kubernetes/grafana-create-alert-rule/index.html","hash":"ae447d1f524b580624eb45a9d6d7c69fdd5bf13d","modified":1699586580008},{"_id":"public/2023/08/25/kubernetes/metrics-server/index.html","hash":"0e0ab9c37166b3f799a8a6bd7bf88d9c837816fc","modified":1699586580008},{"_id":"public/2023/08/24/kubernetes/efk/index.html","hash":"8c246a964cb0272f08be0a401fa94b5e9c768d2c","modified":1699586580008},{"_id":"public/2023/08/24/kubernetes/fluent_Bit_Fluentd/index.html","hash":"5a80bfad2e609bc94e984afdcf8c4cfeab13484b","modified":1699586580008},{"_id":"public/2023/08/23/golang/go_template/index.html","hash":"d4b1fc6d4b0e60fda9951dcda14b5c9bb9ab6f89","modified":1699586580008},{"_id":"public/2023/08/23/docker/uninstall_docker/index.html","hash":"0ca6d4ce0782ea0ac0176c73d40655119ce71df8","modified":1699586580008},{"_id":"public/2023/08/22/nodejs/install_nodejs/index.html","hash":"839f5e06b330b852d825ade728ba086e4ae61e2a","modified":1699586580008},{"_id":"public/2023/08/22/kubernetes/uninstall_cintainerd/index.html","hash":"c6ce5ca37620c266defe15cee5e55fda03b809ed","modified":1699586580008},{"_id":"public/2023/08/18/golang/last_version_mod/index.html","hash":"f6b6573a7818f89b4e5d28b8973e6f0ee6b4d7ca","modified":1699586580008},{"_id":"public/2023/08/18/kubernetes/monitor/index.html","hash":"702684df5a6faca2661f623115f8b6fcaa82af74","modified":1699586580008},{"_id":"public/2023/08/04/hello-world/index.html","hash":"c434c50c656383128c0041a94a4d8c6c3efd0811","modified":1699586580008},{"_id":"public/archives/index.html","hash":"831c38e768c582199d37d3143454f577ca97857d","modified":1699586580008},{"_id":"public/archives/page/2/index.html","hash":"d6b9274a499609c0e416c28b4b31aeb53d2e1ac4","modified":1699586580008},{"_id":"public/archives/page/3/index.html","hash":"8148d0d22d52bde234b0d6f26e51f75f67f50fcf","modified":1699586580008},{"_id":"public/archives/2023/index.html","hash":"3879cafd6c40e05d0f16285d5e1304cdde069ddc","modified":1699586580008},{"_id":"public/archives/2023/page/2/index.html","hash":"0c4f57e5b41e79f0eb5aaae53ea27a85c7c86c9b","modified":1699586580008},{"_id":"public/archives/2023/page/3/index.html","hash":"f610826a3cec9fd70df072ab834f86d9473b4c5a","modified":1699586580008},{"_id":"public/archives/2023/08/index.html","hash":"63fdaecdd9a9f4968f29b6f4075471b83587484c","modified":1699586580008},{"_id":"public/archives/2023/08/page/2/index.html","hash":"99018a58982271ae2b9e68c23f38af0abb27954c","modified":1699586580008},{"_id":"public/archives/2023/09/index.html","hash":"8b2f6a59270374b384b2764e425c8948a17cdefc","modified":1699586580008},{"_id":"public/archives/2023/10/index.html","hash":"1d53703a41df9acb030d3c3ca6fef8eced2ecf30","modified":1699586580008},{"_id":"public/archives/2023/11/index.html","hash":"a6b3ca4c76394a1ddc340ee3e42d413993d87b99","modified":1699586580008},{"_id":"public/categories/docker/index.html","hash":"1fe8c4ee7d94068ce17a2eb397de9af70e63d528","modified":1699586580008},{"_id":"public/categories/golang/index.html","hash":"331827088ae71676d81e4c42ea3bf39c289bc91b","modified":1699586580008},{"_id":"public/categories/kubernetes/index.html","hash":"ed35a409cd58dfd57245772041d71a1002d80885","modified":1699586580008},{"_id":"public/categories/kubernetes/page/2/index.html","hash":"75104de8f2b2bb54f63b88d6abe26f9fd0dc0b56","modified":1699586580008},{"_id":"public/categories/linux/index.html","hash":"1b4f47394b97d3753871e782285edf0a265ad51c","modified":1699586580008},{"_id":"public/index.html","hash":"4b4fc56022ebf21111d840f36f06d62cb041d03d","modified":1699586580008},{"_id":"public/page/2/index.html","hash":"999effb006d1ecc82de1c3a034efb98cca39ad55","modified":1699586580008},{"_id":"public/page/3/index.html","hash":"dfafaed9a0657dbbd12de66d1399ce2adae4ca68","modified":1699586580008},{"_id":"public/tags/docker/index.html","hash":"282c15cc93b5a43decae4c2534d016b1ba501368","modified":1699586580008},{"_id":"public/tags/golang/index.html","hash":"5be32b013962be6917c18dfe9c9ddb74a611518d","modified":1699586580008},{"_id":"public/tags/logging/index.html","hash":"e03362d67bcde1e0bb1cb339fbbf676c1ae58eab","modified":1699586580008},{"_id":"public/tags/deepflow/index.html","hash":"2d5ed4d734ab9b1bac135316a059fe915878db90","modified":1699586580008},{"_id":"public/tags/grafana/index.html","hash":"9fc0a60d4dcd232eab23847599ff17e0c50b8085","modified":1699586580008},{"_id":"public/tags/gateway/index.html","hash":"6a4ad0041def8bbe45cc2a68118131d83ef5e031","modified":1699586580008},{"_id":"public/tags/计算机网络/index.html","hash":"a214460b2fe698e934f2ac90e78c4ea3990bc5ca","modified":1699586580008},{"_id":"public/tags/kibana/index.html","hash":"f6b49b038e7573b170c0ca3f901088b67c6369f8","modified":1699586580008},{"_id":"public/tags/kubeovn/index.html","hash":"6267162b57130c68b8f07fbcd1fd1549b1d8cad6","modified":1699586580008},{"_id":"public/tags/kubevirt/index.html","hash":"b4653f935645c97299950b8ed3affe73337960c7","modified":1699586580008},{"_id":"public/tags/kubernetes/index.html","hash":"97a2f620a091499b4a3db377caf4f2cd0b8260e6","modified":1699586580008},{"_id":"public/tags/PromQL/index.html","hash":"0245b1a5f6df5ee8c645a0aa356925ed550f16af","modified":1699586580008},{"_id":"public/tags/containerd/index.html","hash":"3771559ab64a18bac1d867202fc44a34ae80ec07","modified":1699586580008},{"_id":"public/tags/VXLAN/index.html","hash":"7e09c32e33920875d1c7184c1f16c1cb50df654e","modified":1699586580008},{"_id":"public/tags/chrony/index.html","hash":"5195e505899eeb941b1771e0b99e705e94abb40c","modified":1699586580008},{"_id":"public/tags/nodejs/index.html","hash":"80e6f052535faf2df2fb7d161990b160946c827b","modified":1699586580008},{"_id":"public/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1699586580008},{"_id":"public/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1699586580008},{"_id":"public/img/favicon.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1699586580008},{"_id":"public/img/thumbbig-1221433.jpg","hash":"8c32ca61f09cf449dee0024a21972a3ad9c26eff","modified":1699586580008},{"_id":"public/img/20230818103122.jpg","hash":"690b5dbaea6aff4c293708ec80de2ac601b3495c","modified":1699586580008},{"_id":"public/css/var.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1699586580008},{"_id":"public/js/utils.js","hash":"aaaedc207440095da1ffabcad870fc2641befb0e","modified":1699586580008},{"_id":"public/js/search/algolia.js","hash":"fd86281d4f0f99ce173e49c1a0df3507fe268d37","modified":1699586580008},{"_id":"public/js/search/local-search.js","hash":"8509cbd954ee9e099dcfbbfdafba70893a56e9ae","modified":1699586580008},{"_id":"public/css/index.css","hash":"d2ac9ea2eda7e3436cf544deaafd55ae1e3a81e3","modified":1699586580008},{"_id":"public/js/tw_cn.js","hash":"42b106354d72a0ea1fe62587b313a5b7de3cc393","modified":1699586580008},{"_id":"public/js/main.js","hash":"0227b5bd233a3c66582e0ee820cdb353ce52ece1","modified":1699586580008},{"_id":"public/img/20230822143445.jpg","hash":"3a109901811ca6833fb3223189064fa867653bbf","modified":1699586580008},{"_id":"public/img/20230823160932.png","hash":"9864346b852cb55c5fb3fdd45b80265e0f64bf20","modified":1699586580008}],"Category":[{"name":"docker","_id":"clos1z0bo000afmjx6ny3eboi"},{"name":"golang","_id":"clos1z0bt000efmjxhek798cc"},{"name":"kubernetes","_id":"clos1z0c5000pfmjxgtv023al"},{"name":"linux","_id":"clos1z0cu002ifmjx8vruegtu"}],"Data":[{"_id":"link","data":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}],"Page":[{"title":"about","date":"2023-08-04T03:17:19.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2023-08-04 11:17:19\n---\n","updated":"2023-08-04T03:17:19.026Z","path":"about/index.html","comments":1,"layout":"page","_id":"clos1z0aw0000fmjx9pvk3l2b","content":"","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":""},{"title":"link","date":"2023-08-18T02:10:46.000Z","type":"link","_content":"","source":"link/index.md","raw":"---\ntitle: link\ndate: 2023-08-18 10:10:46\ntype: \"link\"\n---\n","updated":"2023-08-18T02:11:20.798Z","path":"link/index.html","comments":1,"layout":"page","_id":"clos1z0b90002fmjxa1fdez5b","content":"","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":""},{"title":"categories","date":"2023-08-18T02:10:06.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2023-08-18 10:10:06\ntype: \"categories\"\n---\n","updated":"2023-08-18T02:10:31.370Z","path":"categories/index.html","comments":1,"layout":"page","_id":"clos1z0bf0004fmjxdkwpfo5m","content":"","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":""},{"title":"tags","date":"2023-08-18T02:08:43.000Z","type":"tags","orderby":"name","order":1,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2023-08-18 10:08:43\ntype: \"tags\"\norderby: name\norder: 1\n---\n","updated":"2023-08-18T02:10:02.674Z","path":"tags/index.html","comments":1,"layout":"page","_id":"clos1z0bi0006fmjxdv157uca","content":"","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":""}],"Post":[{"title":"draft","_content":"","source":"_drafts/draft.md","raw":"---\ntitle: draft\ntags:\n---\n","slug":"draft","published":0,"date":"2023-08-18T02:53:22.494Z","updated":"2023-08-18T02:53:22.494Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0b20001fmjx75d31iro","content":"","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":""},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\ndependencies:\n* node, npm\n* sudo npm install -g hexo-cli\n* sudo npm install hexo\n* npm install hexo-deployer-git --save\n* npm install hexo-generator-search --save\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\ndependencies:\n* node, npm\n* sudo npm install -g hexo-cli\n* sudo npm install hexo\n* npm install hexo-deployer-git --save\n* npm install hexo-generator-search --save\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2023-08-04T02:11:25.933Z","updated":"2023-08-23T07:14:10.502Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0bb0003fmjxc04w6vlp","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><p>dependencies:</p>\n<ul>\n<li>node, npm</li>\n<li>sudo npm install -g hexo-cli</li>\n<li>sudo npm install hexo</li>\n<li>npm install hexo-deployer-git –save</li>\n<li>npm install hexo-generator-search –save</li>\n</ul>\n<h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><p>dependencies:</p>\n<ul>\n<li>node, npm</li>\n<li>sudo npm install -g hexo-cli</li>\n<li>sudo npm install hexo</li>\n<li>npm install hexo-deployer-git –save</li>\n<li>npm install hexo-generator-search –save</li>\n</ul>\n<h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"uninstall docker","date":"2023-08-23T05:53:22.000Z","comments":1,"_content":"要在CentOS 7上干净地卸载Docker，可以执行以下步骤：\n\n1. 停止Docker服务：\n\n```\nsudo systemctl stop docker\n```\n\n2. 移除所有Docker容器和镜像。这将删除所有相关数据，包括容器、镜像以及存储卷等。请注意，这将不可逆转地删除数据。\n\n```\nsudo rm -rf /var/lib/docker\n```\n\n3. 卸载Docker软件包。可以使用以下命令之一，根据Docker的安装方式选择相应的命令：\n\n- 如果Docker是通过`yum`进行安装的：\n\n```\nsudo yum remove docker-ce docker-ce-cli containerd.io\n```\n\n- 如果Docker是通过`dnf`进行安装的：\n\n```\nsudo dnf remove docker-ce docker-ce-cli containerd.io\n```\n\n- 如果Docker是通过RPM包进行手动安装的，可以使用以下命令之一：\n\n```\nsudo rpm -e docker-ce docker-ce-cli containerd.io\n```\n\n4. 删除相关配置文件：\n\n```\nsudo rm -rf /etc/docker\nsudo rm -rf /etc/systemd/system/docker.service.d\n```\n\n5. 删除用户组和用户（可选）：\n\n```\nsudo groupdel docker\nsudo userdel docker\n```\n\n完成以上步骤后，Docker将被完全卸载。","source":"_posts/docker/uninstall_docker.md","raw":"---\ntitle: uninstall docker\ndate: 2023-08-23 13:53:22\ncategories:\n  - [docker]\ntags: docker\ncomments: true\n---\n要在CentOS 7上干净地卸载Docker，可以执行以下步骤：\n\n1. 停止Docker服务：\n\n```\nsudo systemctl stop docker\n```\n\n2. 移除所有Docker容器和镜像。这将删除所有相关数据，包括容器、镜像以及存储卷等。请注意，这将不可逆转地删除数据。\n\n```\nsudo rm -rf /var/lib/docker\n```\n\n3. 卸载Docker软件包。可以使用以下命令之一，根据Docker的安装方式选择相应的命令：\n\n- 如果Docker是通过`yum`进行安装的：\n\n```\nsudo yum remove docker-ce docker-ce-cli containerd.io\n```\n\n- 如果Docker是通过`dnf`进行安装的：\n\n```\nsudo dnf remove docker-ce docker-ce-cli containerd.io\n```\n\n- 如果Docker是通过RPM包进行手动安装的，可以使用以下命令之一：\n\n```\nsudo rpm -e docker-ce docker-ce-cli containerd.io\n```\n\n4. 删除相关配置文件：\n\n```\nsudo rm -rf /etc/docker\nsudo rm -rf /etc/systemd/system/docker.service.d\n```\n\n5. 删除用户组和用户（可选）：\n\n```\nsudo groupdel docker\nsudo userdel docker\n```\n\n完成以上步骤后，Docker将被完全卸载。","slug":"docker/uninstall_docker","published":1,"updated":"2023-08-24T05:52:19.606Z","layout":"post","photos":[],"link":"","_id":"clos1z0bg0005fmjxdcmccx9m","content":"<p>要在CentOS 7上干净地卸载Docker，可以执行以下步骤：</p>\n<ol>\n<li>停止Docker服务：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl stop docker</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>移除所有Docker容器和镜像。这将删除所有相关数据，包括容器、镜像以及存储卷等。请注意，这将不可逆转地删除数据。</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rm -rf /var/lib/docker</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>卸载Docker软件包。可以使用以下命令之一，根据Docker的安装方式选择相应的命令：</li>\n</ol>\n<ul>\n<li>如果Docker是通过<code>yum</code>进行安装的：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum remove docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>如果Docker是通过<code>dnf</code>进行安装的：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf remove docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>如果Docker是通过RPM包进行手动安装的，可以使用以下命令之一：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rpm -e docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li>删除相关配置文件：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rm -rf /etc/docker</span><br><span class=\"line\">sudo rm -rf /etc/systemd/system/docker.service.d</span><br></pre></td></tr></table></figure>\n\n<ol start=\"5\">\n<li>删除用户组和用户（可选）：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo groupdel docker</span><br><span class=\"line\">sudo userdel docker</span><br></pre></td></tr></table></figure>\n\n<p>完成以上步骤后，Docker将被完全卸载。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>要在CentOS 7上干净地卸载Docker，可以执行以下步骤：</p>\n<ol>\n<li>停止Docker服务：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl stop docker</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>移除所有Docker容器和镜像。这将删除所有相关数据，包括容器、镜像以及存储卷等。请注意，这将不可逆转地删除数据。</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rm -rf /var/lib/docker</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>卸载Docker软件包。可以使用以下命令之一，根据Docker的安装方式选择相应的命令：</li>\n</ol>\n<ul>\n<li>如果Docker是通过<code>yum</code>进行安装的：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum remove docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>如果Docker是通过<code>dnf</code>进行安装的：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dnf remove docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>如果Docker是通过RPM包进行手动安装的，可以使用以下命令之一：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rpm -e docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li>删除相关配置文件：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rm -rf /etc/docker</span><br><span class=\"line\">sudo rm -rf /etc/systemd/system/docker.service.d</span><br></pre></td></tr></table></figure>\n\n<ol start=\"5\">\n<li>删除用户组和用户（可选）：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo groupdel docker</span><br><span class=\"line\">sudo userdel docker</span><br></pre></td></tr></table></figure>\n\n<p>完成以上步骤后，Docker将被完全卸载。</p>\n"},{"title":"golang模板语法及预定义函数","date":"2023-08-23T06:52:39.000Z","_content":"在Go语言中，使用模板可以通过`text/template`或者`html/template`包来实现。这两个包的主要区别是，`html/template`包会自动对输出进行转义，以防止跨站点脚本攻击。\n\n下面是`text/template`和`html/template`包中常用的模板语法和示例：\n\n1. 注释：\n\n   可以使用`{{/* 注释内容 */}}`语法添加注释。注释可以在模板执行时忽略。\n\n   示例：\n   ```\n   {{/* This is a comment */}}\n   ```\n\n2. 输出变量值：\n\n   使用`{{.}}`语法输出当前的上下文变量值。\n\n   示例：\n   ```\n   {{.}}  // 输出当前上下文的变量值\n   ```\n\n3. 条件语句：\n\n   使用`{{if .Condition}} ... {{else}} ... {{end}}`语法进行条件判断。\n\n   示例：\n   ```\n   {{if .Condition}}\n       True Block\n   {{else}}\n       False Block\n   {{end}}\n   ```\n\n4. 循环语句：\n\n   使用`{{range .Slice}} ... {{end}}`语法进行循环迭代。\n\n   示例：\n   ```\n   {{range .Slice}}\n       {{.}}  // .表示当前迭代的元素\n   {{end}}\n   ```\n\n5. 定义和使用变量：\n\n   使用`{{with .Variable}} ... {{end}}`语法定义和使用临时变量。\n\n   示例：\n   ```\n   {{with .Variable}}\n       {{.}}  // 使用临时变量\n   {{end}}\n   ```\n\n6. 函数调用：\n\n   使用`{{函数名 参数1 参数2 ...}}`语法调用内置或自定义函数。\n\n   示例：\n   ```\n   {{len .String}}  // 调用len函数返回字符串的长度\n   ```\n\n7. 嵌套模板：\n\n   使用`{{template \"模板名称\" .数据}}`语法在模板中嵌套另一个模板。\n\n   示例：\n   ```\n   {{template \"header\" .PageTitle}}  // 嵌套名为\"header\"的模板，并传入.PageTitle参数\n   ```\n\n这些是常用的模板语法和示例，通过这些语法可以实现动态生成文本或者HTML代码的功能。具体使用方法可以参考Go语言文档中的模板包说明：https://golang.org/pkg/html/template/\n\n在Go语言的模板中，可以通过在模板中调用预定义的全局函数来进行一些常用的操作。Go语言的模板引擎提供了一些内置函数，这些函数可以在模板中直接使用，而不需要额外的导入。\n\n以下是一些常用的预定义全局函数：\n\n1. `and`：接受任意数量的布尔值作为参数，并返回它们的与运算结果。\n示例：\n```\n{{and true true}}  // true\n{{and true false}} // false\n```\n\n2. `or`：接受任意数量的布尔值作为参数，并返回它们的或运算结果。\n示例：\n```\n{{or true true}}  // true\n{{or true false}} // true\n```\n\n3. `not`：接受布尔值作为参数，并返回它的否定值。\n示例：\n```\n{{not true}}  // false\n{{not false}} // true\n```\n\n4. `eq`：用于比较两个值是否相等。\n示例：\n```\n{{eq 10 10}}   // true\n{{eq \"abc\" \"def\"}} // false\n```\n\n5. `ne`：用于比较两个值是否不相等。\n示例：\n```\n{{ne 10 20}}   // true\n{{ne \"abc\" \"abc\"}} // false\n```\n\n6. `lt`：用于比较两个值是否左边小于右边。\n示例：\n```\n{{lt 10 20}}   // true\n{{lt \"abc\" \"def\"}} // true\n```\n\n7. `le`：用于比较两个值是否左边小于等于右边。\n示例：\n```\n{{le 20 20}}   // true\n{{le \"abc\" \"def\"}} // true\n```\n\n8. `gt`：用于比较两个值是否左边大于右边。\n示例：\n```\n{{gt 20 10}}   // true\n{{gt \"def\" \"abc\"}} // true\n```\n\n9. `ge`：用于比较两个值是否左边大于等于右边。\n示例：\n```\n{{ge 20 20}}   // true\n{{ge \"def\" \"abc\"}} // true\n```\n\n10. `len`：返回一个字符串或数组的长度。\n示例：\n```\n{{len \"hello\"}}  // 5\n{{len .slice}}   // 数组或切片的长度\n```\n\n以上就是一些常用的预定义全局函数的使用方法和示例。使用这些函数可以在模板中进行一些基本的逻辑操作和比较。","source":"_posts/golang/go_template.md","raw":"---\ntitle: golang模板语法及预定义函数\ndate: 2023-08-23 14:52:39\ncategories:\n  - [golang]\ntags: golang\n---\n在Go语言中，使用模板可以通过`text/template`或者`html/template`包来实现。这两个包的主要区别是，`html/template`包会自动对输出进行转义，以防止跨站点脚本攻击。\n\n下面是`text/template`和`html/template`包中常用的模板语法和示例：\n\n1. 注释：\n\n   可以使用`{{/* 注释内容 */}}`语法添加注释。注释可以在模板执行时忽略。\n\n   示例：\n   ```\n   {{/* This is a comment */}}\n   ```\n\n2. 输出变量值：\n\n   使用`{{.}}`语法输出当前的上下文变量值。\n\n   示例：\n   ```\n   {{.}}  // 输出当前上下文的变量值\n   ```\n\n3. 条件语句：\n\n   使用`{{if .Condition}} ... {{else}} ... {{end}}`语法进行条件判断。\n\n   示例：\n   ```\n   {{if .Condition}}\n       True Block\n   {{else}}\n       False Block\n   {{end}}\n   ```\n\n4. 循环语句：\n\n   使用`{{range .Slice}} ... {{end}}`语法进行循环迭代。\n\n   示例：\n   ```\n   {{range .Slice}}\n       {{.}}  // .表示当前迭代的元素\n   {{end}}\n   ```\n\n5. 定义和使用变量：\n\n   使用`{{with .Variable}} ... {{end}}`语法定义和使用临时变量。\n\n   示例：\n   ```\n   {{with .Variable}}\n       {{.}}  // 使用临时变量\n   {{end}}\n   ```\n\n6. 函数调用：\n\n   使用`{{函数名 参数1 参数2 ...}}`语法调用内置或自定义函数。\n\n   示例：\n   ```\n   {{len .String}}  // 调用len函数返回字符串的长度\n   ```\n\n7. 嵌套模板：\n\n   使用`{{template \"模板名称\" .数据}}`语法在模板中嵌套另一个模板。\n\n   示例：\n   ```\n   {{template \"header\" .PageTitle}}  // 嵌套名为\"header\"的模板，并传入.PageTitle参数\n   ```\n\n这些是常用的模板语法和示例，通过这些语法可以实现动态生成文本或者HTML代码的功能。具体使用方法可以参考Go语言文档中的模板包说明：https://golang.org/pkg/html/template/\n\n在Go语言的模板中，可以通过在模板中调用预定义的全局函数来进行一些常用的操作。Go语言的模板引擎提供了一些内置函数，这些函数可以在模板中直接使用，而不需要额外的导入。\n\n以下是一些常用的预定义全局函数：\n\n1. `and`：接受任意数量的布尔值作为参数，并返回它们的与运算结果。\n示例：\n```\n{{and true true}}  // true\n{{and true false}} // false\n```\n\n2. `or`：接受任意数量的布尔值作为参数，并返回它们的或运算结果。\n示例：\n```\n{{or true true}}  // true\n{{or true false}} // true\n```\n\n3. `not`：接受布尔值作为参数，并返回它的否定值。\n示例：\n```\n{{not true}}  // false\n{{not false}} // true\n```\n\n4. `eq`：用于比较两个值是否相等。\n示例：\n```\n{{eq 10 10}}   // true\n{{eq \"abc\" \"def\"}} // false\n```\n\n5. `ne`：用于比较两个值是否不相等。\n示例：\n```\n{{ne 10 20}}   // true\n{{ne \"abc\" \"abc\"}} // false\n```\n\n6. `lt`：用于比较两个值是否左边小于右边。\n示例：\n```\n{{lt 10 20}}   // true\n{{lt \"abc\" \"def\"}} // true\n```\n\n7. `le`：用于比较两个值是否左边小于等于右边。\n示例：\n```\n{{le 20 20}}   // true\n{{le \"abc\" \"def\"}} // true\n```\n\n8. `gt`：用于比较两个值是否左边大于右边。\n示例：\n```\n{{gt 20 10}}   // true\n{{gt \"def\" \"abc\"}} // true\n```\n\n9. `ge`：用于比较两个值是否左边大于等于右边。\n示例：\n```\n{{ge 20 20}}   // true\n{{ge \"def\" \"abc\"}} // true\n```\n\n10. `len`：返回一个字符串或数组的长度。\n示例：\n```\n{{len \"hello\"}}  // 5\n{{len .slice}}   // 数组或切片的长度\n```\n\n以上就是一些常用的预定义全局函数的使用方法和示例。使用这些函数可以在模板中进行一些基本的逻辑操作和比较。","slug":"golang/go_template","published":1,"updated":"2023-08-23T06:55:23.180Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0bj0007fmjxhg1v1idl","content":"<p>在Go语言中，使用模板可以通过<code>text/template</code>或者<code>html/template</code>包来实现。这两个包的主要区别是，<code>html/template</code>包会自动对输出进行转义，以防止跨站点脚本攻击。</p>\n<p>下面是<code>text/template</code>和<code>html/template</code>包中常用的模板语法和示例：</p>\n<ol>\n<li><p>注释：</p>\n<p>可以使用<code>&#123;&#123;/* 注释内容 */&#125;&#125;</code>语法添加注释。注释可以在模板执行时忽略。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;/* This is a comment */&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>输出变量值：</p>\n<p>使用<code>&#123;&#123;.&#125;&#125;</code>语法输出当前的上下文变量值。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;.&#125;&#125;  // 输出当前上下文的变量值</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>条件语句：</p>\n<p>使用<code>&#123;&#123;if .Condition&#125;&#125; ... &#123;&#123;else&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法进行条件判断。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;if .Condition&#125;&#125;</span><br><span class=\"line\">    True Block</span><br><span class=\"line\">&#123;&#123;else&#125;&#125;</span><br><span class=\"line\">    False Block</span><br><span class=\"line\">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>循环语句：</p>\n<p>使用<code>&#123;&#123;range .Slice&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法进行循环迭代。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;range .Slice&#125;&#125;</span><br><span class=\"line\">    &#123;&#123;.&#125;&#125;  // .表示当前迭代的元素</span><br><span class=\"line\">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>定义和使用变量：</p>\n<p>使用<code>&#123;&#123;with .Variable&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法定义和使用临时变量。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;with .Variable&#125;&#125;</span><br><span class=\"line\">    &#123;&#123;.&#125;&#125;  // 使用临时变量</span><br><span class=\"line\">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>函数调用：</p>\n<p>使用<code>&#123;&#123;函数名 参数1 参数2 ...&#125;&#125;</code>语法调用内置或自定义函数。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;len .String&#125;&#125;  // 调用len函数返回字符串的长度</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>嵌套模板：</p>\n<p>使用<code>&#123;&#123;template \"模板名称\" .数据&#125;&#125;</code>语法在模板中嵌套另一个模板。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;template &quot;header&quot; .PageTitle&#125;&#125;  // 嵌套名为&quot;header&quot;的模板，并传入.PageTitle参数</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p>这些是常用的模板语法和示例，通过这些语法可以实现动态生成文本或者HTML代码的功能。具体使用方法可以参考Go语言文档中的模板包说明：<a href=\"https://golang.org/pkg/html/template/\">https://golang.org/pkg/html/template/</a></p>\n<p>在Go语言的模板中，可以通过在模板中调用预定义的全局函数来进行一些常用的操作。Go语言的模板引擎提供了一些内置函数，这些函数可以在模板中直接使用，而不需要额外的导入。</p>\n<p>以下是一些常用的预定义全局函数：</p>\n<ol>\n<li><p><code>and</code>：接受任意数量的布尔值作为参数，并返回它们的与运算结果。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;and true true&#125;&#125;  // true</span><br><span class=\"line\">&#123;&#123;and true false&#125;&#125; // false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>or</code>：接受任意数量的布尔值作为参数，并返回它们的或运算结果。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;or true true&#125;&#125;  // true</span><br><span class=\"line\">&#123;&#123;or true false&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>not</code>：接受布尔值作为参数，并返回它的否定值。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;not true&#125;&#125;  // false</span><br><span class=\"line\">&#123;&#123;not false&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>eq</code>：用于比较两个值是否相等。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;eq 10 10&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;eq &quot;abc&quot; &quot;def&quot;&#125;&#125; // false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>ne</code>：用于比较两个值是否不相等。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;ne 10 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;ne &quot;abc&quot; &quot;abc&quot;&#125;&#125; // false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>lt</code>：用于比较两个值是否左边小于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;lt 10 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;lt &quot;abc&quot; &quot;def&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>le</code>：用于比较两个值是否左边小于等于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;le 20 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;le &quot;abc&quot; &quot;def&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>gt</code>：用于比较两个值是否左边大于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;gt 20 10&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;gt &quot;def&quot; &quot;abc&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>ge</code>：用于比较两个值是否左边大于等于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;ge 20 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;ge &quot;def&quot; &quot;abc&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>len</code>：返回一个字符串或数组的长度。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;len &quot;hello&quot;&#125;&#125;  // 5</span><br><span class=\"line\">&#123;&#123;len .slice&#125;&#125;   // 数组或切片的长度</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p>以上就是一些常用的预定义全局函数的使用方法和示例。使用这些函数可以在模板中进行一些基本的逻辑操作和比较。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>在Go语言中，使用模板可以通过<code>text/template</code>或者<code>html/template</code>包来实现。这两个包的主要区别是，<code>html/template</code>包会自动对输出进行转义，以防止跨站点脚本攻击。</p>\n<p>下面是<code>text/template</code>和<code>html/template</code>包中常用的模板语法和示例：</p>\n<ol>\n<li><p>注释：</p>\n<p>可以使用<code>&#123;&#123;/* 注释内容 */&#125;&#125;</code>语法添加注释。注释可以在模板执行时忽略。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;/* This is a comment */&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>输出变量值：</p>\n<p>使用<code>&#123;&#123;.&#125;&#125;</code>语法输出当前的上下文变量值。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;.&#125;&#125;  // 输出当前上下文的变量值</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>条件语句：</p>\n<p>使用<code>&#123;&#123;if .Condition&#125;&#125; ... &#123;&#123;else&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法进行条件判断。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;if .Condition&#125;&#125;</span><br><span class=\"line\">    True Block</span><br><span class=\"line\">&#123;&#123;else&#125;&#125;</span><br><span class=\"line\">    False Block</span><br><span class=\"line\">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>循环语句：</p>\n<p>使用<code>&#123;&#123;range .Slice&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法进行循环迭代。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;range .Slice&#125;&#125;</span><br><span class=\"line\">    &#123;&#123;.&#125;&#125;  // .表示当前迭代的元素</span><br><span class=\"line\">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>定义和使用变量：</p>\n<p>使用<code>&#123;&#123;with .Variable&#125;&#125; ... &#123;&#123;end&#125;&#125;</code>语法定义和使用临时变量。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;with .Variable&#125;&#125;</span><br><span class=\"line\">    &#123;&#123;.&#125;&#125;  // 使用临时变量</span><br><span class=\"line\">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>函数调用：</p>\n<p>使用<code>&#123;&#123;函数名 参数1 参数2 ...&#125;&#125;</code>语法调用内置或自定义函数。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;len .String&#125;&#125;  // 调用len函数返回字符串的长度</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>嵌套模板：</p>\n<p>使用<code>&#123;&#123;template \"模板名称\" .数据&#125;&#125;</code>语法在模板中嵌套另一个模板。</p>\n<p>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;template &quot;header&quot; .PageTitle&#125;&#125;  // 嵌套名为&quot;header&quot;的模板，并传入.PageTitle参数</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p>这些是常用的模板语法和示例，通过这些语法可以实现动态生成文本或者HTML代码的功能。具体使用方法可以参考Go语言文档中的模板包说明：<a href=\"https://golang.org/pkg/html/template/\">https://golang.org/pkg/html/template/</a></p>\n<p>在Go语言的模板中，可以通过在模板中调用预定义的全局函数来进行一些常用的操作。Go语言的模板引擎提供了一些内置函数，这些函数可以在模板中直接使用，而不需要额外的导入。</p>\n<p>以下是一些常用的预定义全局函数：</p>\n<ol>\n<li><p><code>and</code>：接受任意数量的布尔值作为参数，并返回它们的与运算结果。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;and true true&#125;&#125;  // true</span><br><span class=\"line\">&#123;&#123;and true false&#125;&#125; // false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>or</code>：接受任意数量的布尔值作为参数，并返回它们的或运算结果。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;or true true&#125;&#125;  // true</span><br><span class=\"line\">&#123;&#123;or true false&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>not</code>：接受布尔值作为参数，并返回它的否定值。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;not true&#125;&#125;  // false</span><br><span class=\"line\">&#123;&#123;not false&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>eq</code>：用于比较两个值是否相等。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;eq 10 10&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;eq &quot;abc&quot; &quot;def&quot;&#125;&#125; // false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>ne</code>：用于比较两个值是否不相等。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;ne 10 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;ne &quot;abc&quot; &quot;abc&quot;&#125;&#125; // false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>lt</code>：用于比较两个值是否左边小于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;lt 10 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;lt &quot;abc&quot; &quot;def&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>le</code>：用于比较两个值是否左边小于等于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;le 20 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;le &quot;abc&quot; &quot;def&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>gt</code>：用于比较两个值是否左边大于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;gt 20 10&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;gt &quot;def&quot; &quot;abc&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>ge</code>：用于比较两个值是否左边大于等于右边。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;ge 20 20&#125;&#125;   // true</span><br><span class=\"line\">&#123;&#123;ge &quot;def&quot; &quot;abc&quot;&#125;&#125; // true</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>len</code>：返回一个字符串或数组的长度。<br>示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;len &quot;hello&quot;&#125;&#125;  // 5</span><br><span class=\"line\">&#123;&#123;len .slice&#125;&#125;   // 数组或切片的长度</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p>以上就是一些常用的预定义全局函数的使用方法和示例。使用这些函数可以在模板中进行一些基本的逻辑操作和比较。</p>\n"},{"title":"go mod使用最新提交","date":"2023-08-18T10:49:14.000Z","_content":"​\n例如一个项目在其中依赖了    github.com/linuxsuren/go-fake-runtime v0.0.1\n\ngo.mod内容：\n\n\tgithub.com/linuxsuren/go-fake-runtime v0.0.1\n\n修改了github.com/linuxsuren/go-fake-runtime代码，存在一个最新的commit hash值为25fa814c6232e545f5bce03bd4db04fc37e10250\n\n修改项目中的go.mod\n```\ngithub.com/linuxsuren/go-fake-runtime 25fa814c6232e545f5bce03bd4db04fc37e10250\n```\n然后执行go mod tidy,会看到go.mod中的依赖会更新为最新的提交\n```\ngithub.com/linuxsuren/go-fake-runtime v0.0.2-0.20230815071200-25fa814c6232\n```\n至此项目依赖的github.com/linuxsuren/go-fake-runtime已由v0.0.1版本更为指定的commit。\n\n​","source":"_posts/golang/last_version_mod.md","raw":"---\ntitle: go mod使用最新提交\ndate: 2023-08-18 18:49:14\ncategories:\n  - [golang]\ntags: golang\n---\n​\n例如一个项目在其中依赖了    github.com/linuxsuren/go-fake-runtime v0.0.1\n\ngo.mod内容：\n\n\tgithub.com/linuxsuren/go-fake-runtime v0.0.1\n\n修改了github.com/linuxsuren/go-fake-runtime代码，存在一个最新的commit hash值为25fa814c6232e545f5bce03bd4db04fc37e10250\n\n修改项目中的go.mod\n```\ngithub.com/linuxsuren/go-fake-runtime 25fa814c6232e545f5bce03bd4db04fc37e10250\n```\n然后执行go mod tidy,会看到go.mod中的依赖会更新为最新的提交\n```\ngithub.com/linuxsuren/go-fake-runtime v0.0.2-0.20230815071200-25fa814c6232\n```\n至此项目依赖的github.com/linuxsuren/go-fake-runtime已由v0.0.1版本更为指定的commit。\n\n​","slug":"golang/last_version_mod","published":1,"updated":"2023-08-23T06:55:29.952Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0bn0009fmjx7r4n7y30","content":"<p>​<br>例如一个项目在其中依赖了    github.com&#x2F;linuxsuren&#x2F;go-fake-runtime v0.0.1</p>\n<p>go.mod内容：</p>\n<pre><code>github.com/linuxsuren/go-fake-runtime v0.0.1\n</code></pre>\n<p>修改了github.com&#x2F;linuxsuren&#x2F;go-fake-runtime代码，存在一个最新的commit hash值为25fa814c6232e545f5bce03bd4db04fc37e10250</p>\n<p>修改项目中的go.mod</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">github.com/linuxsuren/go-fake-runtime 25fa814c6232e545f5bce03bd4db04fc37e10250</span><br></pre></td></tr></table></figure>\n<p>然后执行go mod tidy,会看到go.mod中的依赖会更新为最新的提交</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">github.com/linuxsuren/go-fake-runtime v0.0.2-0.20230815071200-25fa814c6232</span><br></pre></td></tr></table></figure>\n<p>至此项目依赖的github.com&#x2F;linuxsuren&#x2F;go-fake-runtime已由v0.0.1版本更为指定的commit。</p>\n<p>​</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>​<br>例如一个项目在其中依赖了    github.com&#x2F;linuxsuren&#x2F;go-fake-runtime v0.0.1</p>\n<p>go.mod内容：</p>\n<pre><code>github.com/linuxsuren/go-fake-runtime v0.0.1\n</code></pre>\n<p>修改了github.com&#x2F;linuxsuren&#x2F;go-fake-runtime代码，存在一个最新的commit hash值为25fa814c6232e545f5bce03bd4db04fc37e10250</p>\n<p>修改项目中的go.mod</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">github.com/linuxsuren/go-fake-runtime 25fa814c6232e545f5bce03bd4db04fc37e10250</span><br></pre></td></tr></table></figure>\n<p>然后执行go mod tidy,会看到go.mod中的依赖会更新为最新的提交</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">github.com/linuxsuren/go-fake-runtime v0.0.2-0.20230815071200-25fa814c6232</span><br></pre></td></tr></table></figure>\n<p>至此项目依赖的github.com&#x2F;linuxsuren&#x2F;go-fake-runtime已由v0.0.1版本更为指定的commit。</p>\n<p>​</p>\n"},{"title":"EFK","date":"2023-08-24T08:34:28.000Z","_content":"要在Kubernetes中部署Filebeat、Elasticsearch和Kibana来采集容器日志，可以按照以下步骤进行:\n\n1. 部署Elasticsearch:\n   在Kubernetes集群上创建一个Elasticsearch的Deployment，这个Deployment将用于存储和索引日志数据。可以使用以下示例配置文件创建Deployment:\n\n   ```yaml\n   apiVersion: apps/v1\n   kind: Deployment\n   metadata:\n     name: elasticsearch\n   spec:\n     replicas: 1\n     selector:\n       matchLabels:\n         app: elasticsearch\n     template:\n       metadata:\n         labels:\n           app: elasticsearch\n       spec:\n         containers:\n         - name: elasticsearch\n           image: elasticsearch:7.12.1\n           resources:\n             requests:\n               memory: 2Gi\n               cpu: 1\n           ports:\n           - containerPort: 9200\n   ```\n\n   运行`kubectl apply -f elasticsearch.yaml`命令来创建Deployment。\n\n2. 部署Kibana:\n   在Kubernetes集群上创建一个Kibana的Deployment，这个Deployment将用于可视化和查询日志数据。可以使用以下示例配置文件创建Deployment:\n\n   ```yaml\n   apiVersion: apps/v1\n   kind: Deployment\n   metadata:\n     name: kibana\n   spec:\n     replicas: 1\n     selector:\n       matchLabels:\n         app: kibana\n     template:\n       metadata:\n         labels:\n           app: kibana\n       spec:\n         containers:\n         - name: kibana\n           image: kibana:7.12.1\n           resources:\n             requests:\n               memory: 1Gi\n               cpu: 0.5\n           ports:\n           - containerPort: 5601\n   ```\n\n   运行`kubectl apply -f kibana.yaml`命令来创建Deployment。\n\n3. 部署Filebeat:\n   在Kubernetes集群上创建一个Filebeat DaemonSet，这个DaemonSet将在每个节点上运行一个Filebeat实例来收集容器日志。可以使用以下示例配置文件创建DaemonSet:\n\n   ```yaml\n   apiVersion: apps/v1\n   kind: DaemonSet\n   metadata:\n     name: filebeat\n     labels:\n       app: filebeat\n   spec:\n     selector:\n       matchLabels:\n         app: filebeat\n     template:\n       metadata:\n         labels:\n           app: filebeat\n       spec:\n         containers:\n         - name: filebeat\n           image: docker.elastic.co/beats/filebeat:7.12.1\n           volumeMounts:\n           - name: varlibdockercontainers\n             mountPath: /var/lib/docker/containers\n             readOnly: true\n           - name: varlog\n             mountPath: /var/log\n             readOnly: true\n           - name: varlogpod\n             mountPath: /var/log/pods\n             readOnly: true\n           - name: varrun\n             mountPath: /var/run\n           - name: varlibkubelet\n             mountPath: /var/lib/kubelet\n           - name: varlognode\n             mountPath: /var/log/node\n             readOnly: true\n           - name: varlogcontainersnew\n             mountPath: /var/log/containersnew\n             readOnly: true\n           - name: dockersocket\n             mountPath: /var/run/docker.sock\n           - name: config\n             mountPath: /usr/share/filebeat/filebeat.yml\n             subPath: filebeat.yml\n             readOnly: true\n           env:\n           - name: K8S_NODE_NAME\n             valueFrom:\n               fieldRef:\n                 fieldPath: spec.nodeName\n           - name: NODE_NAME\n             valueFrom:\n               fieldRef:\n                 fieldPath: spec.nodeName\n           - name: FILEBEAT_HOST\n             valueFrom:\n               fieldRef:\n                 fieldPath: status.hostIP\n           - name: FILEBEAT_CONFIG_CHECK_FREQUENCY\n             value: \"5s\"\n           - name: OUTPUT_TYPE\n             value: elasticsearch\n           - name: ELASTICSEARCH_HOST\n             value: elasticsearch:9200\n           - name: ELASTICSEARCH_USERNAME\n             value: \"<ELASTICSEARCH_USERNAME>\"\n           - name: ELASTICSEARCH_PASSWORD\n             value: \"<ELASTICSEARCH_PASSWORD>\"\n           - name: ELASTICSEARCH_INDEX\n             value: \"filebeat-%{[agent.version]}-%{+yyyy.MM.dd}\"\n           - name: ELASTICSEARCH_PIPELINE\n             value: \"<ELASTICSEARCH_PIPELINE>\"\n           resources:\n             limits:\n               memory: 200Mi\n             requests:\n               cpu: 100m\n               memory: 100Mi\n           terminationGracePeriodSeconds: 30\n           dnsPolicy: ClusterFirstWithHostNet\n           restartPolicy: Always\n           hostNetwork: true\n           volumes:\n           - name: varlibdockercontainers\n             hostPath:\n               path: /var/lib/docker/containers\n           - name: varlog\n             hostPath:\n               path: /var/log\n           - name: varlogpod\n             hostPath:\n               path: /var/log/pods\n           - name: varrun\n             hostPath:\n               path: /var/run\n           - name: varlibkubelet\n             hostPath:\n               path: /var/lib/kubelet\n           - name: varlognode\n             hostPath:\n               path: /var/log/node\n           - name: varlogcontainersnew\n             hostPath:\n               path: /var/log/containersnew\n           - name: dockersocket\n             hostPath:\n               path: /var/run/docker.sock\n           - name: config\n             configMap:\n               name: filebeat-config\n       updateStrategy:\n         type: RollingUpdate\n        rollingUpdate:\n           maxUnavailable: 1\n   ```\n\n   创建一个ConfigMap来存储Filebeat的配置文件(filebeat.yml)，示例配置文件可以参考以下内容:\n\n   ```yaml\n   filebeat.config:\n     modules:\n       path: ${path.config}/modules.d/*.yml\n       reload.enabled: false\n\n   filebeat.modules:\n   - module: system\n     syslog:\n       enabled: true\n     auth:\n       enabled: true\n     package:\n       enabled: true\n     coredns:\n       enabled: true\n\n   output.elasticsearch:\n     hosts: ['elasticsearch:9200']\n     username: '<ELASTICSEARCH_USERNAME>'\n     password: '<ELASTICSEARCH_PASSWORD>'\n     pipeline: '<ELASTICSEARCH_PIPELINE>'\n   ```\n\n   运行`kubectl create configmap filebeat-config --from-file=filebeat.yml`命令来创建ConfigMap。\n\n   然后，运行`kubectl apply -f filebeat.yaml`命令来创建DaemonSet。\n\n4. 日志采集:\n   当Filebeat启动后，它将开始采集Kubernetes集群中所有容器的日志数据，并将其发送到Elasticsearch进行存储和索引。您可以使用Kibana来可视化和查询这些日志数据。\n\n这是一个简单的部署Filebeat、Elasticsearch和Kibana来采集Kubernetes集群中容器日志的示例配置。根据您的实际需求，可能还需要进行一些其他的配置和调整。","source":"_posts/kubernetes/efk.md","raw":"---\ntitle: EFK\ndate: 2023-08-24 16:34:28\ncategories:\n  - [kubernetes]\ntags: logging\n---\n要在Kubernetes中部署Filebeat、Elasticsearch和Kibana来采集容器日志，可以按照以下步骤进行:\n\n1. 部署Elasticsearch:\n   在Kubernetes集群上创建一个Elasticsearch的Deployment，这个Deployment将用于存储和索引日志数据。可以使用以下示例配置文件创建Deployment:\n\n   ```yaml\n   apiVersion: apps/v1\n   kind: Deployment\n   metadata:\n     name: elasticsearch\n   spec:\n     replicas: 1\n     selector:\n       matchLabels:\n         app: elasticsearch\n     template:\n       metadata:\n         labels:\n           app: elasticsearch\n       spec:\n         containers:\n         - name: elasticsearch\n           image: elasticsearch:7.12.1\n           resources:\n             requests:\n               memory: 2Gi\n               cpu: 1\n           ports:\n           - containerPort: 9200\n   ```\n\n   运行`kubectl apply -f elasticsearch.yaml`命令来创建Deployment。\n\n2. 部署Kibana:\n   在Kubernetes集群上创建一个Kibana的Deployment，这个Deployment将用于可视化和查询日志数据。可以使用以下示例配置文件创建Deployment:\n\n   ```yaml\n   apiVersion: apps/v1\n   kind: Deployment\n   metadata:\n     name: kibana\n   spec:\n     replicas: 1\n     selector:\n       matchLabels:\n         app: kibana\n     template:\n       metadata:\n         labels:\n           app: kibana\n       spec:\n         containers:\n         - name: kibana\n           image: kibana:7.12.1\n           resources:\n             requests:\n               memory: 1Gi\n               cpu: 0.5\n           ports:\n           - containerPort: 5601\n   ```\n\n   运行`kubectl apply -f kibana.yaml`命令来创建Deployment。\n\n3. 部署Filebeat:\n   在Kubernetes集群上创建一个Filebeat DaemonSet，这个DaemonSet将在每个节点上运行一个Filebeat实例来收集容器日志。可以使用以下示例配置文件创建DaemonSet:\n\n   ```yaml\n   apiVersion: apps/v1\n   kind: DaemonSet\n   metadata:\n     name: filebeat\n     labels:\n       app: filebeat\n   spec:\n     selector:\n       matchLabels:\n         app: filebeat\n     template:\n       metadata:\n         labels:\n           app: filebeat\n       spec:\n         containers:\n         - name: filebeat\n           image: docker.elastic.co/beats/filebeat:7.12.1\n           volumeMounts:\n           - name: varlibdockercontainers\n             mountPath: /var/lib/docker/containers\n             readOnly: true\n           - name: varlog\n             mountPath: /var/log\n             readOnly: true\n           - name: varlogpod\n             mountPath: /var/log/pods\n             readOnly: true\n           - name: varrun\n             mountPath: /var/run\n           - name: varlibkubelet\n             mountPath: /var/lib/kubelet\n           - name: varlognode\n             mountPath: /var/log/node\n             readOnly: true\n           - name: varlogcontainersnew\n             mountPath: /var/log/containersnew\n             readOnly: true\n           - name: dockersocket\n             mountPath: /var/run/docker.sock\n           - name: config\n             mountPath: /usr/share/filebeat/filebeat.yml\n             subPath: filebeat.yml\n             readOnly: true\n           env:\n           - name: K8S_NODE_NAME\n             valueFrom:\n               fieldRef:\n                 fieldPath: spec.nodeName\n           - name: NODE_NAME\n             valueFrom:\n               fieldRef:\n                 fieldPath: spec.nodeName\n           - name: FILEBEAT_HOST\n             valueFrom:\n               fieldRef:\n                 fieldPath: status.hostIP\n           - name: FILEBEAT_CONFIG_CHECK_FREQUENCY\n             value: \"5s\"\n           - name: OUTPUT_TYPE\n             value: elasticsearch\n           - name: ELASTICSEARCH_HOST\n             value: elasticsearch:9200\n           - name: ELASTICSEARCH_USERNAME\n             value: \"<ELASTICSEARCH_USERNAME>\"\n           - name: ELASTICSEARCH_PASSWORD\n             value: \"<ELASTICSEARCH_PASSWORD>\"\n           - name: ELASTICSEARCH_INDEX\n             value: \"filebeat-%{[agent.version]}-%{+yyyy.MM.dd}\"\n           - name: ELASTICSEARCH_PIPELINE\n             value: \"<ELASTICSEARCH_PIPELINE>\"\n           resources:\n             limits:\n               memory: 200Mi\n             requests:\n               cpu: 100m\n               memory: 100Mi\n           terminationGracePeriodSeconds: 30\n           dnsPolicy: ClusterFirstWithHostNet\n           restartPolicy: Always\n           hostNetwork: true\n           volumes:\n           - name: varlibdockercontainers\n             hostPath:\n               path: /var/lib/docker/containers\n           - name: varlog\n             hostPath:\n               path: /var/log\n           - name: varlogpod\n             hostPath:\n               path: /var/log/pods\n           - name: varrun\n             hostPath:\n               path: /var/run\n           - name: varlibkubelet\n             hostPath:\n               path: /var/lib/kubelet\n           - name: varlognode\n             hostPath:\n               path: /var/log/node\n           - name: varlogcontainersnew\n             hostPath:\n               path: /var/log/containersnew\n           - name: dockersocket\n             hostPath:\n               path: /var/run/docker.sock\n           - name: config\n             configMap:\n               name: filebeat-config\n       updateStrategy:\n         type: RollingUpdate\n        rollingUpdate:\n           maxUnavailable: 1\n   ```\n\n   创建一个ConfigMap来存储Filebeat的配置文件(filebeat.yml)，示例配置文件可以参考以下内容:\n\n   ```yaml\n   filebeat.config:\n     modules:\n       path: ${path.config}/modules.d/*.yml\n       reload.enabled: false\n\n   filebeat.modules:\n   - module: system\n     syslog:\n       enabled: true\n     auth:\n       enabled: true\n     package:\n       enabled: true\n     coredns:\n       enabled: true\n\n   output.elasticsearch:\n     hosts: ['elasticsearch:9200']\n     username: '<ELASTICSEARCH_USERNAME>'\n     password: '<ELASTICSEARCH_PASSWORD>'\n     pipeline: '<ELASTICSEARCH_PIPELINE>'\n   ```\n\n   运行`kubectl create configmap filebeat-config --from-file=filebeat.yml`命令来创建ConfigMap。\n\n   然后，运行`kubectl apply -f filebeat.yaml`命令来创建DaemonSet。\n\n4. 日志采集:\n   当Filebeat启动后，它将开始采集Kubernetes集群中所有容器的日志数据，并将其发送到Elasticsearch进行存储和索引。您可以使用Kibana来可视化和查询这些日志数据。\n\n这是一个简单的部署Filebeat、Elasticsearch和Kibana来采集Kubernetes集群中容器日志的示例配置。根据您的实际需求，可能还需要进行一些其他的配置和调整。","slug":"kubernetes/efk","published":1,"updated":"2023-08-24T08:35:02.494Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0bq000bfmjx3h2d9mqb","content":"<p>要在Kubernetes中部署Filebeat、Elasticsearch和Kibana来采集容器日志，可以按照以下步骤进行:</p>\n<ol>\n<li><p>部署Elasticsearch:<br>在Kubernetes集群上创建一个Elasticsearch的Deployment，这个Deployment将用于存储和索引日志数据。可以使用以下示例配置文件创建Deployment:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">elasticsearch:7.12.1</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">2Gi</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">9200</span></span><br></pre></td></tr></table></figure>\n\n<p>运行<code>kubectl apply -f elasticsearch.yaml</code>命令来创建Deployment。</p>\n</li>\n<li><p>部署Kibana:<br>在Kubernetes集群上创建一个Kibana的Deployment，这个Deployment将用于可视化和查询日志数据。可以使用以下示例配置文件创建Deployment:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">kibana:7.12.1</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">1Gi</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"number\">0.5</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">5601</span></span><br></pre></td></tr></table></figure>\n\n<p>运行<code>kubectl apply -f kibana.yaml</code>命令来创建Deployment。</p>\n</li>\n<li><p>部署Filebeat:<br>在Kubernetes集群上创建一个Filebeat DaemonSet，这个DaemonSet将在每个节点上运行一个Filebeat实例来收集容器日志。可以使用以下示例配置文件创建DaemonSet:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">DaemonSet</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">docker.elastic.co/beats/filebeat:7.12.1</span></span><br><span class=\"line\">        <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibdockercontainers</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/lib/docker/containers</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlog</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogpod</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log/pods</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varrun</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/run</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibkubelet</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/lib/kubelet</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlognode</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log/node</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogcontainersnew</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log/containersnew</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">dockersocket</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/run/docker.sock</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/usr/share/filebeat/filebeat.yml</span></span><br><span class=\"line\">          <span class=\"attr\">subPath:</span> <span class=\"string\">filebeat.yml</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">env:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">K8S_NODE_NAME</span></span><br><span class=\"line\">          <span class=\"attr\">valueFrom:</span></span><br><span class=\"line\">            <span class=\"attr\">fieldRef:</span></span><br><span class=\"line\">              <span class=\"attr\">fieldPath:</span> <span class=\"string\">spec.nodeName</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">NODE_NAME</span></span><br><span class=\"line\">          <span class=\"attr\">valueFrom:</span></span><br><span class=\"line\">            <span class=\"attr\">fieldRef:</span></span><br><span class=\"line\">              <span class=\"attr\">fieldPath:</span> <span class=\"string\">spec.nodeName</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">FILEBEAT_HOST</span></span><br><span class=\"line\">          <span class=\"attr\">valueFrom:</span></span><br><span class=\"line\">            <span class=\"attr\">fieldRef:</span></span><br><span class=\"line\">              <span class=\"attr\">fieldPath:</span> <span class=\"string\">status.hostIP</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">FILEBEAT_CONFIG_CHECK_FREQUENCY</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;5s&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">OUTPUT_TYPE</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_HOST</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">elasticsearch:9200</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_USERNAME</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;&lt;ELASTICSEARCH_USERNAME&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_PASSWORD</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;&lt;ELASTICSEARCH_PASSWORD&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_INDEX</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;filebeat-<span class=\"template-variable\">%&#123;[agent.version]&#125;</span>-<span class=\"template-variable\">%&#123;+yyyy.MM.dd&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_PIPELINE</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;&lt;ELASTICSEARCH_PIPELINE&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">limits:</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">200Mi</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"string\">100m</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">100Mi</span></span><br><span class=\"line\">        <span class=\"attr\">terminationGracePeriodSeconds:</span> <span class=\"number\">30</span></span><br><span class=\"line\">        <span class=\"attr\">dnsPolicy:</span> <span class=\"string\">ClusterFirstWithHostNet</span></span><br><span class=\"line\">        <span class=\"attr\">restartPolicy:</span> <span class=\"string\">Always</span></span><br><span class=\"line\">        <span class=\"attr\">hostNetwork:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibdockercontainers</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/lib/docker/containers</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlog</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogpod</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log/pods</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varrun</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/run</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibkubelet</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/lib/kubelet</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlognode</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log/node</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogcontainersnew</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log/containersnew</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">dockersocket</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/run/docker.sock</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config</span></span><br><span class=\"line\">          <span class=\"attr\">configMap:</span></span><br><span class=\"line\">            <span class=\"attr\">name:</span> <span class=\"string\">filebeat-config</span></span><br><span class=\"line\">    <span class=\"attr\">updateStrategy:</span></span><br><span class=\"line\">      <span class=\"attr\">type:</span> <span class=\"string\">RollingUpdate</span></span><br><span class=\"line\">     <span class=\"attr\">rollingUpdate:</span></span><br><span class=\"line\">        <span class=\"attr\">maxUnavailable:</span> <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n<p>创建一个ConfigMap来存储Filebeat的配置文件(filebeat.yml)，示例配置文件可以参考以下内容:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">filebeat.config:</span></span><br><span class=\"line\">  <span class=\"attr\">modules:</span></span><br><span class=\"line\">    <span class=\"attr\">path:</span> <span class=\"string\">$&#123;path.config&#125;/modules.d/*.yml</span></span><br><span class=\"line\">    <span class=\"attr\">reload.enabled:</span> <span class=\"literal\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">filebeat.modules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">module:</span> <span class=\"string\">system</span></span><br><span class=\"line\">  <span class=\"attr\">syslog:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">auth:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">package:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">coredns:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">output.elasticsearch:</span></span><br><span class=\"line\">  <span class=\"attr\">hosts:</span> [<span class=\"string\">&#x27;elasticsearch:9200&#x27;</span>]</span><br><span class=\"line\">  <span class=\"attr\">username:</span> <span class=\"string\">&#x27;&lt;ELASTICSEARCH_USERNAME&gt;&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">password:</span> <span class=\"string\">&#x27;&lt;ELASTICSEARCH_PASSWORD&gt;&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">pipeline:</span> <span class=\"string\">&#x27;&lt;ELASTICSEARCH_PIPELINE&gt;&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>运行<code>kubectl create configmap filebeat-config --from-file=filebeat.yml</code>命令来创建ConfigMap。</p>\n<p>然后，运行<code>kubectl apply -f filebeat.yaml</code>命令来创建DaemonSet。</p>\n</li>\n<li><p>日志采集:<br>当Filebeat启动后，它将开始采集Kubernetes集群中所有容器的日志数据，并将其发送到Elasticsearch进行存储和索引。您可以使用Kibana来可视化和查询这些日志数据。</p>\n</li>\n</ol>\n<p>这是一个简单的部署Filebeat、Elasticsearch和Kibana来采集Kubernetes集群中容器日志的示例配置。根据您的实际需求，可能还需要进行一些其他的配置和调整。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>要在Kubernetes中部署Filebeat、Elasticsearch和Kibana来采集容器日志，可以按照以下步骤进行:</p>\n<ol>\n<li><p>部署Elasticsearch:<br>在Kubernetes集群上创建一个Elasticsearch的Deployment，这个Deployment将用于存储和索引日志数据。可以使用以下示例配置文件创建Deployment:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">elasticsearch:7.12.1</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">2Gi</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">9200</span></span><br></pre></td></tr></table></figure>\n\n<p>运行<code>kubectl apply -f elasticsearch.yaml</code>命令来创建Deployment。</p>\n</li>\n<li><p>部署Kibana:<br>在Kubernetes集群上创建一个Kibana的Deployment，这个Deployment将用于可视化和查询日志数据。可以使用以下示例配置文件创建Deployment:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">kibana</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">kibana:7.12.1</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">1Gi</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"number\">0.5</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">5601</span></span><br></pre></td></tr></table></figure>\n\n<p>运行<code>kubectl apply -f kibana.yaml</code>命令来创建Deployment。</p>\n</li>\n<li><p>部署Filebeat:<br>在Kubernetes集群上创建一个Filebeat DaemonSet，这个DaemonSet将在每个节点上运行一个Filebeat实例来收集容器日志。可以使用以下示例配置文件创建DaemonSet:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">DaemonSet</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">filebeat</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">docker.elastic.co/beats/filebeat:7.12.1</span></span><br><span class=\"line\">        <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibdockercontainers</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/lib/docker/containers</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlog</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogpod</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log/pods</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varrun</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/run</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibkubelet</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/lib/kubelet</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlognode</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log/node</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogcontainersnew</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/log/containersnew</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">dockersocket</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/run/docker.sock</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config</span></span><br><span class=\"line\">          <span class=\"attr\">mountPath:</span> <span class=\"string\">/usr/share/filebeat/filebeat.yml</span></span><br><span class=\"line\">          <span class=\"attr\">subPath:</span> <span class=\"string\">filebeat.yml</span></span><br><span class=\"line\">          <span class=\"attr\">readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">env:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">K8S_NODE_NAME</span></span><br><span class=\"line\">          <span class=\"attr\">valueFrom:</span></span><br><span class=\"line\">            <span class=\"attr\">fieldRef:</span></span><br><span class=\"line\">              <span class=\"attr\">fieldPath:</span> <span class=\"string\">spec.nodeName</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">NODE_NAME</span></span><br><span class=\"line\">          <span class=\"attr\">valueFrom:</span></span><br><span class=\"line\">            <span class=\"attr\">fieldRef:</span></span><br><span class=\"line\">              <span class=\"attr\">fieldPath:</span> <span class=\"string\">spec.nodeName</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">FILEBEAT_HOST</span></span><br><span class=\"line\">          <span class=\"attr\">valueFrom:</span></span><br><span class=\"line\">            <span class=\"attr\">fieldRef:</span></span><br><span class=\"line\">              <span class=\"attr\">fieldPath:</span> <span class=\"string\">status.hostIP</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">FILEBEAT_CONFIG_CHECK_FREQUENCY</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;5s&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">OUTPUT_TYPE</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">elasticsearch</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_HOST</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">elasticsearch:9200</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_USERNAME</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;&lt;ELASTICSEARCH_USERNAME&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_PASSWORD</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;&lt;ELASTICSEARCH_PASSWORD&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_INDEX</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;filebeat-<span class=\"template-variable\">%&#123;[agent.version]&#125;</span>-<span class=\"template-variable\">%&#123;+yyyy.MM.dd&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">ELASTICSEARCH_PIPELINE</span></span><br><span class=\"line\">          <span class=\"attr\">value:</span> <span class=\"string\">&quot;&lt;ELASTICSEARCH_PIPELINE&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">limits:</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">200Mi</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"string\">100m</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">100Mi</span></span><br><span class=\"line\">        <span class=\"attr\">terminationGracePeriodSeconds:</span> <span class=\"number\">30</span></span><br><span class=\"line\">        <span class=\"attr\">dnsPolicy:</span> <span class=\"string\">ClusterFirstWithHostNet</span></span><br><span class=\"line\">        <span class=\"attr\">restartPolicy:</span> <span class=\"string\">Always</span></span><br><span class=\"line\">        <span class=\"attr\">hostNetwork:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibdockercontainers</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/lib/docker/containers</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlog</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogpod</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log/pods</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varrun</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/run</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlibkubelet</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/lib/kubelet</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlognode</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log/node</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">varlogcontainersnew</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/log/containersnew</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">dockersocket</span></span><br><span class=\"line\">          <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/var/run/docker.sock</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config</span></span><br><span class=\"line\">          <span class=\"attr\">configMap:</span></span><br><span class=\"line\">            <span class=\"attr\">name:</span> <span class=\"string\">filebeat-config</span></span><br><span class=\"line\">    <span class=\"attr\">updateStrategy:</span></span><br><span class=\"line\">      <span class=\"attr\">type:</span> <span class=\"string\">RollingUpdate</span></span><br><span class=\"line\">     <span class=\"attr\">rollingUpdate:</span></span><br><span class=\"line\">        <span class=\"attr\">maxUnavailable:</span> <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n<p>创建一个ConfigMap来存储Filebeat的配置文件(filebeat.yml)，示例配置文件可以参考以下内容:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">filebeat.config:</span></span><br><span class=\"line\">  <span class=\"attr\">modules:</span></span><br><span class=\"line\">    <span class=\"attr\">path:</span> <span class=\"string\">$&#123;path.config&#125;/modules.d/*.yml</span></span><br><span class=\"line\">    <span class=\"attr\">reload.enabled:</span> <span class=\"literal\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">filebeat.modules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">module:</span> <span class=\"string\">system</span></span><br><span class=\"line\">  <span class=\"attr\">syslog:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">auth:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">package:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">coredns:</span></span><br><span class=\"line\">    <span class=\"attr\">enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">output.elasticsearch:</span></span><br><span class=\"line\">  <span class=\"attr\">hosts:</span> [<span class=\"string\">&#x27;elasticsearch:9200&#x27;</span>]</span><br><span class=\"line\">  <span class=\"attr\">username:</span> <span class=\"string\">&#x27;&lt;ELASTICSEARCH_USERNAME&gt;&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">password:</span> <span class=\"string\">&#x27;&lt;ELASTICSEARCH_PASSWORD&gt;&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">pipeline:</span> <span class=\"string\">&#x27;&lt;ELASTICSEARCH_PIPELINE&gt;&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>运行<code>kubectl create configmap filebeat-config --from-file=filebeat.yml</code>命令来创建ConfigMap。</p>\n<p>然后，运行<code>kubectl apply -f filebeat.yaml</code>命令来创建DaemonSet。</p>\n</li>\n<li><p>日志采集:<br>当Filebeat启动后，它将开始采集Kubernetes集群中所有容器的日志数据，并将其发送到Elasticsearch进行存储和索引。您可以使用Kibana来可视化和查询这些日志数据。</p>\n</li>\n</ol>\n<p>这是一个简单的部署Filebeat、Elasticsearch和Kibana来采集Kubernetes集群中容器日志的示例配置。根据您的实际需求，可能还需要进行一些其他的配置和调整。</p>\n"},{"title":"deepflow dashboard","date":"2023-10-18T08:54:51.000Z","_content":"1. Application-Service List\n此dashboard包含两个部分，分别是Service List和EndPoint List。展示了服务时延，请求速率，成功率等信息。\n1.2 Service List\n![Alt text](image.png)\n● Data Source： 数据源为DeepFlow\n● auto_service： 筛选指定的service\n● app_service:  筛选app_service\n● signal_source: 筛选信号源\nAuto Service\nApp Service\nSignal Source\nRequest Rate\nDelay Avg\nDelay P75\nClient Error Ratio\nServer Error Ratio\n对应k8s中service name\n\n分为三种类型信号源：\nPacket (cBPF)、eBPF、OTel来自不同信号源数据有细微差距。\n请求速率 \n平均时延\n75%的请求时延时间段\n客户端异常比例，通过客户端异常 / 响应计算得，即 client_error / response\n服务端异常比例，通过服务端异常 / 响应计算得，即 server_error / response\n1.3 Endpoint List\n![Alt text](image-1.png)\n服务端点时延信息。\n2. Application - Cloud Host\n此dashboard主要以kubernetes节点的角度展示了请求成功率时延等信息。\n![Alt text](image-2.png)\n● vm: 筛选指定节点\n● protocol: 筛选指定协议\nchost\nProtocol\nRequest\nClient error\nServer error\nLatency\n云节点名\n网络协议类型\n请求速率\n客户端错误百分比\n服务端错误百分比\n平均时延\n3. Application - Cloud Host Map\n此dashboard主要通过Map展示，当节点作为server，和当节点作为client两种角色情况下，请求时延，请求速率，客户端错误百分比，服务端百分比等信息。\n3.1 当节点上服务作为服务端时：\n![Alt text](image-3.png)\n3.2 当节点上服务作为客户端时：\n![Alt text](image-4.png)\n4. Application - DNS Monitoring\n该dashbord主要展示了dns协议请求信息，包括请求总数，客户端错误率，客户端错误数量，服务端错误率，服务段错误数量，DNS Topo，请求时延等等信息，可用于分析DNS解析相关错误。\n\n4.1 Total Request、DNS Topo、Delay Distribution、Error\n![Alt text](image-5.png)\n这部分面板展示了DNS请求总数，客户端及服务端错误数量和错误率，DNS亲求拓扑，在Client Error(by client)面板中展示了客户端错误数量列表。\n4.2 Server Error Ratio、Time Out、Delay\n![Alt text](image-6.png)\n这部分面板展示了DNS服务端错误百分比，服务端超时数量及按客户端统计列表；服务端时延，客户端时延等信息。\n4.3 Request、Log Analysis、Request log Delay Distribution、Request Log\n![Alt text](image-7.png)\n● Request: 展示DNS服务请求速率、客户端请求数量和所占百分比。\n● Log Analysis: 展示请求日志数量列表，可按服务端、客户端、成功或错误进行筛选。如图展示了失败的DNS请求客户端和请求域名列表及对应数量，通过Request Log（by response desc）可以看出错误都是Non-Existent Domain。通过Request Log Delay Distribution可看出请求日志时延。Reqeust Log展示例如请求日志列表。\n5. Dubbo Monitoring - K8S\n![Alt text](image-8.png)\n\nDubbo微服务监控。展示请求总数，服务连接，时延、错误、请求日志分析等内容。\n6. Application - K8s Ingress\n![Alt text](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/31b5dcc3-e80c-44df-b008-63f844c2fba3.png)\n\nIngress服务监控。展示请求、时延、错误、吞吐量等内容。\n7. Application - K8s Pod\n此dashboard展示了各个pod作为客户端和服务端发送请求的速率，错误率，时延等信息。\n![Alt text](image-10.png)\n我们以部署的测试服务deepflow-ebpf-spring-demo为例：\n● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。\n● workload：筛选工作负载。\n● protocol：筛选网络协议。\n7.1 Request面板\n以redis-master-0 Redis为例，在此面板中可以看到名为redis-master-0的pod，网络协议Redis的最小请求速率（Min）为0.667 req/s, 平均请求速率（Mean）为1.26 req/s，最大请求速率1.33 req/s。\n7.2 Server error面板\n展示了各pod指定网络协议的服务端错误百分比。\n7.3 Latency面板\n展示了各pod指定协议时延信息。\n7.4 Pod List面板\n指定pod,指定协议的请求速率，客户端错误百分比，服务端错误百分比，平均时延列表。\n8. Application - K8s Pod Map\n此dashboard展示了pod请求map,请求速率，服务段错误百分比，客户端错误百分比，时延等信息。\n我们以部署的测试服务deepflow-ebpf-spring-demo为例：\n● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。\n● workload：筛选工作负载。\n● protocol：筛选网络协议。\n8.1 Show client\n![Alt text](image-11.png)\n此时展示指定namespace中所有pod作为服务端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。\n8.2 Show server\n![Alt text](image-12.png)\n此时展示指定namespace中所有pod作为客户端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。\n9. Application - Redis Monitoring - Cloud\n此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。\n![Alt text](image-13.png)\n● Cloud Host: 按节点筛选redis服务\n● IP: 按IP筛选redis服务\n10. Application - Redis Monitoring - K8S\n此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。\n![Alt text](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/7a2ab804-36f5-4ef2-a9fc-dc4a477851c7.png)\n● cluster： 筛选指定集群\n● Redis Service: 筛选指定redis服务\n● redis willdCard：通配符匹配\n● Tap Side： 可选择不同的数据采集点，获取不同的指标，例如查看客户端网卡吞吐量，服务端网卡吞吐量等。\n1.  Application - Request Log\n此dashboard展示了请求日志相关数据。\n![Alt text](image-15.png)\n● 筛选条件：可根据cluster（集群名）、namespace（命名空间）、workload（工作负载名）、protocol（网络协议）、request_type（请求类型）、reqeust_resource（请求资源）、status（响应状态）进行数据筛选。\n● Summary count: 请求数量摘要。以一分钟区间统计请求数量。\n● Error Count: 请求错误数量。\n● Latency histogram: 请求时延直方图。\n● Request log: 请求日志，包括Start time(请求开始时间)，Client(客户端)、Server(服务端)、Tap Side(数据采集点)、Protocol(网络协议)、App Protocol(应用协议)、Request type(请求类型)、Request domain(请求域名)、Request resource(请求资源)、Response Status(响应状态)、Response Code(响应码)、Response Delay(响应时延)。\n1.  Application - Request Log - Cloud\n\n![Alt text](image-16.png)\n此dashborad也是展示请求日志，与Application - Request Log展示内容相同，筛选条件不同：\n● vm: 根据节点筛选\n● protocol: 根据网络协议筛选\n● request_type: 根据请求类型筛选\n● reqeust_resource：根据请求资源筛选\n● status：根据响应状态筛选\n13. Application - SQL Monitoring - Cloud\n![Alt text](image-18.png)\n此dashboar展示了mysql相关数据库监控信息。\n● 筛选条件：可根据client(客户端)、DB Host(数据库所在节点)、DB IP(数据库IP)、Client For SQL Analysis（需要SQL分析的客户端匹配.\n● 展示内容：请求总数、客户端列表、topo概览、客户端服务端错误百分比及错误数及列表、连接数、平均活跃连接数、时延、时延客户端列表、SQL执行分析（SQL Statement、Request Type、响应状态、时延、AffectedRows、执行数量）、吞吐量、分布式追踪、SQL语句时延列表。\n14. Application - SQL Monitoring - K8S\n![Alt text](image-19.png)\n此dashboar也是展示了mysql相关数据库监控信息。展示数据内容与SQL Monitoring - Cloud相同，筛选角度不同：\n● client: 根据客户端筛选\n● DB Cluster: 根据数据库所在集群筛选\n● DB Service:  根据数据可服务筛选\n● DB Wildcard: 根据数据库通配符筛选\n● Tap Side: 根据数据采集点筛选\n● Client For SQL Analysis：根据需要SQL分析的客户端匹配筛选\n15. Distributed Tracing\n![Alt text](image-20.png)\n此dashboard展示了分布式调用追踪，可选择一个调用进行例如点击Request中的_id，就会显示其调用的Flame Graph(火焰图)。Service List展示了调用在各个Service所花费的时间和百分比。Request Log展示了请求体制数据，Related Data展示了相关数据。\n● N： 通过 BPF 从网络流量中提取的 Span\n● S:  通过 eBPF 从系统或应用函数调用中提取的 Span\nSpan 是分布式跟踪的基本构建块。分布式跟踪中的单个跟踪由一系列标记的时间间隔组成,称为跨度。跨度表示完成用户请求或事务的逻辑工作单元。在分布式链路跟踪中有两个重要的概念：跟踪（trace）和 跨度（ span）。trace 是请求在分布式系统中的整个链路视图，span 则代表整个链路中不同服务内部的视图，span 组合在一起就是整个 trace 的视图。\n16. Distributed Tracing - Cloud\n![Alt text](image-21.png)\n此dashboard也展示了分布式调用追踪，与Distributed Tracing展示内容相同，筛选条件不同：\n● vm: 根据节点筛选\n● trace_id： 根据tarceID进行筛选，traceID是一个唯一标识符，用于跟踪整个分布式系统中的请求。它可以帮助我们追踪请求在整个系统中所经过的所有服务和操作，并且可以帮助我们在出现问题时快速定位问题。\n● span_id：根据SpanID进行筛选，traceid 在请求的整个调用链中始终保持不变，所以在日志中可以通过 traceid 查询到整个请求期间系统记录下来的所有日志。请求到达每个服务后，服务都会为请求生成spanid，而随请求一起从上游传过来的上游服务的 spanid 会被记录成parent-spanid或者叫 pspanid。当前服务生成的 spanid 随着请求一起再传到下游服务时，这个spanid 又会被下游服务当做 pspanid 记录。\n● request_resource：请求资源。\n17. Network - Cloud Host\n![Alt text](image-22.png)\n此dashboard展示了各节点网络性能指标。可根据Vm(节点)进行筛选。\n● Throught(bps): 展示了节点吞吐量，包括最小值、平均值、最大值。\n● Retrans rate: 展示包重传率，包括最小值、平均值、最大值。\n● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。\n● TCP conn. establishment latency：TCP连接建立延迟指的是从客户端向服务器发起TCP连接请求，到服务器成功响应这个请求并建立起TCP连接所需的时间。这个延迟时间通常由网络延迟、服务器处理能力和其他因素决定。在高性能网络和服务器环境中，TCP连接建立延迟应该尽可能低。如果延迟时间过长，可能会导致用户体验不佳或者网络应用程序性能下降。\n● Cloud Host List：展示节点网络性能详情列表。\nchost\nThroughput(bps)\nThroughput(pps)\nTCP new conn.\nTCP retrans rate\nTCP conn. establishment fail rate\nTCP conn. establishment latency\nTCP/UDP data latency\n节点名\n是吞吐量的单位，表示每秒传输的比特数（bits per second）\n是网络吞吐量的一种单位，表示每秒发送的分组数据包数量\nTCP新建连接数\n包重传率\nTCP连接建立失败率\nTCP连接建立延迟\nTCP或UDP协议下数据传输的延迟时间。\nTCP/UDP data latency指的是TCP或UDP协议下数据传输的延迟时间。这是从数据发送端到接收端的时间，包括在网络中传输以及在发送和接收端的处理时间。这个延迟可能会受到网络拥堵、硬件性能、协议效率等因素的影响。一般来说，低延迟的通信对于实时性要求高的应用非常重要。\n18. Network - Cloud Host Map\n此dashboard展示了各节点，网络性能拓扑图。可根据VM(节点)，进行筛选。\n18.1 Show Client\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/f5dfef4b-f7e9-4182-86b4-7dcd565b362c.png)\n展示了指定节点作为服务短时，网络性能指标，通过拓扑图可以点至查看指定客户端服务端之间的数据传输速率。\n在Cloud Host Path列表中展示的数据与Network - Cloud Host相比多了以下数据：\n● CLient: 客户端名。\n● Server: 服务端。\n● Tap side: 数据采样点。\n● Protocol: 网络协议。\n● Server port: 服务端口。\n18.2 Show Server\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/8fa5d9e2-859d-42c7-9d3d-a1e1edabcb96.png)\n与show client展示内容相同，角度不同，此时展示当指定节点作为客户端时相关网络性能指标。\n19.  Network - Flow Log\n![Alt text](image-25.png)\n此dashboard展示了网络流日志内容。\n可根据cluster(集群)、namespace(命名空间)、workload(工作负载)进行筛选。\n● Summary count: 日志总量摘要。\n● Error count: 错误数量。\n● TCP est.conn latency distribution：连接建立（establishment）延迟时间分布。\n● TCP data latency distribution： 指的是在TCP协议下，数据传输延迟时间分布。\n● Flow log：网络流日志列表，内容包括 start time(开始时间)、client(客户端)、server(服务端)、tap side(数据才采集点)、protocol(网络协议)、client port(客户端端口)、server port(服务端端口)、status(状态，由 close_type（流结束类型）与 protocol（协议）决定：正常结束/周期性上报/非TCP超时=正常，客户端XX=客户端异常，服务端XX/TCP超时=服务端异常，其他结束方式=未知。)、Byte TX(发送字节数)、Byte RX(接收字节数)、TCP Client Retransmission(TCP客户端重传)、TCP Server Retransmission(TCP服务端重传)、Avg TCP Est. Delay(连接建立平均时延)、Avg Data Delay（数据传输平均时延）。\n20. Network - Flow Log - Cloud\n![Alt text](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/cbf20764-c8a8-48b3-a0c2-a023923ef515.png)\n此dashboard展示的网络流日志内容与Flow Log相同，区别是筛选条件不同，此dashboard提供根据VM(节点)进行筛选，查看各节点上工作流日志。\n21. Network - K8s Pod\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/334e9637-7366-4397-a79c-c61ec162c7f3.png)\n此dashboard展示了pod的网络性能相关指标，可根据cluster、namespace、workload进行筛选。\n● Throught(bps): 展示了pod网络吞吐量，包括最小值、平均值、最大值。\n● Retrans rate: 展示pod包重传率，包括最小值、平均值、最大值。\n● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。\n● TCP conn. establishment latency：TCP连接建立延迟。\n● Pod List： pod网络性能列表。\n22.  Network - K8s Pod Map\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/85fd8ca0-bea9-43e3-8a12-1a9b82cac676.png)\n网络性能全景图，点击路径可查看相关指标，包括bps、retrans_ratio(TCP 重传比例：TCP 重传比例，通过TCP 重传 / 所有的包计算得，即 retrans / packet)、tcp_establish_fail_ratio（建连-失败比例：建连-失败比例，通过 TCP 建连-失败次数 / 所有的关闭连接计算得，即 tcp_establish_fail / close_flow）、rtt(平均 TCP 建连时延,统计周期内，所有 TCP 建连时延的平均值)、art(平均数据时延:统计周期内，所有数据时延的平均值，数据时延包含 TCP/UDP)等。","source":"_posts/kubernetes/deepflow-dashboard.md","raw":"---\ntitle: deepflow dashboard\ndate: 2023-10-18 16:54:51\ncategories:\n  - [kubernetes]\ntags: deepflow\n---\n1. Application-Service List\n此dashboard包含两个部分，分别是Service List和EndPoint List。展示了服务时延，请求速率，成功率等信息。\n1.2 Service List\n![Alt text](image.png)\n● Data Source： 数据源为DeepFlow\n● auto_service： 筛选指定的service\n● app_service:  筛选app_service\n● signal_source: 筛选信号源\nAuto Service\nApp Service\nSignal Source\nRequest Rate\nDelay Avg\nDelay P75\nClient Error Ratio\nServer Error Ratio\n对应k8s中service name\n\n分为三种类型信号源：\nPacket (cBPF)、eBPF、OTel来自不同信号源数据有细微差距。\n请求速率 \n平均时延\n75%的请求时延时间段\n客户端异常比例，通过客户端异常 / 响应计算得，即 client_error / response\n服务端异常比例，通过服务端异常 / 响应计算得，即 server_error / response\n1.3 Endpoint List\n![Alt text](image-1.png)\n服务端点时延信息。\n2. Application - Cloud Host\n此dashboard主要以kubernetes节点的角度展示了请求成功率时延等信息。\n![Alt text](image-2.png)\n● vm: 筛选指定节点\n● protocol: 筛选指定协议\nchost\nProtocol\nRequest\nClient error\nServer error\nLatency\n云节点名\n网络协议类型\n请求速率\n客户端错误百分比\n服务端错误百分比\n平均时延\n3. Application - Cloud Host Map\n此dashboard主要通过Map展示，当节点作为server，和当节点作为client两种角色情况下，请求时延，请求速率，客户端错误百分比，服务端百分比等信息。\n3.1 当节点上服务作为服务端时：\n![Alt text](image-3.png)\n3.2 当节点上服务作为客户端时：\n![Alt text](image-4.png)\n4. Application - DNS Monitoring\n该dashbord主要展示了dns协议请求信息，包括请求总数，客户端错误率，客户端错误数量，服务端错误率，服务段错误数量，DNS Topo，请求时延等等信息，可用于分析DNS解析相关错误。\n\n4.1 Total Request、DNS Topo、Delay Distribution、Error\n![Alt text](image-5.png)\n这部分面板展示了DNS请求总数，客户端及服务端错误数量和错误率，DNS亲求拓扑，在Client Error(by client)面板中展示了客户端错误数量列表。\n4.2 Server Error Ratio、Time Out、Delay\n![Alt text](image-6.png)\n这部分面板展示了DNS服务端错误百分比，服务端超时数量及按客户端统计列表；服务端时延，客户端时延等信息。\n4.3 Request、Log Analysis、Request log Delay Distribution、Request Log\n![Alt text](image-7.png)\n● Request: 展示DNS服务请求速率、客户端请求数量和所占百分比。\n● Log Analysis: 展示请求日志数量列表，可按服务端、客户端、成功或错误进行筛选。如图展示了失败的DNS请求客户端和请求域名列表及对应数量，通过Request Log（by response desc）可以看出错误都是Non-Existent Domain。通过Request Log Delay Distribution可看出请求日志时延。Reqeust Log展示例如请求日志列表。\n5. Dubbo Monitoring - K8S\n![Alt text](image-8.png)\n\nDubbo微服务监控。展示请求总数，服务连接，时延、错误、请求日志分析等内容。\n6. Application - K8s Ingress\n![Alt text](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/31b5dcc3-e80c-44df-b008-63f844c2fba3.png)\n\nIngress服务监控。展示请求、时延、错误、吞吐量等内容。\n7. Application - K8s Pod\n此dashboard展示了各个pod作为客户端和服务端发送请求的速率，错误率，时延等信息。\n![Alt text](image-10.png)\n我们以部署的测试服务deepflow-ebpf-spring-demo为例：\n● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。\n● workload：筛选工作负载。\n● protocol：筛选网络协议。\n7.1 Request面板\n以redis-master-0 Redis为例，在此面板中可以看到名为redis-master-0的pod，网络协议Redis的最小请求速率（Min）为0.667 req/s, 平均请求速率（Mean）为1.26 req/s，最大请求速率1.33 req/s。\n7.2 Server error面板\n展示了各pod指定网络协议的服务端错误百分比。\n7.3 Latency面板\n展示了各pod指定协议时延信息。\n7.4 Pod List面板\n指定pod,指定协议的请求速率，客户端错误百分比，服务端错误百分比，平均时延列表。\n8. Application - K8s Pod Map\n此dashboard展示了pod请求map,请求速率，服务段错误百分比，客户端错误百分比，时延等信息。\n我们以部署的测试服务deepflow-ebpf-spring-demo为例：\n● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。\n● workload：筛选工作负载。\n● protocol：筛选网络协议。\n8.1 Show client\n![Alt text](image-11.png)\n此时展示指定namespace中所有pod作为服务端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。\n8.2 Show server\n![Alt text](image-12.png)\n此时展示指定namespace中所有pod作为客户端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。\n9. Application - Redis Monitoring - Cloud\n此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。\n![Alt text](image-13.png)\n● Cloud Host: 按节点筛选redis服务\n● IP: 按IP筛选redis服务\n10. Application - Redis Monitoring - K8S\n此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。\n![Alt text](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/7a2ab804-36f5-4ef2-a9fc-dc4a477851c7.png)\n● cluster： 筛选指定集群\n● Redis Service: 筛选指定redis服务\n● redis willdCard：通配符匹配\n● Tap Side： 可选择不同的数据采集点，获取不同的指标，例如查看客户端网卡吞吐量，服务端网卡吞吐量等。\n1.  Application - Request Log\n此dashboard展示了请求日志相关数据。\n![Alt text](image-15.png)\n● 筛选条件：可根据cluster（集群名）、namespace（命名空间）、workload（工作负载名）、protocol（网络协议）、request_type（请求类型）、reqeust_resource（请求资源）、status（响应状态）进行数据筛选。\n● Summary count: 请求数量摘要。以一分钟区间统计请求数量。\n● Error Count: 请求错误数量。\n● Latency histogram: 请求时延直方图。\n● Request log: 请求日志，包括Start time(请求开始时间)，Client(客户端)、Server(服务端)、Tap Side(数据采集点)、Protocol(网络协议)、App Protocol(应用协议)、Request type(请求类型)、Request domain(请求域名)、Request resource(请求资源)、Response Status(响应状态)、Response Code(响应码)、Response Delay(响应时延)。\n1.  Application - Request Log - Cloud\n\n![Alt text](image-16.png)\n此dashborad也是展示请求日志，与Application - Request Log展示内容相同，筛选条件不同：\n● vm: 根据节点筛选\n● protocol: 根据网络协议筛选\n● request_type: 根据请求类型筛选\n● reqeust_resource：根据请求资源筛选\n● status：根据响应状态筛选\n13. Application - SQL Monitoring - Cloud\n![Alt text](image-18.png)\n此dashboar展示了mysql相关数据库监控信息。\n● 筛选条件：可根据client(客户端)、DB Host(数据库所在节点)、DB IP(数据库IP)、Client For SQL Analysis（需要SQL分析的客户端匹配.\n● 展示内容：请求总数、客户端列表、topo概览、客户端服务端错误百分比及错误数及列表、连接数、平均活跃连接数、时延、时延客户端列表、SQL执行分析（SQL Statement、Request Type、响应状态、时延、AffectedRows、执行数量）、吞吐量、分布式追踪、SQL语句时延列表。\n14. Application - SQL Monitoring - K8S\n![Alt text](image-19.png)\n此dashboar也是展示了mysql相关数据库监控信息。展示数据内容与SQL Monitoring - Cloud相同，筛选角度不同：\n● client: 根据客户端筛选\n● DB Cluster: 根据数据库所在集群筛选\n● DB Service:  根据数据可服务筛选\n● DB Wildcard: 根据数据库通配符筛选\n● Tap Side: 根据数据采集点筛选\n● Client For SQL Analysis：根据需要SQL分析的客户端匹配筛选\n15. Distributed Tracing\n![Alt text](image-20.png)\n此dashboard展示了分布式调用追踪，可选择一个调用进行例如点击Request中的_id，就会显示其调用的Flame Graph(火焰图)。Service List展示了调用在各个Service所花费的时间和百分比。Request Log展示了请求体制数据，Related Data展示了相关数据。\n● N： 通过 BPF 从网络流量中提取的 Span\n● S:  通过 eBPF 从系统或应用函数调用中提取的 Span\nSpan 是分布式跟踪的基本构建块。分布式跟踪中的单个跟踪由一系列标记的时间间隔组成,称为跨度。跨度表示完成用户请求或事务的逻辑工作单元。在分布式链路跟踪中有两个重要的概念：跟踪（trace）和 跨度（ span）。trace 是请求在分布式系统中的整个链路视图，span 则代表整个链路中不同服务内部的视图，span 组合在一起就是整个 trace 的视图。\n16. Distributed Tracing - Cloud\n![Alt text](image-21.png)\n此dashboard也展示了分布式调用追踪，与Distributed Tracing展示内容相同，筛选条件不同：\n● vm: 根据节点筛选\n● trace_id： 根据tarceID进行筛选，traceID是一个唯一标识符，用于跟踪整个分布式系统中的请求。它可以帮助我们追踪请求在整个系统中所经过的所有服务和操作，并且可以帮助我们在出现问题时快速定位问题。\n● span_id：根据SpanID进行筛选，traceid 在请求的整个调用链中始终保持不变，所以在日志中可以通过 traceid 查询到整个请求期间系统记录下来的所有日志。请求到达每个服务后，服务都会为请求生成spanid，而随请求一起从上游传过来的上游服务的 spanid 会被记录成parent-spanid或者叫 pspanid。当前服务生成的 spanid 随着请求一起再传到下游服务时，这个spanid 又会被下游服务当做 pspanid 记录。\n● request_resource：请求资源。\n17. Network - Cloud Host\n![Alt text](image-22.png)\n此dashboard展示了各节点网络性能指标。可根据Vm(节点)进行筛选。\n● Throught(bps): 展示了节点吞吐量，包括最小值、平均值、最大值。\n● Retrans rate: 展示包重传率，包括最小值、平均值、最大值。\n● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。\n● TCP conn. establishment latency：TCP连接建立延迟指的是从客户端向服务器发起TCP连接请求，到服务器成功响应这个请求并建立起TCP连接所需的时间。这个延迟时间通常由网络延迟、服务器处理能力和其他因素决定。在高性能网络和服务器环境中，TCP连接建立延迟应该尽可能低。如果延迟时间过长，可能会导致用户体验不佳或者网络应用程序性能下降。\n● Cloud Host List：展示节点网络性能详情列表。\nchost\nThroughput(bps)\nThroughput(pps)\nTCP new conn.\nTCP retrans rate\nTCP conn. establishment fail rate\nTCP conn. establishment latency\nTCP/UDP data latency\n节点名\n是吞吐量的单位，表示每秒传输的比特数（bits per second）\n是网络吞吐量的一种单位，表示每秒发送的分组数据包数量\nTCP新建连接数\n包重传率\nTCP连接建立失败率\nTCP连接建立延迟\nTCP或UDP协议下数据传输的延迟时间。\nTCP/UDP data latency指的是TCP或UDP协议下数据传输的延迟时间。这是从数据发送端到接收端的时间，包括在网络中传输以及在发送和接收端的处理时间。这个延迟可能会受到网络拥堵、硬件性能、协议效率等因素的影响。一般来说，低延迟的通信对于实时性要求高的应用非常重要。\n18. Network - Cloud Host Map\n此dashboard展示了各节点，网络性能拓扑图。可根据VM(节点)，进行筛选。\n18.1 Show Client\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/f5dfef4b-f7e9-4182-86b4-7dcd565b362c.png)\n展示了指定节点作为服务短时，网络性能指标，通过拓扑图可以点至查看指定客户端服务端之间的数据传输速率。\n在Cloud Host Path列表中展示的数据与Network - Cloud Host相比多了以下数据：\n● CLient: 客户端名。\n● Server: 服务端。\n● Tap side: 数据采样点。\n● Protocol: 网络协议。\n● Server port: 服务端口。\n18.2 Show Server\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/8fa5d9e2-859d-42c7-9d3d-a1e1edabcb96.png)\n与show client展示内容相同，角度不同，此时展示当指定节点作为客户端时相关网络性能指标。\n19.  Network - Flow Log\n![Alt text](image-25.png)\n此dashboard展示了网络流日志内容。\n可根据cluster(集群)、namespace(命名空间)、workload(工作负载)进行筛选。\n● Summary count: 日志总量摘要。\n● Error count: 错误数量。\n● TCP est.conn latency distribution：连接建立（establishment）延迟时间分布。\n● TCP data latency distribution： 指的是在TCP协议下，数据传输延迟时间分布。\n● Flow log：网络流日志列表，内容包括 start time(开始时间)、client(客户端)、server(服务端)、tap side(数据才采集点)、protocol(网络协议)、client port(客户端端口)、server port(服务端端口)、status(状态，由 close_type（流结束类型）与 protocol（协议）决定：正常结束/周期性上报/非TCP超时=正常，客户端XX=客户端异常，服务端XX/TCP超时=服务端异常，其他结束方式=未知。)、Byte TX(发送字节数)、Byte RX(接收字节数)、TCP Client Retransmission(TCP客户端重传)、TCP Server Retransmission(TCP服务端重传)、Avg TCP Est. Delay(连接建立平均时延)、Avg Data Delay（数据传输平均时延）。\n20. Network - Flow Log - Cloud\n![Alt text](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/cbf20764-c8a8-48b3-a0c2-a023923ef515.png)\n此dashboard展示的网络流日志内容与Flow Log相同，区别是筛选条件不同，此dashboard提供根据VM(节点)进行筛选，查看各节点上工作流日志。\n21. Network - K8s Pod\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/334e9637-7366-4397-a79c-c61ec162c7f3.png)\n此dashboard展示了pod的网络性能相关指标，可根据cluster、namespace、workload进行筛选。\n● Throught(bps): 展示了pod网络吞吐量，包括最小值、平均值、最大值。\n● Retrans rate: 展示pod包重传率，包括最小值、平均值、最大值。\n● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。\n● TCP conn. establishment latency：TCP连接建立延迟。\n● Pod List： pod网络性能列表。\n22.  Network - K8s Pod Map\n![](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/85fd8ca0-bea9-43e3-8a12-1a9b82cac676.png)\n网络性能全景图，点击路径可查看相关指标，包括bps、retrans_ratio(TCP 重传比例：TCP 重传比例，通过TCP 重传 / 所有的包计算得，即 retrans / packet)、tcp_establish_fail_ratio（建连-失败比例：建连-失败比例，通过 TCP 建连-失败次数 / 所有的关闭连接计算得，即 tcp_establish_fail / close_flow）、rtt(平均 TCP 建连时延,统计周期内，所有 TCP 建连时延的平均值)、art(平均数据时延:统计周期内，所有数据时延的平均值，数据时延包含 TCP/UDP)等。","slug":"kubernetes/deepflow-dashboard","published":1,"updated":"2023-10-18T09:18:27.736Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0br000cfmjx6ab0e5hz","content":"<ol>\n<li>Application-Service List<br>此dashboard包含两个部分，分别是Service List和EndPoint List。展示了服务时延，请求速率，成功率等信息。<br>1.2 Service List<br><img src=\"/image.png\" alt=\"Alt text\"><br>● Data Source： 数据源为DeepFlow<br>● auto_service： 筛选指定的service<br>● app_service:  筛选app_service<br>● signal_source: 筛选信号源<br>Auto Service<br>App Service<br>Signal Source<br>Request Rate<br>Delay Avg<br>Delay P75<br>Client Error Ratio<br>Server Error Ratio<br>对应k8s中service name</li>\n</ol>\n<p>分为三种类型信号源：<br>Packet (cBPF)、eBPF、OTel来自不同信号源数据有细微差距。<br>请求速率<br>平均时延<br>75%的请求时延时间段<br>客户端异常比例，通过客户端异常 &#x2F; 响应计算得，即 client_error &#x2F; response<br>服务端异常比例，通过服务端异常 &#x2F; 响应计算得，即 server_error &#x2F; response<br>1.3 Endpoint List<br><img src=\"/image-1.png\" alt=\"Alt text\"><br>服务端点时延信息。<br>2. Application - Cloud Host<br>此dashboard主要以kubernetes节点的角度展示了请求成功率时延等信息。<br><img src=\"/image-2.png\" alt=\"Alt text\"><br>● vm: 筛选指定节点<br>● protocol: 筛选指定协议<br>chost<br>Protocol<br>Request<br>Client error<br>Server error<br>Latency<br>云节点名<br>网络协议类型<br>请求速率<br>客户端错误百分比<br>服务端错误百分比<br>平均时延<br>3. Application - Cloud Host Map<br>此dashboard主要通过Map展示，当节点作为server，和当节点作为client两种角色情况下，请求时延，请求速率，客户端错误百分比，服务端百分比等信息。<br>3.1 当节点上服务作为服务端时：<br><img src=\"/image-3.png\" alt=\"Alt text\"><br>3.2 当节点上服务作为客户端时：<br><img src=\"/image-4.png\" alt=\"Alt text\"><br>4. Application - DNS Monitoring<br>该dashbord主要展示了dns协议请求信息，包括请求总数，客户端错误率，客户端错误数量，服务端错误率，服务段错误数量，DNS Topo，请求时延等等信息，可用于分析DNS解析相关错误。</p>\n<p>4.1 Total Request、DNS Topo、Delay Distribution、Error<br><img src=\"/image-5.png\" alt=\"Alt text\"><br>这部分面板展示了DNS请求总数，客户端及服务端错误数量和错误率，DNS亲求拓扑，在Client Error(by client)面板中展示了客户端错误数量列表。<br>4.2 Server Error Ratio、Time Out、Delay<br><img src=\"/image-6.png\" alt=\"Alt text\"><br>这部分面板展示了DNS服务端错误百分比，服务端超时数量及按客户端统计列表；服务端时延，客户端时延等信息。<br>4.3 Request、Log Analysis、Request log Delay Distribution、Request Log<br><img src=\"/image-7.png\" alt=\"Alt text\"><br>● Request: 展示DNS服务请求速率、客户端请求数量和所占百分比。<br>● Log Analysis: 展示请求日志数量列表，可按服务端、客户端、成功或错误进行筛选。如图展示了失败的DNS请求客户端和请求域名列表及对应数量，通过Request Log（by response desc）可以看出错误都是Non-Existent Domain。通过Request Log Delay Distribution可看出请求日志时延。Reqeust Log展示例如请求日志列表。<br>5. Dubbo Monitoring - K8S<br><img src=\"/image-8.png\" alt=\"Alt text\"></p>\n<p>Dubbo微服务监控。展示请求总数，服务连接，时延、错误、请求日志分析等内容。<br>6. Application - K8s Ingress<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/31b5dcc3-e80c-44df-b008-63f844c2fba3.png\" alt=\"Alt text\"></p>\n<p>Ingress服务监控。展示请求、时延、错误、吞吐量等内容。<br>7. Application - K8s Pod<br>此dashboard展示了各个pod作为客户端和服务端发送请求的速率，错误率，时延等信息。<br><img src=\"/image-10.png\" alt=\"Alt text\"><br>我们以部署的测试服务deepflow-ebpf-spring-demo为例：<br>● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。<br>● workload：筛选工作负载。<br>● protocol：筛选网络协议。<br>7.1 Request面板<br>以redis-master-0 Redis为例，在此面板中可以看到名为redis-master-0的pod，网络协议Redis的最小请求速率（Min）为0.667 req&#x2F;s, 平均请求速率（Mean）为1.26 req&#x2F;s，最大请求速率1.33 req&#x2F;s。<br>7.2 Server error面板<br>展示了各pod指定网络协议的服务端错误百分比。<br>7.3 Latency面板<br>展示了各pod指定协议时延信息。<br>7.4 Pod List面板<br>指定pod,指定协议的请求速率，客户端错误百分比，服务端错误百分比，平均时延列表。<br>8. Application - K8s Pod Map<br>此dashboard展示了pod请求map,请求速率，服务段错误百分比，客户端错误百分比，时延等信息。<br>我们以部署的测试服务deepflow-ebpf-spring-demo为例：<br>● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。<br>● workload：筛选工作负载。<br>● protocol：筛选网络协议。<br>8.1 Show client<br><img src=\"/image-11.png\" alt=\"Alt text\"><br>此时展示指定namespace中所有pod作为服务端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。<br>8.2 Show server<br><img src=\"/image-12.png\" alt=\"Alt text\"><br>此时展示指定namespace中所有pod作为客户端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。<br>9. Application - Redis Monitoring - Cloud<br>此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。<br><img src=\"/image-13.png\" alt=\"Alt text\"><br>● Cloud Host: 按节点筛选redis服务<br>● IP: 按IP筛选redis服务<br>10. Application - Redis Monitoring - K8S<br>此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/7a2ab804-36f5-4ef2-a9fc-dc4a477851c7.png\" alt=\"Alt text\"><br>● cluster： 筛选指定集群<br>● Redis Service: 筛选指定redis服务<br>● redis willdCard：通配符匹配<br>● Tap Side： 可选择不同的数据采集点，获取不同的指标，例如查看客户端网卡吞吐量，服务端网卡吞吐量等。</p>\n<ol>\n<li>Application - Request Log<br>此dashboard展示了请求日志相关数据。<br><img src=\"/image-15.png\" alt=\"Alt text\"><br>● 筛选条件：可根据cluster（集群名）、namespace（命名空间）、workload（工作负载名）、protocol（网络协议）、request_type（请求类型）、reqeust_resource（请求资源）、status（响应状态）进行数据筛选。<br>● Summary count: 请求数量摘要。以一分钟区间统计请求数量。<br>● Error Count: 请求错误数量。<br>● Latency histogram: 请求时延直方图。<br>● Request log: 请求日志，包括Start time(请求开始时间)，Client(客户端)、Server(服务端)、Tap Side(数据采集点)、Protocol(网络协议)、App Protocol(应用协议)、Request type(请求类型)、Request domain(请求域名)、Request resource(请求资源)、Response Status(响应状态)、Response Code(响应码)、Response Delay(响应时延)。</li>\n<li>Application - Request Log - Cloud</li>\n</ol>\n<p><img src=\"/image-16.png\" alt=\"Alt text\"><br>此dashborad也是展示请求日志，与Application - Request Log展示内容相同，筛选条件不同：<br>● vm: 根据节点筛选<br>● protocol: 根据网络协议筛选<br>● request_type: 根据请求类型筛选<br>● reqeust_resource：根据请求资源筛选<br>● status：根据响应状态筛选<br>13. Application - SQL Monitoring - Cloud<br><img src=\"/image-18.png\" alt=\"Alt text\"><br>此dashboar展示了mysql相关数据库监控信息。<br>● 筛选条件：可根据client(客户端)、DB Host(数据库所在节点)、DB IP(数据库IP)、Client For SQL Analysis（需要SQL分析的客户端匹配.<br>● 展示内容：请求总数、客户端列表、topo概览、客户端服务端错误百分比及错误数及列表、连接数、平均活跃连接数、时延、时延客户端列表、SQL执行分析（SQL Statement、Request Type、响应状态、时延、AffectedRows、执行数量）、吞吐量、分布式追踪、SQL语句时延列表。<br>14. Application - SQL Monitoring - K8S<br><img src=\"/image-19.png\" alt=\"Alt text\"><br>此dashboar也是展示了mysql相关数据库监控信息。展示数据内容与SQL Monitoring - Cloud相同，筛选角度不同：<br>● client: 根据客户端筛选<br>● DB Cluster: 根据数据库所在集群筛选<br>● DB Service:  根据数据可服务筛选<br>● DB Wildcard: 根据数据库通配符筛选<br>● Tap Side: 根据数据采集点筛选<br>● Client For SQL Analysis：根据需要SQL分析的客户端匹配筛选<br>15. Distributed Tracing<br><img src=\"/image-20.png\" alt=\"Alt text\"><br>此dashboard展示了分布式调用追踪，可选择一个调用进行例如点击Request中的_id，就会显示其调用的Flame Graph(火焰图)。Service List展示了调用在各个Service所花费的时间和百分比。Request Log展示了请求体制数据，Related Data展示了相关数据。<br>● N： 通过 BPF 从网络流量中提取的 Span<br>● S:  通过 eBPF 从系统或应用函数调用中提取的 Span<br>Span 是分布式跟踪的基本构建块。分布式跟踪中的单个跟踪由一系列标记的时间间隔组成,称为跨度。跨度表示完成用户请求或事务的逻辑工作单元。在分布式链路跟踪中有两个重要的概念：跟踪（trace）和 跨度（ span）。trace 是请求在分布式系统中的整个链路视图，span 则代表整个链路中不同服务内部的视图，span 组合在一起就是整个 trace 的视图。<br>16. Distributed Tracing - Cloud<br><img src=\"/image-21.png\" alt=\"Alt text\"><br>此dashboard也展示了分布式调用追踪，与Distributed Tracing展示内容相同，筛选条件不同：<br>● vm: 根据节点筛选<br>● trace_id： 根据tarceID进行筛选，traceID是一个唯一标识符，用于跟踪整个分布式系统中的请求。它可以帮助我们追踪请求在整个系统中所经过的所有服务和操作，并且可以帮助我们在出现问题时快速定位问题。<br>● span_id：根据SpanID进行筛选，traceid 在请求的整个调用链中始终保持不变，所以在日志中可以通过 traceid 查询到整个请求期间系统记录下来的所有日志。请求到达每个服务后，服务都会为请求生成spanid，而随请求一起从上游传过来的上游服务的 spanid 会被记录成parent-spanid或者叫 pspanid。当前服务生成的 spanid 随着请求一起再传到下游服务时，这个spanid 又会被下游服务当做 pspanid 记录。<br>● request_resource：请求资源。<br>17. Network - Cloud Host<br><img src=\"/image-22.png\" alt=\"Alt text\"><br>此dashboard展示了各节点网络性能指标。可根据Vm(节点)进行筛选。<br>● Throught(bps): 展示了节点吞吐量，包括最小值、平均值、最大值。<br>● Retrans rate: 展示包重传率，包括最小值、平均值、最大值。<br>● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。<br>● TCP conn. establishment latency：TCP连接建立延迟指的是从客户端向服务器发起TCP连接请求，到服务器成功响应这个请求并建立起TCP连接所需的时间。这个延迟时间通常由网络延迟、服务器处理能力和其他因素决定。在高性能网络和服务器环境中，TCP连接建立延迟应该尽可能低。如果延迟时间过长，可能会导致用户体验不佳或者网络应用程序性能下降。<br>● Cloud Host List：展示节点网络性能详情列表。<br>chost<br>Throughput(bps)<br>Throughput(pps)<br>TCP new conn.<br>TCP retrans rate<br>TCP conn. establishment fail rate<br>TCP conn. establishment latency<br>TCP&#x2F;UDP data latency<br>节点名<br>是吞吐量的单位，表示每秒传输的比特数（bits per second）<br>是网络吞吐量的一种单位，表示每秒发送的分组数据包数量<br>TCP新建连接数<br>包重传率<br>TCP连接建立失败率<br>TCP连接建立延迟<br>TCP或UDP协议下数据传输的延迟时间。<br>TCP&#x2F;UDP data latency指的是TCP或UDP协议下数据传输的延迟时间。这是从数据发送端到接收端的时间，包括在网络中传输以及在发送和接收端的处理时间。这个延迟可能会受到网络拥堵、硬件性能、协议效率等因素的影响。一般来说，低延迟的通信对于实时性要求高的应用非常重要。<br>18. Network - Cloud Host Map<br>此dashboard展示了各节点，网络性能拓扑图。可根据VM(节点)，进行筛选。<br>18.1 Show Client<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/f5dfef4b-f7e9-4182-86b4-7dcd565b362c.png\"><br>展示了指定节点作为服务短时，网络性能指标，通过拓扑图可以点至查看指定客户端服务端之间的数据传输速率。<br>在Cloud Host Path列表中展示的数据与Network - Cloud Host相比多了以下数据：<br>● CLient: 客户端名。<br>● Server: 服务端。<br>● Tap side: 数据采样点。<br>● Protocol: 网络协议。<br>● Server port: 服务端口。<br>18.2 Show Server<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/8fa5d9e2-859d-42c7-9d3d-a1e1edabcb96.png\"><br>与show client展示内容相同，角度不同，此时展示当指定节点作为客户端时相关网络性能指标。<br>19.  Network - Flow Log<br><img src=\"/image-25.png\" alt=\"Alt text\"><br>此dashboard展示了网络流日志内容。<br>可根据cluster(集群)、namespace(命名空间)、workload(工作负载)进行筛选。<br>● Summary count: 日志总量摘要。<br>● Error count: 错误数量。<br>● TCP est.conn latency distribution：连接建立（establishment）延迟时间分布。<br>● TCP data latency distribution： 指的是在TCP协议下，数据传输延迟时间分布。<br>● Flow log：网络流日志列表，内容包括 start time(开始时间)、client(客户端)、server(服务端)、tap side(数据才采集点)、protocol(网络协议)、client port(客户端端口)、server port(服务端端口)、status(状态，由 close_type（流结束类型）与 protocol（协议）决定：正常结束&#x2F;周期性上报&#x2F;非TCP超时&#x3D;正常，客户端XX&#x3D;客户端异常，服务端XX&#x2F;TCP超时&#x3D;服务端异常，其他结束方式&#x3D;未知。)、Byte TX(发送字节数)、Byte RX(接收字节数)、TCP Client Retransmission(TCP客户端重传)、TCP Server Retransmission(TCP服务端重传)、Avg TCP Est. Delay(连接建立平均时延)、Avg Data Delay（数据传输平均时延）。<br>20. Network - Flow Log - Cloud<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/cbf20764-c8a8-48b3-a0c2-a023923ef515.png\" alt=\"Alt text\"><br>此dashboard展示的网络流日志内容与Flow Log相同，区别是筛选条件不同，此dashboard提供根据VM(节点)进行筛选，查看各节点上工作流日志。<br>21. Network - K8s Pod<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/334e9637-7366-4397-a79c-c61ec162c7f3.png\"><br>此dashboard展示了pod的网络性能相关指标，可根据cluster、namespace、workload进行筛选。<br>● Throught(bps): 展示了pod网络吞吐量，包括最小值、平均值、最大值。<br>● Retrans rate: 展示pod包重传率，包括最小值、平均值、最大值。<br>● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。<br>● TCP conn. establishment latency：TCP连接建立延迟。<br>● Pod List： pod网络性能列表。<br>22.  Network - K8s Pod Map<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/85fd8ca0-bea9-43e3-8a12-1a9b82cac676.png\"><br>网络性能全景图，点击路径可查看相关指标，包括bps、retrans_ratio(TCP 重传比例：TCP 重传比例，通过TCP 重传 &#x2F; 所有的包计算得，即 retrans &#x2F; packet)、tcp_establish_fail_ratio（建连-失败比例：建连-失败比例，通过 TCP 建连-失败次数 &#x2F; 所有的关闭连接计算得，即 tcp_establish_fail &#x2F; close_flow）、rtt(平均 TCP 建连时延,统计周期内，所有 TCP 建连时延的平均值)、art(平均数据时延:统计周期内，所有数据时延的平均值，数据时延包含 TCP&#x2F;UDP)等。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<ol>\n<li>Application-Service List<br>此dashboard包含两个部分，分别是Service List和EndPoint List。展示了服务时延，请求速率，成功率等信息。<br>1.2 Service List<br><img src=\"/image.png\" alt=\"Alt text\"><br>● Data Source： 数据源为DeepFlow<br>● auto_service： 筛选指定的service<br>● app_service:  筛选app_service<br>● signal_source: 筛选信号源<br>Auto Service<br>App Service<br>Signal Source<br>Request Rate<br>Delay Avg<br>Delay P75<br>Client Error Ratio<br>Server Error Ratio<br>对应k8s中service name</li>\n</ol>\n<p>分为三种类型信号源：<br>Packet (cBPF)、eBPF、OTel来自不同信号源数据有细微差距。<br>请求速率<br>平均时延<br>75%的请求时延时间段<br>客户端异常比例，通过客户端异常 &#x2F; 响应计算得，即 client_error &#x2F; response<br>服务端异常比例，通过服务端异常 &#x2F; 响应计算得，即 server_error &#x2F; response<br>1.3 Endpoint List<br><img src=\"/image-1.png\" alt=\"Alt text\"><br>服务端点时延信息。<br>2. Application - Cloud Host<br>此dashboard主要以kubernetes节点的角度展示了请求成功率时延等信息。<br><img src=\"/image-2.png\" alt=\"Alt text\"><br>● vm: 筛选指定节点<br>● protocol: 筛选指定协议<br>chost<br>Protocol<br>Request<br>Client error<br>Server error<br>Latency<br>云节点名<br>网络协议类型<br>请求速率<br>客户端错误百分比<br>服务端错误百分比<br>平均时延<br>3. Application - Cloud Host Map<br>此dashboard主要通过Map展示，当节点作为server，和当节点作为client两种角色情况下，请求时延，请求速率，客户端错误百分比，服务端百分比等信息。<br>3.1 当节点上服务作为服务端时：<br><img src=\"/image-3.png\" alt=\"Alt text\"><br>3.2 当节点上服务作为客户端时：<br><img src=\"/image-4.png\" alt=\"Alt text\"><br>4. Application - DNS Monitoring<br>该dashbord主要展示了dns协议请求信息，包括请求总数，客户端错误率，客户端错误数量，服务端错误率，服务段错误数量，DNS Topo，请求时延等等信息，可用于分析DNS解析相关错误。</p>\n<p>4.1 Total Request、DNS Topo、Delay Distribution、Error<br><img src=\"/image-5.png\" alt=\"Alt text\"><br>这部分面板展示了DNS请求总数，客户端及服务端错误数量和错误率，DNS亲求拓扑，在Client Error(by client)面板中展示了客户端错误数量列表。<br>4.2 Server Error Ratio、Time Out、Delay<br><img src=\"/image-6.png\" alt=\"Alt text\"><br>这部分面板展示了DNS服务端错误百分比，服务端超时数量及按客户端统计列表；服务端时延，客户端时延等信息。<br>4.3 Request、Log Analysis、Request log Delay Distribution、Request Log<br><img src=\"/image-7.png\" alt=\"Alt text\"><br>● Request: 展示DNS服务请求速率、客户端请求数量和所占百分比。<br>● Log Analysis: 展示请求日志数量列表，可按服务端、客户端、成功或错误进行筛选。如图展示了失败的DNS请求客户端和请求域名列表及对应数量，通过Request Log（by response desc）可以看出错误都是Non-Existent Domain。通过Request Log Delay Distribution可看出请求日志时延。Reqeust Log展示例如请求日志列表。<br>5. Dubbo Monitoring - K8S<br><img src=\"/image-8.png\" alt=\"Alt text\"></p>\n<p>Dubbo微服务监控。展示请求总数，服务连接，时延、错误、请求日志分析等内容。<br>6. Application - K8s Ingress<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/31b5dcc3-e80c-44df-b008-63f844c2fba3.png\" alt=\"Alt text\"></p>\n<p>Ingress服务监控。展示请求、时延、错误、吞吐量等内容。<br>7. Application - K8s Pod<br>此dashboard展示了各个pod作为客户端和服务端发送请求的速率，错误率，时延等信息。<br><img src=\"/image-10.png\" alt=\"Alt text\"><br>我们以部署的测试服务deepflow-ebpf-spring-demo为例：<br>● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。<br>● workload：筛选工作负载。<br>● protocol：筛选网络协议。<br>7.1 Request面板<br>以redis-master-0 Redis为例，在此面板中可以看到名为redis-master-0的pod，网络协议Redis的最小请求速率（Min）为0.667 req&#x2F;s, 平均请求速率（Mean）为1.26 req&#x2F;s，最大请求速率1.33 req&#x2F;s。<br>7.2 Server error面板<br>展示了各pod指定网络协议的服务端错误百分比。<br>7.3 Latency面板<br>展示了各pod指定协议时延信息。<br>7.4 Pod List面板<br>指定pod,指定协议的请求速率，客户端错误百分比，服务端错误百分比，平均时延列表。<br>8. Application - K8s Pod Map<br>此dashboard展示了pod请求map,请求速率，服务段错误百分比，客户端错误百分比，时延等信息。<br>我们以部署的测试服务deepflow-ebpf-spring-demo为例：<br>● namespace: 筛选namespace为：deepflow-ebpf-spring-demo。<br>● workload：筛选工作负载。<br>● protocol：筛选网络协议。<br>8.1 Show client<br><img src=\"/image-11.png\" alt=\"Alt text\"><br>此时展示指定namespace中所有pod作为服务端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。<br>8.2 Show server<br><img src=\"/image-12.png\" alt=\"Alt text\"><br>此时展示指定namespace中所有pod作为客户端时，相关client和server相关请求信息，包括请求速率，服务端错误率，请求时延。<br>9. Application - Redis Monitoring - Cloud<br>此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。<br><img src=\"/image-13.png\" alt=\"Alt text\"><br>● Cloud Host: 按节点筛选redis服务<br>● IP: 按IP筛选redis服务<br>10. Application - Redis Monitoring - K8S<br>此dashboard展示了集群redis的监控数据。包括同请求数量，客户端、服务端错误数量错误百分比，吞吐量，时延，服务拓扑、请求速率，客户端请求量列表、请求日志分析，TOP N 执行的redis命令等。<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/7a2ab804-36f5-4ef2-a9fc-dc4a477851c7.png\" alt=\"Alt text\"><br>● cluster： 筛选指定集群<br>● Redis Service: 筛选指定redis服务<br>● redis willdCard：通配符匹配<br>● Tap Side： 可选择不同的数据采集点，获取不同的指标，例如查看客户端网卡吞吐量，服务端网卡吞吐量等。</p>\n<ol>\n<li>Application - Request Log<br>此dashboard展示了请求日志相关数据。<br><img src=\"/image-15.png\" alt=\"Alt text\"><br>● 筛选条件：可根据cluster（集群名）、namespace（命名空间）、workload（工作负载名）、protocol（网络协议）、request_type（请求类型）、reqeust_resource（请求资源）、status（响应状态）进行数据筛选。<br>● Summary count: 请求数量摘要。以一分钟区间统计请求数量。<br>● Error Count: 请求错误数量。<br>● Latency histogram: 请求时延直方图。<br>● Request log: 请求日志，包括Start time(请求开始时间)，Client(客户端)、Server(服务端)、Tap Side(数据采集点)、Protocol(网络协议)、App Protocol(应用协议)、Request type(请求类型)、Request domain(请求域名)、Request resource(请求资源)、Response Status(响应状态)、Response Code(响应码)、Response Delay(响应时延)。</li>\n<li>Application - Request Log - Cloud</li>\n</ol>\n<p><img src=\"/image-16.png\" alt=\"Alt text\"><br>此dashborad也是展示请求日志，与Application - Request Log展示内容相同，筛选条件不同：<br>● vm: 根据节点筛选<br>● protocol: 根据网络协议筛选<br>● request_type: 根据请求类型筛选<br>● reqeust_resource：根据请求资源筛选<br>● status：根据响应状态筛选<br>13. Application - SQL Monitoring - Cloud<br><img src=\"/image-18.png\" alt=\"Alt text\"><br>此dashboar展示了mysql相关数据库监控信息。<br>● 筛选条件：可根据client(客户端)、DB Host(数据库所在节点)、DB IP(数据库IP)、Client For SQL Analysis（需要SQL分析的客户端匹配.<br>● 展示内容：请求总数、客户端列表、topo概览、客户端服务端错误百分比及错误数及列表、连接数、平均活跃连接数、时延、时延客户端列表、SQL执行分析（SQL Statement、Request Type、响应状态、时延、AffectedRows、执行数量）、吞吐量、分布式追踪、SQL语句时延列表。<br>14. Application - SQL Monitoring - K8S<br><img src=\"/image-19.png\" alt=\"Alt text\"><br>此dashboar也是展示了mysql相关数据库监控信息。展示数据内容与SQL Monitoring - Cloud相同，筛选角度不同：<br>● client: 根据客户端筛选<br>● DB Cluster: 根据数据库所在集群筛选<br>● DB Service:  根据数据可服务筛选<br>● DB Wildcard: 根据数据库通配符筛选<br>● Tap Side: 根据数据采集点筛选<br>● Client For SQL Analysis：根据需要SQL分析的客户端匹配筛选<br>15. Distributed Tracing<br><img src=\"/image-20.png\" alt=\"Alt text\"><br>此dashboard展示了分布式调用追踪，可选择一个调用进行例如点击Request中的_id，就会显示其调用的Flame Graph(火焰图)。Service List展示了调用在各个Service所花费的时间和百分比。Request Log展示了请求体制数据，Related Data展示了相关数据。<br>● N： 通过 BPF 从网络流量中提取的 Span<br>● S:  通过 eBPF 从系统或应用函数调用中提取的 Span<br>Span 是分布式跟踪的基本构建块。分布式跟踪中的单个跟踪由一系列标记的时间间隔组成,称为跨度。跨度表示完成用户请求或事务的逻辑工作单元。在分布式链路跟踪中有两个重要的概念：跟踪（trace）和 跨度（ span）。trace 是请求在分布式系统中的整个链路视图，span 则代表整个链路中不同服务内部的视图，span 组合在一起就是整个 trace 的视图。<br>16. Distributed Tracing - Cloud<br><img src=\"/image-21.png\" alt=\"Alt text\"><br>此dashboard也展示了分布式调用追踪，与Distributed Tracing展示内容相同，筛选条件不同：<br>● vm: 根据节点筛选<br>● trace_id： 根据tarceID进行筛选，traceID是一个唯一标识符，用于跟踪整个分布式系统中的请求。它可以帮助我们追踪请求在整个系统中所经过的所有服务和操作，并且可以帮助我们在出现问题时快速定位问题。<br>● span_id：根据SpanID进行筛选，traceid 在请求的整个调用链中始终保持不变，所以在日志中可以通过 traceid 查询到整个请求期间系统记录下来的所有日志。请求到达每个服务后，服务都会为请求生成spanid，而随请求一起从上游传过来的上游服务的 spanid 会被记录成parent-spanid或者叫 pspanid。当前服务生成的 spanid 随着请求一起再传到下游服务时，这个spanid 又会被下游服务当做 pspanid 记录。<br>● request_resource：请求资源。<br>17. Network - Cloud Host<br><img src=\"/image-22.png\" alt=\"Alt text\"><br>此dashboard展示了各节点网络性能指标。可根据Vm(节点)进行筛选。<br>● Throught(bps): 展示了节点吞吐量，包括最小值、平均值、最大值。<br>● Retrans rate: 展示包重传率，包括最小值、平均值、最大值。<br>● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。<br>● TCP conn. establishment latency：TCP连接建立延迟指的是从客户端向服务器发起TCP连接请求，到服务器成功响应这个请求并建立起TCP连接所需的时间。这个延迟时间通常由网络延迟、服务器处理能力和其他因素决定。在高性能网络和服务器环境中，TCP连接建立延迟应该尽可能低。如果延迟时间过长，可能会导致用户体验不佳或者网络应用程序性能下降。<br>● Cloud Host List：展示节点网络性能详情列表。<br>chost<br>Throughput(bps)<br>Throughput(pps)<br>TCP new conn.<br>TCP retrans rate<br>TCP conn. establishment fail rate<br>TCP conn. establishment latency<br>TCP&#x2F;UDP data latency<br>节点名<br>是吞吐量的单位，表示每秒传输的比特数（bits per second）<br>是网络吞吐量的一种单位，表示每秒发送的分组数据包数量<br>TCP新建连接数<br>包重传率<br>TCP连接建立失败率<br>TCP连接建立延迟<br>TCP或UDP协议下数据传输的延迟时间。<br>TCP&#x2F;UDP data latency指的是TCP或UDP协议下数据传输的延迟时间。这是从数据发送端到接收端的时间，包括在网络中传输以及在发送和接收端的处理时间。这个延迟可能会受到网络拥堵、硬件性能、协议效率等因素的影响。一般来说，低延迟的通信对于实时性要求高的应用非常重要。<br>18. Network - Cloud Host Map<br>此dashboard展示了各节点，网络性能拓扑图。可根据VM(节点)，进行筛选。<br>18.1 Show Client<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/f5dfef4b-f7e9-4182-86b4-7dcd565b362c.png\"><br>展示了指定节点作为服务短时，网络性能指标，通过拓扑图可以点至查看指定客户端服务端之间的数据传输速率。<br>在Cloud Host Path列表中展示的数据与Network - Cloud Host相比多了以下数据：<br>● CLient: 客户端名。<br>● Server: 服务端。<br>● Tap side: 数据采样点。<br>● Protocol: 网络协议。<br>● Server port: 服务端口。<br>18.2 Show Server<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/8fa5d9e2-859d-42c7-9d3d-a1e1edabcb96.png\"><br>与show client展示内容相同，角度不同，此时展示当指定节点作为客户端时相关网络性能指标。<br>19.  Network - Flow Log<br><img src=\"/image-25.png\" alt=\"Alt text\"><br>此dashboard展示了网络流日志内容。<br>可根据cluster(集群)、namespace(命名空间)、workload(工作负载)进行筛选。<br>● Summary count: 日志总量摘要。<br>● Error count: 错误数量。<br>● TCP est.conn latency distribution：连接建立（establishment）延迟时间分布。<br>● TCP data latency distribution： 指的是在TCP协议下，数据传输延迟时间分布。<br>● Flow log：网络流日志列表，内容包括 start time(开始时间)、client(客户端)、server(服务端)、tap side(数据才采集点)、protocol(网络协议)、client port(客户端端口)、server port(服务端端口)、status(状态，由 close_type（流结束类型）与 protocol（协议）决定：正常结束&#x2F;周期性上报&#x2F;非TCP超时&#x3D;正常，客户端XX&#x3D;客户端异常，服务端XX&#x2F;TCP超时&#x3D;服务端异常，其他结束方式&#x3D;未知。)、Byte TX(发送字节数)、Byte RX(接收字节数)、TCP Client Retransmission(TCP客户端重传)、TCP Server Retransmission(TCP服务端重传)、Avg TCP Est. Delay(连接建立平均时延)、Avg Data Delay（数据传输平均时延）。<br>20. Network - Flow Log - Cloud<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/cbf20764-c8a8-48b3-a0c2-a023923ef515.png\" alt=\"Alt text\"><br>此dashboard展示的网络流日志内容与Flow Log相同，区别是筛选条件不同，此dashboard提供根据VM(节点)进行筛选，查看各节点上工作流日志。<br>21. Network - K8s Pod<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/334e9637-7366-4397-a79c-c61ec162c7f3.png\"><br>此dashboard展示了pod的网络性能相关指标，可根据cluster、namespace、workload进行筛选。<br>● Throught(bps): 展示了pod网络吞吐量，包括最小值、平均值、最大值。<br>● Retrans rate: 展示pod包重传率，包括最小值、平均值、最大值。<br>● TCP conn. establishment fail rate: TCP连接建立失败率，包括最小值、平均值、最大值。<br>● TCP conn. establishment latency：TCP连接建立延迟。<br>● Pod List： pod网络性能列表。<br>22.  Network - K8s Pod Map<br><img src=\"https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYPPLZoQO8j9/img/85fd8ca0-bea9-43e3-8a12-1a9b82cac676.png\"><br>网络性能全景图，点击路径可查看相关指标，包括bps、retrans_ratio(TCP 重传比例：TCP 重传比例，通过TCP 重传 &#x2F; 所有的包计算得，即 retrans &#x2F; packet)、tcp_establish_fail_ratio（建连-失败比例：建连-失败比例，通过 TCP 建连-失败次数 &#x2F; 所有的关闭连接计算得，即 tcp_establish_fail &#x2F; close_flow）、rtt(平均 TCP 建连时延,统计周期内，所有 TCP 建连时延的平均值)、art(平均数据时延:统计周期内，所有数据时延的平均值，数据时延包含 TCP&#x2F;UDP)等。</p>\n"},{"title":"Fluent Bit和Fluentd之间的联系及区别","date":"2023-08-24T08:13:26.000Z","_content":"Fluent Bit和Fluentd是两个流行的开源日志收集工具，并且它们有一些共同的设计目标，但也有一些区别。\n\n1. Fluent Bit（轻量型的日志收集器）\nFluent Bit是一个轻量级和高性能的日志收集器，由Treasure Data公司开发。它专注于收集、过滤和转发日志，具有低内存占用和低性能开销的特点。Fluent Bit设计用于嵌入式系统和容器环境中，可以作为提供日志数据的终端。\n\n使用场景：\n- IoT设备：Fluent Bit作为嵌入式日志收集器，适用于在资源有限的物联网设备上收集日志数据。\n- 容器环境：Fluent Bit能够与Docker等容器平台无缝集成，并快速收集、聚合和转发容器日志。\n- 边缘计算：部署在边缘节点的Fluent Bit能够实时收集和传输边缘设备上的日志数据。\n\n使用方式：\n- 配置管理：通过配置文件定义输入源、过滤规则和输出目标。\n- 轻量级部署：由于其低资源消耗，Fluent Bit适合在嵌入式设备和容器中部署。\n- 插件支持：提供多种插件，如输入、过滤和输出插件，可根据需求扩展功能。\n\n2. Fluentd（全能型的日志收集引擎）\nFluentd是一个功能强大的开源日志收集和流数据处理引擎，也是由Treasure Data公司开发。它设计用于处理大规模和复杂的数据流，提供了更丰富的功能和灵活性。\n\n使用场景：\n- 日志聚合：收集来自多个源（文件、系统日志、应用程序日志等）的日志数据，并将其聚合到一处进行分析和存储。\n- 实时大数据处理：通过Fluentd的插件生态系统，可以将数据发送到Hadoop、Elasticsearch等数据处理和存储平台。\n- 日志路由和转换：Fluentd支持对日志数据进行过滤、标准化和转换，以便在不同目标之间进行路由。\n\n使用方式：\n- 插件生态系统：拥有丰富的插件生态系统，可用于收集、处理和转发各种类型的数据。\n- 高度可配置：通过配置文件进行配置，可以定义输入源、过滤器和输出目标，并自定义数据流的处理逻辑。\n- 部署灵活：Fluentd可以以独立进程或守护进程的形式部署，也可以在容器中运行。\n\n联系与区别：\n- 它们都是由Treasure Data公司开发的开源日志收集工具，具有类似的设计目标。\n- Fluent Bit更注重轻量级和高性能，适用于嵌入式和容器环境中的日志收集，而Fluentd则更适合处理大规模和复杂的数据流。\n- Fluent Bit的功能相对较少，专注于基本的日志收集、过滤和转发，而Fluentd具有更丰富的功能和插件生态系统。\n- Fluent Bit和Fluentd可以在同一系统中共存，实现多层次的日志收集和处理。\n\n总结：\nFluent Bit和Fluentd都是用于日志收集的工具，但根据应用场景和需求的不同，可以选择适合的工具。如果你需要一个轻量级的解决方案，以及在嵌入式设备和容器中高效收集和转发日志，可以选择Fluent Bit。而如果你面对复杂的数据流和需要更多功能和灵活性的场景，可以选择Fluentd。","source":"_posts/kubernetes/fluent_Bit_Fluentd.md","raw":"---\ntitle: Fluent Bit和Fluentd之间的联系及区别\ndate: 2023-08-24 16:13:26\ncategories:\n  - [kubernetes]\ntags: logging\n---\nFluent Bit和Fluentd是两个流行的开源日志收集工具，并且它们有一些共同的设计目标，但也有一些区别。\n\n1. Fluent Bit（轻量型的日志收集器）\nFluent Bit是一个轻量级和高性能的日志收集器，由Treasure Data公司开发。它专注于收集、过滤和转发日志，具有低内存占用和低性能开销的特点。Fluent Bit设计用于嵌入式系统和容器环境中，可以作为提供日志数据的终端。\n\n使用场景：\n- IoT设备：Fluent Bit作为嵌入式日志收集器，适用于在资源有限的物联网设备上收集日志数据。\n- 容器环境：Fluent Bit能够与Docker等容器平台无缝集成，并快速收集、聚合和转发容器日志。\n- 边缘计算：部署在边缘节点的Fluent Bit能够实时收集和传输边缘设备上的日志数据。\n\n使用方式：\n- 配置管理：通过配置文件定义输入源、过滤规则和输出目标。\n- 轻量级部署：由于其低资源消耗，Fluent Bit适合在嵌入式设备和容器中部署。\n- 插件支持：提供多种插件，如输入、过滤和输出插件，可根据需求扩展功能。\n\n2. Fluentd（全能型的日志收集引擎）\nFluentd是一个功能强大的开源日志收集和流数据处理引擎，也是由Treasure Data公司开发。它设计用于处理大规模和复杂的数据流，提供了更丰富的功能和灵活性。\n\n使用场景：\n- 日志聚合：收集来自多个源（文件、系统日志、应用程序日志等）的日志数据，并将其聚合到一处进行分析和存储。\n- 实时大数据处理：通过Fluentd的插件生态系统，可以将数据发送到Hadoop、Elasticsearch等数据处理和存储平台。\n- 日志路由和转换：Fluentd支持对日志数据进行过滤、标准化和转换，以便在不同目标之间进行路由。\n\n使用方式：\n- 插件生态系统：拥有丰富的插件生态系统，可用于收集、处理和转发各种类型的数据。\n- 高度可配置：通过配置文件进行配置，可以定义输入源、过滤器和输出目标，并自定义数据流的处理逻辑。\n- 部署灵活：Fluentd可以以独立进程或守护进程的形式部署，也可以在容器中运行。\n\n联系与区别：\n- 它们都是由Treasure Data公司开发的开源日志收集工具，具有类似的设计目标。\n- Fluent Bit更注重轻量级和高性能，适用于嵌入式和容器环境中的日志收集，而Fluentd则更适合处理大规模和复杂的数据流。\n- Fluent Bit的功能相对较少，专注于基本的日志收集、过滤和转发，而Fluentd具有更丰富的功能和插件生态系统。\n- Fluent Bit和Fluentd可以在同一系统中共存，实现多层次的日志收集和处理。\n\n总结：\nFluent Bit和Fluentd都是用于日志收集的工具，但根据应用场景和需求的不同，可以选择适合的工具。如果你需要一个轻量级的解决方案，以及在嵌入式设备和容器中高效收集和转发日志，可以选择Fluent Bit。而如果你面对复杂的数据流和需要更多功能和灵活性的场景，可以选择Fluentd。","slug":"kubernetes/fluent_Bit_Fluentd","published":1,"updated":"2023-08-24T08:14:42.291Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0bu000gfmjx2x7xh5nv","content":"<p>Fluent Bit和Fluentd是两个流行的开源日志收集工具，并且它们有一些共同的设计目标，但也有一些区别。</p>\n<ol>\n<li>Fluent Bit（轻量型的日志收集器）<br>Fluent Bit是一个轻量级和高性能的日志收集器，由Treasure Data公司开发。它专注于收集、过滤和转发日志，具有低内存占用和低性能开销的特点。Fluent Bit设计用于嵌入式系统和容器环境中，可以作为提供日志数据的终端。</li>\n</ol>\n<p>使用场景：</p>\n<ul>\n<li>IoT设备：Fluent Bit作为嵌入式日志收集器，适用于在资源有限的物联网设备上收集日志数据。</li>\n<li>容器环境：Fluent Bit能够与Docker等容器平台无缝集成，并快速收集、聚合和转发容器日志。</li>\n<li>边缘计算：部署在边缘节点的Fluent Bit能够实时收集和传输边缘设备上的日志数据。</li>\n</ul>\n<p>使用方式：</p>\n<ul>\n<li>配置管理：通过配置文件定义输入源、过滤规则和输出目标。</li>\n<li>轻量级部署：由于其低资源消耗，Fluent Bit适合在嵌入式设备和容器中部署。</li>\n<li>插件支持：提供多种插件，如输入、过滤和输出插件，可根据需求扩展功能。</li>\n</ul>\n<ol start=\"2\">\n<li>Fluentd（全能型的日志收集引擎）<br>Fluentd是一个功能强大的开源日志收集和流数据处理引擎，也是由Treasure Data公司开发。它设计用于处理大规模和复杂的数据流，提供了更丰富的功能和灵活性。</li>\n</ol>\n<p>使用场景：</p>\n<ul>\n<li>日志聚合：收集来自多个源（文件、系统日志、应用程序日志等）的日志数据，并将其聚合到一处进行分析和存储。</li>\n<li>实时大数据处理：通过Fluentd的插件生态系统，可以将数据发送到Hadoop、Elasticsearch等数据处理和存储平台。</li>\n<li>日志路由和转换：Fluentd支持对日志数据进行过滤、标准化和转换，以便在不同目标之间进行路由。</li>\n</ul>\n<p>使用方式：</p>\n<ul>\n<li>插件生态系统：拥有丰富的插件生态系统，可用于收集、处理和转发各种类型的数据。</li>\n<li>高度可配置：通过配置文件进行配置，可以定义输入源、过滤器和输出目标，并自定义数据流的处理逻辑。</li>\n<li>部署灵活：Fluentd可以以独立进程或守护进程的形式部署，也可以在容器中运行。</li>\n</ul>\n<p>联系与区别：</p>\n<ul>\n<li>它们都是由Treasure Data公司开发的开源日志收集工具，具有类似的设计目标。</li>\n<li>Fluent Bit更注重轻量级和高性能，适用于嵌入式和容器环境中的日志收集，而Fluentd则更适合处理大规模和复杂的数据流。</li>\n<li>Fluent Bit的功能相对较少，专注于基本的日志收集、过滤和转发，而Fluentd具有更丰富的功能和插件生态系统。</li>\n<li>Fluent Bit和Fluentd可以在同一系统中共存，实现多层次的日志收集和处理。</li>\n</ul>\n<p>总结：<br>Fluent Bit和Fluentd都是用于日志收集的工具，但根据应用场景和需求的不同，可以选择适合的工具。如果你需要一个轻量级的解决方案，以及在嵌入式设备和容器中高效收集和转发日志，可以选择Fluent Bit。而如果你面对复杂的数据流和需要更多功能和灵活性的场景，可以选择Fluentd。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>Fluent Bit和Fluentd是两个流行的开源日志收集工具，并且它们有一些共同的设计目标，但也有一些区别。</p>\n<ol>\n<li>Fluent Bit（轻量型的日志收集器）<br>Fluent Bit是一个轻量级和高性能的日志收集器，由Treasure Data公司开发。它专注于收集、过滤和转发日志，具有低内存占用和低性能开销的特点。Fluent Bit设计用于嵌入式系统和容器环境中，可以作为提供日志数据的终端。</li>\n</ol>\n<p>使用场景：</p>\n<ul>\n<li>IoT设备：Fluent Bit作为嵌入式日志收集器，适用于在资源有限的物联网设备上收集日志数据。</li>\n<li>容器环境：Fluent Bit能够与Docker等容器平台无缝集成，并快速收集、聚合和转发容器日志。</li>\n<li>边缘计算：部署在边缘节点的Fluent Bit能够实时收集和传输边缘设备上的日志数据。</li>\n</ul>\n<p>使用方式：</p>\n<ul>\n<li>配置管理：通过配置文件定义输入源、过滤规则和输出目标。</li>\n<li>轻量级部署：由于其低资源消耗，Fluent Bit适合在嵌入式设备和容器中部署。</li>\n<li>插件支持：提供多种插件，如输入、过滤和输出插件，可根据需求扩展功能。</li>\n</ul>\n<ol start=\"2\">\n<li>Fluentd（全能型的日志收集引擎）<br>Fluentd是一个功能强大的开源日志收集和流数据处理引擎，也是由Treasure Data公司开发。它设计用于处理大规模和复杂的数据流，提供了更丰富的功能和灵活性。</li>\n</ol>\n<p>使用场景：</p>\n<ul>\n<li>日志聚合：收集来自多个源（文件、系统日志、应用程序日志等）的日志数据，并将其聚合到一处进行分析和存储。</li>\n<li>实时大数据处理：通过Fluentd的插件生态系统，可以将数据发送到Hadoop、Elasticsearch等数据处理和存储平台。</li>\n<li>日志路由和转换：Fluentd支持对日志数据进行过滤、标准化和转换，以便在不同目标之间进行路由。</li>\n</ul>\n<p>使用方式：</p>\n<ul>\n<li>插件生态系统：拥有丰富的插件生态系统，可用于收集、处理和转发各种类型的数据。</li>\n<li>高度可配置：通过配置文件进行配置，可以定义输入源、过滤器和输出目标，并自定义数据流的处理逻辑。</li>\n<li>部署灵活：Fluentd可以以独立进程或守护进程的形式部署，也可以在容器中运行。</li>\n</ul>\n<p>联系与区别：</p>\n<ul>\n<li>它们都是由Treasure Data公司开发的开源日志收集工具，具有类似的设计目标。</li>\n<li>Fluent Bit更注重轻量级和高性能，适用于嵌入式和容器环境中的日志收集，而Fluentd则更适合处理大规模和复杂的数据流。</li>\n<li>Fluent Bit的功能相对较少，专注于基本的日志收集、过滤和转发，而Fluentd具有更丰富的功能和插件生态系统。</li>\n<li>Fluent Bit和Fluentd可以在同一系统中共存，实现多层次的日志收集和处理。</li>\n</ul>\n<p>总结：<br>Fluent Bit和Fluentd都是用于日志收集的工具，但根据应用场景和需求的不同，可以选择适合的工具。如果你需要一个轻量级的解决方案，以及在嵌入式设备和容器中高效收集和转发日志，可以选择Fluent Bit。而如果你面对复杂的数据流和需要更多功能和灵活性的场景，可以选择Fluentd。</p>\n"},{"title":"grafana how to create alert rule","date":"2023-08-31T09:08:54.000Z","_content":"# 1. 部署grafana的配置文件修改\n\n因为要采用发送邮件的方式通知告警内容所以，在部署grafana时要先配置好SMTP / Emailing的内容：\n\n```\n    [smtp]\n    enabled = true # 开启smtp\n    host = smtp.mxhichina.com:465  #设置邮箱服务器地址\n    user = test@test.com  #设置邮箱用户\n    password = test123456 #设置邮箱密码或授权码\n    from_address = test@test.com #设置邮箱发送方地址\n    from_name = Grafana #设置邮箱发送name\n```\n\n# 2. 配置contact points(告警通道)\n\n使用contact points定义在告警发生时如何通知联系人。包括创建message template和contact points。\n\n## 2.1 创建message template(消息模板)\n\ngrafana的消息模板基于go语言的模板系统。如下模板数据表列出了可用于模板的变量\n\n| Name | Type | Notes |\n| --- | --- | --- |\n| Receiver | string | Name of the contact point that the notification is being sent to. |\n| Status | string | `firing` if at least one alert is firing, otherwise `resolved`. |\n| Alerts | Alert | List of alert objects that are included in this notification (see below). |\n| GroupLabels | KeyValue | Labels these alerts were grouped by. |\n| CommonLabels | KeyValue | Labels common to all the alerts included in this notification. |\n| CommonAnnotations | KeyValue | Annotations common to all the alerts included in this notification. |\n| ExternalURL | string | Back link to the Grafana that sent the notification. If using external Alertmanager, back link to this Alertmanager. |\n\nAlerts类型是一个过滤告警的函数：\n\n- `Alerts.Firing` returns a list of firing alerts.\n- `Alerts.Resolved` returns a list of resolved alerts.\n\n![template](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-message-template.png)\n\ndefine用来设置模板名，是可选的，如果不设置默认采用Template name,最佳实践时与Template name 保持一致。\n\n## 2.2 创建 contact point\n\n![point](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-contact-point.png)\n\n创建name和不同类型的contact，包括邮箱，钉钉等，同一个name下可以添加多个contact。详细说一下邮箱类型的tact：\n\n- Addresses: 接收通知的邮件地址，可以写多个，用英文分号（;)隔开。\n  \n- Single email: 勾选表示发送一个邮件给所有的接受者。\n  \n- message: 可以通过模板变量引用前面创建的模板：\n  \n  ```\n  {{template \"alert message\" .}}\n  ```\n  \n- Disable resloved message: 是否关闭告警解决通知。\n  \n\n# 3. 创建通知策略（Notification policies）\n\n通知策略通过label配置告警，通知指定 contact point设置接收告警通知的对象。\n\n![np](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/n-p.png)\n\n- matching labels： 添加指定的匹配label用于匹配alerts。\n  \n- contact point: 设置创建好的指定的contact point.\n  \n- Continue matching subsequent sibling nodes: 是否继续匹配嵌套策略。\n  \n- Override grouping：是一种告警策略设置，可用于覆盖默认的告警分组工作方式。默认情况下，Grafana根据告警规则的标签对告警进行分组。但是，对于某些特殊情况，用户可能希望以不同的方式进行告警分组，这时就可以使用Override grouping来实现。\n  \n  使用Override grouping，用户可以通过自定义指标和筛选条件来定义告警的分组方式。这样可以根据特定的业务需求，将相关的告警归为一组，便于在仪表盘中统一管理和查看。\n  \n  Override grouping的设置涉及以下几个重要的概念：\n  \n  1. 可聚合的字段：定义用于分组的字段，可以是任意的标签或指标。\n  2. 聚合器：确定了要使用哪种方法来聚合分组，如平均值、最大值、最小值等。\n  3. 时间范围：告警分组的时间范围，可以是一个固定的时间段或相对于当前时间的一段时间。\n  \n  用户可以根据具体情况选择合适的聚合字段、聚合器和时间范围来定义告警的分组方式。通过Override grouping，用户可以更加灵活地管理和控制告警的分组行为，从而更好地满足业务需求。\n  \n- Override general timings（覆盖一般定时）：用来覆盖通用的重复和间隔定时。\n  \n  具体来说，Grafana的告警策略中，可以设置一个重复间隔时间（Repeat interval），用于确定告警规则检查条件的重复间隔。默认情况下，这个间隔会使用Grafana的全局设置。\n  \n  然而，有时候我们希望针对特定的告警规则使用不同的重复间隔时间，这就可以使用Override general timings（覆盖一般定时）来实现。通过勾选此选项，并设置相应的重复间隔时间，可以覆盖全局设置，使特定的告警规则使用不同的重复间隔时间。\n  \n  这样做的好处是，可以根据特定的告警规则的需求，灵活地定义重复间隔时间，以更加精确和准确地监控和警告系统的状态变化。这对于保证系统的稳定性、性能和安全性非常有帮助。\n  \n  1. Group wait: 为传入警报创建的新组发送初始通知之前的等待时间。\n    \n  2. Group interval: 发送第一个通知后为该组发送一批新警报的等待时间。\n    \n  3. Repeat interval: 成功发送警报后重新发送警报的等待时间。\n    \n\n# 4. 创建告警规则（rule)\n\nrule有三种类型：\n\n- Cortex or Loki managed alerting rule：创建由Cortex或者Loki管理的rule；需要对Prometheus或者其他数据源有读写权限。\n  \n  Cortex和Loki都是与Grafana密切相关的工具。\n  \n  Cortex是一个可扩展、多租户、分布式的时间序列数据库。它能够接收和存储大规模的指标数据，并提供高速查询、聚合和处理数据的能力。Cortex的设计目标是能够处理海量的时间序列数据，并且具有可水平扩展性和高可用性。Cortex允许用户通过内置的查询语言PromQL来查询和分析指标数据，并支持数据的可视化和报表功能。Cortex还提供了横向扩展的能力，可以轻松地增加存储容量和查询吞吐量。因此，Cortex适用于大规模监控系统中需要存储和查询大量指标数据的场景。\n  \n  Loki是一个用于日志聚合和存储的系统。它可以接收多个来源的日志数据，并将它们存储为可搜索和可查询的格式。与传统的日志存储系统相比，Loki采用了一种高效的存储和索引方法，可以充分利用现代存储技术和硬件，以提供更高的性能和可扩展性。Loki支持使用标准的日志查询语言PromQL来查询和分析日志数据，并且与Cortex集成，可以实现和指标数据的混合查询和分析。此外，Loki还提供了强大的数据可视化和报表功能，可以方便地展示和监控系统的日志信息。\n  \n  综上所述，Cortex和Loki是Grafana监控和可视化平台的两个重要组成部分。Cortex用于存储和查询大规模的指标数据，而Loki则用于存储和查询系统的日志数据。它们都具有高性能、可扩展性和易于使用的特点，能够满足大规模监控系统中对指标和日志数据的存储、查询和分析需求。\n  \n- Cortex or Loki managed recording rule：创建recording类型的rule。\n  \n- Grafana managed alerting rule：创建grafana管理的告警规则，我们主要介绍这个类型的规则。\n  \n\n## 4.2 Grafana managed alerting rule\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-1.png)\n\n- rule name: 告警规则名。\n  \n- rule type: 告警规则类型。\n  \n- Folder: 选择所属的Folder。\n  \n- 创建告警规则语句：\n  \n  1. 选择数据源为Prometheus\n    \n  2. 查询展示的最近10分钟的数据。\n    \n  3. Metrics browser: 设定数据查询的语句使用PromQL语法。\n    \n  4. Legend: 根据查询出的数据变量设置显示指标名。\n    \n  5. Min step: 最小步长表示图形里每两个点的最小数据间隔是多少，例如：这里我设置了 200，那表示图形上每隔 200 个单位才会有一个点。\n    \n  6. Resolution： 这表示其数据精度是怎样的，是 1 比 1 的精度，还是原有的 1/2，还是 1/3 等等。如果是 1/2 的话，那么就是原本 1 个单位显示一个点，现在 2 个单位合并起来显示成一个点了，那么其精度就变低了。\n    \n  7. Format： 表示你的数据格式是什么，这里有：Time series、Table、Heap Map 三个选项。Time series 表示是时间序列数据，即随着时间的流动有源源不断的数据。Table 表示是一个表格数据。Heap Map 表示是热力图数据。\n    \n    1. instant: 勾选时查询只在指定的单个时间点上执行，这对于需要聚合或对单个时间点数据感兴趣的场景非常有用。面板的时间选择器将被禁用，因为查询仅在一个固定时间点上执行。不勾选时：查询将返回一个时间范围内的数据，这对于需要在一段时间内进行数据分析或比较的情况非常有用。面板的时间选择器将启用，可以选择查询的时间范围。\n\n    ![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-2.png)\n      \n    \n    创建Expression（表达式）：\n      \n    - classic condition:\n        \n        1. `avg()`: 用于计算一段时间内的平均值。适用于告警需要基于平均值的场景。例如，如果需要在CPU平均负载超过阈值时触发告警，可以使用`avg()`函数。\n          \n        2. `last()`: 用于获取时间段内最后一个数据点的值。适用于告警需要基于最后一个数据点的场景。例如，如果需要在最后一个数据点超过阈值时触发告警，可以使用`last()`函数。\n          \n        3. `max()`: 用于计算一段时间内的最大值。适用于告警需要基于最大值的场景。例如，如果需要在CPU负载的最大值超过阈值时触发告警，可以使用`max()`函数。\n          \n        4. `min()`: 用于计算一段时间内的最小值。适用于告警需要基于最小值的场景。例如，如果需要在CPU负载的最小值低于阈值时触发告警，可以使用`min()`函数。\n          \n        5. `sum()`: 用于计算一段时间内的总和。适用于告警需要基于总和的场景。例如，如果需要在一段时间内的请求数总和超过阈值时触发告警，可以使用`sum()`函数。\n          \n        6. `count()`: 用于计算一段时间内的数据点数量。适用于告警需要基于数据点数量的场景。例如，如果需要在一段时间内的请求数量超过阈值时触发告警，可以使用`count()`函数。\n          \n        \n      \n      Define alert conditions: 定义告警状态：\n      \n      - condition: 选择基于哪个query或者表达式进行告警。\n        \n      - Evaluate: 设置多久评估一次告警条件，\n        \n      - For： 满足条件持续多久触发告警，改变告警状态到firing.\n        \n      - Configure no data and error handling: 设定无数错和错误处理：\n        \n        | No Data Option | Description |\n        | --- | --- |\n        | No Data | Create a new alert `DatasourceNoData` with the name and UID of the alert rule, and UID of the datasource that returned no data as labels. |\n        | Alerting | Set alert rule state to `Alerting`. |\n        | Ok  | Set alert rule state to `Normal`. |\n        \n        | Error or timeout option | Description |\n        | --- | --- |\n        | Alerting | Set alert rule state to `Alerting` |\n        | OK  | Set alert rule state to `Normal` |\n        | Error | Create a new alert `DatasourceError` with the name and UID of the alert rule, and UID of the datasource that returned no data as labels. |\n        \n      \n      Add details for your alert： 添加其他额外的alert信息。","source":"_posts/kubernetes/grafana-create-alert-rule.md","raw":"---\ntitle: grafana how to create alert rule\ndate: 2023-08-31 17:08:54\ncategories:\n  - [kubernetes]\ntags: grafana\n---\n# 1. 部署grafana的配置文件修改\n\n因为要采用发送邮件的方式通知告警内容所以，在部署grafana时要先配置好SMTP / Emailing的内容：\n\n```\n    [smtp]\n    enabled = true # 开启smtp\n    host = smtp.mxhichina.com:465  #设置邮箱服务器地址\n    user = test@test.com  #设置邮箱用户\n    password = test123456 #设置邮箱密码或授权码\n    from_address = test@test.com #设置邮箱发送方地址\n    from_name = Grafana #设置邮箱发送name\n```\n\n# 2. 配置contact points(告警通道)\n\n使用contact points定义在告警发生时如何通知联系人。包括创建message template和contact points。\n\n## 2.1 创建message template(消息模板)\n\ngrafana的消息模板基于go语言的模板系统。如下模板数据表列出了可用于模板的变量\n\n| Name | Type | Notes |\n| --- | --- | --- |\n| Receiver | string | Name of the contact point that the notification is being sent to. |\n| Status | string | `firing` if at least one alert is firing, otherwise `resolved`. |\n| Alerts | Alert | List of alert objects that are included in this notification (see below). |\n| GroupLabels | KeyValue | Labels these alerts were grouped by. |\n| CommonLabels | KeyValue | Labels common to all the alerts included in this notification. |\n| CommonAnnotations | KeyValue | Annotations common to all the alerts included in this notification. |\n| ExternalURL | string | Back link to the Grafana that sent the notification. If using external Alertmanager, back link to this Alertmanager. |\n\nAlerts类型是一个过滤告警的函数：\n\n- `Alerts.Firing` returns a list of firing alerts.\n- `Alerts.Resolved` returns a list of resolved alerts.\n\n![template](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-message-template.png)\n\ndefine用来设置模板名，是可选的，如果不设置默认采用Template name,最佳实践时与Template name 保持一致。\n\n## 2.2 创建 contact point\n\n![point](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-contact-point.png)\n\n创建name和不同类型的contact，包括邮箱，钉钉等，同一个name下可以添加多个contact。详细说一下邮箱类型的tact：\n\n- Addresses: 接收通知的邮件地址，可以写多个，用英文分号（;)隔开。\n  \n- Single email: 勾选表示发送一个邮件给所有的接受者。\n  \n- message: 可以通过模板变量引用前面创建的模板：\n  \n  ```\n  {{template \"alert message\" .}}\n  ```\n  \n- Disable resloved message: 是否关闭告警解决通知。\n  \n\n# 3. 创建通知策略（Notification policies）\n\n通知策略通过label配置告警，通知指定 contact point设置接收告警通知的对象。\n\n![np](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/n-p.png)\n\n- matching labels： 添加指定的匹配label用于匹配alerts。\n  \n- contact point: 设置创建好的指定的contact point.\n  \n- Continue matching subsequent sibling nodes: 是否继续匹配嵌套策略。\n  \n- Override grouping：是一种告警策略设置，可用于覆盖默认的告警分组工作方式。默认情况下，Grafana根据告警规则的标签对告警进行分组。但是，对于某些特殊情况，用户可能希望以不同的方式进行告警分组，这时就可以使用Override grouping来实现。\n  \n  使用Override grouping，用户可以通过自定义指标和筛选条件来定义告警的分组方式。这样可以根据特定的业务需求，将相关的告警归为一组，便于在仪表盘中统一管理和查看。\n  \n  Override grouping的设置涉及以下几个重要的概念：\n  \n  1. 可聚合的字段：定义用于分组的字段，可以是任意的标签或指标。\n  2. 聚合器：确定了要使用哪种方法来聚合分组，如平均值、最大值、最小值等。\n  3. 时间范围：告警分组的时间范围，可以是一个固定的时间段或相对于当前时间的一段时间。\n  \n  用户可以根据具体情况选择合适的聚合字段、聚合器和时间范围来定义告警的分组方式。通过Override grouping，用户可以更加灵活地管理和控制告警的分组行为，从而更好地满足业务需求。\n  \n- Override general timings（覆盖一般定时）：用来覆盖通用的重复和间隔定时。\n  \n  具体来说，Grafana的告警策略中，可以设置一个重复间隔时间（Repeat interval），用于确定告警规则检查条件的重复间隔。默认情况下，这个间隔会使用Grafana的全局设置。\n  \n  然而，有时候我们希望针对特定的告警规则使用不同的重复间隔时间，这就可以使用Override general timings（覆盖一般定时）来实现。通过勾选此选项，并设置相应的重复间隔时间，可以覆盖全局设置，使特定的告警规则使用不同的重复间隔时间。\n  \n  这样做的好处是，可以根据特定的告警规则的需求，灵活地定义重复间隔时间，以更加精确和准确地监控和警告系统的状态变化。这对于保证系统的稳定性、性能和安全性非常有帮助。\n  \n  1. Group wait: 为传入警报创建的新组发送初始通知之前的等待时间。\n    \n  2. Group interval: 发送第一个通知后为该组发送一批新警报的等待时间。\n    \n  3. Repeat interval: 成功发送警报后重新发送警报的等待时间。\n    \n\n# 4. 创建告警规则（rule)\n\nrule有三种类型：\n\n- Cortex or Loki managed alerting rule：创建由Cortex或者Loki管理的rule；需要对Prometheus或者其他数据源有读写权限。\n  \n  Cortex和Loki都是与Grafana密切相关的工具。\n  \n  Cortex是一个可扩展、多租户、分布式的时间序列数据库。它能够接收和存储大规模的指标数据，并提供高速查询、聚合和处理数据的能力。Cortex的设计目标是能够处理海量的时间序列数据，并且具有可水平扩展性和高可用性。Cortex允许用户通过内置的查询语言PromQL来查询和分析指标数据，并支持数据的可视化和报表功能。Cortex还提供了横向扩展的能力，可以轻松地增加存储容量和查询吞吐量。因此，Cortex适用于大规模监控系统中需要存储和查询大量指标数据的场景。\n  \n  Loki是一个用于日志聚合和存储的系统。它可以接收多个来源的日志数据，并将它们存储为可搜索和可查询的格式。与传统的日志存储系统相比，Loki采用了一种高效的存储和索引方法，可以充分利用现代存储技术和硬件，以提供更高的性能和可扩展性。Loki支持使用标准的日志查询语言PromQL来查询和分析日志数据，并且与Cortex集成，可以实现和指标数据的混合查询和分析。此外，Loki还提供了强大的数据可视化和报表功能，可以方便地展示和监控系统的日志信息。\n  \n  综上所述，Cortex和Loki是Grafana监控和可视化平台的两个重要组成部分。Cortex用于存储和查询大规模的指标数据，而Loki则用于存储和查询系统的日志数据。它们都具有高性能、可扩展性和易于使用的特点，能够满足大规模监控系统中对指标和日志数据的存储、查询和分析需求。\n  \n- Cortex or Loki managed recording rule：创建recording类型的rule。\n  \n- Grafana managed alerting rule：创建grafana管理的告警规则，我们主要介绍这个类型的规则。\n  \n\n## 4.2 Grafana managed alerting rule\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-1.png)\n\n- rule name: 告警规则名。\n  \n- rule type: 告警规则类型。\n  \n- Folder: 选择所属的Folder。\n  \n- 创建告警规则语句：\n  \n  1. 选择数据源为Prometheus\n    \n  2. 查询展示的最近10分钟的数据。\n    \n  3. Metrics browser: 设定数据查询的语句使用PromQL语法。\n    \n  4. Legend: 根据查询出的数据变量设置显示指标名。\n    \n  5. Min step: 最小步长表示图形里每两个点的最小数据间隔是多少，例如：这里我设置了 200，那表示图形上每隔 200 个单位才会有一个点。\n    \n  6. Resolution： 这表示其数据精度是怎样的，是 1 比 1 的精度，还是原有的 1/2，还是 1/3 等等。如果是 1/2 的话，那么就是原本 1 个单位显示一个点，现在 2 个单位合并起来显示成一个点了，那么其精度就变低了。\n    \n  7. Format： 表示你的数据格式是什么，这里有：Time series、Table、Heap Map 三个选项。Time series 表示是时间序列数据，即随着时间的流动有源源不断的数据。Table 表示是一个表格数据。Heap Map 表示是热力图数据。\n    \n    1. instant: 勾选时查询只在指定的单个时间点上执行，这对于需要聚合或对单个时间点数据感兴趣的场景非常有用。面板的时间选择器将被禁用，因为查询仅在一个固定时间点上执行。不勾选时：查询将返回一个时间范围内的数据，这对于需要在一段时间内进行数据分析或比较的情况非常有用。面板的时间选择器将启用，可以选择查询的时间范围。\n\n    ![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-2.png)\n      \n    \n    创建Expression（表达式）：\n      \n    - classic condition:\n        \n        1. `avg()`: 用于计算一段时间内的平均值。适用于告警需要基于平均值的场景。例如，如果需要在CPU平均负载超过阈值时触发告警，可以使用`avg()`函数。\n          \n        2. `last()`: 用于获取时间段内最后一个数据点的值。适用于告警需要基于最后一个数据点的场景。例如，如果需要在最后一个数据点超过阈值时触发告警，可以使用`last()`函数。\n          \n        3. `max()`: 用于计算一段时间内的最大值。适用于告警需要基于最大值的场景。例如，如果需要在CPU负载的最大值超过阈值时触发告警，可以使用`max()`函数。\n          \n        4. `min()`: 用于计算一段时间内的最小值。适用于告警需要基于最小值的场景。例如，如果需要在CPU负载的最小值低于阈值时触发告警，可以使用`min()`函数。\n          \n        5. `sum()`: 用于计算一段时间内的总和。适用于告警需要基于总和的场景。例如，如果需要在一段时间内的请求数总和超过阈值时触发告警，可以使用`sum()`函数。\n          \n        6. `count()`: 用于计算一段时间内的数据点数量。适用于告警需要基于数据点数量的场景。例如，如果需要在一段时间内的请求数量超过阈值时触发告警，可以使用`count()`函数。\n          \n        \n      \n      Define alert conditions: 定义告警状态：\n      \n      - condition: 选择基于哪个query或者表达式进行告警。\n        \n      - Evaluate: 设置多久评估一次告警条件，\n        \n      - For： 满足条件持续多久触发告警，改变告警状态到firing.\n        \n      - Configure no data and error handling: 设定无数错和错误处理：\n        \n        | No Data Option | Description |\n        | --- | --- |\n        | No Data | Create a new alert `DatasourceNoData` with the name and UID of the alert rule, and UID of the datasource that returned no data as labels. |\n        | Alerting | Set alert rule state to `Alerting`. |\n        | Ok  | Set alert rule state to `Normal`. |\n        \n        | Error or timeout option | Description |\n        | --- | --- |\n        | Alerting | Set alert rule state to `Alerting` |\n        | OK  | Set alert rule state to `Normal` |\n        | Error | Create a new alert `DatasourceError` with the name and UID of the alert rule, and UID of the datasource that returned no data as labels. |\n        \n      \n      Add details for your alert： 添加其他额外的alert信息。","slug":"kubernetes/grafana-create-alert-rule","published":1,"updated":"2023-11-07T02:41:52.156Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0bv000hfmjx6sl11d6z","content":"<h1 id=\"1-部署grafana的配置文件修改\"><a href=\"#1-部署grafana的配置文件修改\" class=\"headerlink\" title=\"1. 部署grafana的配置文件修改\"></a>1. 部署grafana的配置文件修改</h1><p>因为要采用发送邮件的方式通知告警内容所以，在部署grafana时要先配置好SMTP &#x2F; Emailing的内容：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[smtp]</span><br><span class=\"line\">enabled = true # 开启smtp</span><br><span class=\"line\">host = smtp.mxhichina.com:465  #设置邮箱服务器地址</span><br><span class=\"line\">user = test@test.com  #设置邮箱用户</span><br><span class=\"line\">password = test123456 #设置邮箱密码或授权码</span><br><span class=\"line\">from_address = test@test.com #设置邮箱发送方地址</span><br><span class=\"line\">from_name = Grafana #设置邮箱发送name</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-配置contact-points-告警通道\"><a href=\"#2-配置contact-points-告警通道\" class=\"headerlink\" title=\"2. 配置contact points(告警通道)\"></a>2. 配置contact points(告警通道)</h1><p>使用contact points定义在告警发生时如何通知联系人。包括创建message template和contact points。</p>\n<h2 id=\"2-1-创建message-template-消息模板\"><a href=\"#2-1-创建message-template-消息模板\" class=\"headerlink\" title=\"2.1 创建message template(消息模板)\"></a>2.1 创建message template(消息模板)</h2><p>grafana的消息模板基于go语言的模板系统。如下模板数据表列出了可用于模板的变量</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Type</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Receiver</td>\n<td>string</td>\n<td>Name of the contact point that the notification is being sent to.</td>\n</tr>\n<tr>\n<td>Status</td>\n<td>string</td>\n<td><code>firing</code> if at least one alert is firing, otherwise <code>resolved</code>.</td>\n</tr>\n<tr>\n<td>Alerts</td>\n<td>Alert</td>\n<td>List of alert objects that are included in this notification (see below).</td>\n</tr>\n<tr>\n<td>GroupLabels</td>\n<td>KeyValue</td>\n<td>Labels these alerts were grouped by.</td>\n</tr>\n<tr>\n<td>CommonLabels</td>\n<td>KeyValue</td>\n<td>Labels common to all the alerts included in this notification.</td>\n</tr>\n<tr>\n<td>CommonAnnotations</td>\n<td>KeyValue</td>\n<td>Annotations common to all the alerts included in this notification.</td>\n</tr>\n<tr>\n<td>ExternalURL</td>\n<td>string</td>\n<td>Back link to the Grafana that sent the notification. If using external Alertmanager, back link to this Alertmanager.</td>\n</tr>\n</tbody></table>\n<p>Alerts类型是一个过滤告警的函数：</p>\n<ul>\n<li><code>Alerts.Firing</code> returns a list of firing alerts.</li>\n<li><code>Alerts.Resolved</code> returns a list of resolved alerts.</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-message-template.png\" alt=\"template\"></p>\n<p>define用来设置模板名，是可选的，如果不设置默认采用Template name,最佳实践时与Template name 保持一致。</p>\n<h2 id=\"2-2-创建-contact-point\"><a href=\"#2-2-创建-contact-point\" class=\"headerlink\" title=\"2.2 创建 contact point\"></a>2.2 创建 contact point</h2><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-contact-point.png\" alt=\"point\"></p>\n<p>创建name和不同类型的contact，包括邮箱，钉钉等，同一个name下可以添加多个contact。详细说一下邮箱类型的tact：</p>\n<ul>\n<li><p>Addresses: 接收通知的邮件地址，可以写多个，用英文分号（;)隔开。</p>\n</li>\n<li><p>Single email: 勾选表示发送一个邮件给所有的接受者。</p>\n</li>\n<li><p>message: 可以通过模板变量引用前面创建的模板：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;template &quot;alert message&quot; .&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Disable resloved message: 是否关闭告警解决通知。</p>\n</li>\n</ul>\n<h1 id=\"3-创建通知策略（Notification-policies）\"><a href=\"#3-创建通知策略（Notification-policies）\" class=\"headerlink\" title=\"3. 创建通知策略（Notification policies）\"></a>3. 创建通知策略（Notification policies）</h1><p>通知策略通过label配置告警，通知指定 contact point设置接收告警通知的对象。</p>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/n-p.png\" alt=\"np\"></p>\n<ul>\n<li><p>matching labels： 添加指定的匹配label用于匹配alerts。</p>\n</li>\n<li><p>contact point: 设置创建好的指定的contact point.</p>\n</li>\n<li><p>Continue matching subsequent sibling nodes: 是否继续匹配嵌套策略。</p>\n</li>\n<li><p>Override grouping：是一种告警策略设置，可用于覆盖默认的告警分组工作方式。默认情况下，Grafana根据告警规则的标签对告警进行分组。但是，对于某些特殊情况，用户可能希望以不同的方式进行告警分组，这时就可以使用Override grouping来实现。</p>\n<p>使用Override grouping，用户可以通过自定义指标和筛选条件来定义告警的分组方式。这样可以根据特定的业务需求，将相关的告警归为一组，便于在仪表盘中统一管理和查看。</p>\n<p>Override grouping的设置涉及以下几个重要的概念：</p>\n<ol>\n<li>可聚合的字段：定义用于分组的字段，可以是任意的标签或指标。</li>\n<li>聚合器：确定了要使用哪种方法来聚合分组，如平均值、最大值、最小值等。</li>\n<li>时间范围：告警分组的时间范围，可以是一个固定的时间段或相对于当前时间的一段时间。</li>\n</ol>\n<p>用户可以根据具体情况选择合适的聚合字段、聚合器和时间范围来定义告警的分组方式。通过Override grouping，用户可以更加灵活地管理和控制告警的分组行为，从而更好地满足业务需求。</p>\n</li>\n<li><p>Override general timings（覆盖一般定时）：用来覆盖通用的重复和间隔定时。</p>\n<p>具体来说，Grafana的告警策略中，可以设置一个重复间隔时间（Repeat interval），用于确定告警规则检查条件的重复间隔。默认情况下，这个间隔会使用Grafana的全局设置。</p>\n<p>然而，有时候我们希望针对特定的告警规则使用不同的重复间隔时间，这就可以使用Override general timings（覆盖一般定时）来实现。通过勾选此选项，并设置相应的重复间隔时间，可以覆盖全局设置，使特定的告警规则使用不同的重复间隔时间。</p>\n<p>这样做的好处是，可以根据特定的告警规则的需求，灵活地定义重复间隔时间，以更加精确和准确地监控和警告系统的状态变化。这对于保证系统的稳定性、性能和安全性非常有帮助。</p>\n<ol>\n<li><p>Group wait: 为传入警报创建的新组发送初始通知之前的等待时间。</p>\n</li>\n<li><p>Group interval: 发送第一个通知后为该组发送一批新警报的等待时间。</p>\n</li>\n<li><p>Repeat interval: 成功发送警报后重新发送警报的等待时间。</p>\n</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"4-创建告警规则（rule\"><a href=\"#4-创建告警规则（rule\" class=\"headerlink\" title=\"4. 创建告警规则（rule)\"></a>4. 创建告警规则（rule)</h1><p>rule有三种类型：</p>\n<ul>\n<li><p>Cortex or Loki managed alerting rule：创建由Cortex或者Loki管理的rule；需要对Prometheus或者其他数据源有读写权限。</p>\n<p>Cortex和Loki都是与Grafana密切相关的工具。</p>\n<p>Cortex是一个可扩展、多租户、分布式的时间序列数据库。它能够接收和存储大规模的指标数据，并提供高速查询、聚合和处理数据的能力。Cortex的设计目标是能够处理海量的时间序列数据，并且具有可水平扩展性和高可用性。Cortex允许用户通过内置的查询语言PromQL来查询和分析指标数据，并支持数据的可视化和报表功能。Cortex还提供了横向扩展的能力，可以轻松地增加存储容量和查询吞吐量。因此，Cortex适用于大规模监控系统中需要存储和查询大量指标数据的场景。</p>\n<p>Loki是一个用于日志聚合和存储的系统。它可以接收多个来源的日志数据，并将它们存储为可搜索和可查询的格式。与传统的日志存储系统相比，Loki采用了一种高效的存储和索引方法，可以充分利用现代存储技术和硬件，以提供更高的性能和可扩展性。Loki支持使用标准的日志查询语言PromQL来查询和分析日志数据，并且与Cortex集成，可以实现和指标数据的混合查询和分析。此外，Loki还提供了强大的数据可视化和报表功能，可以方便地展示和监控系统的日志信息。</p>\n<p>综上所述，Cortex和Loki是Grafana监控和可视化平台的两个重要组成部分。Cortex用于存储和查询大规模的指标数据，而Loki则用于存储和查询系统的日志数据。它们都具有高性能、可扩展性和易于使用的特点，能够满足大规模监控系统中对指标和日志数据的存储、查询和分析需求。</p>\n</li>\n<li><p>Cortex or Loki managed recording rule：创建recording类型的rule。</p>\n</li>\n<li><p>Grafana managed alerting rule：创建grafana管理的告警规则，我们主要介绍这个类型的规则。</p>\n</li>\n</ul>\n<h2 id=\"4-2-Grafana-managed-alerting-rule\"><a href=\"#4-2-Grafana-managed-alerting-rule\" class=\"headerlink\" title=\"4.2 Grafana managed alerting rule\"></a>4.2 Grafana managed alerting rule</h2><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-1.png\"></p>\n<ul>\n<li><p>rule name: 告警规则名。</p>\n</li>\n<li><p>rule type: 告警规则类型。</p>\n</li>\n<li><p>Folder: 选择所属的Folder。</p>\n</li>\n<li><p>创建告警规则语句：</p>\n<ol>\n<li><p>选择数据源为Prometheus</p>\n</li>\n<li><p>查询展示的最近10分钟的数据。</p>\n</li>\n<li><p>Metrics browser: 设定数据查询的语句使用PromQL语法。</p>\n</li>\n<li><p>Legend: 根据查询出的数据变量设置显示指标名。</p>\n</li>\n<li><p>Min step: 最小步长表示图形里每两个点的最小数据间隔是多少，例如：这里我设置了 200，那表示图形上每隔 200 个单位才会有一个点。</p>\n</li>\n<li><p>Resolution： 这表示其数据精度是怎样的，是 1 比 1 的精度，还是原有的 1&#x2F;2，还是 1&#x2F;3 等等。如果是 1&#x2F;2 的话，那么就是原本 1 个单位显示一个点，现在 2 个单位合并起来显示成一个点了，那么其精度就变低了。</p>\n</li>\n<li><p>Format： 表示你的数据格式是什么，这里有：Time series、Table、Heap Map 三个选项。Time series 表示是时间序列数据，即随着时间的流动有源源不断的数据。Table 表示是一个表格数据。Heap Map 表示是热力图数据。</p>\n</li>\n<li><p>instant: 勾选时查询只在指定的单个时间点上执行，这对于需要聚合或对单个时间点数据感兴趣的场景非常有用。面板的时间选择器将被禁用，因为查询仅在一个固定时间点上执行。不勾选时：查询将返回一个时间范围内的数据，这对于需要在一段时间内进行数据分析或比较的情况非常有用。面板的时间选择器将启用，可以选择查询的时间范围。</p>\n</li>\n</ol>\n<p>  <img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-2.png\"></p>\n<p>  创建Expression（表达式）：</p>\n<ul>\n<li><p>classic condition:</p>\n<ol>\n<li><p><code>avg()</code>: 用于计算一段时间内的平均值。适用于告警需要基于平均值的场景。例如，如果需要在CPU平均负载超过阈值时触发告警，可以使用<code>avg()</code>函数。</p>\n</li>\n<li><p><code>last()</code>: 用于获取时间段内最后一个数据点的值。适用于告警需要基于最后一个数据点的场景。例如，如果需要在最后一个数据点超过阈值时触发告警，可以使用<code>last()</code>函数。</p>\n</li>\n<li><p><code>max()</code>: 用于计算一段时间内的最大值。适用于告警需要基于最大值的场景。例如，如果需要在CPU负载的最大值超过阈值时触发告警，可以使用<code>max()</code>函数。</p>\n</li>\n<li><p><code>min()</code>: 用于计算一段时间内的最小值。适用于告警需要基于最小值的场景。例如，如果需要在CPU负载的最小值低于阈值时触发告警，可以使用<code>min()</code>函数。</p>\n</li>\n<li><p><code>sum()</code>: 用于计算一段时间内的总和。适用于告警需要基于总和的场景。例如，如果需要在一段时间内的请求数总和超过阈值时触发告警，可以使用<code>sum()</code>函数。</p>\n</li>\n<li><p><code>count()</code>: 用于计算一段时间内的数据点数量。适用于告警需要基于数据点数量的场景。例如，如果需要在一段时间内的请求数量超过阈值时触发告警，可以使用<code>count()</code>函数。</p>\n</li>\n</ol>\n<p>Define alert conditions: 定义告警状态：</p>\n<ul>\n<li><p>condition: 选择基于哪个query或者表达式进行告警。</p>\n</li>\n<li><p>Evaluate: 设置多久评估一次告警条件，</p>\n</li>\n<li><p>For： 满足条件持续多久触发告警，改变告警状态到firing.</p>\n</li>\n<li><p>Configure no data and error handling: 设定无数错和错误处理：</p>\n<table>\n<thead>\n<tr>\n<th>No Data Option</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No Data</td>\n<td>Create a new alert <code>DatasourceNoData</code> with the name and UID of the alert rule, and UID of the datasource that returned no data as labels.</td>\n</tr>\n<tr>\n<td>Alerting</td>\n<td>Set alert rule state to <code>Alerting</code>.</td>\n</tr>\n<tr>\n<td>Ok</td>\n<td>Set alert rule state to <code>Normal</code>.</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th>Error or timeout option</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Alerting</td>\n<td>Set alert rule state to <code>Alerting</code></td>\n</tr>\n<tr>\n<td>OK</td>\n<td>Set alert rule state to <code>Normal</code></td>\n</tr>\n<tr>\n<td>Error</td>\n<td>Create a new alert <code>DatasourceError</code> with the name and UID of the alert rule, and UID of the datasource that returned no data as labels.</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<p>Add details for your alert： 添加其他额外的alert信息。</p>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<h1 id=\"1-部署grafana的配置文件修改\"><a href=\"#1-部署grafana的配置文件修改\" class=\"headerlink\" title=\"1. 部署grafana的配置文件修改\"></a>1. 部署grafana的配置文件修改</h1><p>因为要采用发送邮件的方式通知告警内容所以，在部署grafana时要先配置好SMTP &#x2F; Emailing的内容：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[smtp]</span><br><span class=\"line\">enabled = true # 开启smtp</span><br><span class=\"line\">host = smtp.mxhichina.com:465  #设置邮箱服务器地址</span><br><span class=\"line\">user = test@test.com  #设置邮箱用户</span><br><span class=\"line\">password = test123456 #设置邮箱密码或授权码</span><br><span class=\"line\">from_address = test@test.com #设置邮箱发送方地址</span><br><span class=\"line\">from_name = Grafana #设置邮箱发送name</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-配置contact-points-告警通道\"><a href=\"#2-配置contact-points-告警通道\" class=\"headerlink\" title=\"2. 配置contact points(告警通道)\"></a>2. 配置contact points(告警通道)</h1><p>使用contact points定义在告警发生时如何通知联系人。包括创建message template和contact points。</p>\n<h2 id=\"2-1-创建message-template-消息模板\"><a href=\"#2-1-创建message-template-消息模板\" class=\"headerlink\" title=\"2.1 创建message template(消息模板)\"></a>2.1 创建message template(消息模板)</h2><p>grafana的消息模板基于go语言的模板系统。如下模板数据表列出了可用于模板的变量</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Type</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Receiver</td>\n<td>string</td>\n<td>Name of the contact point that the notification is being sent to.</td>\n</tr>\n<tr>\n<td>Status</td>\n<td>string</td>\n<td><code>firing</code> if at least one alert is firing, otherwise <code>resolved</code>.</td>\n</tr>\n<tr>\n<td>Alerts</td>\n<td>Alert</td>\n<td>List of alert objects that are included in this notification (see below).</td>\n</tr>\n<tr>\n<td>GroupLabels</td>\n<td>KeyValue</td>\n<td>Labels these alerts were grouped by.</td>\n</tr>\n<tr>\n<td>CommonLabels</td>\n<td>KeyValue</td>\n<td>Labels common to all the alerts included in this notification.</td>\n</tr>\n<tr>\n<td>CommonAnnotations</td>\n<td>KeyValue</td>\n<td>Annotations common to all the alerts included in this notification.</td>\n</tr>\n<tr>\n<td>ExternalURL</td>\n<td>string</td>\n<td>Back link to the Grafana that sent the notification. If using external Alertmanager, back link to this Alertmanager.</td>\n</tr>\n</tbody></table>\n<p>Alerts类型是一个过滤告警的函数：</p>\n<ul>\n<li><code>Alerts.Firing</code> returns a list of firing alerts.</li>\n<li><code>Alerts.Resolved</code> returns a list of resolved alerts.</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-message-template.png\" alt=\"template\"></p>\n<p>define用来设置模板名，是可选的，如果不设置默认采用Template name,最佳实践时与Template name 保持一致。</p>\n<h2 id=\"2-2-创建-contact-point\"><a href=\"#2-2-创建-contact-point\" class=\"headerlink\" title=\"2.2 创建 contact point\"></a>2.2 创建 contact point</h2><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-contact-point.png\" alt=\"point\"></p>\n<p>创建name和不同类型的contact，包括邮箱，钉钉等，同一个name下可以添加多个contact。详细说一下邮箱类型的tact：</p>\n<ul>\n<li><p>Addresses: 接收通知的邮件地址，可以写多个，用英文分号（;)隔开。</p>\n</li>\n<li><p>Single email: 勾选表示发送一个邮件给所有的接受者。</p>\n</li>\n<li><p>message: 可以通过模板变量引用前面创建的模板：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&#123;template &quot;alert message&quot; .&#125;&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Disable resloved message: 是否关闭告警解决通知。</p>\n</li>\n</ul>\n<h1 id=\"3-创建通知策略（Notification-policies）\"><a href=\"#3-创建通知策略（Notification-policies）\" class=\"headerlink\" title=\"3. 创建通知策略（Notification policies）\"></a>3. 创建通知策略（Notification policies）</h1><p>通知策略通过label配置告警，通知指定 contact point设置接收告警通知的对象。</p>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/n-p.png\" alt=\"np\"></p>\n<ul>\n<li><p>matching labels： 添加指定的匹配label用于匹配alerts。</p>\n</li>\n<li><p>contact point: 设置创建好的指定的contact point.</p>\n</li>\n<li><p>Continue matching subsequent sibling nodes: 是否继续匹配嵌套策略。</p>\n</li>\n<li><p>Override grouping：是一种告警策略设置，可用于覆盖默认的告警分组工作方式。默认情况下，Grafana根据告警规则的标签对告警进行分组。但是，对于某些特殊情况，用户可能希望以不同的方式进行告警分组，这时就可以使用Override grouping来实现。</p>\n<p>使用Override grouping，用户可以通过自定义指标和筛选条件来定义告警的分组方式。这样可以根据特定的业务需求，将相关的告警归为一组，便于在仪表盘中统一管理和查看。</p>\n<p>Override grouping的设置涉及以下几个重要的概念：</p>\n<ol>\n<li>可聚合的字段：定义用于分组的字段，可以是任意的标签或指标。</li>\n<li>聚合器：确定了要使用哪种方法来聚合分组，如平均值、最大值、最小值等。</li>\n<li>时间范围：告警分组的时间范围，可以是一个固定的时间段或相对于当前时间的一段时间。</li>\n</ol>\n<p>用户可以根据具体情况选择合适的聚合字段、聚合器和时间范围来定义告警的分组方式。通过Override grouping，用户可以更加灵活地管理和控制告警的分组行为，从而更好地满足业务需求。</p>\n</li>\n<li><p>Override general timings（覆盖一般定时）：用来覆盖通用的重复和间隔定时。</p>\n<p>具体来说，Grafana的告警策略中，可以设置一个重复间隔时间（Repeat interval），用于确定告警规则检查条件的重复间隔。默认情况下，这个间隔会使用Grafana的全局设置。</p>\n<p>然而，有时候我们希望针对特定的告警规则使用不同的重复间隔时间，这就可以使用Override general timings（覆盖一般定时）来实现。通过勾选此选项，并设置相应的重复间隔时间，可以覆盖全局设置，使特定的告警规则使用不同的重复间隔时间。</p>\n<p>这样做的好处是，可以根据特定的告警规则的需求，灵活地定义重复间隔时间，以更加精确和准确地监控和警告系统的状态变化。这对于保证系统的稳定性、性能和安全性非常有帮助。</p>\n<ol>\n<li><p>Group wait: 为传入警报创建的新组发送初始通知之前的等待时间。</p>\n</li>\n<li><p>Group interval: 发送第一个通知后为该组发送一批新警报的等待时间。</p>\n</li>\n<li><p>Repeat interval: 成功发送警报后重新发送警报的等待时间。</p>\n</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"4-创建告警规则（rule\"><a href=\"#4-创建告警规则（rule\" class=\"headerlink\" title=\"4. 创建告警规则（rule)\"></a>4. 创建告警规则（rule)</h1><p>rule有三种类型：</p>\n<ul>\n<li><p>Cortex or Loki managed alerting rule：创建由Cortex或者Loki管理的rule；需要对Prometheus或者其他数据源有读写权限。</p>\n<p>Cortex和Loki都是与Grafana密切相关的工具。</p>\n<p>Cortex是一个可扩展、多租户、分布式的时间序列数据库。它能够接收和存储大规模的指标数据，并提供高速查询、聚合和处理数据的能力。Cortex的设计目标是能够处理海量的时间序列数据，并且具有可水平扩展性和高可用性。Cortex允许用户通过内置的查询语言PromQL来查询和分析指标数据，并支持数据的可视化和报表功能。Cortex还提供了横向扩展的能力，可以轻松地增加存储容量和查询吞吐量。因此，Cortex适用于大规模监控系统中需要存储和查询大量指标数据的场景。</p>\n<p>Loki是一个用于日志聚合和存储的系统。它可以接收多个来源的日志数据，并将它们存储为可搜索和可查询的格式。与传统的日志存储系统相比，Loki采用了一种高效的存储和索引方法，可以充分利用现代存储技术和硬件，以提供更高的性能和可扩展性。Loki支持使用标准的日志查询语言PromQL来查询和分析日志数据，并且与Cortex集成，可以实现和指标数据的混合查询和分析。此外，Loki还提供了强大的数据可视化和报表功能，可以方便地展示和监控系统的日志信息。</p>\n<p>综上所述，Cortex和Loki是Grafana监控和可视化平台的两个重要组成部分。Cortex用于存储和查询大规模的指标数据，而Loki则用于存储和查询系统的日志数据。它们都具有高性能、可扩展性和易于使用的特点，能够满足大规模监控系统中对指标和日志数据的存储、查询和分析需求。</p>\n</li>\n<li><p>Cortex or Loki managed recording rule：创建recording类型的rule。</p>\n</li>\n<li><p>Grafana managed alerting rule：创建grafana管理的告警规则，我们主要介绍这个类型的规则。</p>\n</li>\n</ul>\n<h2 id=\"4-2-Grafana-managed-alerting-rule\"><a href=\"#4-2-Grafana-managed-alerting-rule\" class=\"headerlink\" title=\"4.2 Grafana managed alerting rule\"></a>4.2 Grafana managed alerting rule</h2><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-1.png\"></p>\n<ul>\n<li><p>rule name: 告警规则名。</p>\n</li>\n<li><p>rule type: 告警规则类型。</p>\n</li>\n<li><p>Folder: 选择所属的Folder。</p>\n</li>\n<li><p>创建告警规则语句：</p>\n<ol>\n<li><p>选择数据源为Prometheus</p>\n</li>\n<li><p>查询展示的最近10分钟的数据。</p>\n</li>\n<li><p>Metrics browser: 设定数据查询的语句使用PromQL语法。</p>\n</li>\n<li><p>Legend: 根据查询出的数据变量设置显示指标名。</p>\n</li>\n<li><p>Min step: 最小步长表示图形里每两个点的最小数据间隔是多少，例如：这里我设置了 200，那表示图形上每隔 200 个单位才会有一个点。</p>\n</li>\n<li><p>Resolution： 这表示其数据精度是怎样的，是 1 比 1 的精度，还是原有的 1&#x2F;2，还是 1&#x2F;3 等等。如果是 1&#x2F;2 的话，那么就是原本 1 个单位显示一个点，现在 2 个单位合并起来显示成一个点了，那么其精度就变低了。</p>\n</li>\n<li><p>Format： 表示你的数据格式是什么，这里有：Time series、Table、Heap Map 三个选项。Time series 表示是时间序列数据，即随着时间的流动有源源不断的数据。Table 表示是一个表格数据。Heap Map 表示是热力图数据。</p>\n</li>\n<li><p>instant: 勾选时查询只在指定的单个时间点上执行，这对于需要聚合或对单个时间点数据感兴趣的场景非常有用。面板的时间选择器将被禁用，因为查询仅在一个固定时间点上执行。不勾选时：查询将返回一个时间范围内的数据，这对于需要在一段时间内进行数据分析或比较的情况非常有用。面板的时间选择器将启用，可以选择查询的时间范围。</p>\n</li>\n</ol>\n<p>  <img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/grafana/create-rule-2.png\"></p>\n<p>  创建Expression（表达式）：</p>\n<ul>\n<li><p>classic condition:</p>\n<ol>\n<li><p><code>avg()</code>: 用于计算一段时间内的平均值。适用于告警需要基于平均值的场景。例如，如果需要在CPU平均负载超过阈值时触发告警，可以使用<code>avg()</code>函数。</p>\n</li>\n<li><p><code>last()</code>: 用于获取时间段内最后一个数据点的值。适用于告警需要基于最后一个数据点的场景。例如，如果需要在最后一个数据点超过阈值时触发告警，可以使用<code>last()</code>函数。</p>\n</li>\n<li><p><code>max()</code>: 用于计算一段时间内的最大值。适用于告警需要基于最大值的场景。例如，如果需要在CPU负载的最大值超过阈值时触发告警，可以使用<code>max()</code>函数。</p>\n</li>\n<li><p><code>min()</code>: 用于计算一段时间内的最小值。适用于告警需要基于最小值的场景。例如，如果需要在CPU负载的最小值低于阈值时触发告警，可以使用<code>min()</code>函数。</p>\n</li>\n<li><p><code>sum()</code>: 用于计算一段时间内的总和。适用于告警需要基于总和的场景。例如，如果需要在一段时间内的请求数总和超过阈值时触发告警，可以使用<code>sum()</code>函数。</p>\n</li>\n<li><p><code>count()</code>: 用于计算一段时间内的数据点数量。适用于告警需要基于数据点数量的场景。例如，如果需要在一段时间内的请求数量超过阈值时触发告警，可以使用<code>count()</code>函数。</p>\n</li>\n</ol>\n<p>Define alert conditions: 定义告警状态：</p>\n<ul>\n<li><p>condition: 选择基于哪个query或者表达式进行告警。</p>\n</li>\n<li><p>Evaluate: 设置多久评估一次告警条件，</p>\n</li>\n<li><p>For： 满足条件持续多久触发告警，改变告警状态到firing.</p>\n</li>\n<li><p>Configure no data and error handling: 设定无数错和错误处理：</p>\n<table>\n<thead>\n<tr>\n<th>No Data Option</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No Data</td>\n<td>Create a new alert <code>DatasourceNoData</code> with the name and UID of the alert rule, and UID of the datasource that returned no data as labels.</td>\n</tr>\n<tr>\n<td>Alerting</td>\n<td>Set alert rule state to <code>Alerting</code>.</td>\n</tr>\n<tr>\n<td>Ok</td>\n<td>Set alert rule state to <code>Normal</code>.</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th>Error or timeout option</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Alerting</td>\n<td>Set alert rule state to <code>Alerting</code></td>\n</tr>\n<tr>\n<td>OK</td>\n<td>Set alert rule state to <code>Normal</code></td>\n</tr>\n<tr>\n<td>Error</td>\n<td>Create a new alert <code>DatasourceError</code> with the name and UID of the alert rule, and UID of the datasource that returned no data as labels.</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<p>Add details for your alert： 添加其他额外的alert信息。</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"网关技术详解及常见网关对比","date":"2023-11-02T03:01:02.000Z","_content":"原文地址: https://blog.csdn.net/huangjinjin520/article/details/126863371\n## 什么是网关\n网关，很多地方将网关比如成门， 没什么问题， 但是需要区分网关与网桥的区别，\n\n网桥 工作在数据链路层，在不同或相同类型的LAN之间存储并转发数据帧，必要时进行链路层上的协议转换。可连接两个或多个网络，在其中传送信息包。\n\n网关 是一个大概念，不具体特指一类产品，只要连接两个不同的网络都可以叫网关，网桥一般只转发信息，而网关可能进行包装。\n## 网关通俗理解\n根据网关的特性，举个例子:\n\n假如你要去找集团老板(这儿只是举个例子)， 大家都知道老板肯定不是谁想见就能见的， 也怕坏人嘛， 那么你去老板所在的办公楼，假如是集团总部， 大楼这个门就充当了网关的角色， 大门一般都有看门员 ，看门员会做哪些事情呢?\n\n首先所有想见老板的人肯定都得从这个门进(统一入口 )， 这个门相当于将办公室和外界隔离了，主要为了保护里面的安全以及正常工作， 来到这个门之后， 门卫肯定会让你出示相关证件(鉴权检验 )， 意思就是判断你要见老板这个请求是否合理， 如果不合理直接就拒绝了， 让你回家等消息 ， 如果鉴权之后， 发现你找老板其实只是为了和他谈谈两元店的生意， 门卫会跟你说这个用不着找老板， 你去集团投资部就行了(动态路由 ， 将请求路由到不同的后端集群中)， 此时会对你进行一些包装 ，例如给你出具一个访问证类似的，然后告诉你路该怎么走，等等。\n\n你看看，网关的作用是不是就是这三个， 最终目的就是减少你与集团的耦合，具体到计算机上就是减少客户端与服务端的耦合，如果没有网关意味着所有请求都会直接调用服务器上的资源，这样耦合太强了，服务器出了问题，客户端会直接报错， 例如老板换工作的地方了，如果没有网关你直接去原来的地方找， 肯定会被告知老板不在这儿。\n## 为什么需要网关\n当使用单体应用程序架构时，客户端（Web 或移动端）通过向后端应用程序发起一次 REST 调用来获取数据。负载均衡器将请求路由给 N 个相同的应用程序实例中的一个。然后应用程序会查询各种数据库表，并将响应返回给客户端。微服务架构下，单体应用被切割成多个微服务，如果将所有的微服务直接对外暴露，势必会出现安全方面的各种问题，另外内外耦合严重。\n\n客户端可以直接向每个微服务发送请求，其问题主要如下：\n\n客户端需求和每个微服务暴露的细粒度 API 不匹配。\n\n部分服务使用的协议不是Web友好协议。可能使用 Thrift 二进制 RPC，也可能使用 AMQP 消息传递协议。\n\n微服务难以重构。如果合并两个服务，或者将一个服务拆分成两个或更多服务，这类重构就非常困难了。\n\n服务端的各个服务直接暴露给客户端调用势必会引起各种问题。同时，服务端的各个服务可扩展和伸缩性很差。API 网关是微服务架构中的基础组件，位于接入层之下和业务服务层之上，如前所述的这些功能适合在 API 网关实现。\n\n## 网关与服务器集群\n回到我们服务器上，下面图介绍了网关(Gateway)作用，可知 Gateway 方式下的架构，可以细到为每一个服务的实例配置一个自己的 Gateway，也可以粗到为一组服务配置一个，甚至可以粗到为整个架构配置一个接入的 Gateway。于是，整个系统架构的复杂度就会变得简单可控起来。\n\n![Alt text](image-104.png)\n\n这张图展示了一个多层 Gateway 架构，其中有一个总的 Gateway 接入所有的流量(流量网关 )，并分发给不同的子系统，还有第二级 Gateway 用于做各个子系统的接入 Gateway(业务网关 )。可以看到，网关所管理的服务粒度可粗可细。通过网关，我们可以把分布式架构组织成一个星型架构，由网络对服务的请求进行路由和分发。下面来聊聊好的网关应该具备哪些功能，也就是网关设计模式。\n## 网关设计思路\n一个网关需要有以下的功能:\n\n### 1. 请求路由\n网关一定要有请求路由的功能。这样一来，对于调用端来说，也是一件非常方便的事情。因为调用端不需要知道自己需要用到的其它服务的地址，全部统一地交给 Gateway 来处理。\n\n### 2. 服务注册\n为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些 API 接口。比如，HTTP 的 Restful 请求，可以注册相应 API 的 URI、方法、HTTP 头。这样，Gateway 就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。\n\n### 3. 负载均衡\n因为一个网关可以接收多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单点就是直接 Round-Robin 轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到 session 粘连。\n\n### 4. 弹力设计\n网关还可以把弹力设计中的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去。这样，同样可以像 Service Mesh 那样，让应用服务只关心自己的业务逻辑（或是说数据面上的事）而不是控制逻辑（控制面）。\n\n### 5. 安全方面\nSSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。错误处理越靠前的位置就是越好，所以，网关可以做到一个全站的接入组件来对后端的服务进行保护。当然，网关还可以做更多更有趣的事情，比如：灰度发布、API聚合、API编排。\n\n#### 灰度发布\n\n网关完全可以做到对相同服务不同版本的实例进行导流，还可以收集相关的数据。这样对于软件质量的提升，甚至产品试错都有非常积极的意义。\n\n#### API 聚合\n\n使用网关可以将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。于是，我们可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）。\n\n#### API 编排\n\n同样在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。\n## 网关设计重点\n网关设计重点主要是三个， 高性能、高可用、高扩展:\n\n### 1. 高性能\n在技术设计上，网关不应该也不能成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务一定要使用异步非阻塞的 I/O 来确保后端延迟不会导致应用程序中出现性能问题。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I/O Completion Port 的异步 IO 模型，Java 下如 Netty、Spring Reactor 的 NIO 框架。\n\n### 2. 高可用\n因为所有的流量或调用经过网关，所以网关必须成为一个高可用的技术组件，它的稳定直接关系到了所有服务的稳定。网关如果没有设计，就会成变一个单点故障。因此，一个好的网关至少要做到以下几点。\n\n集群化 。网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。\n\n服务化 。网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置。\n\n持续化 。比如重启，就是像 Nginx 那样优雅地重启。有一个主管请求分发的主进程。当我们需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。\n\n### 3. 高扩展\n因为网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。而我们都知道，业务逻辑是多变和不确定的。比如，需要在网关上加入一些和业务相关的东西。因此，一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。\n\n另外，在运维方面 ，网关应该有以下几个设计原则。\n\n* 业务松耦合，协议紧耦合 。在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。\n\n* 应用监视，提供分析数据 。网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用 Tracing ID 实施分布式链路跟踪，并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。\n\n* 用弹力设计保护后端服务 。网关上一定要实现熔断、限流、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据。你可以考虑一下这样的设计。\n\n* DevOps 。因为网关这个组件太关键了，所以需要 DevOps 这样的东西，将其发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。\n\n## 网关设计注意事项\n1. 不要在网关中的代码里内置聚合后端服务的功能，而应考虑将聚合服务放在网关核心代码之外。可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。\n\n2. 网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。这里多说一句，网关处理的静态内容应该靠近用户（应该放到 CDN 上），而网关和此时的动态服务应该靠近后端服务。\n\n3. 网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过 DNS 轮询的方式实现，要么通过 CDN 来做流量调度，或者通过更为底层的性能更高的负载均衡设备。\n\n4. 对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都去查一下相关的服务所在的地方。当然，如果你的系统不复杂，可以考虑把服务发现的功能直接集成进网关中。\n\n5. 为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。\n\n另外，因为网关是为用户请求和后端服务的桥接装置，所以需要考虑一些安全方面的事宜。具体如下：\n\n* 加密数据 。可以把 SSL 相关的证书放到网关上，由网关做统一的 SSL 传输管理。\n\n* 校验用户的请求 。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。但是，我们需要权衡一下，网关是否需要校验用户的输入。因为这样一来，网关就需要从只关心协议头，到需要关心协议体。而协议体中的东西一方面不像协议头是标准的，另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能。对此，我想说的是，看具体需求，一方面如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。\n\n* 检测异常访问 。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；还比如，同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击。\n\n## 流量网关\n流量网关，顾名思义就是控制流量进入集群的网关，有很多工作需要在这一步做，对于一个服务集群，势必有很多非法的请求或者无效的请求，这时候要将请求拒之门外，降低集群的流量压力。\n![Alt text](image-105.png)\n定义全局性的、跟具体的后端业务应用和服务完全无关的策略网关就是上图所示的架构模型——流量网关。流量网关通常只专注于全局的Api管理策略，比如全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等，有点类似防火墙。Kong 就是典型的流量网关。\n\n下面是kong的架构图，来自官网：https://konghq.com\n![Alt text](image-106.png)\n这里需要补充一点的是，业务网关一般部署在流量网关之后、业务系统之前，比流量网关更靠近业务系统。通常API网指的是业务网关。有时候我们也会模糊流量网关和业务网关，让一个网关承担所有的工作，所以这两者之间并没有严格的界线。\n## 业务网关\n当一个单体应用被拆分成许许多多的微服务应用后，也带来了一些问题。一些与业务非强相关的功能，比如权限控制、日志输出、数据加密、熔断限流等，每个微服务应用都需要，因此存在着大量重复的代码实现。而且由于系统的迭代、人员的更替，各个微服务中这些功能的实现细节出现了较大的差异，导致维护成本变高。另一方面，原先单体应用下非常容易做的接口管理，在服务拆分后没有了一个集中管理的地方，无法统计已存在哪些接口、接口定义是什么、运行状态如何。\n\n网关就是为了解决上述问题。作为微服务体系中的核心基础设施，一般需要具备接口管理、协议适配、熔断限流、安全防护等功能，各种开源的网关产品（比如 zuul）都提供了优秀高可扩展性的架构、可以很方便的实现我们需要的一些功能、比如鉴权、日志监控、熔断限流等。\n\n与流量网关相对应的就是业务网关，业务网关更靠近我们的业务，也就是与服务器应用层打交道，那么有很多应用层需要考虑的事情就可以依托业务网关，例如在线程模型、协议适配、熔断限流，服务编排等。下面看看业务网关体系结构:\n![Alt text](image-107.png)\n从这个途中可以看出业务网关主要职责以及所做的事情， 目前业务网关比较成熟的 API 网关框架产品有三个 分别是:Zuul1、Zuul2 和 SpringCloud Gateway， 后面再进行对比。\n## 常见网关对比\n既然对比，就先宏观上对各种网关有一个了解，后面再挑一些常用的或者说应用广泛的详细了解。\n\n目前常见的开源网关大致上按照语言分类有如下几类：\n\nNginx+lua ：OpenResty、Kong、Orange、Abtesting gateway 等\n\nJava ：Zuul/Zuul2、Spring Cloud Gateway、Kaazing KWG、gravitee、Dromara soul 等\n\nGo ：Janus、fagongzi、Grpc-gateway\n\nDotnet ：Ocelot\n\nNodeJS ：Express Gateway、Micro Gateway\n\n按照使用数量、成熟度等来划分，主流的有 5个：\n\nOpenResty\n\nKong\n\nZuul、Zuul2\n\nSpring Cloud Gateway\n\n### 1. OpenResty\nOpenResty是一个流量网关，根据前面对流量网关的介绍就可以知道流量网关的指责。\n\nOpenResty基于 Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。\n\n通过揉和众多设计良好的 Nginx 模块，OpenResty 有效地把 Nginx 服务器转变为一个强大的 Web 应用服务器，基于它开发人员可以使用 Lua 编程语言对 Nginx 核心以及现有的各种 Nginx C 模块进行脚本编程，构建出可以处理一万以上并发请求的极端高性能的 Web 应用\n\nOpenResty 最早是顺应 OpenAPI 的潮流做的，所以 Open 取自“开放”之意，而Resty便是 REST 风格的意思。虽然后来也可以基于 ngx_openresty 实现任何形式的 web service 或者传统的 web 应用。\n\n也就是说 Nginx 不再是一个简单的静态网页服务器，也不再是一个简单的反向代理了。第二代的 openresty 致力于通过一系列 nginx 模块，把nginx扩展为全功能的 web 应用服务器。\n\nngx_openresty 是用户驱动的项目，后来也有不少国内用户的参与，从 openresty.org 的点击量分布上看，国内和国外的点击量基本持平。\n\nngx_openresty 目前有两大应用目标：\n\n通用目的的 web 应用服务器。在这个目标下，现有的 web 应用技术都可以算是和 OpenResty 或多或少有些类似，比如 Nodejs， PHP 等等。ngx_openresty 的性能（包括内存使用和 CPU 效率）算是最大的卖点之一。\n\nNginx 的脚本扩展编程，用于构建灵活的 Web 应用网关和 Web 应用防火墙。有些类似的是 NetScaler。其优势在于 Lua 编程带来的巨大灵活性。\n\n### 2. Kong\nKong基于OpenResty开发，也是流量层网关， 是一个云原生、快速、可扩展、分布式的Api 网关。继承了OpenResty的高性能、易扩展性等特点。Kong通过简单的增加机器节点，可以很容易的水平扩展。同时功能插件化，可通过插件来扩展其能力。而且在任何基础架构上都可以运行。具有以下特性：\n\n提供了多样化的认证层来保护Api。\n\n可对出入流量进行管制。\n\n提供了可视化的流量检查、监视分析Api。\n\n能够及时的转换请求和相应。\n\n提供log解决方案\n\n可通过api调用Serverless 函数。\n\n#### Kong解决了什么问题\n\n当我们决定对应用进行微服务改造时，应用客户端如何与微服务交互的问题也随之而来，毕竟服务数量的增加会直接导致部署授权、负载均衡、通信管理、分析和改变的难度增加。\n\n面对以上问题，API GATEWAY是一个不错的解决方案，其所提供的访问限制、安全、流量控制、分析监控、日志、请求转发、合成和协议转换功能，可以解放开发者去把精力集中在具体逻辑的代码，而不是把时间花费在考虑如何解决应用和其他微服务链接的问题上。\n\n图片来自Kong官网:\n\n![Alt text](image-108.png)\n可以看到Kong解决的问题。专注于全局的Api管理策略，全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等。\n#### Kong的优点以及性能\n\n在众多 API GATEWAY 框架中，Mashape 开源的高性能高可用API网关和API服务管理层——KONG（基于 NGINX+Lua）特点尤为突出，它可以通过插件扩展已有功能，这些插件（使用 lua 编写）在API请求响应循环的生命周期中被执行。于此同时，KONG本身提供包括 HTTP 基本认证、密钥认证、CORS、TCP、UDP、文件日志、API请求限流、请求转发及 NGINX 监控等基本功能。目前，Kong 在 Mashape 管理了超过 15，000 个 API，为 200，000 开发者提供了每月数十亿的请求支持。\n\n#### Kong架构\n\nKong提供一些列的服务，这就不得不谈谈内部的架构:\n![Alt text](image-109.png)\n首先最底层是基于Nginx， Nginx是高性能的基础层， 一个良好的负载均衡、反向代理器，然后在此基础上增加Lua脚本库，形成了OpenResty，拦截请求， 响应生命周期，可以通过Lua编写脚本，所以插件比较丰富。\n\n关于Kong的一些插件库以及如何配置，可以参考简书:开源API网关系统（Kong教程）入门到精通：https://www.jianshu.com/p/a68e45bcadb6\n\n### 3. Zuul1.0\nZuul是所有从设备和web站点到Netflix流媒体应用程序后端请求的前门。作为一个边缘服务应用程序，Zuul被构建来支持动态路由、监视、弹性和安全性。它还可以根据需要将请求路由到多个Amazon自动伸缩组。\n\nZuul使用了一系列不同类型的过滤器，使我们能够快速灵活地将功能应用到服务中。\n\n#### 过滤器\n\n过滤器是Zuul的核心功能。它们负责应用程序的业务逻辑，可以执行各种任务。\n\nType ：通常定义过滤器应用在哪个阶段\n\nAsync ：定义过滤器是同步还是异步\n\nExecution Order ：执行顺序\n\nCriteria ：过滤器执行的条件\n\nAction ：如果条件满足，过滤器执行的动作\n\nZuul提供了一个动态读取、编译和运行这些过滤器的框架。过滤器之间不直接通信，而是通过每个请求特有的RequestContext共享状态。\n\n下面是Zuul的一些过滤器:\n\n#### Incoming\n\nIncoming过滤器在请求被代理到Origin之前执行。这通常是执行大部分业务逻辑的地方。例如:认证、动态路由、速率限制、DDoS保护、指标。\n\n#### Endpoint\n\nEndpoint过滤器负责基于incoming过滤器的执行来处理请求。Zuul有一个内置的过滤器（ProxyEndpoint），用于将请求代理到后端服务器，因此这些过滤器的典型用途是用于静态端点。例如:健康检查响应，静态错误响应，404响应。\n\n#### Outgoing\n\nOutgoing过滤器在从后端接收到响应以后执行处理操作。通常情况下，它们更多地用于形成响应和添加指标，而不是用于任何繁重的工作。例如:存储统计信息、添加/剥离标准标题、向实时流发送事件、gziping响应。\n\n#### 过滤器类型\n\n下面是与一个请求典型的生命周期对应的标准的过滤器类型：\n\nPRE ：路由到Origin之前执行\n\nROUTING ：路由到Origin期间执行\n\nPOST ：请求被路由到Origin之后执行\n\nERROR ：发生错误的时候执行\n\n这些过滤器帮助我们执行以下功能：\n\n身份验证和安全性 ：识别每个资源的身份验证需求，并拒绝不满足它们的请求\n\n监控 ：在边缘跟踪有意义的数据和统计数据，以便给我们一个准确的生产视图\n\n动态路由 ：动态路由请求到不同的后端集群\n\n压力测试 ：逐渐增加集群的流量，以评估性能\n\n限流 ：为每种请求类型分配容量，并丢弃超过限制的请求\n\n静态响应处理 ：直接在边缘构建一些响应，而不是将它们转发到内部集群\n#### Zuul 1.0 请求生命周期\n![Alt text](image-110.png)\nNetflix宣布了通用API网关Zuul的架构转型。Zuul原本采用同步阻塞架构，转型后叫作Zuul2，采用异步非阻塞架构。Zuul2和Zuul1在架构方面的主要区别在于，Zuul2运行在异步非阻塞的框架上，比如Netty。Zuul1依赖多线程来支持吞吐量的增长，而Zuul 2使用的Netty框架依赖事件循环和回调函数。\n### 4. Zuul2.0\nZuul 2.0 架构图\n![Alt text](image-111.png)\n上图是Zuul2的架构，和Zuul1没有本质区别，两点变化：\n\n前端用Netty Server代替Servlet，目的是支持前端异步。后端用Netty Client代替Http Client，目的是支持后端异步。\n\n过滤器换了一下名字，用Inbound Filters代替Pre-routing Filters，用Endpoint Filter代替Routing Filter，用Outbound Filters代替Post-routing Filters。\n\nInbound Filters ：路由到 Origin 之前执行，可以用于身份验证、路由和装饰请求\n\nEndpoint Filters ：可用于返回静态响应，否则内置的ProxyEndpoint过滤器将请求路由到Origin\n\nOutbound Filters ：从Origin那里获取响应后执行，可以用于度量、装饰用户的响应或添加自定义header\n\n有两种类型的过滤器：sync 和 async。因为Zuul是运行在一个事件循环之上的，因此从来不要在过滤中阻塞。如果你非要阻塞，可以在一个异步过滤器中这样做，并且在一个单独的线程池上运行，否则可以使用同步过滤器。\n\n上文提到过Zuul2开始采用了异步模型\n\n优势 是异步非阻塞模式启动的线程很少，基本上一个CPU core上只需启一个事件环处理线程，它使用的线程资源就很少，上下文切换(Context Switch)开销也少。非阻塞模式可以接受的连接数大大增加，可以简单理解为请求来了只需要进队列，这个队列的容量可以设得很大，只要不超时，队列中的请求都会被依次处理。\n\n不足 ，异步模式让编程模型变得复杂。一方面Zuul2本身的代码要比Zuul1复杂很多，Zuul1的代码比较容易看懂，Zuul2的代码看起来就比较费劲。另一方面异步模型没有一个明确清晰的请求->处理->响应执行流程(call flow)，它的流程是通过事件触发的，请求处理的流程随时可能被切换断开，内部实现要通过一些关联id机制才能把整个执行流再串联起来，这就给开发调试运维引入了很多复杂性，比如你在IDE里头调试异步请求流就非常困难。另外ThreadLocal机制在这种异步模式下就不能简单工作，因为只有一个事件环线程，不是每个请求一个线程，也就没有线程局部的概念，所以对于CAT这种依赖于ThreadLocal才能工作的监控工具，调用链埋点就不好搞(实际可以工作但需要进行特殊处理)。\n\n总体上，异步非阻塞模式比较适用于IO密集型(IO bound)场景，这种场景下系统大部分时间在处理IO，CPU计算比较轻，少量事件环线程就能处理。\n#### Zuul 与 Zuul 2 性能对比\n![Alt text](image-112.png)\nNetflix给出了一个比较模糊的数据，大致Zuul2的性能比Zuul1好20%左右 ，这里的性能主要指每节点每秒处理的请求数。为什么说模糊呢？因为这个数据受实际测试环境，流量场景模式等众多因素影响，你很难复现这个测试数据。即便这个20%的性能提升是确实的，其实这个性能提升也并不大，和异步引入的复杂性相比，这20%的提升是否值得是个问题。Netflix本身在其博文22和ppt11中也是有点含糊其词，甚至自身都有一些疑问的。\n### 5. Spring Cloud Gateway\nSpringCloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。\n\nSpringCloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 2.0之前的非Reactor模式的老版本。而为了提升网关的性能，SpringCloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。\n\nSpring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/指标，和限流。\n\nSpring Cloud Gateway 底层使用了高性能的通信框架Netty 。\n\nSpringCloud Gateway 特征\n\nSpringCloud官方，对SpringCloud Gateway 特征介绍如下：\n\n（1）基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0\n\n（2）集成 Hystrix 断路器\n\n（3）集成 Spring Cloud DiscoveryClient\n\n（4）Predicates 和 Filters 作用于特定路由，易于编写的 Predicates 和 Filters\n\n（5）具备一些网关的高级功能：动态路由、限流、路径重写\n\n从以上的特征来说，和Zuul的特征差别不大。SpringCloud Gateway和Zuul主要的区别，还是在底层的通信框架上。\n\n简单说明一下上文中的三个术语：\n\n#### Filter （过滤器）\n\n和Zuul的过滤器在概念上类似，可以使用它拦截和修改请求，并且对上游的响应，进行二次处理。过滤器为org.springframework.cloud.gateway.filter.GatewayFilter类的实例。\n\n#### Route （路由）\n\n网关配置的基本组成模块，和Zuul的路由配置模块类似。一个Route模块 由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。\n\n#### Predicate （断言）：\n\n这是一个 Java 8 的 Predicate，可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。断言的 输入类型是一个 ServerWebExchange。\n### 几种网关的对比\n![Alt text](image-113.png)\n作者：等不到的口琴\n\n来源：//www.cnblogs.com/Courage129/p/14446586.html\n\n版权申明：内容来源网络，仅供分享学习，版权归原创者所有。除非无法确认，我们都会标明作者及出处，如有侵权烦请告知，我们会立即删除并表示歉意。谢谢!","source":"_posts/kubernetes/gateway.md","raw":"---\ntitle: 网关技术详解及常见网关对比\ndate: 2023-11-02 11:01:02\ncategories:\n  - [kubernetes]\ntags: gateway\n---\n原文地址: https://blog.csdn.net/huangjinjin520/article/details/126863371\n## 什么是网关\n网关，很多地方将网关比如成门， 没什么问题， 但是需要区分网关与网桥的区别，\n\n网桥 工作在数据链路层，在不同或相同类型的LAN之间存储并转发数据帧，必要时进行链路层上的协议转换。可连接两个或多个网络，在其中传送信息包。\n\n网关 是一个大概念，不具体特指一类产品，只要连接两个不同的网络都可以叫网关，网桥一般只转发信息，而网关可能进行包装。\n## 网关通俗理解\n根据网关的特性，举个例子:\n\n假如你要去找集团老板(这儿只是举个例子)， 大家都知道老板肯定不是谁想见就能见的， 也怕坏人嘛， 那么你去老板所在的办公楼，假如是集团总部， 大楼这个门就充当了网关的角色， 大门一般都有看门员 ，看门员会做哪些事情呢?\n\n首先所有想见老板的人肯定都得从这个门进(统一入口 )， 这个门相当于将办公室和外界隔离了，主要为了保护里面的安全以及正常工作， 来到这个门之后， 门卫肯定会让你出示相关证件(鉴权检验 )， 意思就是判断你要见老板这个请求是否合理， 如果不合理直接就拒绝了， 让你回家等消息 ， 如果鉴权之后， 发现你找老板其实只是为了和他谈谈两元店的生意， 门卫会跟你说这个用不着找老板， 你去集团投资部就行了(动态路由 ， 将请求路由到不同的后端集群中)， 此时会对你进行一些包装 ，例如给你出具一个访问证类似的，然后告诉你路该怎么走，等等。\n\n你看看，网关的作用是不是就是这三个， 最终目的就是减少你与集团的耦合，具体到计算机上就是减少客户端与服务端的耦合，如果没有网关意味着所有请求都会直接调用服务器上的资源，这样耦合太强了，服务器出了问题，客户端会直接报错， 例如老板换工作的地方了，如果没有网关你直接去原来的地方找， 肯定会被告知老板不在这儿。\n## 为什么需要网关\n当使用单体应用程序架构时，客户端（Web 或移动端）通过向后端应用程序发起一次 REST 调用来获取数据。负载均衡器将请求路由给 N 个相同的应用程序实例中的一个。然后应用程序会查询各种数据库表，并将响应返回给客户端。微服务架构下，单体应用被切割成多个微服务，如果将所有的微服务直接对外暴露，势必会出现安全方面的各种问题，另外内外耦合严重。\n\n客户端可以直接向每个微服务发送请求，其问题主要如下：\n\n客户端需求和每个微服务暴露的细粒度 API 不匹配。\n\n部分服务使用的协议不是Web友好协议。可能使用 Thrift 二进制 RPC，也可能使用 AMQP 消息传递协议。\n\n微服务难以重构。如果合并两个服务，或者将一个服务拆分成两个或更多服务，这类重构就非常困难了。\n\n服务端的各个服务直接暴露给客户端调用势必会引起各种问题。同时，服务端的各个服务可扩展和伸缩性很差。API 网关是微服务架构中的基础组件，位于接入层之下和业务服务层之上，如前所述的这些功能适合在 API 网关实现。\n\n## 网关与服务器集群\n回到我们服务器上，下面图介绍了网关(Gateway)作用，可知 Gateway 方式下的架构，可以细到为每一个服务的实例配置一个自己的 Gateway，也可以粗到为一组服务配置一个，甚至可以粗到为整个架构配置一个接入的 Gateway。于是，整个系统架构的复杂度就会变得简单可控起来。\n\n![Alt text](image-104.png)\n\n这张图展示了一个多层 Gateway 架构，其中有一个总的 Gateway 接入所有的流量(流量网关 )，并分发给不同的子系统，还有第二级 Gateway 用于做各个子系统的接入 Gateway(业务网关 )。可以看到，网关所管理的服务粒度可粗可细。通过网关，我们可以把分布式架构组织成一个星型架构，由网络对服务的请求进行路由和分发。下面来聊聊好的网关应该具备哪些功能，也就是网关设计模式。\n## 网关设计思路\n一个网关需要有以下的功能:\n\n### 1. 请求路由\n网关一定要有请求路由的功能。这样一来，对于调用端来说，也是一件非常方便的事情。因为调用端不需要知道自己需要用到的其它服务的地址，全部统一地交给 Gateway 来处理。\n\n### 2. 服务注册\n为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些 API 接口。比如，HTTP 的 Restful 请求，可以注册相应 API 的 URI、方法、HTTP 头。这样，Gateway 就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。\n\n### 3. 负载均衡\n因为一个网关可以接收多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单点就是直接 Round-Robin 轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到 session 粘连。\n\n### 4. 弹力设计\n网关还可以把弹力设计中的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去。这样，同样可以像 Service Mesh 那样，让应用服务只关心自己的业务逻辑（或是说数据面上的事）而不是控制逻辑（控制面）。\n\n### 5. 安全方面\nSSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。错误处理越靠前的位置就是越好，所以，网关可以做到一个全站的接入组件来对后端的服务进行保护。当然，网关还可以做更多更有趣的事情，比如：灰度发布、API聚合、API编排。\n\n#### 灰度发布\n\n网关完全可以做到对相同服务不同版本的实例进行导流，还可以收集相关的数据。这样对于软件质量的提升，甚至产品试错都有非常积极的意义。\n\n#### API 聚合\n\n使用网关可以将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。于是，我们可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）。\n\n#### API 编排\n\n同样在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。\n## 网关设计重点\n网关设计重点主要是三个， 高性能、高可用、高扩展:\n\n### 1. 高性能\n在技术设计上，网关不应该也不能成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务一定要使用异步非阻塞的 I/O 来确保后端延迟不会导致应用程序中出现性能问题。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I/O Completion Port 的异步 IO 模型，Java 下如 Netty、Spring Reactor 的 NIO 框架。\n\n### 2. 高可用\n因为所有的流量或调用经过网关，所以网关必须成为一个高可用的技术组件，它的稳定直接关系到了所有服务的稳定。网关如果没有设计，就会成变一个单点故障。因此，一个好的网关至少要做到以下几点。\n\n集群化 。网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。\n\n服务化 。网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置。\n\n持续化 。比如重启，就是像 Nginx 那样优雅地重启。有一个主管请求分发的主进程。当我们需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。\n\n### 3. 高扩展\n因为网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。而我们都知道，业务逻辑是多变和不确定的。比如，需要在网关上加入一些和业务相关的东西。因此，一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。\n\n另外，在运维方面 ，网关应该有以下几个设计原则。\n\n* 业务松耦合，协议紧耦合 。在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。\n\n* 应用监视，提供分析数据 。网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用 Tracing ID 实施分布式链路跟踪，并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。\n\n* 用弹力设计保护后端服务 。网关上一定要实现熔断、限流、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据。你可以考虑一下这样的设计。\n\n* DevOps 。因为网关这个组件太关键了，所以需要 DevOps 这样的东西，将其发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。\n\n## 网关设计注意事项\n1. 不要在网关中的代码里内置聚合后端服务的功能，而应考虑将聚合服务放在网关核心代码之外。可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。\n\n2. 网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。这里多说一句，网关处理的静态内容应该靠近用户（应该放到 CDN 上），而网关和此时的动态服务应该靠近后端服务。\n\n3. 网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过 DNS 轮询的方式实现，要么通过 CDN 来做流量调度，或者通过更为底层的性能更高的负载均衡设备。\n\n4. 对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都去查一下相关的服务所在的地方。当然，如果你的系统不复杂，可以考虑把服务发现的功能直接集成进网关中。\n\n5. 为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。\n\n另外，因为网关是为用户请求和后端服务的桥接装置，所以需要考虑一些安全方面的事宜。具体如下：\n\n* 加密数据 。可以把 SSL 相关的证书放到网关上，由网关做统一的 SSL 传输管理。\n\n* 校验用户的请求 。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。但是，我们需要权衡一下，网关是否需要校验用户的输入。因为这样一来，网关就需要从只关心协议头，到需要关心协议体。而协议体中的东西一方面不像协议头是标准的，另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能。对此，我想说的是，看具体需求，一方面如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。\n\n* 检测异常访问 。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；还比如，同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击。\n\n## 流量网关\n流量网关，顾名思义就是控制流量进入集群的网关，有很多工作需要在这一步做，对于一个服务集群，势必有很多非法的请求或者无效的请求，这时候要将请求拒之门外，降低集群的流量压力。\n![Alt text](image-105.png)\n定义全局性的、跟具体的后端业务应用和服务完全无关的策略网关就是上图所示的架构模型——流量网关。流量网关通常只专注于全局的Api管理策略，比如全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等，有点类似防火墙。Kong 就是典型的流量网关。\n\n下面是kong的架构图，来自官网：https://konghq.com\n![Alt text](image-106.png)\n这里需要补充一点的是，业务网关一般部署在流量网关之后、业务系统之前，比流量网关更靠近业务系统。通常API网指的是业务网关。有时候我们也会模糊流量网关和业务网关，让一个网关承担所有的工作，所以这两者之间并没有严格的界线。\n## 业务网关\n当一个单体应用被拆分成许许多多的微服务应用后，也带来了一些问题。一些与业务非强相关的功能，比如权限控制、日志输出、数据加密、熔断限流等，每个微服务应用都需要，因此存在着大量重复的代码实现。而且由于系统的迭代、人员的更替，各个微服务中这些功能的实现细节出现了较大的差异，导致维护成本变高。另一方面，原先单体应用下非常容易做的接口管理，在服务拆分后没有了一个集中管理的地方，无法统计已存在哪些接口、接口定义是什么、运行状态如何。\n\n网关就是为了解决上述问题。作为微服务体系中的核心基础设施，一般需要具备接口管理、协议适配、熔断限流、安全防护等功能，各种开源的网关产品（比如 zuul）都提供了优秀高可扩展性的架构、可以很方便的实现我们需要的一些功能、比如鉴权、日志监控、熔断限流等。\n\n与流量网关相对应的就是业务网关，业务网关更靠近我们的业务，也就是与服务器应用层打交道，那么有很多应用层需要考虑的事情就可以依托业务网关，例如在线程模型、协议适配、熔断限流，服务编排等。下面看看业务网关体系结构:\n![Alt text](image-107.png)\n从这个途中可以看出业务网关主要职责以及所做的事情， 目前业务网关比较成熟的 API 网关框架产品有三个 分别是:Zuul1、Zuul2 和 SpringCloud Gateway， 后面再进行对比。\n## 常见网关对比\n既然对比，就先宏观上对各种网关有一个了解，后面再挑一些常用的或者说应用广泛的详细了解。\n\n目前常见的开源网关大致上按照语言分类有如下几类：\n\nNginx+lua ：OpenResty、Kong、Orange、Abtesting gateway 等\n\nJava ：Zuul/Zuul2、Spring Cloud Gateway、Kaazing KWG、gravitee、Dromara soul 等\n\nGo ：Janus、fagongzi、Grpc-gateway\n\nDotnet ：Ocelot\n\nNodeJS ：Express Gateway、Micro Gateway\n\n按照使用数量、成熟度等来划分，主流的有 5个：\n\nOpenResty\n\nKong\n\nZuul、Zuul2\n\nSpring Cloud Gateway\n\n### 1. OpenResty\nOpenResty是一个流量网关，根据前面对流量网关的介绍就可以知道流量网关的指责。\n\nOpenResty基于 Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。\n\n通过揉和众多设计良好的 Nginx 模块，OpenResty 有效地把 Nginx 服务器转变为一个强大的 Web 应用服务器，基于它开发人员可以使用 Lua 编程语言对 Nginx 核心以及现有的各种 Nginx C 模块进行脚本编程，构建出可以处理一万以上并发请求的极端高性能的 Web 应用\n\nOpenResty 最早是顺应 OpenAPI 的潮流做的，所以 Open 取自“开放”之意，而Resty便是 REST 风格的意思。虽然后来也可以基于 ngx_openresty 实现任何形式的 web service 或者传统的 web 应用。\n\n也就是说 Nginx 不再是一个简单的静态网页服务器，也不再是一个简单的反向代理了。第二代的 openresty 致力于通过一系列 nginx 模块，把nginx扩展为全功能的 web 应用服务器。\n\nngx_openresty 是用户驱动的项目，后来也有不少国内用户的参与，从 openresty.org 的点击量分布上看，国内和国外的点击量基本持平。\n\nngx_openresty 目前有两大应用目标：\n\n通用目的的 web 应用服务器。在这个目标下，现有的 web 应用技术都可以算是和 OpenResty 或多或少有些类似，比如 Nodejs， PHP 等等。ngx_openresty 的性能（包括内存使用和 CPU 效率）算是最大的卖点之一。\n\nNginx 的脚本扩展编程，用于构建灵活的 Web 应用网关和 Web 应用防火墙。有些类似的是 NetScaler。其优势在于 Lua 编程带来的巨大灵活性。\n\n### 2. Kong\nKong基于OpenResty开发，也是流量层网关， 是一个云原生、快速、可扩展、分布式的Api 网关。继承了OpenResty的高性能、易扩展性等特点。Kong通过简单的增加机器节点，可以很容易的水平扩展。同时功能插件化，可通过插件来扩展其能力。而且在任何基础架构上都可以运行。具有以下特性：\n\n提供了多样化的认证层来保护Api。\n\n可对出入流量进行管制。\n\n提供了可视化的流量检查、监视分析Api。\n\n能够及时的转换请求和相应。\n\n提供log解决方案\n\n可通过api调用Serverless 函数。\n\n#### Kong解决了什么问题\n\n当我们决定对应用进行微服务改造时，应用客户端如何与微服务交互的问题也随之而来，毕竟服务数量的增加会直接导致部署授权、负载均衡、通信管理、分析和改变的难度增加。\n\n面对以上问题，API GATEWAY是一个不错的解决方案，其所提供的访问限制、安全、流量控制、分析监控、日志、请求转发、合成和协议转换功能，可以解放开发者去把精力集中在具体逻辑的代码，而不是把时间花费在考虑如何解决应用和其他微服务链接的问题上。\n\n图片来自Kong官网:\n\n![Alt text](image-108.png)\n可以看到Kong解决的问题。专注于全局的Api管理策略，全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等。\n#### Kong的优点以及性能\n\n在众多 API GATEWAY 框架中，Mashape 开源的高性能高可用API网关和API服务管理层——KONG（基于 NGINX+Lua）特点尤为突出，它可以通过插件扩展已有功能，这些插件（使用 lua 编写）在API请求响应循环的生命周期中被执行。于此同时，KONG本身提供包括 HTTP 基本认证、密钥认证、CORS、TCP、UDP、文件日志、API请求限流、请求转发及 NGINX 监控等基本功能。目前，Kong 在 Mashape 管理了超过 15，000 个 API，为 200，000 开发者提供了每月数十亿的请求支持。\n\n#### Kong架构\n\nKong提供一些列的服务，这就不得不谈谈内部的架构:\n![Alt text](image-109.png)\n首先最底层是基于Nginx， Nginx是高性能的基础层， 一个良好的负载均衡、反向代理器，然后在此基础上增加Lua脚本库，形成了OpenResty，拦截请求， 响应生命周期，可以通过Lua编写脚本，所以插件比较丰富。\n\n关于Kong的一些插件库以及如何配置，可以参考简书:开源API网关系统（Kong教程）入门到精通：https://www.jianshu.com/p/a68e45bcadb6\n\n### 3. Zuul1.0\nZuul是所有从设备和web站点到Netflix流媒体应用程序后端请求的前门。作为一个边缘服务应用程序，Zuul被构建来支持动态路由、监视、弹性和安全性。它还可以根据需要将请求路由到多个Amazon自动伸缩组。\n\nZuul使用了一系列不同类型的过滤器，使我们能够快速灵活地将功能应用到服务中。\n\n#### 过滤器\n\n过滤器是Zuul的核心功能。它们负责应用程序的业务逻辑，可以执行各种任务。\n\nType ：通常定义过滤器应用在哪个阶段\n\nAsync ：定义过滤器是同步还是异步\n\nExecution Order ：执行顺序\n\nCriteria ：过滤器执行的条件\n\nAction ：如果条件满足，过滤器执行的动作\n\nZuul提供了一个动态读取、编译和运行这些过滤器的框架。过滤器之间不直接通信，而是通过每个请求特有的RequestContext共享状态。\n\n下面是Zuul的一些过滤器:\n\n#### Incoming\n\nIncoming过滤器在请求被代理到Origin之前执行。这通常是执行大部分业务逻辑的地方。例如:认证、动态路由、速率限制、DDoS保护、指标。\n\n#### Endpoint\n\nEndpoint过滤器负责基于incoming过滤器的执行来处理请求。Zuul有一个内置的过滤器（ProxyEndpoint），用于将请求代理到后端服务器，因此这些过滤器的典型用途是用于静态端点。例如:健康检查响应，静态错误响应，404响应。\n\n#### Outgoing\n\nOutgoing过滤器在从后端接收到响应以后执行处理操作。通常情况下，它们更多地用于形成响应和添加指标，而不是用于任何繁重的工作。例如:存储统计信息、添加/剥离标准标题、向实时流发送事件、gziping响应。\n\n#### 过滤器类型\n\n下面是与一个请求典型的生命周期对应的标准的过滤器类型：\n\nPRE ：路由到Origin之前执行\n\nROUTING ：路由到Origin期间执行\n\nPOST ：请求被路由到Origin之后执行\n\nERROR ：发生错误的时候执行\n\n这些过滤器帮助我们执行以下功能：\n\n身份验证和安全性 ：识别每个资源的身份验证需求，并拒绝不满足它们的请求\n\n监控 ：在边缘跟踪有意义的数据和统计数据，以便给我们一个准确的生产视图\n\n动态路由 ：动态路由请求到不同的后端集群\n\n压力测试 ：逐渐增加集群的流量，以评估性能\n\n限流 ：为每种请求类型分配容量，并丢弃超过限制的请求\n\n静态响应处理 ：直接在边缘构建一些响应，而不是将它们转发到内部集群\n#### Zuul 1.0 请求生命周期\n![Alt text](image-110.png)\nNetflix宣布了通用API网关Zuul的架构转型。Zuul原本采用同步阻塞架构，转型后叫作Zuul2，采用异步非阻塞架构。Zuul2和Zuul1在架构方面的主要区别在于，Zuul2运行在异步非阻塞的框架上，比如Netty。Zuul1依赖多线程来支持吞吐量的增长，而Zuul 2使用的Netty框架依赖事件循环和回调函数。\n### 4. Zuul2.0\nZuul 2.0 架构图\n![Alt text](image-111.png)\n上图是Zuul2的架构，和Zuul1没有本质区别，两点变化：\n\n前端用Netty Server代替Servlet，目的是支持前端异步。后端用Netty Client代替Http Client，目的是支持后端异步。\n\n过滤器换了一下名字，用Inbound Filters代替Pre-routing Filters，用Endpoint Filter代替Routing Filter，用Outbound Filters代替Post-routing Filters。\n\nInbound Filters ：路由到 Origin 之前执行，可以用于身份验证、路由和装饰请求\n\nEndpoint Filters ：可用于返回静态响应，否则内置的ProxyEndpoint过滤器将请求路由到Origin\n\nOutbound Filters ：从Origin那里获取响应后执行，可以用于度量、装饰用户的响应或添加自定义header\n\n有两种类型的过滤器：sync 和 async。因为Zuul是运行在一个事件循环之上的，因此从来不要在过滤中阻塞。如果你非要阻塞，可以在一个异步过滤器中这样做，并且在一个单独的线程池上运行，否则可以使用同步过滤器。\n\n上文提到过Zuul2开始采用了异步模型\n\n优势 是异步非阻塞模式启动的线程很少，基本上一个CPU core上只需启一个事件环处理线程，它使用的线程资源就很少，上下文切换(Context Switch)开销也少。非阻塞模式可以接受的连接数大大增加，可以简单理解为请求来了只需要进队列，这个队列的容量可以设得很大，只要不超时，队列中的请求都会被依次处理。\n\n不足 ，异步模式让编程模型变得复杂。一方面Zuul2本身的代码要比Zuul1复杂很多，Zuul1的代码比较容易看懂，Zuul2的代码看起来就比较费劲。另一方面异步模型没有一个明确清晰的请求->处理->响应执行流程(call flow)，它的流程是通过事件触发的，请求处理的流程随时可能被切换断开，内部实现要通过一些关联id机制才能把整个执行流再串联起来，这就给开发调试运维引入了很多复杂性，比如你在IDE里头调试异步请求流就非常困难。另外ThreadLocal机制在这种异步模式下就不能简单工作，因为只有一个事件环线程，不是每个请求一个线程，也就没有线程局部的概念，所以对于CAT这种依赖于ThreadLocal才能工作的监控工具，调用链埋点就不好搞(实际可以工作但需要进行特殊处理)。\n\n总体上，异步非阻塞模式比较适用于IO密集型(IO bound)场景，这种场景下系统大部分时间在处理IO，CPU计算比较轻，少量事件环线程就能处理。\n#### Zuul 与 Zuul 2 性能对比\n![Alt text](image-112.png)\nNetflix给出了一个比较模糊的数据，大致Zuul2的性能比Zuul1好20%左右 ，这里的性能主要指每节点每秒处理的请求数。为什么说模糊呢？因为这个数据受实际测试环境，流量场景模式等众多因素影响，你很难复现这个测试数据。即便这个20%的性能提升是确实的，其实这个性能提升也并不大，和异步引入的复杂性相比，这20%的提升是否值得是个问题。Netflix本身在其博文22和ppt11中也是有点含糊其词，甚至自身都有一些疑问的。\n### 5. Spring Cloud Gateway\nSpringCloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。\n\nSpringCloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 2.0之前的非Reactor模式的老版本。而为了提升网关的性能，SpringCloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。\n\nSpring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/指标，和限流。\n\nSpring Cloud Gateway 底层使用了高性能的通信框架Netty 。\n\nSpringCloud Gateway 特征\n\nSpringCloud官方，对SpringCloud Gateway 特征介绍如下：\n\n（1）基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0\n\n（2）集成 Hystrix 断路器\n\n（3）集成 Spring Cloud DiscoveryClient\n\n（4）Predicates 和 Filters 作用于特定路由，易于编写的 Predicates 和 Filters\n\n（5）具备一些网关的高级功能：动态路由、限流、路径重写\n\n从以上的特征来说，和Zuul的特征差别不大。SpringCloud Gateway和Zuul主要的区别，还是在底层的通信框架上。\n\n简单说明一下上文中的三个术语：\n\n#### Filter （过滤器）\n\n和Zuul的过滤器在概念上类似，可以使用它拦截和修改请求，并且对上游的响应，进行二次处理。过滤器为org.springframework.cloud.gateway.filter.GatewayFilter类的实例。\n\n#### Route （路由）\n\n网关配置的基本组成模块，和Zuul的路由配置模块类似。一个Route模块 由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。\n\n#### Predicate （断言）：\n\n这是一个 Java 8 的 Predicate，可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。断言的 输入类型是一个 ServerWebExchange。\n### 几种网关的对比\n![Alt text](image-113.png)\n作者：等不到的口琴\n\n来源：//www.cnblogs.com/Courage129/p/14446586.html\n\n版权申明：内容来源网络，仅供分享学习，版权归原创者所有。除非无法确认，我们都会标明作者及出处，如有侵权烦请告知，我们会立即删除并表示歉意。谢谢!","slug":"kubernetes/gateway","published":1,"updated":"2023-11-02T03:29:35.022Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0c0000kfmjxfeov3bw1","content":"<p>原文地址: <a href=\"https://blog.csdn.net/huangjinjin520/article/details/126863371\">https://blog.csdn.net/huangjinjin520/article/details/126863371</a></p>\n<h2 id=\"什么是网关\"><a href=\"#什么是网关\" class=\"headerlink\" title=\"什么是网关\"></a>什么是网关</h2><p>网关，很多地方将网关比如成门， 没什么问题， 但是需要区分网关与网桥的区别，</p>\n<p>网桥 工作在数据链路层，在不同或相同类型的LAN之间存储并转发数据帧，必要时进行链路层上的协议转换。可连接两个或多个网络，在其中传送信息包。</p>\n<p>网关 是一个大概念，不具体特指一类产品，只要连接两个不同的网络都可以叫网关，网桥一般只转发信息，而网关可能进行包装。</p>\n<h2 id=\"网关通俗理解\"><a href=\"#网关通俗理解\" class=\"headerlink\" title=\"网关通俗理解\"></a>网关通俗理解</h2><p>根据网关的特性，举个例子:</p>\n<p>假如你要去找集团老板(这儿只是举个例子)， 大家都知道老板肯定不是谁想见就能见的， 也怕坏人嘛， 那么你去老板所在的办公楼，假如是集团总部， 大楼这个门就充当了网关的角色， 大门一般都有看门员 ，看门员会做哪些事情呢?</p>\n<p>首先所有想见老板的人肯定都得从这个门进(统一入口 )， 这个门相当于将办公室和外界隔离了，主要为了保护里面的安全以及正常工作， 来到这个门之后， 门卫肯定会让你出示相关证件(鉴权检验 )， 意思就是判断你要见老板这个请求是否合理， 如果不合理直接就拒绝了， 让你回家等消息 ， 如果鉴权之后， 发现你找老板其实只是为了和他谈谈两元店的生意， 门卫会跟你说这个用不着找老板， 你去集团投资部就行了(动态路由 ， 将请求路由到不同的后端集群中)， 此时会对你进行一些包装 ，例如给你出具一个访问证类似的，然后告诉你路该怎么走，等等。</p>\n<p>你看看，网关的作用是不是就是这三个， 最终目的就是减少你与集团的耦合，具体到计算机上就是减少客户端与服务端的耦合，如果没有网关意味着所有请求都会直接调用服务器上的资源，这样耦合太强了，服务器出了问题，客户端会直接报错， 例如老板换工作的地方了，如果没有网关你直接去原来的地方找， 肯定会被告知老板不在这儿。</p>\n<h2 id=\"为什么需要网关\"><a href=\"#为什么需要网关\" class=\"headerlink\" title=\"为什么需要网关\"></a>为什么需要网关</h2><p>当使用单体应用程序架构时，客户端（Web 或移动端）通过向后端应用程序发起一次 REST 调用来获取数据。负载均衡器将请求路由给 N 个相同的应用程序实例中的一个。然后应用程序会查询各种数据库表，并将响应返回给客户端。微服务架构下，单体应用被切割成多个微服务，如果将所有的微服务直接对外暴露，势必会出现安全方面的各种问题，另外内外耦合严重。</p>\n<p>客户端可以直接向每个微服务发送请求，其问题主要如下：</p>\n<p>客户端需求和每个微服务暴露的细粒度 API 不匹配。</p>\n<p>部分服务使用的协议不是Web友好协议。可能使用 Thrift 二进制 RPC，也可能使用 AMQP 消息传递协议。</p>\n<p>微服务难以重构。如果合并两个服务，或者将一个服务拆分成两个或更多服务，这类重构就非常困难了。</p>\n<p>服务端的各个服务直接暴露给客户端调用势必会引起各种问题。同时，服务端的各个服务可扩展和伸缩性很差。API 网关是微服务架构中的基础组件，位于接入层之下和业务服务层之上，如前所述的这些功能适合在 API 网关实现。</p>\n<h2 id=\"网关与服务器集群\"><a href=\"#网关与服务器集群\" class=\"headerlink\" title=\"网关与服务器集群\"></a>网关与服务器集群</h2><p>回到我们服务器上，下面图介绍了网关(Gateway)作用，可知 Gateway 方式下的架构，可以细到为每一个服务的实例配置一个自己的 Gateway，也可以粗到为一组服务配置一个，甚至可以粗到为整个架构配置一个接入的 Gateway。于是，整个系统架构的复杂度就会变得简单可控起来。</p>\n<p><img src=\"/image-104.png\" alt=\"Alt text\"></p>\n<p>这张图展示了一个多层 Gateway 架构，其中有一个总的 Gateway 接入所有的流量(流量网关 )，并分发给不同的子系统，还有第二级 Gateway 用于做各个子系统的接入 Gateway(业务网关 )。可以看到，网关所管理的服务粒度可粗可细。通过网关，我们可以把分布式架构组织成一个星型架构，由网络对服务的请求进行路由和分发。下面来聊聊好的网关应该具备哪些功能，也就是网关设计模式。</p>\n<h2 id=\"网关设计思路\"><a href=\"#网关设计思路\" class=\"headerlink\" title=\"网关设计思路\"></a>网关设计思路</h2><p>一个网关需要有以下的功能:</p>\n<h3 id=\"1-请求路由\"><a href=\"#1-请求路由\" class=\"headerlink\" title=\"1. 请求路由\"></a>1. 请求路由</h3><p>网关一定要有请求路由的功能。这样一来，对于调用端来说，也是一件非常方便的事情。因为调用端不需要知道自己需要用到的其它服务的地址，全部统一地交给 Gateway 来处理。</p>\n<h3 id=\"2-服务注册\"><a href=\"#2-服务注册\" class=\"headerlink\" title=\"2. 服务注册\"></a>2. 服务注册</h3><p>为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些 API 接口。比如，HTTP 的 Restful 请求，可以注册相应 API 的 URI、方法、HTTP 头。这样，Gateway 就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。</p>\n<h3 id=\"3-负载均衡\"><a href=\"#3-负载均衡\" class=\"headerlink\" title=\"3. 负载均衡\"></a>3. 负载均衡</h3><p>因为一个网关可以接收多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单点就是直接 Round-Robin 轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到 session 粘连。</p>\n<h3 id=\"4-弹力设计\"><a href=\"#4-弹力设计\" class=\"headerlink\" title=\"4. 弹力设计\"></a>4. 弹力设计</h3><p>网关还可以把弹力设计中的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去。这样，同样可以像 Service Mesh 那样，让应用服务只关心自己的业务逻辑（或是说数据面上的事）而不是控制逻辑（控制面）。</p>\n<h3 id=\"5-安全方面\"><a href=\"#5-安全方面\" class=\"headerlink\" title=\"5. 安全方面\"></a>5. 安全方面</h3><p>SSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。错误处理越靠前的位置就是越好，所以，网关可以做到一个全站的接入组件来对后端的服务进行保护。当然，网关还可以做更多更有趣的事情，比如：灰度发布、API聚合、API编排。</p>\n<h4 id=\"灰度发布\"><a href=\"#灰度发布\" class=\"headerlink\" title=\"灰度发布\"></a>灰度发布</h4><p>网关完全可以做到对相同服务不同版本的实例进行导流，还可以收集相关的数据。这样对于软件质量的提升，甚至产品试错都有非常积极的意义。</p>\n<h4 id=\"API-聚合\"><a href=\"#API-聚合\" class=\"headerlink\" title=\"API 聚合\"></a>API 聚合</h4><p>使用网关可以将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。于是，我们可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）。</p>\n<h4 id=\"API-编排\"><a href=\"#API-编排\" class=\"headerlink\" title=\"API 编排\"></a>API 编排</h4><p>同样在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。</p>\n<h2 id=\"网关设计重点\"><a href=\"#网关设计重点\" class=\"headerlink\" title=\"网关设计重点\"></a>网关设计重点</h2><p>网关设计重点主要是三个， 高性能、高可用、高扩展:</p>\n<h3 id=\"1-高性能\"><a href=\"#1-高性能\" class=\"headerlink\" title=\"1. 高性能\"></a>1. 高性能</h3><p>在技术设计上，网关不应该也不能成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务一定要使用异步非阻塞的 I&#x2F;O 来确保后端延迟不会导致应用程序中出现性能问题。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I&#x2F;O Completion Port 的异步 IO 模型，Java 下如 Netty、Spring Reactor 的 NIO 框架。</p>\n<h3 id=\"2-高可用\"><a href=\"#2-高可用\" class=\"headerlink\" title=\"2. 高可用\"></a>2. 高可用</h3><p>因为所有的流量或调用经过网关，所以网关必须成为一个高可用的技术组件，它的稳定直接关系到了所有服务的稳定。网关如果没有设计，就会成变一个单点故障。因此，一个好的网关至少要做到以下几点。</p>\n<p>集群化 。网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。</p>\n<p>服务化 。网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置。</p>\n<p>持续化 。比如重启，就是像 Nginx 那样优雅地重启。有一个主管请求分发的主进程。当我们需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。</p>\n<h3 id=\"3-高扩展\"><a href=\"#3-高扩展\" class=\"headerlink\" title=\"3. 高扩展\"></a>3. 高扩展</h3><p>因为网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。而我们都知道，业务逻辑是多变和不确定的。比如，需要在网关上加入一些和业务相关的东西。因此，一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。</p>\n<p>另外，在运维方面 ，网关应该有以下几个设计原则。</p>\n<ul>\n<li><p>业务松耦合，协议紧耦合 。在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。</p>\n</li>\n<li><p>应用监视，提供分析数据 。网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用 Tracing ID 实施分布式链路跟踪，并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。</p>\n</li>\n<li><p>用弹力设计保护后端服务 。网关上一定要实现熔断、限流、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据。你可以考虑一下这样的设计。</p>\n</li>\n<li><p>DevOps 。因为网关这个组件太关键了，所以需要 DevOps 这样的东西，将其发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。</p>\n</li>\n</ul>\n<h2 id=\"网关设计注意事项\"><a href=\"#网关设计注意事项\" class=\"headerlink\" title=\"网关设计注意事项\"></a>网关设计注意事项</h2><ol>\n<li><p>不要在网关中的代码里内置聚合后端服务的功能，而应考虑将聚合服务放在网关核心代码之外。可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。</p>\n</li>\n<li><p>网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。这里多说一句，网关处理的静态内容应该靠近用户（应该放到 CDN 上），而网关和此时的动态服务应该靠近后端服务。</p>\n</li>\n<li><p>网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过 DNS 轮询的方式实现，要么通过 CDN 来做流量调度，或者通过更为底层的性能更高的负载均衡设备。</p>\n</li>\n<li><p>对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都去查一下相关的服务所在的地方。当然，如果你的系统不复杂，可以考虑把服务发现的功能直接集成进网关中。</p>\n</li>\n<li><p>为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。</p>\n</li>\n</ol>\n<p>另外，因为网关是为用户请求和后端服务的桥接装置，所以需要考虑一些安全方面的事宜。具体如下：</p>\n<ul>\n<li><p>加密数据 。可以把 SSL 相关的证书放到网关上，由网关做统一的 SSL 传输管理。</p>\n</li>\n<li><p>校验用户的请求 。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。但是，我们需要权衡一下，网关是否需要校验用户的输入。因为这样一来，网关就需要从只关心协议头，到需要关心协议体。而协议体中的东西一方面不像协议头是标准的，另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能。对此，我想说的是，看具体需求，一方面如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。</p>\n</li>\n<li><p>检测异常访问 。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；还比如，同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击。</p>\n</li>\n</ul>\n<h2 id=\"流量网关\"><a href=\"#流量网关\" class=\"headerlink\" title=\"流量网关\"></a>流量网关</h2><p>流量网关，顾名思义就是控制流量进入集群的网关，有很多工作需要在这一步做，对于一个服务集群，势必有很多非法的请求或者无效的请求，这时候要将请求拒之门外，降低集群的流量压力。<br><img src=\"/image-105.png\" alt=\"Alt text\"><br>定义全局性的、跟具体的后端业务应用和服务完全无关的策略网关就是上图所示的架构模型——流量网关。流量网关通常只专注于全局的Api管理策略，比如全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等，有点类似防火墙。Kong 就是典型的流量网关。</p>\n<p>下面是kong的架构图，来自官网：<a href=\"https://konghq.com/\">https://konghq.com</a><br><img src=\"/image-106.png\" alt=\"Alt text\"><br>这里需要补充一点的是，业务网关一般部署在流量网关之后、业务系统之前，比流量网关更靠近业务系统。通常API网指的是业务网关。有时候我们也会模糊流量网关和业务网关，让一个网关承担所有的工作，所以这两者之间并没有严格的界线。</p>\n<h2 id=\"业务网关\"><a href=\"#业务网关\" class=\"headerlink\" title=\"业务网关\"></a>业务网关</h2><p>当一个单体应用被拆分成许许多多的微服务应用后，也带来了一些问题。一些与业务非强相关的功能，比如权限控制、日志输出、数据加密、熔断限流等，每个微服务应用都需要，因此存在着大量重复的代码实现。而且由于系统的迭代、人员的更替，各个微服务中这些功能的实现细节出现了较大的差异，导致维护成本变高。另一方面，原先单体应用下非常容易做的接口管理，在服务拆分后没有了一个集中管理的地方，无法统计已存在哪些接口、接口定义是什么、运行状态如何。</p>\n<p>网关就是为了解决上述问题。作为微服务体系中的核心基础设施，一般需要具备接口管理、协议适配、熔断限流、安全防护等功能，各种开源的网关产品（比如 zuul）都提供了优秀高可扩展性的架构、可以很方便的实现我们需要的一些功能、比如鉴权、日志监控、熔断限流等。</p>\n<p>与流量网关相对应的就是业务网关，业务网关更靠近我们的业务，也就是与服务器应用层打交道，那么有很多应用层需要考虑的事情就可以依托业务网关，例如在线程模型、协议适配、熔断限流，服务编排等。下面看看业务网关体系结构:<br><img src=\"/image-107.png\" alt=\"Alt text\"><br>从这个途中可以看出业务网关主要职责以及所做的事情， 目前业务网关比较成熟的 API 网关框架产品有三个 分别是:Zuul1、Zuul2 和 SpringCloud Gateway， 后面再进行对比。</p>\n<h2 id=\"常见网关对比\"><a href=\"#常见网关对比\" class=\"headerlink\" title=\"常见网关对比\"></a>常见网关对比</h2><p>既然对比，就先宏观上对各种网关有一个了解，后面再挑一些常用的或者说应用广泛的详细了解。</p>\n<p>目前常见的开源网关大致上按照语言分类有如下几类：</p>\n<p>Nginx+lua ：OpenResty、Kong、Orange、Abtesting gateway 等</p>\n<p>Java ：Zuul&#x2F;Zuul2、Spring Cloud Gateway、Kaazing KWG、gravitee、Dromara soul 等</p>\n<p>Go ：Janus、fagongzi、Grpc-gateway</p>\n<p>Dotnet ：Ocelot</p>\n<p>NodeJS ：Express Gateway、Micro Gateway</p>\n<p>按照使用数量、成熟度等来划分，主流的有 5个：</p>\n<p>OpenResty</p>\n<p>Kong</p>\n<p>Zuul、Zuul2</p>\n<p>Spring Cloud Gateway</p>\n<h3 id=\"1-OpenResty\"><a href=\"#1-OpenResty\" class=\"headerlink\" title=\"1. OpenResty\"></a>1. OpenResty</h3><p>OpenResty是一个流量网关，根据前面对流量网关的介绍就可以知道流量网关的指责。</p>\n<p>OpenResty基于 Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。</p>\n<p>通过揉和众多设计良好的 Nginx 模块，OpenResty 有效地把 Nginx 服务器转变为一个强大的 Web 应用服务器，基于它开发人员可以使用 Lua 编程语言对 Nginx 核心以及现有的各种 Nginx C 模块进行脚本编程，构建出可以处理一万以上并发请求的极端高性能的 Web 应用</p>\n<p>OpenResty 最早是顺应 OpenAPI 的潮流做的，所以 Open 取自“开放”之意，而Resty便是 REST 风格的意思。虽然后来也可以基于 ngx_openresty 实现任何形式的 web service 或者传统的 web 应用。</p>\n<p>也就是说 Nginx 不再是一个简单的静态网页服务器，也不再是一个简单的反向代理了。第二代的 openresty 致力于通过一系列 nginx 模块，把nginx扩展为全功能的 web 应用服务器。</p>\n<p>ngx_openresty 是用户驱动的项目，后来也有不少国内用户的参与，从 openresty.org 的点击量分布上看，国内和国外的点击量基本持平。</p>\n<p>ngx_openresty 目前有两大应用目标：</p>\n<p>通用目的的 web 应用服务器。在这个目标下，现有的 web 应用技术都可以算是和 OpenResty 或多或少有些类似，比如 Nodejs， PHP 等等。ngx_openresty 的性能（包括内存使用和 CPU 效率）算是最大的卖点之一。</p>\n<p>Nginx 的脚本扩展编程，用于构建灵活的 Web 应用网关和 Web 应用防火墙。有些类似的是 NetScaler。其优势在于 Lua 编程带来的巨大灵活性。</p>\n<h3 id=\"2-Kong\"><a href=\"#2-Kong\" class=\"headerlink\" title=\"2. Kong\"></a>2. Kong</h3><p>Kong基于OpenResty开发，也是流量层网关， 是一个云原生、快速、可扩展、分布式的Api 网关。继承了OpenResty的高性能、易扩展性等特点。Kong通过简单的增加机器节点，可以很容易的水平扩展。同时功能插件化，可通过插件来扩展其能力。而且在任何基础架构上都可以运行。具有以下特性：</p>\n<p>提供了多样化的认证层来保护Api。</p>\n<p>可对出入流量进行管制。</p>\n<p>提供了可视化的流量检查、监视分析Api。</p>\n<p>能够及时的转换请求和相应。</p>\n<p>提供log解决方案</p>\n<p>可通过api调用Serverless 函数。</p>\n<h4 id=\"Kong解决了什么问题\"><a href=\"#Kong解决了什么问题\" class=\"headerlink\" title=\"Kong解决了什么问题\"></a>Kong解决了什么问题</h4><p>当我们决定对应用进行微服务改造时，应用客户端如何与微服务交互的问题也随之而来，毕竟服务数量的增加会直接导致部署授权、负载均衡、通信管理、分析和改变的难度增加。</p>\n<p>面对以上问题，API GATEWAY是一个不错的解决方案，其所提供的访问限制、安全、流量控制、分析监控、日志、请求转发、合成和协议转换功能，可以解放开发者去把精力集中在具体逻辑的代码，而不是把时间花费在考虑如何解决应用和其他微服务链接的问题上。</p>\n<p>图片来自Kong官网:</p>\n<p><img src=\"/image-108.png\" alt=\"Alt text\"><br>可以看到Kong解决的问题。专注于全局的Api管理策略，全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等。</p>\n<h4 id=\"Kong的优点以及性能\"><a href=\"#Kong的优点以及性能\" class=\"headerlink\" title=\"Kong的优点以及性能\"></a>Kong的优点以及性能</h4><p>在众多 API GATEWAY 框架中，Mashape 开源的高性能高可用API网关和API服务管理层——KONG（基于 NGINX+Lua）特点尤为突出，它可以通过插件扩展已有功能，这些插件（使用 lua 编写）在API请求响应循环的生命周期中被执行。于此同时，KONG本身提供包括 HTTP 基本认证、密钥认证、CORS、TCP、UDP、文件日志、API请求限流、请求转发及 NGINX 监控等基本功能。目前，Kong 在 Mashape 管理了超过 15，000 个 API，为 200，000 开发者提供了每月数十亿的请求支持。</p>\n<h4 id=\"Kong架构\"><a href=\"#Kong架构\" class=\"headerlink\" title=\"Kong架构\"></a>Kong架构</h4><p>Kong提供一些列的服务，这就不得不谈谈内部的架构:<br><img src=\"/image-109.png\" alt=\"Alt text\"><br>首先最底层是基于Nginx， Nginx是高性能的基础层， 一个良好的负载均衡、反向代理器，然后在此基础上增加Lua脚本库，形成了OpenResty，拦截请求， 响应生命周期，可以通过Lua编写脚本，所以插件比较丰富。</p>\n<p>关于Kong的一些插件库以及如何配置，可以参考简书:开源API网关系统（Kong教程）入门到精通：<a href=\"https://www.jianshu.com/p/a68e45bcadb6\">https://www.jianshu.com/p/a68e45bcadb6</a></p>\n<h3 id=\"3-Zuul1-0\"><a href=\"#3-Zuul1-0\" class=\"headerlink\" title=\"3. Zuul1.0\"></a>3. Zuul1.0</h3><p>Zuul是所有从设备和web站点到Netflix流媒体应用程序后端请求的前门。作为一个边缘服务应用程序，Zuul被构建来支持动态路由、监视、弹性和安全性。它还可以根据需要将请求路由到多个Amazon自动伸缩组。</p>\n<p>Zuul使用了一系列不同类型的过滤器，使我们能够快速灵活地将功能应用到服务中。</p>\n<h4 id=\"过滤器\"><a href=\"#过滤器\" class=\"headerlink\" title=\"过滤器\"></a>过滤器</h4><p>过滤器是Zuul的核心功能。它们负责应用程序的业务逻辑，可以执行各种任务。</p>\n<p>Type ：通常定义过滤器应用在哪个阶段</p>\n<p>Async ：定义过滤器是同步还是异步</p>\n<p>Execution Order ：执行顺序</p>\n<p>Criteria ：过滤器执行的条件</p>\n<p>Action ：如果条件满足，过滤器执行的动作</p>\n<p>Zuul提供了一个动态读取、编译和运行这些过滤器的框架。过滤器之间不直接通信，而是通过每个请求特有的RequestContext共享状态。</p>\n<p>下面是Zuul的一些过滤器:</p>\n<h4 id=\"Incoming\"><a href=\"#Incoming\" class=\"headerlink\" title=\"Incoming\"></a>Incoming</h4><p>Incoming过滤器在请求被代理到Origin之前执行。这通常是执行大部分业务逻辑的地方。例如:认证、动态路由、速率限制、DDoS保护、指标。</p>\n<h4 id=\"Endpoint\"><a href=\"#Endpoint\" class=\"headerlink\" title=\"Endpoint\"></a>Endpoint</h4><p>Endpoint过滤器负责基于incoming过滤器的执行来处理请求。Zuul有一个内置的过滤器（ProxyEndpoint），用于将请求代理到后端服务器，因此这些过滤器的典型用途是用于静态端点。例如:健康检查响应，静态错误响应，404响应。</p>\n<h4 id=\"Outgoing\"><a href=\"#Outgoing\" class=\"headerlink\" title=\"Outgoing\"></a>Outgoing</h4><p>Outgoing过滤器在从后端接收到响应以后执行处理操作。通常情况下，它们更多地用于形成响应和添加指标，而不是用于任何繁重的工作。例如:存储统计信息、添加&#x2F;剥离标准标题、向实时流发送事件、gziping响应。</p>\n<h4 id=\"过滤器类型\"><a href=\"#过滤器类型\" class=\"headerlink\" title=\"过滤器类型\"></a>过滤器类型</h4><p>下面是与一个请求典型的生命周期对应的标准的过滤器类型：</p>\n<p>PRE ：路由到Origin之前执行</p>\n<p>ROUTING ：路由到Origin期间执行</p>\n<p>POST ：请求被路由到Origin之后执行</p>\n<p>ERROR ：发生错误的时候执行</p>\n<p>这些过滤器帮助我们执行以下功能：</p>\n<p>身份验证和安全性 ：识别每个资源的身份验证需求，并拒绝不满足它们的请求</p>\n<p>监控 ：在边缘跟踪有意义的数据和统计数据，以便给我们一个准确的生产视图</p>\n<p>动态路由 ：动态路由请求到不同的后端集群</p>\n<p>压力测试 ：逐渐增加集群的流量，以评估性能</p>\n<p>限流 ：为每种请求类型分配容量，并丢弃超过限制的请求</p>\n<p>静态响应处理 ：直接在边缘构建一些响应，而不是将它们转发到内部集群</p>\n<h4 id=\"Zuul-1-0-请求生命周期\"><a href=\"#Zuul-1-0-请求生命周期\" class=\"headerlink\" title=\"Zuul 1.0 请求生命周期\"></a>Zuul 1.0 请求生命周期</h4><p><img src=\"/image-110.png\" alt=\"Alt text\"><br>Netflix宣布了通用API网关Zuul的架构转型。Zuul原本采用同步阻塞架构，转型后叫作Zuul2，采用异步非阻塞架构。Zuul2和Zuul1在架构方面的主要区别在于，Zuul2运行在异步非阻塞的框架上，比如Netty。Zuul1依赖多线程来支持吞吐量的增长，而Zuul 2使用的Netty框架依赖事件循环和回调函数。</p>\n<h3 id=\"4-Zuul2-0\"><a href=\"#4-Zuul2-0\" class=\"headerlink\" title=\"4. Zuul2.0\"></a>4. Zuul2.0</h3><p>Zuul 2.0 架构图<br><img src=\"/image-111.png\" alt=\"Alt text\"><br>上图是Zuul2的架构，和Zuul1没有本质区别，两点变化：</p>\n<p>前端用Netty Server代替Servlet，目的是支持前端异步。后端用Netty Client代替Http Client，目的是支持后端异步。</p>\n<p>过滤器换了一下名字，用Inbound Filters代替Pre-routing Filters，用Endpoint Filter代替Routing Filter，用Outbound Filters代替Post-routing Filters。</p>\n<p>Inbound Filters ：路由到 Origin 之前执行，可以用于身份验证、路由和装饰请求</p>\n<p>Endpoint Filters ：可用于返回静态响应，否则内置的ProxyEndpoint过滤器将请求路由到Origin</p>\n<p>Outbound Filters ：从Origin那里获取响应后执行，可以用于度量、装饰用户的响应或添加自定义header</p>\n<p>有两种类型的过滤器：sync 和 async。因为Zuul是运行在一个事件循环之上的，因此从来不要在过滤中阻塞。如果你非要阻塞，可以在一个异步过滤器中这样做，并且在一个单独的线程池上运行，否则可以使用同步过滤器。</p>\n<p>上文提到过Zuul2开始采用了异步模型</p>\n<p>优势 是异步非阻塞模式启动的线程很少，基本上一个CPU core上只需启一个事件环处理线程，它使用的线程资源就很少，上下文切换(Context Switch)开销也少。非阻塞模式可以接受的连接数大大增加，可以简单理解为请求来了只需要进队列，这个队列的容量可以设得很大，只要不超时，队列中的请求都会被依次处理。</p>\n<p>不足 ，异步模式让编程模型变得复杂。一方面Zuul2本身的代码要比Zuul1复杂很多，Zuul1的代码比较容易看懂，Zuul2的代码看起来就比较费劲。另一方面异步模型没有一个明确清晰的请求-&gt;处理-&gt;响应执行流程(call flow)，它的流程是通过事件触发的，请求处理的流程随时可能被切换断开，内部实现要通过一些关联id机制才能把整个执行流再串联起来，这就给开发调试运维引入了很多复杂性，比如你在IDE里头调试异步请求流就非常困难。另外ThreadLocal机制在这种异步模式下就不能简单工作，因为只有一个事件环线程，不是每个请求一个线程，也就没有线程局部的概念，所以对于CAT这种依赖于ThreadLocal才能工作的监控工具，调用链埋点就不好搞(实际可以工作但需要进行特殊处理)。</p>\n<p>总体上，异步非阻塞模式比较适用于IO密集型(IO bound)场景，这种场景下系统大部分时间在处理IO，CPU计算比较轻，少量事件环线程就能处理。</p>\n<h4 id=\"Zuul-与-Zuul-2-性能对比\"><a href=\"#Zuul-与-Zuul-2-性能对比\" class=\"headerlink\" title=\"Zuul 与 Zuul 2 性能对比\"></a>Zuul 与 Zuul 2 性能对比</h4><p><img src=\"/image-112.png\" alt=\"Alt text\"><br>Netflix给出了一个比较模糊的数据，大致Zuul2的性能比Zuul1好20%左右 ，这里的性能主要指每节点每秒处理的请求数。为什么说模糊呢？因为这个数据受实际测试环境，流量场景模式等众多因素影响，你很难复现这个测试数据。即便这个20%的性能提升是确实的，其实这个性能提升也并不大，和异步引入的复杂性相比，这20%的提升是否值得是个问题。Netflix本身在其博文22和ppt11中也是有点含糊其词，甚至自身都有一些疑问的。</p>\n<h3 id=\"5-Spring-Cloud-Gateway\"><a href=\"#5-Spring-Cloud-Gateway\" class=\"headerlink\" title=\"5. Spring Cloud Gateway\"></a>5. Spring Cloud Gateway</h3><p>SpringCloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。</p>\n<p>SpringCloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 2.0之前的非Reactor模式的老版本。而为了提升网关的性能，SpringCloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。</p>\n<p>Spring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控&#x2F;指标，和限流。</p>\n<p>Spring Cloud Gateway 底层使用了高性能的通信框架Netty 。</p>\n<p>SpringCloud Gateway 特征</p>\n<p>SpringCloud官方，对SpringCloud Gateway 特征介绍如下：</p>\n<p>（1）基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0</p>\n<p>（2）集成 Hystrix 断路器</p>\n<p>（3）集成 Spring Cloud DiscoveryClient</p>\n<p>（4）Predicates 和 Filters 作用于特定路由，易于编写的 Predicates 和 Filters</p>\n<p>（5）具备一些网关的高级功能：动态路由、限流、路径重写</p>\n<p>从以上的特征来说，和Zuul的特征差别不大。SpringCloud Gateway和Zuul主要的区别，还是在底层的通信框架上。</p>\n<p>简单说明一下上文中的三个术语：</p>\n<h4 id=\"Filter-（过滤器）\"><a href=\"#Filter-（过滤器）\" class=\"headerlink\" title=\"Filter （过滤器）\"></a>Filter （过滤器）</h4><p>和Zuul的过滤器在概念上类似，可以使用它拦截和修改请求，并且对上游的响应，进行二次处理。过滤器为org.springframework.cloud.gateway.filter.GatewayFilter类的实例。</p>\n<h4 id=\"Route-（路由）\"><a href=\"#Route-（路由）\" class=\"headerlink\" title=\"Route （路由）\"></a>Route （路由）</h4><p>网关配置的基本组成模块，和Zuul的路由配置模块类似。一个Route模块 由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。</p>\n<h4 id=\"Predicate-（断言）：\"><a href=\"#Predicate-（断言）：\" class=\"headerlink\" title=\"Predicate （断言）：\"></a>Predicate （断言）：</h4><p>这是一个 Java 8 的 Predicate，可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。断言的 输入类型是一个 ServerWebExchange。</p>\n<h3 id=\"几种网关的对比\"><a href=\"#几种网关的对比\" class=\"headerlink\" title=\"几种网关的对比\"></a>几种网关的对比</h3><p><img src=\"/image-113.png\" alt=\"Alt text\"><br>作者：等不到的口琴</p>\n<p>来源：&#x2F;&#x2F;<a href=\"http://www.cnblogs.com/Courage129/p/14446586.html\">www.cnblogs.com/Courage129/p/14446586.html</a></p>\n<p>版权申明：内容来源网络，仅供分享学习，版权归原创者所有。除非无法确认，我们都会标明作者及出处，如有侵权烦请告知，我们会立即删除并表示歉意。谢谢!</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>原文地址: <a href=\"https://blog.csdn.net/huangjinjin520/article/details/126863371\">https://blog.csdn.net/huangjinjin520/article/details/126863371</a></p>\n<h2 id=\"什么是网关\"><a href=\"#什么是网关\" class=\"headerlink\" title=\"什么是网关\"></a>什么是网关</h2><p>网关，很多地方将网关比如成门， 没什么问题， 但是需要区分网关与网桥的区别，</p>\n<p>网桥 工作在数据链路层，在不同或相同类型的LAN之间存储并转发数据帧，必要时进行链路层上的协议转换。可连接两个或多个网络，在其中传送信息包。</p>\n<p>网关 是一个大概念，不具体特指一类产品，只要连接两个不同的网络都可以叫网关，网桥一般只转发信息，而网关可能进行包装。</p>\n<h2 id=\"网关通俗理解\"><a href=\"#网关通俗理解\" class=\"headerlink\" title=\"网关通俗理解\"></a>网关通俗理解</h2><p>根据网关的特性，举个例子:</p>\n<p>假如你要去找集团老板(这儿只是举个例子)， 大家都知道老板肯定不是谁想见就能见的， 也怕坏人嘛， 那么你去老板所在的办公楼，假如是集团总部， 大楼这个门就充当了网关的角色， 大门一般都有看门员 ，看门员会做哪些事情呢?</p>\n<p>首先所有想见老板的人肯定都得从这个门进(统一入口 )， 这个门相当于将办公室和外界隔离了，主要为了保护里面的安全以及正常工作， 来到这个门之后， 门卫肯定会让你出示相关证件(鉴权检验 )， 意思就是判断你要见老板这个请求是否合理， 如果不合理直接就拒绝了， 让你回家等消息 ， 如果鉴权之后， 发现你找老板其实只是为了和他谈谈两元店的生意， 门卫会跟你说这个用不着找老板， 你去集团投资部就行了(动态路由 ， 将请求路由到不同的后端集群中)， 此时会对你进行一些包装 ，例如给你出具一个访问证类似的，然后告诉你路该怎么走，等等。</p>\n<p>你看看，网关的作用是不是就是这三个， 最终目的就是减少你与集团的耦合，具体到计算机上就是减少客户端与服务端的耦合，如果没有网关意味着所有请求都会直接调用服务器上的资源，这样耦合太强了，服务器出了问题，客户端会直接报错， 例如老板换工作的地方了，如果没有网关你直接去原来的地方找， 肯定会被告知老板不在这儿。</p>\n<h2 id=\"为什么需要网关\"><a href=\"#为什么需要网关\" class=\"headerlink\" title=\"为什么需要网关\"></a>为什么需要网关</h2><p>当使用单体应用程序架构时，客户端（Web 或移动端）通过向后端应用程序发起一次 REST 调用来获取数据。负载均衡器将请求路由给 N 个相同的应用程序实例中的一个。然后应用程序会查询各种数据库表，并将响应返回给客户端。微服务架构下，单体应用被切割成多个微服务，如果将所有的微服务直接对外暴露，势必会出现安全方面的各种问题，另外内外耦合严重。</p>\n<p>客户端可以直接向每个微服务发送请求，其问题主要如下：</p>\n<p>客户端需求和每个微服务暴露的细粒度 API 不匹配。</p>\n<p>部分服务使用的协议不是Web友好协议。可能使用 Thrift 二进制 RPC，也可能使用 AMQP 消息传递协议。</p>\n<p>微服务难以重构。如果合并两个服务，或者将一个服务拆分成两个或更多服务，这类重构就非常困难了。</p>\n<p>服务端的各个服务直接暴露给客户端调用势必会引起各种问题。同时，服务端的各个服务可扩展和伸缩性很差。API 网关是微服务架构中的基础组件，位于接入层之下和业务服务层之上，如前所述的这些功能适合在 API 网关实现。</p>\n<h2 id=\"网关与服务器集群\"><a href=\"#网关与服务器集群\" class=\"headerlink\" title=\"网关与服务器集群\"></a>网关与服务器集群</h2><p>回到我们服务器上，下面图介绍了网关(Gateway)作用，可知 Gateway 方式下的架构，可以细到为每一个服务的实例配置一个自己的 Gateway，也可以粗到为一组服务配置一个，甚至可以粗到为整个架构配置一个接入的 Gateway。于是，整个系统架构的复杂度就会变得简单可控起来。</p>\n<p><img src=\"/image-104.png\" alt=\"Alt text\"></p>\n<p>这张图展示了一个多层 Gateway 架构，其中有一个总的 Gateway 接入所有的流量(流量网关 )，并分发给不同的子系统，还有第二级 Gateway 用于做各个子系统的接入 Gateway(业务网关 )。可以看到，网关所管理的服务粒度可粗可细。通过网关，我们可以把分布式架构组织成一个星型架构，由网络对服务的请求进行路由和分发。下面来聊聊好的网关应该具备哪些功能，也就是网关设计模式。</p>\n<h2 id=\"网关设计思路\"><a href=\"#网关设计思路\" class=\"headerlink\" title=\"网关设计思路\"></a>网关设计思路</h2><p>一个网关需要有以下的功能:</p>\n<h3 id=\"1-请求路由\"><a href=\"#1-请求路由\" class=\"headerlink\" title=\"1. 请求路由\"></a>1. 请求路由</h3><p>网关一定要有请求路由的功能。这样一来，对于调用端来说，也是一件非常方便的事情。因为调用端不需要知道自己需要用到的其它服务的地址，全部统一地交给 Gateway 来处理。</p>\n<h3 id=\"2-服务注册\"><a href=\"#2-服务注册\" class=\"headerlink\" title=\"2. 服务注册\"></a>2. 服务注册</h3><p>为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些 API 接口。比如，HTTP 的 Restful 请求，可以注册相应 API 的 URI、方法、HTTP 头。这样，Gateway 就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。</p>\n<h3 id=\"3-负载均衡\"><a href=\"#3-负载均衡\" class=\"headerlink\" title=\"3. 负载均衡\"></a>3. 负载均衡</h3><p>因为一个网关可以接收多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单点就是直接 Round-Robin 轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到 session 粘连。</p>\n<h3 id=\"4-弹力设计\"><a href=\"#4-弹力设计\" class=\"headerlink\" title=\"4. 弹力设计\"></a>4. 弹力设计</h3><p>网关还可以把弹力设计中的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去。这样，同样可以像 Service Mesh 那样，让应用服务只关心自己的业务逻辑（或是说数据面上的事）而不是控制逻辑（控制面）。</p>\n<h3 id=\"5-安全方面\"><a href=\"#5-安全方面\" class=\"headerlink\" title=\"5. 安全方面\"></a>5. 安全方面</h3><p>SSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。错误处理越靠前的位置就是越好，所以，网关可以做到一个全站的接入组件来对后端的服务进行保护。当然，网关还可以做更多更有趣的事情，比如：灰度发布、API聚合、API编排。</p>\n<h4 id=\"灰度发布\"><a href=\"#灰度发布\" class=\"headerlink\" title=\"灰度发布\"></a>灰度发布</h4><p>网关完全可以做到对相同服务不同版本的实例进行导流，还可以收集相关的数据。这样对于软件质量的提升，甚至产品试错都有非常积极的意义。</p>\n<h4 id=\"API-聚合\"><a href=\"#API-聚合\" class=\"headerlink\" title=\"API 聚合\"></a>API 聚合</h4><p>使用网关可以将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。于是，我们可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）。</p>\n<h4 id=\"API-编排\"><a href=\"#API-编排\" class=\"headerlink\" title=\"API 编排\"></a>API 编排</h4><p>同样在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。</p>\n<h2 id=\"网关设计重点\"><a href=\"#网关设计重点\" class=\"headerlink\" title=\"网关设计重点\"></a>网关设计重点</h2><p>网关设计重点主要是三个， 高性能、高可用、高扩展:</p>\n<h3 id=\"1-高性能\"><a href=\"#1-高性能\" class=\"headerlink\" title=\"1. 高性能\"></a>1. 高性能</h3><p>在技术设计上，网关不应该也不能成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务一定要使用异步非阻塞的 I&#x2F;O 来确保后端延迟不会导致应用程序中出现性能问题。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I&#x2F;O Completion Port 的异步 IO 模型，Java 下如 Netty、Spring Reactor 的 NIO 框架。</p>\n<h3 id=\"2-高可用\"><a href=\"#2-高可用\" class=\"headerlink\" title=\"2. 高可用\"></a>2. 高可用</h3><p>因为所有的流量或调用经过网关，所以网关必须成为一个高可用的技术组件，它的稳定直接关系到了所有服务的稳定。网关如果没有设计，就会成变一个单点故障。因此，一个好的网关至少要做到以下几点。</p>\n<p>集群化 。网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。</p>\n<p>服务化 。网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置。</p>\n<p>持续化 。比如重启，就是像 Nginx 那样优雅地重启。有一个主管请求分发的主进程。当我们需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。</p>\n<h3 id=\"3-高扩展\"><a href=\"#3-高扩展\" class=\"headerlink\" title=\"3. 高扩展\"></a>3. 高扩展</h3><p>因为网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。而我们都知道，业务逻辑是多变和不确定的。比如，需要在网关上加入一些和业务相关的东西。因此，一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。</p>\n<p>另外，在运维方面 ，网关应该有以下几个设计原则。</p>\n<ul>\n<li><p>业务松耦合，协议紧耦合 。在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。</p>\n</li>\n<li><p>应用监视，提供分析数据 。网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用 Tracing ID 实施分布式链路跟踪，并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。</p>\n</li>\n<li><p>用弹力设计保护后端服务 。网关上一定要实现熔断、限流、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据。你可以考虑一下这样的设计。</p>\n</li>\n<li><p>DevOps 。因为网关这个组件太关键了，所以需要 DevOps 这样的东西，将其发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。</p>\n</li>\n</ul>\n<h2 id=\"网关设计注意事项\"><a href=\"#网关设计注意事项\" class=\"headerlink\" title=\"网关设计注意事项\"></a>网关设计注意事项</h2><ol>\n<li><p>不要在网关中的代码里内置聚合后端服务的功能，而应考虑将聚合服务放在网关核心代码之外。可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。</p>\n</li>\n<li><p>网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。这里多说一句，网关处理的静态内容应该靠近用户（应该放到 CDN 上），而网关和此时的动态服务应该靠近后端服务。</p>\n</li>\n<li><p>网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过 DNS 轮询的方式实现，要么通过 CDN 来做流量调度，或者通过更为底层的性能更高的负载均衡设备。</p>\n</li>\n<li><p>对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都去查一下相关的服务所在的地方。当然，如果你的系统不复杂，可以考虑把服务发现的功能直接集成进网关中。</p>\n</li>\n<li><p>为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。</p>\n</li>\n</ol>\n<p>另外，因为网关是为用户请求和后端服务的桥接装置，所以需要考虑一些安全方面的事宜。具体如下：</p>\n<ul>\n<li><p>加密数据 。可以把 SSL 相关的证书放到网关上，由网关做统一的 SSL 传输管理。</p>\n</li>\n<li><p>校验用户的请求 。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。但是，我们需要权衡一下，网关是否需要校验用户的输入。因为这样一来，网关就需要从只关心协议头，到需要关心协议体。而协议体中的东西一方面不像协议头是标准的，另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能。对此，我想说的是，看具体需求，一方面如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。</p>\n</li>\n<li><p>检测异常访问 。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；还比如，同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击。</p>\n</li>\n</ul>\n<h2 id=\"流量网关\"><a href=\"#流量网关\" class=\"headerlink\" title=\"流量网关\"></a>流量网关</h2><p>流量网关，顾名思义就是控制流量进入集群的网关，有很多工作需要在这一步做，对于一个服务集群，势必有很多非法的请求或者无效的请求，这时候要将请求拒之门外，降低集群的流量压力。<br><img src=\"/image-105.png\" alt=\"Alt text\"><br>定义全局性的、跟具体的后端业务应用和服务完全无关的策略网关就是上图所示的架构模型——流量网关。流量网关通常只专注于全局的Api管理策略，比如全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等，有点类似防火墙。Kong 就是典型的流量网关。</p>\n<p>下面是kong的架构图，来自官网：<a href=\"https://konghq.com/\">https://konghq.com</a><br><img src=\"/image-106.png\" alt=\"Alt text\"><br>这里需要补充一点的是，业务网关一般部署在流量网关之后、业务系统之前，比流量网关更靠近业务系统。通常API网指的是业务网关。有时候我们也会模糊流量网关和业务网关，让一个网关承担所有的工作，所以这两者之间并没有严格的界线。</p>\n<h2 id=\"业务网关\"><a href=\"#业务网关\" class=\"headerlink\" title=\"业务网关\"></a>业务网关</h2><p>当一个单体应用被拆分成许许多多的微服务应用后，也带来了一些问题。一些与业务非强相关的功能，比如权限控制、日志输出、数据加密、熔断限流等，每个微服务应用都需要，因此存在着大量重复的代码实现。而且由于系统的迭代、人员的更替，各个微服务中这些功能的实现细节出现了较大的差异，导致维护成本变高。另一方面，原先单体应用下非常容易做的接口管理，在服务拆分后没有了一个集中管理的地方，无法统计已存在哪些接口、接口定义是什么、运行状态如何。</p>\n<p>网关就是为了解决上述问题。作为微服务体系中的核心基础设施，一般需要具备接口管理、协议适配、熔断限流、安全防护等功能，各种开源的网关产品（比如 zuul）都提供了优秀高可扩展性的架构、可以很方便的实现我们需要的一些功能、比如鉴权、日志监控、熔断限流等。</p>\n<p>与流量网关相对应的就是业务网关，业务网关更靠近我们的业务，也就是与服务器应用层打交道，那么有很多应用层需要考虑的事情就可以依托业务网关，例如在线程模型、协议适配、熔断限流，服务编排等。下面看看业务网关体系结构:<br><img src=\"/image-107.png\" alt=\"Alt text\"><br>从这个途中可以看出业务网关主要职责以及所做的事情， 目前业务网关比较成熟的 API 网关框架产品有三个 分别是:Zuul1、Zuul2 和 SpringCloud Gateway， 后面再进行对比。</p>\n<h2 id=\"常见网关对比\"><a href=\"#常见网关对比\" class=\"headerlink\" title=\"常见网关对比\"></a>常见网关对比</h2><p>既然对比，就先宏观上对各种网关有一个了解，后面再挑一些常用的或者说应用广泛的详细了解。</p>\n<p>目前常见的开源网关大致上按照语言分类有如下几类：</p>\n<p>Nginx+lua ：OpenResty、Kong、Orange、Abtesting gateway 等</p>\n<p>Java ：Zuul&#x2F;Zuul2、Spring Cloud Gateway、Kaazing KWG、gravitee、Dromara soul 等</p>\n<p>Go ：Janus、fagongzi、Grpc-gateway</p>\n<p>Dotnet ：Ocelot</p>\n<p>NodeJS ：Express Gateway、Micro Gateway</p>\n<p>按照使用数量、成熟度等来划分，主流的有 5个：</p>\n<p>OpenResty</p>\n<p>Kong</p>\n<p>Zuul、Zuul2</p>\n<p>Spring Cloud Gateway</p>\n<h3 id=\"1-OpenResty\"><a href=\"#1-OpenResty\" class=\"headerlink\" title=\"1. OpenResty\"></a>1. OpenResty</h3><p>OpenResty是一个流量网关，根据前面对流量网关的介绍就可以知道流量网关的指责。</p>\n<p>OpenResty基于 Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。</p>\n<p>通过揉和众多设计良好的 Nginx 模块，OpenResty 有效地把 Nginx 服务器转变为一个强大的 Web 应用服务器，基于它开发人员可以使用 Lua 编程语言对 Nginx 核心以及现有的各种 Nginx C 模块进行脚本编程，构建出可以处理一万以上并发请求的极端高性能的 Web 应用</p>\n<p>OpenResty 最早是顺应 OpenAPI 的潮流做的，所以 Open 取自“开放”之意，而Resty便是 REST 风格的意思。虽然后来也可以基于 ngx_openresty 实现任何形式的 web service 或者传统的 web 应用。</p>\n<p>也就是说 Nginx 不再是一个简单的静态网页服务器，也不再是一个简单的反向代理了。第二代的 openresty 致力于通过一系列 nginx 模块，把nginx扩展为全功能的 web 应用服务器。</p>\n<p>ngx_openresty 是用户驱动的项目，后来也有不少国内用户的参与，从 openresty.org 的点击量分布上看，国内和国外的点击量基本持平。</p>\n<p>ngx_openresty 目前有两大应用目标：</p>\n<p>通用目的的 web 应用服务器。在这个目标下，现有的 web 应用技术都可以算是和 OpenResty 或多或少有些类似，比如 Nodejs， PHP 等等。ngx_openresty 的性能（包括内存使用和 CPU 效率）算是最大的卖点之一。</p>\n<p>Nginx 的脚本扩展编程，用于构建灵活的 Web 应用网关和 Web 应用防火墙。有些类似的是 NetScaler。其优势在于 Lua 编程带来的巨大灵活性。</p>\n<h3 id=\"2-Kong\"><a href=\"#2-Kong\" class=\"headerlink\" title=\"2. Kong\"></a>2. Kong</h3><p>Kong基于OpenResty开发，也是流量层网关， 是一个云原生、快速、可扩展、分布式的Api 网关。继承了OpenResty的高性能、易扩展性等特点。Kong通过简单的增加机器节点，可以很容易的水平扩展。同时功能插件化，可通过插件来扩展其能力。而且在任何基础架构上都可以运行。具有以下特性：</p>\n<p>提供了多样化的认证层来保护Api。</p>\n<p>可对出入流量进行管制。</p>\n<p>提供了可视化的流量检查、监视分析Api。</p>\n<p>能够及时的转换请求和相应。</p>\n<p>提供log解决方案</p>\n<p>可通过api调用Serverless 函数。</p>\n<h4 id=\"Kong解决了什么问题\"><a href=\"#Kong解决了什么问题\" class=\"headerlink\" title=\"Kong解决了什么问题\"></a>Kong解决了什么问题</h4><p>当我们决定对应用进行微服务改造时，应用客户端如何与微服务交互的问题也随之而来，毕竟服务数量的增加会直接导致部署授权、负载均衡、通信管理、分析和改变的难度增加。</p>\n<p>面对以上问题，API GATEWAY是一个不错的解决方案，其所提供的访问限制、安全、流量控制、分析监控、日志、请求转发、合成和协议转换功能，可以解放开发者去把精力集中在具体逻辑的代码，而不是把时间花费在考虑如何解决应用和其他微服务链接的问题上。</p>\n<p>图片来自Kong官网:</p>\n<p><img src=\"/image-108.png\" alt=\"Alt text\"><br>可以看到Kong解决的问题。专注于全局的Api管理策略，全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等。</p>\n<h4 id=\"Kong的优点以及性能\"><a href=\"#Kong的优点以及性能\" class=\"headerlink\" title=\"Kong的优点以及性能\"></a>Kong的优点以及性能</h4><p>在众多 API GATEWAY 框架中，Mashape 开源的高性能高可用API网关和API服务管理层——KONG（基于 NGINX+Lua）特点尤为突出，它可以通过插件扩展已有功能，这些插件（使用 lua 编写）在API请求响应循环的生命周期中被执行。于此同时，KONG本身提供包括 HTTP 基本认证、密钥认证、CORS、TCP、UDP、文件日志、API请求限流、请求转发及 NGINX 监控等基本功能。目前，Kong 在 Mashape 管理了超过 15，000 个 API，为 200，000 开发者提供了每月数十亿的请求支持。</p>\n<h4 id=\"Kong架构\"><a href=\"#Kong架构\" class=\"headerlink\" title=\"Kong架构\"></a>Kong架构</h4><p>Kong提供一些列的服务，这就不得不谈谈内部的架构:<br><img src=\"/image-109.png\" alt=\"Alt text\"><br>首先最底层是基于Nginx， Nginx是高性能的基础层， 一个良好的负载均衡、反向代理器，然后在此基础上增加Lua脚本库，形成了OpenResty，拦截请求， 响应生命周期，可以通过Lua编写脚本，所以插件比较丰富。</p>\n<p>关于Kong的一些插件库以及如何配置，可以参考简书:开源API网关系统（Kong教程）入门到精通：<a href=\"https://www.jianshu.com/p/a68e45bcadb6\">https://www.jianshu.com/p/a68e45bcadb6</a></p>\n<h3 id=\"3-Zuul1-0\"><a href=\"#3-Zuul1-0\" class=\"headerlink\" title=\"3. Zuul1.0\"></a>3. Zuul1.0</h3><p>Zuul是所有从设备和web站点到Netflix流媒体应用程序后端请求的前门。作为一个边缘服务应用程序，Zuul被构建来支持动态路由、监视、弹性和安全性。它还可以根据需要将请求路由到多个Amazon自动伸缩组。</p>\n<p>Zuul使用了一系列不同类型的过滤器，使我们能够快速灵活地将功能应用到服务中。</p>\n<h4 id=\"过滤器\"><a href=\"#过滤器\" class=\"headerlink\" title=\"过滤器\"></a>过滤器</h4><p>过滤器是Zuul的核心功能。它们负责应用程序的业务逻辑，可以执行各种任务。</p>\n<p>Type ：通常定义过滤器应用在哪个阶段</p>\n<p>Async ：定义过滤器是同步还是异步</p>\n<p>Execution Order ：执行顺序</p>\n<p>Criteria ：过滤器执行的条件</p>\n<p>Action ：如果条件满足，过滤器执行的动作</p>\n<p>Zuul提供了一个动态读取、编译和运行这些过滤器的框架。过滤器之间不直接通信，而是通过每个请求特有的RequestContext共享状态。</p>\n<p>下面是Zuul的一些过滤器:</p>\n<h4 id=\"Incoming\"><a href=\"#Incoming\" class=\"headerlink\" title=\"Incoming\"></a>Incoming</h4><p>Incoming过滤器在请求被代理到Origin之前执行。这通常是执行大部分业务逻辑的地方。例如:认证、动态路由、速率限制、DDoS保护、指标。</p>\n<h4 id=\"Endpoint\"><a href=\"#Endpoint\" class=\"headerlink\" title=\"Endpoint\"></a>Endpoint</h4><p>Endpoint过滤器负责基于incoming过滤器的执行来处理请求。Zuul有一个内置的过滤器（ProxyEndpoint），用于将请求代理到后端服务器，因此这些过滤器的典型用途是用于静态端点。例如:健康检查响应，静态错误响应，404响应。</p>\n<h4 id=\"Outgoing\"><a href=\"#Outgoing\" class=\"headerlink\" title=\"Outgoing\"></a>Outgoing</h4><p>Outgoing过滤器在从后端接收到响应以后执行处理操作。通常情况下，它们更多地用于形成响应和添加指标，而不是用于任何繁重的工作。例如:存储统计信息、添加&#x2F;剥离标准标题、向实时流发送事件、gziping响应。</p>\n<h4 id=\"过滤器类型\"><a href=\"#过滤器类型\" class=\"headerlink\" title=\"过滤器类型\"></a>过滤器类型</h4><p>下面是与一个请求典型的生命周期对应的标准的过滤器类型：</p>\n<p>PRE ：路由到Origin之前执行</p>\n<p>ROUTING ：路由到Origin期间执行</p>\n<p>POST ：请求被路由到Origin之后执行</p>\n<p>ERROR ：发生错误的时候执行</p>\n<p>这些过滤器帮助我们执行以下功能：</p>\n<p>身份验证和安全性 ：识别每个资源的身份验证需求，并拒绝不满足它们的请求</p>\n<p>监控 ：在边缘跟踪有意义的数据和统计数据，以便给我们一个准确的生产视图</p>\n<p>动态路由 ：动态路由请求到不同的后端集群</p>\n<p>压力测试 ：逐渐增加集群的流量，以评估性能</p>\n<p>限流 ：为每种请求类型分配容量，并丢弃超过限制的请求</p>\n<p>静态响应处理 ：直接在边缘构建一些响应，而不是将它们转发到内部集群</p>\n<h4 id=\"Zuul-1-0-请求生命周期\"><a href=\"#Zuul-1-0-请求生命周期\" class=\"headerlink\" title=\"Zuul 1.0 请求生命周期\"></a>Zuul 1.0 请求生命周期</h4><p><img src=\"/image-110.png\" alt=\"Alt text\"><br>Netflix宣布了通用API网关Zuul的架构转型。Zuul原本采用同步阻塞架构，转型后叫作Zuul2，采用异步非阻塞架构。Zuul2和Zuul1在架构方面的主要区别在于，Zuul2运行在异步非阻塞的框架上，比如Netty。Zuul1依赖多线程来支持吞吐量的增长，而Zuul 2使用的Netty框架依赖事件循环和回调函数。</p>\n<h3 id=\"4-Zuul2-0\"><a href=\"#4-Zuul2-0\" class=\"headerlink\" title=\"4. Zuul2.0\"></a>4. Zuul2.0</h3><p>Zuul 2.0 架构图<br><img src=\"/image-111.png\" alt=\"Alt text\"><br>上图是Zuul2的架构，和Zuul1没有本质区别，两点变化：</p>\n<p>前端用Netty Server代替Servlet，目的是支持前端异步。后端用Netty Client代替Http Client，目的是支持后端异步。</p>\n<p>过滤器换了一下名字，用Inbound Filters代替Pre-routing Filters，用Endpoint Filter代替Routing Filter，用Outbound Filters代替Post-routing Filters。</p>\n<p>Inbound Filters ：路由到 Origin 之前执行，可以用于身份验证、路由和装饰请求</p>\n<p>Endpoint Filters ：可用于返回静态响应，否则内置的ProxyEndpoint过滤器将请求路由到Origin</p>\n<p>Outbound Filters ：从Origin那里获取响应后执行，可以用于度量、装饰用户的响应或添加自定义header</p>\n<p>有两种类型的过滤器：sync 和 async。因为Zuul是运行在一个事件循环之上的，因此从来不要在过滤中阻塞。如果你非要阻塞，可以在一个异步过滤器中这样做，并且在一个单独的线程池上运行，否则可以使用同步过滤器。</p>\n<p>上文提到过Zuul2开始采用了异步模型</p>\n<p>优势 是异步非阻塞模式启动的线程很少，基本上一个CPU core上只需启一个事件环处理线程，它使用的线程资源就很少，上下文切换(Context Switch)开销也少。非阻塞模式可以接受的连接数大大增加，可以简单理解为请求来了只需要进队列，这个队列的容量可以设得很大，只要不超时，队列中的请求都会被依次处理。</p>\n<p>不足 ，异步模式让编程模型变得复杂。一方面Zuul2本身的代码要比Zuul1复杂很多，Zuul1的代码比较容易看懂，Zuul2的代码看起来就比较费劲。另一方面异步模型没有一个明确清晰的请求-&gt;处理-&gt;响应执行流程(call flow)，它的流程是通过事件触发的，请求处理的流程随时可能被切换断开，内部实现要通过一些关联id机制才能把整个执行流再串联起来，这就给开发调试运维引入了很多复杂性，比如你在IDE里头调试异步请求流就非常困难。另外ThreadLocal机制在这种异步模式下就不能简单工作，因为只有一个事件环线程，不是每个请求一个线程，也就没有线程局部的概念，所以对于CAT这种依赖于ThreadLocal才能工作的监控工具，调用链埋点就不好搞(实际可以工作但需要进行特殊处理)。</p>\n<p>总体上，异步非阻塞模式比较适用于IO密集型(IO bound)场景，这种场景下系统大部分时间在处理IO，CPU计算比较轻，少量事件环线程就能处理。</p>\n<h4 id=\"Zuul-与-Zuul-2-性能对比\"><a href=\"#Zuul-与-Zuul-2-性能对比\" class=\"headerlink\" title=\"Zuul 与 Zuul 2 性能对比\"></a>Zuul 与 Zuul 2 性能对比</h4><p><img src=\"/image-112.png\" alt=\"Alt text\"><br>Netflix给出了一个比较模糊的数据，大致Zuul2的性能比Zuul1好20%左右 ，这里的性能主要指每节点每秒处理的请求数。为什么说模糊呢？因为这个数据受实际测试环境，流量场景模式等众多因素影响，你很难复现这个测试数据。即便这个20%的性能提升是确实的，其实这个性能提升也并不大，和异步引入的复杂性相比，这20%的提升是否值得是个问题。Netflix本身在其博文22和ppt11中也是有点含糊其词，甚至自身都有一些疑问的。</p>\n<h3 id=\"5-Spring-Cloud-Gateway\"><a href=\"#5-Spring-Cloud-Gateway\" class=\"headerlink\" title=\"5. Spring Cloud Gateway\"></a>5. Spring Cloud Gateway</h3><p>SpringCloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。</p>\n<p>SpringCloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 2.0之前的非Reactor模式的老版本。而为了提升网关的性能，SpringCloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。</p>\n<p>Spring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控&#x2F;指标，和限流。</p>\n<p>Spring Cloud Gateway 底层使用了高性能的通信框架Netty 。</p>\n<p>SpringCloud Gateway 特征</p>\n<p>SpringCloud官方，对SpringCloud Gateway 特征介绍如下：</p>\n<p>（1）基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0</p>\n<p>（2）集成 Hystrix 断路器</p>\n<p>（3）集成 Spring Cloud DiscoveryClient</p>\n<p>（4）Predicates 和 Filters 作用于特定路由，易于编写的 Predicates 和 Filters</p>\n<p>（5）具备一些网关的高级功能：动态路由、限流、路径重写</p>\n<p>从以上的特征来说，和Zuul的特征差别不大。SpringCloud Gateway和Zuul主要的区别，还是在底层的通信框架上。</p>\n<p>简单说明一下上文中的三个术语：</p>\n<h4 id=\"Filter-（过滤器）\"><a href=\"#Filter-（过滤器）\" class=\"headerlink\" title=\"Filter （过滤器）\"></a>Filter （过滤器）</h4><p>和Zuul的过滤器在概念上类似，可以使用它拦截和修改请求，并且对上游的响应，进行二次处理。过滤器为org.springframework.cloud.gateway.filter.GatewayFilter类的实例。</p>\n<h4 id=\"Route-（路由）\"><a href=\"#Route-（路由）\" class=\"headerlink\" title=\"Route （路由）\"></a>Route （路由）</h4><p>网关配置的基本组成模块，和Zuul的路由配置模块类似。一个Route模块 由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。</p>\n<h4 id=\"Predicate-（断言）：\"><a href=\"#Predicate-（断言）：\" class=\"headerlink\" title=\"Predicate （断言）：\"></a>Predicate （断言）：</h4><p>这是一个 Java 8 的 Predicate，可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。断言的 输入类型是一个 ServerWebExchange。</p>\n<h3 id=\"几种网关的对比\"><a href=\"#几种网关的对比\" class=\"headerlink\" title=\"几种网关的对比\"></a>几种网关的对比</h3><p><img src=\"/image-113.png\" alt=\"Alt text\"><br>作者：等不到的口琴</p>\n<p>来源：&#x2F;&#x2F;<a href=\"http://www.cnblogs.com/Courage129/p/14446586.html\">www.cnblogs.com/Courage129/p/14446586.html</a></p>\n<p>版权申明：内容来源网络，仅供分享学习，版权归原创者所有。除非无法确认，我们都会标明作者及出处，如有侵权烦请告知，我们会立即删除并表示歉意。谢谢!</p>\n"},{"title":"计算机网络（1-3层）详解","date":"2023-11-03T02:17:24.000Z","_content":"计算机被发明出来使用很长时间，都是作为一个独立的个体来使用的，直到后来美国国防部的高级研究计划局（ARPA）计划建设一个军用网，叫做“阿帕网”（ARPAnet），阿帕网于1969年正式启用，当时仅连接了4台计算机，供科学家们进行计算机联网实验使用，直到那时候才开始出现计算机网络的概念。\n\n今天我们就来聊聊计算机组网的那点事儿\n\n第一层（物理层）\n\n从计算机组网的角度来说，将两台计算机通过网线相连，就是一个简单的网络结构，如图所示：\n\n![Alt text](image-120.png)\n但是在实际网络环境中，接入网络的计算机不可能只有两台，那么在有很多台计算机的情况下，我们该如何连接呢？\n\n为此我们发明了一个中间设备，将计算机的网线都插到这个设备上，由这个设备做转发，这样彼此之间就可以通信了。\n\n这个中间设备的名子就叫集线器（俗称HUB）,它的功能非常简单，仅仅是将任意一个接口接受到的电信号转发到所有出口（广播），不做任何处理，因此将他定位为物理层设备。\n\n但是这种转发方式会引起一个新的问题，由于转发到了所有出口，那接在集线器下的其他设备都能接受到数据，那么怎么判断数据是不是发给自己的。\n\n![Alt text](image-121.png)\n这儿就引入一个新的名词，MAC地址，正常情况下MAC地址是全局唯一的标识，全世界独一无二，给每一个设备都配一个MAC地址，这样，A 在发送数据包给 B 时，只要在头部拼接一个源目MAC地址就可以解决此问题了。B 在收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包的确是发给自己的，于是便收下。其他的计算机收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包并不是发给自己的，于是便丢弃。虽然集线器使整个网络布局简单明了，但会出现一个新的问题，原来我只要发给电脑B的消息，现在却要发给连接到集线器中的所有电脑，这样既不安全，又浪费宝贵带宽资源。\n\n第二层（数据链路层）\n\n在第一层中，我们最后虽然解决了多台计算机的组网需求，但最后却留下了问题，即集线器的使用不仅有安全隐患，而且浪费有限的带宽资源。那第二层的主要目标就是解决安全隐患以及带宽浪费的问题，把这个集线器弄得更智能一些，想要将数据发送到那一台设备，就只发给目标 MAC 地址指向的那台电脑，就好了。\n![Alt text](image-122.png)\n\n所以一个全新的设备出现了，这东西就叫做交换机。它能够实现你将数据发送到指定的设备而不会转发到所有出口（广播）的情况，因此将他定位为数据链路层设备。每一台交换机内部维护一张 MAC 地址表，记录着每一个设备的 MAC 地址，连接在其哪一个端口上。\n\n|MAC 地址|\t端口|\n|:------|:------|\nbb-bb-bb-bb-bb-bb|\t1\ncc-cc-cc-cc-cc-cc|\t3\naa-aa-aa-aa-aa-aa|\t4\ndd-dd-dd-dd-dd-dd|\t5\n\n这种情况下，假如你仍然要发给 B 一个数据包，构造了如下的数据结构从网口出去。\n![Alt text](image-123.png)\n\n到达交换机时，交换机内部通过自己维护的 MAC 地址表，发现目标机器 B 的 MAC 地址 bb-bb-bb-bb-bb-bb 映射到了端口 1 上，于是把数据从 1 号端口发给了 B，一次数据转发完成。而以这样传输方式组成的小范围的网络，叫做以太网。当然刚开始的时候，MAC 地址表是空的，那MAC地址表是如何建立起来的呢？假如刚开始交换机 MAC 地址表是空的，你给 B 发送了如下数据：\n\n![Alt text](image-124.png)\n由于这个包从端口 4 进入的交换机，所以此时交换机就可以在 MAC地址表记录第一条数据：\n\n|MAC 地址|\t端口\n|:------|:------|\naa-aa-aa-aa-aa-aa-aa|\t4\n\n交换机看目标 MAC 地址（bb-bb-bb-bb-bb-bb）在地址表中并没有映射关系，于是将此包发给了所有端口，即广播发送。之后，只有机器 B 收到了确实是发给自己的包，于是做出了响应，响应数据从端口 1 进入交换机，于是交换机此时在地址表中更新了第二条数据：\n\n|MAC 地址|\t端口|\n|:------|:------|\naa-aa-aa-aa-aa-aa-aa|\t4\nbb-bb-bb-bb-bb-bb|\t1\n\n经过该网络中的机器不断通信，交换机最终将 MAC 地址表建立完毕~\n\n最直观的展示过程：\n![Alt text](image-125.png)\n\n通过此种方法我们就成功的建立了一个相对安全，也比较智能的局域互联网络，通过此网络我们可以在几台计算机之间分享数据，但是很快新的问题又出现了。随着机器数量越多，一台交换机的端口不够了，我们能想到的最简单的办法，就是将多个交换机连接起来，解决这 个问题，事实上还真的可以，但是这样真的没有问题吗？\n![Alt text](image-126.png)\n\n需要注意的是，上面那根红色的线，最终在 MAC 地址表中可不是一条记录，而是要把 EFGH 这四台机器与该端口（端口6）的映射全部记录在表中。最终，两个交换机将分别记录 A ~ H 所有机器的映射记录。\n\n左边的交换机\n\n|MAC 地址|\t端口|\n|:------|:------|\nbb-bb-bb-bb-bb-bb|\t1\ncc-cc-cc-cc-cc-cc|\t3\naa-aa-aa-aa-aa-aa|\t4\ndd-dd-dd-dd-dd-dd|\t5\nee-ee-ee-ee-ee-ee|\t6\nff-ff-ff-ff-ff-ff|\t6\ngg-gg-gg-gg-gg-gg|\t6\nhh-hh-hh-hh-hh-hh|\t6\n\n\n右边的交换机\n\n|MAC 地址|\t端口|\n|:------|:------|\nbb-bb-bb-bb-bb-bb|\t1\ncc-cc-cc-cc-cc-cc|\t1\naa-aa-aa-aa-aa-aa|\t1\ndd-dd-dd-dd-dd-dd|\t1\nee-ee-ee-ee-ee-ee|\t2\nff-ff-ff-ff-ff-ff|\t3\ngg-gg-gg-gg-gg-gg|\t4\nhh-hh-hh-hh-hh-hh|\t6\n\n\n这种设计方式，在计算机数量不多的情况下是可以正常使用的，但是当接入的计算机数量太多，交换机就无法维护如此巨大的表了。\n\n第三层（网络层）\n\n在第二层中问题的根本在于，连出去的那根红色的网线，后面不知道有多少个设备不断地连接进来，从而使得地址表越来越大。\n![Alt text](image-127.png)\n\n解决的办法就是，再接入一个新的设备，这个设备有自己独立的 MAC 地址同时还能把所有流经的数据包做一次转发，这个设备就是路由器，并将它定在了网络层。现在交换机的 MAC 地址表中，只需要多出一条 MAC 地址 ABAB 与其端口的映射关系，就可以成功把数据包转交给路由器了，而后由路由器转发到其他设备。但是这儿由出现了一个新的问题，那就是如何做到将发送的数据先发送给路由器呢？\n\n为了解决这个问题，我们又发明了一个新的工具，IP 地址。现在每一台电脑，同时有自己的 MAC 地址，又有自己的 IP 地址，只不过 IP 地址是软件层面上的，可以随时修改，MAC 地址一般是无法修改的。这样一个可以随时修改的 IP 地址，就可以根据你规划的网络拓扑结构来调整了。\n![Alt text](image-128.png)\n\n如上图所示，假如我想要发送数据包给 ABCD 其中一台设备，不论哪一台，我都可以这样描述，\"将 IP 地址为 192.168.0 开头的全部发送给到路由器，之后再怎么转发，交给它！那交给路由器之后，路由器又是怎么把数据包准确转发给指定设备的呢？\n\n我们先给上面的组网方式中的每一台设备，加上自己的 IP 地址\n\n![Alt text](image-129.png)\n现在两个设备之间传输，除了加上数据链路层的头部之外，还要再增加一个网络层的头部。假如 A 给 B 发送数据，由于它们直接连着交换机，所以 A 直接发出数据包即可，网络层的功能没有体现出作用。但假如 A 给 C 发送数据，A 就需要先转交给路由器，然后再由路由器转交给 C。由于最底层的传输仍然需要依赖以太网，所以数据包是分成两段的。\n\nA-路由器这段的包如下：\n![Alt text](image-130.png)\n\n路由器-C这段的包如下：\n\n![Alt text](image-131.png)\nA 给 C 发数据包，首先判断源 IP与目的IP是否处于一个子网，如果处于同一个子网，直接将包通过交换机发出，如果源 IP 与目的 IP 不处于一个子网，就交给路由器去处理，这里又有一个新的问题，那就是A 如何知道，哪个设备是路由器呢？答案就是你提前需要在 A 上设置路由器的地址，而这个地址我们叫他默认网关。现在数据已经可以成功发到路由器这里了，最后一个问题就是，路由器如何知道，收到的这个数据包，该从自己的哪个端口出去，才能直接（或间接）地最终到达目的地 C 呢。\n\n这儿就又出现了一张新的表，叫做路由表。至于这个路由表是怎么出来的，可以通过手动的方式指定，也可以通过路由算法自动生成，本文不展开讲述，因为这又是一个庞大的体系。不同于 MAC 地址表的是，路由表并不是一对一这种明确关系，我们下面看一个路由表的结构。\n\n|目的地址|\t子网掩码|\t下一跳|\t端口|\n|:------|:------|:------|:------|\n192.168.0.0|\t255.255.255.0| |\t\t0\n192.168.0.254|\t255.255.255.255| |\t\t0\n192.168.1.0|\t255.255.255.0| |\t\t1\n192.168.1.254|\t255.255.255.255| |\t\t1\n\n\n上表表示，http://192.168.0.xxx 这个子网下的，都转发到 0 号端口，http://192.168.1.xxx 这个子网下的，都转发到 1 号端口。但是这儿又有一个新的麻烦出现了。\n\n现在我们知道要发送数据的目标主机IP地址，但发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？又出现一个新的名词arp，在网络层，我需要把 IP 地址对应的 MAC 地址找到， 这种方式就是 arp 协议，同时电脑每一台电脑里面也会有一张 arp 缓存表，表中记录着 IP 与 MAC 地址的对应关系。\n\n|IP 地址|\tMAC 地址|\n|:------|:------|\n192.168.0.2\t|BBBB\n\n刚开始的时候这个表是空的，电脑 A 为了知道电脑 B的 MAC 地址，将会广播一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个响应。此时 A 便更新了自己的 arp 表。这样通过大家不断广播 arp 请求，最终所有电脑里面都将 arp 缓存表更新完整。\n\n至此一个数据成功的从一个网段转发到另一个网段，复杂的网络是由一个个小型的网络组合而成的，将N个局域网连接到一起可不就是互联网嘛。\n\n原文地址:https://zhuanlan.zhihu.com/p/433393781","source":"_posts/kubernetes/internet-1-3.md","raw":"---\ntitle: 计算机网络（1-3层）详解\ndate: 2023-11-03 10:17:24\ncategories:\n  - [kubernetes]\ntags: 计算机网络\n---\n计算机被发明出来使用很长时间，都是作为一个独立的个体来使用的，直到后来美国国防部的高级研究计划局（ARPA）计划建设一个军用网，叫做“阿帕网”（ARPAnet），阿帕网于1969年正式启用，当时仅连接了4台计算机，供科学家们进行计算机联网实验使用，直到那时候才开始出现计算机网络的概念。\n\n今天我们就来聊聊计算机组网的那点事儿\n\n第一层（物理层）\n\n从计算机组网的角度来说，将两台计算机通过网线相连，就是一个简单的网络结构，如图所示：\n\n![Alt text](image-120.png)\n但是在实际网络环境中，接入网络的计算机不可能只有两台，那么在有很多台计算机的情况下，我们该如何连接呢？\n\n为此我们发明了一个中间设备，将计算机的网线都插到这个设备上，由这个设备做转发，这样彼此之间就可以通信了。\n\n这个中间设备的名子就叫集线器（俗称HUB）,它的功能非常简单，仅仅是将任意一个接口接受到的电信号转发到所有出口（广播），不做任何处理，因此将他定位为物理层设备。\n\n但是这种转发方式会引起一个新的问题，由于转发到了所有出口，那接在集线器下的其他设备都能接受到数据，那么怎么判断数据是不是发给自己的。\n\n![Alt text](image-121.png)\n这儿就引入一个新的名词，MAC地址，正常情况下MAC地址是全局唯一的标识，全世界独一无二，给每一个设备都配一个MAC地址，这样，A 在发送数据包给 B 时，只要在头部拼接一个源目MAC地址就可以解决此问题了。B 在收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包的确是发给自己的，于是便收下。其他的计算机收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包并不是发给自己的，于是便丢弃。虽然集线器使整个网络布局简单明了，但会出现一个新的问题，原来我只要发给电脑B的消息，现在却要发给连接到集线器中的所有电脑，这样既不安全，又浪费宝贵带宽资源。\n\n第二层（数据链路层）\n\n在第一层中，我们最后虽然解决了多台计算机的组网需求，但最后却留下了问题，即集线器的使用不仅有安全隐患，而且浪费有限的带宽资源。那第二层的主要目标就是解决安全隐患以及带宽浪费的问题，把这个集线器弄得更智能一些，想要将数据发送到那一台设备，就只发给目标 MAC 地址指向的那台电脑，就好了。\n![Alt text](image-122.png)\n\n所以一个全新的设备出现了，这东西就叫做交换机。它能够实现你将数据发送到指定的设备而不会转发到所有出口（广播）的情况，因此将他定位为数据链路层设备。每一台交换机内部维护一张 MAC 地址表，记录着每一个设备的 MAC 地址，连接在其哪一个端口上。\n\n|MAC 地址|\t端口|\n|:------|:------|\nbb-bb-bb-bb-bb-bb|\t1\ncc-cc-cc-cc-cc-cc|\t3\naa-aa-aa-aa-aa-aa|\t4\ndd-dd-dd-dd-dd-dd|\t5\n\n这种情况下，假如你仍然要发给 B 一个数据包，构造了如下的数据结构从网口出去。\n![Alt text](image-123.png)\n\n到达交换机时，交换机内部通过自己维护的 MAC 地址表，发现目标机器 B 的 MAC 地址 bb-bb-bb-bb-bb-bb 映射到了端口 1 上，于是把数据从 1 号端口发给了 B，一次数据转发完成。而以这样传输方式组成的小范围的网络，叫做以太网。当然刚开始的时候，MAC 地址表是空的，那MAC地址表是如何建立起来的呢？假如刚开始交换机 MAC 地址表是空的，你给 B 发送了如下数据：\n\n![Alt text](image-124.png)\n由于这个包从端口 4 进入的交换机，所以此时交换机就可以在 MAC地址表记录第一条数据：\n\n|MAC 地址|\t端口\n|:------|:------|\naa-aa-aa-aa-aa-aa-aa|\t4\n\n交换机看目标 MAC 地址（bb-bb-bb-bb-bb-bb）在地址表中并没有映射关系，于是将此包发给了所有端口，即广播发送。之后，只有机器 B 收到了确实是发给自己的包，于是做出了响应，响应数据从端口 1 进入交换机，于是交换机此时在地址表中更新了第二条数据：\n\n|MAC 地址|\t端口|\n|:------|:------|\naa-aa-aa-aa-aa-aa-aa|\t4\nbb-bb-bb-bb-bb-bb|\t1\n\n经过该网络中的机器不断通信，交换机最终将 MAC 地址表建立完毕~\n\n最直观的展示过程：\n![Alt text](image-125.png)\n\n通过此种方法我们就成功的建立了一个相对安全，也比较智能的局域互联网络，通过此网络我们可以在几台计算机之间分享数据，但是很快新的问题又出现了。随着机器数量越多，一台交换机的端口不够了，我们能想到的最简单的办法，就是将多个交换机连接起来，解决这 个问题，事实上还真的可以，但是这样真的没有问题吗？\n![Alt text](image-126.png)\n\n需要注意的是，上面那根红色的线，最终在 MAC 地址表中可不是一条记录，而是要把 EFGH 这四台机器与该端口（端口6）的映射全部记录在表中。最终，两个交换机将分别记录 A ~ H 所有机器的映射记录。\n\n左边的交换机\n\n|MAC 地址|\t端口|\n|:------|:------|\nbb-bb-bb-bb-bb-bb|\t1\ncc-cc-cc-cc-cc-cc|\t3\naa-aa-aa-aa-aa-aa|\t4\ndd-dd-dd-dd-dd-dd|\t5\nee-ee-ee-ee-ee-ee|\t6\nff-ff-ff-ff-ff-ff|\t6\ngg-gg-gg-gg-gg-gg|\t6\nhh-hh-hh-hh-hh-hh|\t6\n\n\n右边的交换机\n\n|MAC 地址|\t端口|\n|:------|:------|\nbb-bb-bb-bb-bb-bb|\t1\ncc-cc-cc-cc-cc-cc|\t1\naa-aa-aa-aa-aa-aa|\t1\ndd-dd-dd-dd-dd-dd|\t1\nee-ee-ee-ee-ee-ee|\t2\nff-ff-ff-ff-ff-ff|\t3\ngg-gg-gg-gg-gg-gg|\t4\nhh-hh-hh-hh-hh-hh|\t6\n\n\n这种设计方式，在计算机数量不多的情况下是可以正常使用的，但是当接入的计算机数量太多，交换机就无法维护如此巨大的表了。\n\n第三层（网络层）\n\n在第二层中问题的根本在于，连出去的那根红色的网线，后面不知道有多少个设备不断地连接进来，从而使得地址表越来越大。\n![Alt text](image-127.png)\n\n解决的办法就是，再接入一个新的设备，这个设备有自己独立的 MAC 地址同时还能把所有流经的数据包做一次转发，这个设备就是路由器，并将它定在了网络层。现在交换机的 MAC 地址表中，只需要多出一条 MAC 地址 ABAB 与其端口的映射关系，就可以成功把数据包转交给路由器了，而后由路由器转发到其他设备。但是这儿由出现了一个新的问题，那就是如何做到将发送的数据先发送给路由器呢？\n\n为了解决这个问题，我们又发明了一个新的工具，IP 地址。现在每一台电脑，同时有自己的 MAC 地址，又有自己的 IP 地址，只不过 IP 地址是软件层面上的，可以随时修改，MAC 地址一般是无法修改的。这样一个可以随时修改的 IP 地址，就可以根据你规划的网络拓扑结构来调整了。\n![Alt text](image-128.png)\n\n如上图所示，假如我想要发送数据包给 ABCD 其中一台设备，不论哪一台，我都可以这样描述，\"将 IP 地址为 192.168.0 开头的全部发送给到路由器，之后再怎么转发，交给它！那交给路由器之后，路由器又是怎么把数据包准确转发给指定设备的呢？\n\n我们先给上面的组网方式中的每一台设备，加上自己的 IP 地址\n\n![Alt text](image-129.png)\n现在两个设备之间传输，除了加上数据链路层的头部之外，还要再增加一个网络层的头部。假如 A 给 B 发送数据，由于它们直接连着交换机，所以 A 直接发出数据包即可，网络层的功能没有体现出作用。但假如 A 给 C 发送数据，A 就需要先转交给路由器，然后再由路由器转交给 C。由于最底层的传输仍然需要依赖以太网，所以数据包是分成两段的。\n\nA-路由器这段的包如下：\n![Alt text](image-130.png)\n\n路由器-C这段的包如下：\n\n![Alt text](image-131.png)\nA 给 C 发数据包，首先判断源 IP与目的IP是否处于一个子网，如果处于同一个子网，直接将包通过交换机发出，如果源 IP 与目的 IP 不处于一个子网，就交给路由器去处理，这里又有一个新的问题，那就是A 如何知道，哪个设备是路由器呢？答案就是你提前需要在 A 上设置路由器的地址，而这个地址我们叫他默认网关。现在数据已经可以成功发到路由器这里了，最后一个问题就是，路由器如何知道，收到的这个数据包，该从自己的哪个端口出去，才能直接（或间接）地最终到达目的地 C 呢。\n\n这儿就又出现了一张新的表，叫做路由表。至于这个路由表是怎么出来的，可以通过手动的方式指定，也可以通过路由算法自动生成，本文不展开讲述，因为这又是一个庞大的体系。不同于 MAC 地址表的是，路由表并不是一对一这种明确关系，我们下面看一个路由表的结构。\n\n|目的地址|\t子网掩码|\t下一跳|\t端口|\n|:------|:------|:------|:------|\n192.168.0.0|\t255.255.255.0| |\t\t0\n192.168.0.254|\t255.255.255.255| |\t\t0\n192.168.1.0|\t255.255.255.0| |\t\t1\n192.168.1.254|\t255.255.255.255| |\t\t1\n\n\n上表表示，http://192.168.0.xxx 这个子网下的，都转发到 0 号端口，http://192.168.1.xxx 这个子网下的，都转发到 1 号端口。但是这儿又有一个新的麻烦出现了。\n\n现在我们知道要发送数据的目标主机IP地址，但发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？又出现一个新的名词arp，在网络层，我需要把 IP 地址对应的 MAC 地址找到， 这种方式就是 arp 协议，同时电脑每一台电脑里面也会有一张 arp 缓存表，表中记录着 IP 与 MAC 地址的对应关系。\n\n|IP 地址|\tMAC 地址|\n|:------|:------|\n192.168.0.2\t|BBBB\n\n刚开始的时候这个表是空的，电脑 A 为了知道电脑 B的 MAC 地址，将会广播一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个响应。此时 A 便更新了自己的 arp 表。这样通过大家不断广播 arp 请求，最终所有电脑里面都将 arp 缓存表更新完整。\n\n至此一个数据成功的从一个网段转发到另一个网段，复杂的网络是由一个个小型的网络组合而成的，将N个局域网连接到一起可不就是互联网嘛。\n\n原文地址:https://zhuanlan.zhihu.com/p/433393781","slug":"kubernetes/internet-1-3","published":1,"updated":"2023-11-03T02:27:36.246Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0c3000nfmjx68w48ht6","content":"<p>计算机被发明出来使用很长时间，都是作为一个独立的个体来使用的，直到后来美国国防部的高级研究计划局（ARPA）计划建设一个军用网，叫做“阿帕网”（ARPAnet），阿帕网于1969年正式启用，当时仅连接了4台计算机，供科学家们进行计算机联网实验使用，直到那时候才开始出现计算机网络的概念。</p>\n<p>今天我们就来聊聊计算机组网的那点事儿</p>\n<p>第一层（物理层）</p>\n<p>从计算机组网的角度来说，将两台计算机通过网线相连，就是一个简单的网络结构，如图所示：</p>\n<p><img src=\"/image-120.png\" alt=\"Alt text\"><br>但是在实际网络环境中，接入网络的计算机不可能只有两台，那么在有很多台计算机的情况下，我们该如何连接呢？</p>\n<p>为此我们发明了一个中间设备，将计算机的网线都插到这个设备上，由这个设备做转发，这样彼此之间就可以通信了。</p>\n<p>这个中间设备的名子就叫集线器（俗称HUB）,它的功能非常简单，仅仅是将任意一个接口接受到的电信号转发到所有出口（广播），不做任何处理，因此将他定位为物理层设备。</p>\n<p>但是这种转发方式会引起一个新的问题，由于转发到了所有出口，那接在集线器下的其他设备都能接受到数据，那么怎么判断数据是不是发给自己的。</p>\n<p><img src=\"/image-121.png\" alt=\"Alt text\"><br>这儿就引入一个新的名词，MAC地址，正常情况下MAC地址是全局唯一的标识，全世界独一无二，给每一个设备都配一个MAC地址，这样，A 在发送数据包给 B 时，只要在头部拼接一个源目MAC地址就可以解决此问题了。B 在收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包的确是发给自己的，于是便收下。其他的计算机收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包并不是发给自己的，于是便丢弃。虽然集线器使整个网络布局简单明了，但会出现一个新的问题，原来我只要发给电脑B的消息，现在却要发给连接到集线器中的所有电脑，这样既不安全，又浪费宝贵带宽资源。</p>\n<p>第二层（数据链路层）</p>\n<p>在第一层中，我们最后虽然解决了多台计算机的组网需求，但最后却留下了问题，即集线器的使用不仅有安全隐患，而且浪费有限的带宽资源。那第二层的主要目标就是解决安全隐患以及带宽浪费的问题，把这个集线器弄得更智能一些，想要将数据发送到那一台设备，就只发给目标 MAC 地址指向的那台电脑，就好了。<br><img src=\"/image-122.png\" alt=\"Alt text\"></p>\n<p>所以一个全新的设备出现了，这东西就叫做交换机。它能够实现你将数据发送到指定的设备而不会转发到所有出口（广播）的情况，因此将他定位为数据链路层设备。每一台交换机内部维护一张 MAC 地址表，记录着每一个设备的 MAC 地址，连接在其哪一个端口上。</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">cc-cc-cc-cc-cc-cc</td>\n<td align=\"left\">3</td>\n</tr>\n<tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">dd-dd-dd-dd-dd-dd</td>\n<td align=\"left\">5</td>\n</tr>\n</tbody></table>\n<p>这种情况下，假如你仍然要发给 B 一个数据包，构造了如下的数据结构从网口出去。<br><img src=\"/image-123.png\" alt=\"Alt text\"></p>\n<p>到达交换机时，交换机内部通过自己维护的 MAC 地址表，发现目标机器 B 的 MAC 地址 bb-bb-bb-bb-bb-bb 映射到了端口 1 上，于是把数据从 1 号端口发给了 B，一次数据转发完成。而以这样传输方式组成的小范围的网络，叫做以太网。当然刚开始的时候，MAC 地址表是空的，那MAC地址表是如何建立起来的呢？假如刚开始交换机 MAC 地址表是空的，你给 B 发送了如下数据：</p>\n<p><img src=\"/image-124.png\" alt=\"Alt text\"><br>由于这个包从端口 4 进入的交换机，所以此时交换机就可以在 MAC地址表记录第一条数据：</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n</tbody></table>\n<p>交换机看目标 MAC 地址（bb-bb-bb-bb-bb-bb）在地址表中并没有映射关系，于是将此包发给了所有端口，即广播发送。之后，只有机器 B 收到了确实是发给自己的包，于是做出了响应，响应数据从端口 1 进入交换机，于是交换机此时在地址表中更新了第二条数据：</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n</tbody></table>\n<p>经过该网络中的机器不断通信，交换机最终将 MAC 地址表建立完毕~</p>\n<p>最直观的展示过程：<br><img src=\"/image-125.png\" alt=\"Alt text\"></p>\n<p>通过此种方法我们就成功的建立了一个相对安全，也比较智能的局域互联网络，通过此网络我们可以在几台计算机之间分享数据，但是很快新的问题又出现了。随着机器数量越多，一台交换机的端口不够了，我们能想到的最简单的办法，就是将多个交换机连接起来，解决这 个问题，事实上还真的可以，但是这样真的没有问题吗？<br><img src=\"/image-126.png\" alt=\"Alt text\"></p>\n<p>需要注意的是，上面那根红色的线，最终在 MAC 地址表中可不是一条记录，而是要把 EFGH 这四台机器与该端口（端口6）的映射全部记录在表中。最终，两个交换机将分别记录 A ~ H 所有机器的映射记录。</p>\n<p>左边的交换机</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">cc-cc-cc-cc-cc-cc</td>\n<td align=\"left\">3</td>\n</tr>\n<tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">dd-dd-dd-dd-dd-dd</td>\n<td align=\"left\">5</td>\n</tr>\n<tr>\n<td align=\"left\">ee-ee-ee-ee-ee-ee</td>\n<td align=\"left\">6</td>\n</tr>\n<tr>\n<td align=\"left\">ff-ff-ff-ff-ff-ff</td>\n<td align=\"left\">6</td>\n</tr>\n<tr>\n<td align=\"left\">gg-gg-gg-gg-gg-gg</td>\n<td align=\"left\">6</td>\n</tr>\n<tr>\n<td align=\"left\">hh-hh-hh-hh-hh-hh</td>\n<td align=\"left\">6</td>\n</tr>\n</tbody></table>\n<p>右边的交换机</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">cc-cc-cc-cc-cc-cc</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">dd-dd-dd-dd-dd-dd</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">ee-ee-ee-ee-ee-ee</td>\n<td align=\"left\">2</td>\n</tr>\n<tr>\n<td align=\"left\">ff-ff-ff-ff-ff-ff</td>\n<td align=\"left\">3</td>\n</tr>\n<tr>\n<td align=\"left\">gg-gg-gg-gg-gg-gg</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">hh-hh-hh-hh-hh-hh</td>\n<td align=\"left\">6</td>\n</tr>\n</tbody></table>\n<p>这种设计方式，在计算机数量不多的情况下是可以正常使用的，但是当接入的计算机数量太多，交换机就无法维护如此巨大的表了。</p>\n<p>第三层（网络层）</p>\n<p>在第二层中问题的根本在于，连出去的那根红色的网线，后面不知道有多少个设备不断地连接进来，从而使得地址表越来越大。<br><img src=\"/image-127.png\" alt=\"Alt text\"></p>\n<p>解决的办法就是，再接入一个新的设备，这个设备有自己独立的 MAC 地址同时还能把所有流经的数据包做一次转发，这个设备就是路由器，并将它定在了网络层。现在交换机的 MAC 地址表中，只需要多出一条 MAC 地址 ABAB 与其端口的映射关系，就可以成功把数据包转交给路由器了，而后由路由器转发到其他设备。但是这儿由出现了一个新的问题，那就是如何做到将发送的数据先发送给路由器呢？</p>\n<p>为了解决这个问题，我们又发明了一个新的工具，IP 地址。现在每一台电脑，同时有自己的 MAC 地址，又有自己的 IP 地址，只不过 IP 地址是软件层面上的，可以随时修改，MAC 地址一般是无法修改的。这样一个可以随时修改的 IP 地址，就可以根据你规划的网络拓扑结构来调整了。<br><img src=\"/image-128.png\" alt=\"Alt text\"></p>\n<p>如上图所示，假如我想要发送数据包给 ABCD 其中一台设备，不论哪一台，我都可以这样描述，”将 IP 地址为 192.168.0 开头的全部发送给到路由器，之后再怎么转发，交给它！那交给路由器之后，路由器又是怎么把数据包准确转发给指定设备的呢？</p>\n<p>我们先给上面的组网方式中的每一台设备，加上自己的 IP 地址</p>\n<p><img src=\"/image-129.png\" alt=\"Alt text\"><br>现在两个设备之间传输，除了加上数据链路层的头部之外，还要再增加一个网络层的头部。假如 A 给 B 发送数据，由于它们直接连着交换机，所以 A 直接发出数据包即可，网络层的功能没有体现出作用。但假如 A 给 C 发送数据，A 就需要先转交给路由器，然后再由路由器转交给 C。由于最底层的传输仍然需要依赖以太网，所以数据包是分成两段的。</p>\n<p>A-路由器这段的包如下：<br><img src=\"/image-130.png\" alt=\"Alt text\"></p>\n<p>路由器-C这段的包如下：</p>\n<p><img src=\"/image-131.png\" alt=\"Alt text\"><br>A 给 C 发数据包，首先判断源 IP与目的IP是否处于一个子网，如果处于同一个子网，直接将包通过交换机发出，如果源 IP 与目的 IP 不处于一个子网，就交给路由器去处理，这里又有一个新的问题，那就是A 如何知道，哪个设备是路由器呢？答案就是你提前需要在 A 上设置路由器的地址，而这个地址我们叫他默认网关。现在数据已经可以成功发到路由器这里了，最后一个问题就是，路由器如何知道，收到的这个数据包，该从自己的哪个端口出去，才能直接（或间接）地最终到达目的地 C 呢。</p>\n<p>这儿就又出现了一张新的表，叫做路由表。至于这个路由表是怎么出来的，可以通过手动的方式指定，也可以通过路由算法自动生成，本文不展开讲述，因为这又是一个庞大的体系。不同于 MAC 地址表的是，路由表并不是一对一这种明确关系，我们下面看一个路由表的结构。</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">目的地址</th>\n<th align=\"left\">子网掩码</th>\n<th align=\"left\">下一跳</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">192.168.0.0</td>\n<td align=\"left\">255.255.255.0</td>\n<td align=\"left\"></td>\n<td align=\"left\">0</td>\n</tr>\n<tr>\n<td align=\"left\">192.168.0.254</td>\n<td align=\"left\">255.255.255.255</td>\n<td align=\"left\"></td>\n<td align=\"left\">0</td>\n</tr>\n<tr>\n<td align=\"left\">192.168.1.0</td>\n<td align=\"left\">255.255.255.0</td>\n<td align=\"left\"></td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">192.168.1.254</td>\n<td align=\"left\">255.255.255.255</td>\n<td align=\"left\"></td>\n<td align=\"left\">1</td>\n</tr>\n</tbody></table>\n<p>上表表示，<a href=\"http://192.168.0.xxx/\">http://192.168.0.xxx</a> 这个子网下的，都转发到 0 号端口，<a href=\"http://192.168.1.xxx/\">http://192.168.1.xxx</a> 这个子网下的，都转发到 1 号端口。但是这儿又有一个新的麻烦出现了。</p>\n<p>现在我们知道要发送数据的目标主机IP地址，但发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？又出现一个新的名词arp，在网络层，我需要把 IP 地址对应的 MAC 地址找到， 这种方式就是 arp 协议，同时电脑每一台电脑里面也会有一张 arp 缓存表，表中记录着 IP 与 MAC 地址的对应关系。</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">IP 地址</th>\n<th align=\"left\">MAC 地址</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">192.168.0.2</td>\n<td align=\"left\">BBBB</td>\n</tr>\n</tbody></table>\n<p>刚开始的时候这个表是空的，电脑 A 为了知道电脑 B的 MAC 地址，将会广播一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个响应。此时 A 便更新了自己的 arp 表。这样通过大家不断广播 arp 请求，最终所有电脑里面都将 arp 缓存表更新完整。</p>\n<p>至此一个数据成功的从一个网段转发到另一个网段，复杂的网络是由一个个小型的网络组合而成的，将N个局域网连接到一起可不就是互联网嘛。</p>\n<p>原文地址:<a href=\"https://zhuanlan.zhihu.com/p/433393781\">https://zhuanlan.zhihu.com/p/433393781</a></p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>计算机被发明出来使用很长时间，都是作为一个独立的个体来使用的，直到后来美国国防部的高级研究计划局（ARPA）计划建设一个军用网，叫做“阿帕网”（ARPAnet），阿帕网于1969年正式启用，当时仅连接了4台计算机，供科学家们进行计算机联网实验使用，直到那时候才开始出现计算机网络的概念。</p>\n<p>今天我们就来聊聊计算机组网的那点事儿</p>\n<p>第一层（物理层）</p>\n<p>从计算机组网的角度来说，将两台计算机通过网线相连，就是一个简单的网络结构，如图所示：</p>\n<p><img src=\"/image-120.png\" alt=\"Alt text\"><br>但是在实际网络环境中，接入网络的计算机不可能只有两台，那么在有很多台计算机的情况下，我们该如何连接呢？</p>\n<p>为此我们发明了一个中间设备，将计算机的网线都插到这个设备上，由这个设备做转发，这样彼此之间就可以通信了。</p>\n<p>这个中间设备的名子就叫集线器（俗称HUB）,它的功能非常简单，仅仅是将任意一个接口接受到的电信号转发到所有出口（广播），不做任何处理，因此将他定位为物理层设备。</p>\n<p>但是这种转发方式会引起一个新的问题，由于转发到了所有出口，那接在集线器下的其他设备都能接受到数据，那么怎么判断数据是不是发给自己的。</p>\n<p><img src=\"/image-121.png\" alt=\"Alt text\"><br>这儿就引入一个新的名词，MAC地址，正常情况下MAC地址是全局唯一的标识，全世界独一无二，给每一个设备都配一个MAC地址，这样，A 在发送数据包给 B 时，只要在头部拼接一个源目MAC地址就可以解决此问题了。B 在收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包的确是发给自己的，于是便收下。其他的计算机收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包并不是发给自己的，于是便丢弃。虽然集线器使整个网络布局简单明了，但会出现一个新的问题，原来我只要发给电脑B的消息，现在却要发给连接到集线器中的所有电脑，这样既不安全，又浪费宝贵带宽资源。</p>\n<p>第二层（数据链路层）</p>\n<p>在第一层中，我们最后虽然解决了多台计算机的组网需求，但最后却留下了问题，即集线器的使用不仅有安全隐患，而且浪费有限的带宽资源。那第二层的主要目标就是解决安全隐患以及带宽浪费的问题，把这个集线器弄得更智能一些，想要将数据发送到那一台设备，就只发给目标 MAC 地址指向的那台电脑，就好了。<br><img src=\"/image-122.png\" alt=\"Alt text\"></p>\n<p>所以一个全新的设备出现了，这东西就叫做交换机。它能够实现你将数据发送到指定的设备而不会转发到所有出口（广播）的情况，因此将他定位为数据链路层设备。每一台交换机内部维护一张 MAC 地址表，记录着每一个设备的 MAC 地址，连接在其哪一个端口上。</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">cc-cc-cc-cc-cc-cc</td>\n<td align=\"left\">3</td>\n</tr>\n<tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">dd-dd-dd-dd-dd-dd</td>\n<td align=\"left\">5</td>\n</tr>\n</tbody></table>\n<p>这种情况下，假如你仍然要发给 B 一个数据包，构造了如下的数据结构从网口出去。<br><img src=\"/image-123.png\" alt=\"Alt text\"></p>\n<p>到达交换机时，交换机内部通过自己维护的 MAC 地址表，发现目标机器 B 的 MAC 地址 bb-bb-bb-bb-bb-bb 映射到了端口 1 上，于是把数据从 1 号端口发给了 B，一次数据转发完成。而以这样传输方式组成的小范围的网络，叫做以太网。当然刚开始的时候，MAC 地址表是空的，那MAC地址表是如何建立起来的呢？假如刚开始交换机 MAC 地址表是空的，你给 B 发送了如下数据：</p>\n<p><img src=\"/image-124.png\" alt=\"Alt text\"><br>由于这个包从端口 4 进入的交换机，所以此时交换机就可以在 MAC地址表记录第一条数据：</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n</tbody></table>\n<p>交换机看目标 MAC 地址（bb-bb-bb-bb-bb-bb）在地址表中并没有映射关系，于是将此包发给了所有端口，即广播发送。之后，只有机器 B 收到了确实是发给自己的包，于是做出了响应，响应数据从端口 1 进入交换机，于是交换机此时在地址表中更新了第二条数据：</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n</tbody></table>\n<p>经过该网络中的机器不断通信，交换机最终将 MAC 地址表建立完毕~</p>\n<p>最直观的展示过程：<br><img src=\"/image-125.png\" alt=\"Alt text\"></p>\n<p>通过此种方法我们就成功的建立了一个相对安全，也比较智能的局域互联网络，通过此网络我们可以在几台计算机之间分享数据，但是很快新的问题又出现了。随着机器数量越多，一台交换机的端口不够了，我们能想到的最简单的办法，就是将多个交换机连接起来，解决这 个问题，事实上还真的可以，但是这样真的没有问题吗？<br><img src=\"/image-126.png\" alt=\"Alt text\"></p>\n<p>需要注意的是，上面那根红色的线，最终在 MAC 地址表中可不是一条记录，而是要把 EFGH 这四台机器与该端口（端口6）的映射全部记录在表中。最终，两个交换机将分别记录 A ~ H 所有机器的映射记录。</p>\n<p>左边的交换机</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">cc-cc-cc-cc-cc-cc</td>\n<td align=\"left\">3</td>\n</tr>\n<tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">dd-dd-dd-dd-dd-dd</td>\n<td align=\"left\">5</td>\n</tr>\n<tr>\n<td align=\"left\">ee-ee-ee-ee-ee-ee</td>\n<td align=\"left\">6</td>\n</tr>\n<tr>\n<td align=\"left\">ff-ff-ff-ff-ff-ff</td>\n<td align=\"left\">6</td>\n</tr>\n<tr>\n<td align=\"left\">gg-gg-gg-gg-gg-gg</td>\n<td align=\"left\">6</td>\n</tr>\n<tr>\n<td align=\"left\">hh-hh-hh-hh-hh-hh</td>\n<td align=\"left\">6</td>\n</tr>\n</tbody></table>\n<p>右边的交换机</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">MAC 地址</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">bb-bb-bb-bb-bb-bb</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">cc-cc-cc-cc-cc-cc</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">aa-aa-aa-aa-aa-aa</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">dd-dd-dd-dd-dd-dd</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">ee-ee-ee-ee-ee-ee</td>\n<td align=\"left\">2</td>\n</tr>\n<tr>\n<td align=\"left\">ff-ff-ff-ff-ff-ff</td>\n<td align=\"left\">3</td>\n</tr>\n<tr>\n<td align=\"left\">gg-gg-gg-gg-gg-gg</td>\n<td align=\"left\">4</td>\n</tr>\n<tr>\n<td align=\"left\">hh-hh-hh-hh-hh-hh</td>\n<td align=\"left\">6</td>\n</tr>\n</tbody></table>\n<p>这种设计方式，在计算机数量不多的情况下是可以正常使用的，但是当接入的计算机数量太多，交换机就无法维护如此巨大的表了。</p>\n<p>第三层（网络层）</p>\n<p>在第二层中问题的根本在于，连出去的那根红色的网线，后面不知道有多少个设备不断地连接进来，从而使得地址表越来越大。<br><img src=\"/image-127.png\" alt=\"Alt text\"></p>\n<p>解决的办法就是，再接入一个新的设备，这个设备有自己独立的 MAC 地址同时还能把所有流经的数据包做一次转发，这个设备就是路由器，并将它定在了网络层。现在交换机的 MAC 地址表中，只需要多出一条 MAC 地址 ABAB 与其端口的映射关系，就可以成功把数据包转交给路由器了，而后由路由器转发到其他设备。但是这儿由出现了一个新的问题，那就是如何做到将发送的数据先发送给路由器呢？</p>\n<p>为了解决这个问题，我们又发明了一个新的工具，IP 地址。现在每一台电脑，同时有自己的 MAC 地址，又有自己的 IP 地址，只不过 IP 地址是软件层面上的，可以随时修改，MAC 地址一般是无法修改的。这样一个可以随时修改的 IP 地址，就可以根据你规划的网络拓扑结构来调整了。<br><img src=\"/image-128.png\" alt=\"Alt text\"></p>\n<p>如上图所示，假如我想要发送数据包给 ABCD 其中一台设备，不论哪一台，我都可以这样描述，”将 IP 地址为 192.168.0 开头的全部发送给到路由器，之后再怎么转发，交给它！那交给路由器之后，路由器又是怎么把数据包准确转发给指定设备的呢？</p>\n<p>我们先给上面的组网方式中的每一台设备，加上自己的 IP 地址</p>\n<p><img src=\"/image-129.png\" alt=\"Alt text\"><br>现在两个设备之间传输，除了加上数据链路层的头部之外，还要再增加一个网络层的头部。假如 A 给 B 发送数据，由于它们直接连着交换机，所以 A 直接发出数据包即可，网络层的功能没有体现出作用。但假如 A 给 C 发送数据，A 就需要先转交给路由器，然后再由路由器转交给 C。由于最底层的传输仍然需要依赖以太网，所以数据包是分成两段的。</p>\n<p>A-路由器这段的包如下：<br><img src=\"/image-130.png\" alt=\"Alt text\"></p>\n<p>路由器-C这段的包如下：</p>\n<p><img src=\"/image-131.png\" alt=\"Alt text\"><br>A 给 C 发数据包，首先判断源 IP与目的IP是否处于一个子网，如果处于同一个子网，直接将包通过交换机发出，如果源 IP 与目的 IP 不处于一个子网，就交给路由器去处理，这里又有一个新的问题，那就是A 如何知道，哪个设备是路由器呢？答案就是你提前需要在 A 上设置路由器的地址，而这个地址我们叫他默认网关。现在数据已经可以成功发到路由器这里了，最后一个问题就是，路由器如何知道，收到的这个数据包，该从自己的哪个端口出去，才能直接（或间接）地最终到达目的地 C 呢。</p>\n<p>这儿就又出现了一张新的表，叫做路由表。至于这个路由表是怎么出来的，可以通过手动的方式指定，也可以通过路由算法自动生成，本文不展开讲述，因为这又是一个庞大的体系。不同于 MAC 地址表的是，路由表并不是一对一这种明确关系，我们下面看一个路由表的结构。</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">目的地址</th>\n<th align=\"left\">子网掩码</th>\n<th align=\"left\">下一跳</th>\n<th align=\"left\">端口</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">192.168.0.0</td>\n<td align=\"left\">255.255.255.0</td>\n<td align=\"left\"></td>\n<td align=\"left\">0</td>\n</tr>\n<tr>\n<td align=\"left\">192.168.0.254</td>\n<td align=\"left\">255.255.255.255</td>\n<td align=\"left\"></td>\n<td align=\"left\">0</td>\n</tr>\n<tr>\n<td align=\"left\">192.168.1.0</td>\n<td align=\"left\">255.255.255.0</td>\n<td align=\"left\"></td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">192.168.1.254</td>\n<td align=\"left\">255.255.255.255</td>\n<td align=\"left\"></td>\n<td align=\"left\">1</td>\n</tr>\n</tbody></table>\n<p>上表表示，<a href=\"http://192.168.0.xxx/\">http://192.168.0.xxx</a> 这个子网下的，都转发到 0 号端口，<a href=\"http://192.168.1.xxx/\">http://192.168.1.xxx</a> 这个子网下的，都转发到 1 号端口。但是这儿又有一个新的麻烦出现了。</p>\n<p>现在我们知道要发送数据的目标主机IP地址，但发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？又出现一个新的名词arp，在网络层，我需要把 IP 地址对应的 MAC 地址找到， 这种方式就是 arp 协议，同时电脑每一台电脑里面也会有一张 arp 缓存表，表中记录着 IP 与 MAC 地址的对应关系。</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">IP 地址</th>\n<th align=\"left\">MAC 地址</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">192.168.0.2</td>\n<td align=\"left\">BBBB</td>\n</tr>\n</tbody></table>\n<p>刚开始的时候这个表是空的，电脑 A 为了知道电脑 B的 MAC 地址，将会广播一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个响应。此时 A 便更新了自己的 arp 表。这样通过大家不断广播 arp 请求，最终所有电脑里面都将 arp 缓存表更新完整。</p>\n<p>至此一个数据成功的从一个网段转发到另一个网段，复杂的网络是由一个个小型的网络组合而成的，将N个局域网连接到一起可不就是互联网嘛。</p>\n<p>原文地址:<a href=\"https://zhuanlan.zhihu.com/p/433393781\">https://zhuanlan.zhihu.com/p/433393781</a></p>\n"},{"title":"看完这篇，成为Grafana高手","date":"2023-10-31T02:10:19.000Z","_content":"看完这篇，成为Grafana高手\n原创 huhuli 腾讯VATeam 2022-09-30 14:08 发表于广东\nhttps://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ\n# 背景\n\nQQ直播前端团队接入腾讯云前端性能监控（RUM）后，对目前的监控能力以及上报数据进行了梳理， 并着手进行了前端性能监控的专项建设，其中监控数据大盘建设是不可或缺的一环。\n可视化的监控大盘可以清晰明了的观察到各项目运行情况，宏观上能快速进行项目间的横向对比，也可以非常便捷的进行项目各数据维度的详细展示，纵向的分析各指标数据的统计。\n\n![Alt text](image-30.png)\n\n通过对数据大盘支持能力的调研，我们采用Grafana进行了数据大盘的建设。通过搭建Grafana服务，然后添加监控上报数据，最终使得【QQ直播前端监控数据大盘】得以建设完成。\n\n\n\n那么什么是Grafana？\n\nGrafana 是一款开源的数据可视化工具，使用Grafana可以非常轻松的将数据转成图表(如下图)的展现形式来做到数据监控以及数据统计。\n\n         \n\nGrafana官方提供Linux，Windows，MacOS，Docker版本\n\n下载链接:  https://grafana.com/get/\n\n\n\n本文将依托建设数据大盘的经验，重点介绍一下Grafana的使用，助力小伙伴们成为Grafana高手。\n\n\n\n\n# 数据与图表\n\n数据的可视化都是通过图表为载体的，不同的图表可以将数据进行不同侧重点的展现，要进行数据大盘的建设，首先要对图表有一个简单的了解，这样才能在数据大盘搭建过程中选择合适的图表，合理的进行可视化效果的展示。\n\n\n\n认识Grafana的图表\n✦\n\nGrafana 的图表的选择路径都是 在 Visualization 类目下进行图表的选择\n\n                \n![Alt text](image-31.png)\n\n\n## 1. 折线图\n\n![Alt text](image-32.png)           \n\n示例图表：Time series\n\n图表配置：Graph styles\n\na. style: Lines\n\nb. Fill opacity: 3\n\nc. Gradient mode: scheme\n\n\n\n## 2. 柱状图\n\n![Alt text](image-39.png)         \n\n示例图表：Time series\n\n图表配置：Graph styles\n\na. style: Bars\n\nb. Fill opacity: 3\n\nc. Gradient mode: scheme\n\n\n\n## 3. 点状图\n\n![Alt text](image-33.png)        \n\n示例图表：Time series\n\n图表配置：Graph styles\n\na. style: Points\n\nb. Point size: 5\n\nc. Stack series: Normal\n\n\n\n## 4. 饼状图\n\n![Alt text](image-34.png)          \n\n示例图表：Pie chart\n\n\n\n## 5. 单一状态图\n\n![Alt text](image-35.png)          \n\n示例图表：Stat\n\n图表配置：Graph styles\n\na. style: Bars\n\nb. Fill opacity: 3\n\nc. Gradient mode: scheme\n\n\n\n## 6. 仪表盘\n\n![Alt text](image-36.png)        \n\n示例图表：Gauge\n\n\n\n## 7. 表格\n\n![Alt text](image-37.png)         \n\n示例图表：Table\n\n\n\n## 8. 文本\n\n![Alt text](image-38.png)           \n\n示例图表：Text（支持Markdown 和 HTML两种格式）\n\n\n\n## 9. …\n\n\n\n\n# 数据与图表的搭配\n\n## 按照数据格式区分\n✦\n\n柱状图， 折线图， 饼状图的图表都需要数据具有时间序列，用于展示在一定的时间区间或者是连续的时间范围内，单一数据或者多种分类数据的变化趋势，或者是数量占比。\n\n\n\n状态图， 表格数据，仪表盘等则对数据没有时间序列要求，状态图，仪表盘可用于进行一些总结性的数据展示，例如速度，温度，进度，完成度等， 表格数据则更适合展示复杂数据或者多维度数据\n\n\n\n## 按照使用意图区分\n✦\n\n数据比较：柱状图，折线图比较合适，可以实现单数据，多种类数据的比较，能清晰看到变化趋势\n\n\n\n占比分类：饼图，仪表盘， 单一状态图等比较合适，可以清晰的看到每个数据整体性的占比\n\n\n\n趋势比较：折线图，面积图(折线可设置覆盖面积) 等比较合适，能直观展现数据变化\n\n\n\n分布类：饼图， 散点图 等比较合适\n\n\n\n\n## 其他      ✦\n文字类图表就如同名字含义一样，可用于展示文字相关信息，并且个性化定制程度，灵活性排布支持都非常高（得益于Markdown 和 HTML的强大灵活性）\n\n\n\n表格对于日志类型，或者是其他多维度数据展示较为合适，适用于整体性给出一个报表，并且具备排序等公共功能，方便数据快速比较。\n\n\n\n\n## 数据与图表的添加与扩展\n\n数据源与图表的扩展Grafana都采用插件的形式，因此我们想要扩展某个类型的数据源或者图表时，都需要先在Grafana插件市场找到目标插件，然后进行安装，如下图代码\n\n```\nFROM grafana/grafana:8.3.1\nUSER root\nRUN grafana-cli plugins install grafana-clickhouse-datasource //数据源插件\nRUN grafana-cli plugins install auxmoney-waterfall-panel //图表插\n```\n\n\n\n## 数据源添加\n✦\n\n打开Grafana平台，点击左侧\"设置\"图标，进入DataSource管理面板。\n\n![Alt text](image-40.png)               \n\n在“Add data source\"面板中选择合适的数据源，并配置数据库信息。下图以Promethrus为例，添加数据源需要进行必要的配置，例如数据源的ip，port以及鉴权信息等。\n\n![Alt text](image-41.png)         \n\n![Alt text](image-42.png)        \n\n\n\n## 图表插件添加\n✦\n\n1. 打开Grafana平台，点击左侧\"设置\"图标，进入Plugins管理面板\n\n ![Alt text](image-43.png)          \n\n\n\n2. 在tab 栏筛选已经安装的插件，就可以看到已经安装可以使用的插件\n\n           \n![Alt text](image-44.png)\n\n\n3. 图表面板已经安装，可以直接在创建面板的时候指定类型使用\n\n![Alt text](image-45.png)       \n\n\n\n\n\n\n# Grafana入门使用\n\n这里需要区分两个概念：\n\n看板（dashboard）: 一个或多个数据图表形成的集合\n\n面板（panel）：组成看板的其中一个图表\n\n\n\n## 创建一个看板 (dashboard)\n✦\n\n创建一个数据可视化看板的前提是需要有数据源的接入， 具体具体接入方法见数据与图表的添加与扩展\n\n\n\n1. 打开Grafana平台，点击左侧\"加号\"，点击Create类目下的Dashboard 按钮，新创建一个空表的看板， 会默认弹出四个添加panel的选项        \n\n![Alt text](image-46.png)\n![Alt text](image-47.png)\n\na.添加一个空白面板\n\nb. 添加一个新的行，用于面板的分类\n\nc. 从面板库添加一个面板\n\nd. 从剪贴板添加一个面板，可以用来快速复制一个已有的面板\n\n\n\n2. 点击看板右上角保存看板。        \n![Alt text](image-48.png)\na. 输入看板名称\n\nb. 输入简单描述文字\n\nc. 选择看板所属目录（用来分类管理看板）\n\nd. 可选为看板设置Tag，标记看板的特征，后期可根据Tag来筛选看板\n\ne. 其他选项可按需自主定义\n\n\n\n## 创建面板 (panel)\n✦\n\n![Alt text](image-50.png)         \n\n点击上图所示的图表，会弹出创建面板的四种选择，可以根据自己的需求自主创建，下面我们以创建空白面板为例\n\n点击Add a new panel 按钮， 你就会创建一个空白数据的图表面板，如下图\n\n   \n![Alt text](image-51.png)\n         \n\n## 面板数据的获取\n前文已经提到， 创建一个数据可视化看板的前提是需要有数据源的接入，因此，我们想要获取数据，必须要进行数据源的接入\n\n1. 选择数据源（Data source）\n![Alt text](image-52.png)\n        配置选择自己接入的数据源后，后续才能进行相关数据获取的语法编写，这里不同的数据源之前需要的语法也不一样，因此大家可以自己根据自己的条件自主选择， 因为QQ直播接入的数据源是influxdb, 因此后面的例子将会以influxdb语法为例。\n\n\n\n2. SQL语句的编写\n\nGrafana的面板语法编辑有两种形式， 简易模式与高级模式\n\nGrafana 一个面板支持多条SQL语句\n\n\n\na. 简易模式：简易模式数据的获取主要通过下拉框的形式选择具体的指标以及判断条件， 支持添加多个条件\n\n![Alt text](image-53.png)   \n\n高级模式：通过点击编辑图标可以进行编辑模式的切换，高级模式下为全部的SQL语句的编书写，此模式对于语法有一定的要求，但是获取数据会更加的灵活\n\n![Alt text](image-54.png)\n\n## 面板的基础配置\n在编辑完成数据获取的SQL语句之后，面板上应该已经有了相关数据的展示，此时可以根据自己的数据格式，以及展示诉求来选择对应的图表，图表具体选择参考上文数据与图表的搭配\n\n\n\n我们以默认的Time series的折线图为例，简述一下面板的基础配置\n\n![Alt text](image-55.png)\n\n\n\n1. 面板的基础信息\n\n![Alt text](image-56.png)      \n\n在通过SQL语句选择加载完成数据后，图表会有默认的样式给到我们，此时如果对面板无其他要求，只需配置一下面板的基础信息就可完成Grafana的看板配置\n\n基础信息包括\n\na. 标题\n\nb. 描述\n\nc. 背景是否透明\n\n\n\n2. 数据提示\n\n![Alt text](image-57.png)        \n\nTootip配置项用于配置当鼠标经过（hover）图表数据点的时候的提示信息， 可选为Single单个提醒， All显示所有数据， Hidden都不显示\n\n         \n![Alt text](image-58.png)\n\n\n3. 图例（legend）显示设置\n\n         \n![Alt text](image-59.png)\n\n\n图例显示模式有三种\n\na. List (默认)， 图例数据横向依次展示\n\nb. Table， 图例数据会按照表格形式展示\n\nc. Hidden, 不展示图例\n\n\n\n图例的位置\n\na. Bottom, 陈列在图表底部\n\nb. Right, 陈列在图表的右侧\n\n\n\n 图例值展示\n\n![Alt text](image-60.png)      \n\n此处会有一个下拉列表供我们选择图例的显示数据，默认不展示，用户也可以选择数据展示形式，例如最大值，最小值，平均值等\n\n\n\n4. 坐标轴（Axis）配置\n\n![Alt text](image-61.png)         \n\n坐标轴的基础配置一般只需要设置一下坐标轴的名称（Label）即可，其余的设置可以按照默认值不用修改，下面简述一下配置的含义\n\na. Width选项可以选择设置坐标轴（Label）的占比宽度\n\nb. Soft min 以及 Soft max 用来设置纵坐标的显示的最大值最小值\n\nc. Show gride lines 可以设置是否显示背景的网格线\n\nd. Scale 用来设置是否进行数据的放大，目的是让数据对比更加清晰\n\n\n\n通过以上对一个图表面板的基础配置，我们的一个图表基本上已经成型，可以达到数据可视化的正常显示目的，剩下的就是加强对自己数据格式类型的分析以及基于自己的可视化诉求来进行合适的图表面板的配置选择，就可以通过多个图表的添加来完成自己初版的数据可视化看板。\n\n\n\n\n# Grafana进阶使用\n\n当我们选择一个图表插件进行数据可视化的时候，图表的一些属性会帮我们设置好了默认值，但是基于兼容性更广的特性，这些默认值也许并不是我们选择图表最合适的展示效果，因此为了进一步提升图表的展示性，我们可以通过以下属性来进行面板的进一步美化。\n\n\n\n## 图表属性配置 (Standard options)\n✦\n\n![Alt text](image-62.png)              \n\n此选项框中的属性配置，可以使得我们的数据展示更加的准确，例如纵坐标的单位，我们不想采用通用意义上的在Label上进行命名标注单位例如耗时（ms）, 那么就可以选择此处的单位属性（Unit）进行更精确的展示\n\n\n\n1. 单位（Unit）\n\n![Alt text](image-63.png)              \n\n在单位选项中， 你可以进行非常精细化的选择，选项框中几乎包含了所有品类用到的单位属性，例如百分比，长度单位，时间单位，角度单位等等\n\n\n\n2. 显示范围（Min, Max）\n\n在Min, Max 选项中，允许用户输入一个数字进行显示范围的限制，那么图表上在显示范围之外的数据将不会在图表中显示，例如我将耗时限制在0~3000范围，那么3000以外的数据将会被隐藏\n\n               \n![Alt text](image-64.png)\n\n\n3. Decimals 选项可以用来设置纵坐标数据的小数点范围\n\n\n\n4. Display Name 选项则可以用来设置图例显示名字，但是由于限制，只能在只有一类数据时比较适用，如果数据类别较多，单纯在此处设置会将全部图例数据覆盖，因此图例的名称最好在SQL语句编写的时候就做好展示。当然后面也会讲有别的方法进行多种图例数据别名的单独设置\n\n\n\n5. 图表颜色配置（Color scheme）\n\n一般图表颜色的展示都会有默认值，不过我们想要改变现在图表曲线的颜色分类可以在此处进行设置。\n\n               \n![Alt text](image-65.png)\n\n\n我们可以选择整体图表的颜色走向或者是颜色分布，但是一般曲线展示的颜色还是会根据数据自己适配，因此如果我们想要改变某一条曲线的颜色，可以直接点击图例前面的颜色icon,进行颜色选择。我们可以根据提供选项进行选择，也可以自定义设置颜色。\n\n\n![Alt text](image-66.png)\n                \n\n## 阈值设置 (Thresholds)\n✦\n\n有些图表插件是支持设置阈值的， 阈值的设置可以使得我们对数据的合规程度有清晰的对比，能够直观的衡量出当前数据的质量，因此阈值设置也是面板美化展示的一个重要部分\n\n\n\n![Alt text](image-67.png)              \n\n\n\n如上图示例，我们设置对耗时的图表设置了两个阈值，上图的意义是：\n\n* 在3000ms和5000ms设置阈值\n\n* 3000ms以下将视为健康，颜色标记为绿色\n\n* 3000ms~5000ms视为亚健康，颜色标记黄色\n\n* 5000ms以上视为警示，颜色标记为红色\n\n\n\n阈值的模式有两种选择\n\n1. 绝对值, 即按照标记的阈值数据进行比较\n\n2. 百分比, 阈值为相对于最大值的占比\n\n\n\n阈值展示的形式有四种：\n\n1. 不展示 （off）\n\n2. 只展示阈值线 （as lines）\n\n3. 只展示区域 （as filled regions）\n\n4. 同时展示阈值线和区域 （as filled regions and lines）\n\n\n\n下图为我们选择绝对值模式下，展示线和区域的阈值示例图， 由图可以看出数据在不同阈值区间的分布，以及与阈值的对比，因此我们能直观的评估出数据的质量\n\n\n\n![Alt text](image-68.png)            \n\n\n\n## 数值映射 (Value mappings)\n✦\n\n![Alt text](image-69.png)            \n\n图表的展示都是由许多的值来组成的一个个点，连线，反过来讲，图表就是数据值的展现，在图表中， 有时候有些数据并不是我们理想的数值，或者说我们想特异性的让某些值显示为其他值（写SQL语句也可以实现）， 这时候可以使用数值映射选项\n\n\n![Alt text](image-70.png)\n               \n\n数值映射的形式可以有以下四种\n\n1 单纯的某个值映射\n\n2. 一段范围区间映射\n\n3. 正则表达式映射\n\n4. 针对某类值映射\n\n\n\n例如在示例中，假如我们健康波段数据具体值不关心， 只是关心整体的数据波动范围是否在健康范围之内，我们可以把0~3000ms的范围映射为健康，那么再具体显示的时候，不再会有具体值给到我们，统一会展示健康，如下图：\n\n               \n![Alt text](image-71.png)\n\n\n这个功能更加适用于表格数据，例如我们明确的将空数据映射为空或0的场景，如下图\n\n               \n![Alt text](image-72.png)\n\n\n## 数据覆盖 (Overrides)\n✦\n\n数据覆盖允许我们对之前已经设置好的图表进行个性化设置，它相当于图表更高级的设置，覆盖的范围可以是整个SQL语句获取的数据，也可以是数据中某一类图例数据\n\n![Alt text](image-73.png)         \n\n具体覆盖的数据类别：\n\n1 某一类数据\n\n2. 正则匹配到的数据\n\n3. 某些类型的数据\n\n4. 整个SQL查询的数据\n\n\n\n在设置了一个Override 之后，就可以进一步进行子项的配置，子项里面的属性几乎与上文介绍的图表属性一致\n\n![Alt text](image-74.png)          \n\n我们通过覆盖属性的配置，可以让修改到之前我们已经在整体设置好的图标样式\n\n\n\n例如我们现在经过SQL查询，已经获取到了js_ready和css_ready的耗时数据，但是我们想让这两种数据对比更加明确，既能够清晰的看到整体的趋势，也能看到某类数据单独的变化，这时我们可以通过override属性进行配置，让两个数据的纵坐标分别在左右两边，并且数据展示用折线和柱状图分别表示。\n\n\n\n具体override配置属性如下图：\n\n![Alt text](image-75.png)              \n\n\n\n对css_ready 数据配置：\n\n1. 图表展示为柱状图， 柱状图数据点居中\n\n2. 纵坐标数据靠右展示，颜色为浅绿色\n\n3. 标题设置为CSS耗时（ms）\n\n\n\n对js_ready数据配置：\n\n1. 默认基础配置折线图\n\n2. 默认纵坐标靠左展示\n\n3. 设置颜色红色\n\n4. 标题设置为JS耗时（ms）\n\n\n\n最终结果如下图：                         \n![Alt text](image-76.png)\n\n## 变量与模板\n✦\n\n在Grafana里面，学会使用变量，会发现打开了新世界的大门，用好变量，可能你的工作量就会缩减一半，甚至更多。\n\n\n\n变量的使用场景有很多，例如我们编写SQL语句中的时间选项（$__interval），就是内置的一个变量，通过这个时间变量，可以控制多个图表在不同时间范围内的展示情况，因此一个好的变量的使用，可以让我们只配置一个图表，达到展示不同条件下的数据的目的，而不用去为每一种情况设置一个图表。\n\n\n\n模板在Grafana中最简单的含义就是任何一条包含变量的查询（query)。\n\n\n\n【变量的设置】\n\n变量的设置是基于看板的，看板内设置的变量，对看板内的所有面板是共享的\n\n点击看板设置，进入变量设置页面\n\n               \n![Alt text](image-77.png)\n\n\n![Alt text](image-78.png)            \n\n\n\n【变量的种类】\n\n ![Alt text](image-79.png)              \n\n\n\n在添加一个变量的可选下拉框中，可以选择添加的变量类型，共计有以下几种变量可以选择\n\n\n\n\n\n|变量类型  |      描述|\n|:-----|:-----|\n| query | 查询变量允许编写可以返回指标名称、标签值或键列表的数据源查询。例如，查询变量可能会返回服务器名称, ID 或数据中心的列表。变量值随着数据源查询动态获取选项而变化。|\n|custom | 手动定义变量选项,使用逗号分隔的列表|\n|text box| 显示具有可选默认值的自由文本输入字段|\n|constant|设置一个常量|\n|data source|快速添加一个数据源的变量|\n|interval|代表时间跨度的变量|\n|ad hoc filters|自动添加到数据源的所有指标查询的键/值过滤器（仅限 InfluxDB、Prometheus 和 Elasticsearch）|\n\n\n\n添加变量的其他输入框选项可以直接根据英文的意义非常直白的看出，例如设置面标签信息，描述信息，以及设置是否在看板中隐藏，对于某些变量类型还可以设置是否可以多选或者是否包含所有的值的选项等等，这些设置可以根据自己的需求来选择。\n\n\n\n【变量的使用】\n\n设置完成变量之后，变量的使用有两种形式\n\n$varname， 这是最直接的方式， 但是这种语法会有限制，就是不能在一个词的中间使用例如：apps.frontend.$varname.requests.count\n\n1. ${var_name}， 如果想要在表达式中间插入变量，请使用此语法，另外这种语法还有一些高级用法，${var_name:<format>}，这种格式可以更好地控制 Grafana 如何插入值，具体的用法可以参考官方文档\n\n\n\n【变量简单使用示例】\n\n沿用上文的数据，我们创建一个简单的自定义变量，url_event,如下图\n\n               \n![Alt text](image-80.png)\n\n\n获取数据的时候,sql 语法就可以写成如下\n\n               \n![Alt text](image-81.png)\n\n\n这样，我们只建立了一个图表面板，由于使用了变量，因此可以只用变量的切换就实现看板数据的变化，如下\n\n变量选择 js_ready\n![Alt text](image-82.png)\n变量选择css_ready\n\n![Alt text](image-83.png)\n\n## Link的使用\n✦\n\n在Grafana中，可以使用链接来进行看板的跳转以及外链的跳转，并且link的使用也非常灵活。\n\n在一个数据面板的设置中，link可以的设置主要有两种方式\n\n\n\n1. 整个面板设置链接\n\n![Alt text](image-84.png)              \n\n\n\n在数据面板的设置中，前文我们没有细讲link的选项，这里其实是为整个数据面板设置跳转链接的入口，通过此处设置link，可以在面板上增加一个icon, 实现我们在点击的时候进行跳转, 具体效果如下图\n\n![Alt text](image-85.png)              \n\n\n\n2. 为具体数据设置link(data links)\n\ndata links属性设置一般只在柱状图、折线图、表格面板里才有，并且，如果没有搭配override属性进行个性化设置的话，默认每个数据点都会设置上跳转的链接，效果如下图\n\n               \n![Alt text](image-86.png)\n\n\n这样的设置其实和整个面板设置link类似，因此不同的data links 最好和override属性搭配，来进行个性化的数据链接跳转，以达到不通数据跳转不同链接的目的。\n\n\n\n## Link与变量的搭配\n✦\n\nGrafana的link设置非常灵活，在link设置中，可以直接使用已经设置的看板变量以及系统的变量来进行链接的组合。\n\n\n\n甚至在data links的设置中，还可以直接使用SQL语句查询到的结果来进行链接的组合，这样也可达到不同数值设置不同的跳转链接的功能\n\n\n\n在添加链接的时候，如果想查看可用变量列表，可以直接在数据链接URL字段中键入 $ 来查看变量列表，效果如下图：\n\n               \n![Alt text](image-87.png)\n\n\n变量列表里的变量主要可以分为三个类型\n\na. 全局内建的变量，例如时间变量的 from, to\n\nb. 用户创建的模板变量，例如上文示例创建的 url_event\n\nc. 基于SQL语句查询出来的数据，一般都在fields字段下\n\n\n\n通过引用变量来创建图表面板的跳转链接，可以较为灵活的实现基于数据的外链跳转以及更为高级的数据看板的之间的联动，下文要讲到的数据下钻就是基于data links 与变量的搭配来实现。\n\n\n\n\n# Grafana高级使用\n\n## 妙用Transform\n✦\n\n前面讲的一些Grafana的使用，都是以SQL语句查询到的数据为基础，在图表可视化上进行的设置与操作，而Transform的功能，大部分是更底层的操作，直接对数据的操作，来达到改变图表展示的目的，是数据可视化之前的操作。\n\ntranform 可以实现将我们查询到的数据进行进一步加工，例如可以进行数据筛选，计算，重命名，排序以及控制隐藏等功能。\n\n               \n![Alt text](image-88.png)\n\n\n本文以几个较为典型的功能简单介绍一下\n\n1. 通过计算添加数据（Add field from calculation）\n\n![Alt text](image-89.png)              \n\n\n\n数据的计算有两种模式：\n\na. Reduce row： 分别对选择的特定字段数据的每一行进行聚合计算\n\nb. Binary option： 选定的两个字段的值进行数学运算例如加减乘除\n\n\n\n2. 转换数据的类型(Convert field type)\n\n可以将选择的特定字段的值的类型指定为固定的数据类型\n\n![Alt text](image-90.png)              \n\n\n\n3. 根据名称筛选数据展示(Filter data by name)\n\na. 可以将SQL语句查询出的字段名称陈列，并且自定义数据的展示与否\n\nb. 也可以直接根据正则表达式进行数据筛选\n\n               \n![Alt text](image-91.png)\n\n\n4. 数据合并（Merge）\n\n类似sql中的join，根据时间序列来进行合并不同的字段数据成为个数据表\n\n               \n![Alt text](image-92.png)\n\n\n5. 重命名（Rename by regex）\n\n可以使用这个功能来进行查询结果名称的转换，允许我们使用正则表达式来进行重命名内容的匹配\n\n![Alt text](image-93.png)          \n\ntransform 还有很多实用的功能，这里就不一一陈列，如果有需要用到操作数据的功能，可以考虑transform功能，全部的功能可以直接看官方文档\n\n\n\n## 面板的Repeat\n✦\n\n面板的repeat 也是需要搭配变量功能来使用，图表面板会根据用户选择的变量个数来进行分别加载，因此，此功能使用的前提是变量的值要大于1个，并且设置了允许多个变量可选，见下图示例\n\n               \n![Alt text](image-94.png)\n\n\n当前提条件满足后，可以在面板的repeat属性进行设置\n\n               \n\n\n\nrepeat 可选加载的方向是横向还是纵向，并且可以设置最大的重复个数，来避免造成加载展示问题以及性能问题。\n\n\n\n当设置完成后，并不会马上生效，需要保存然后退出此图表面板然后重新加载一下数据看板，然后数据图表就会根据我们选择的变量的个数来进行分别的展示。\n\n以上文的示例设置之后，效果如图：\n\n               \n![Alt text](image-95.png)\n\n\n## 数据下钻\n✦\n\n要实现一个数据下钻，需要link搭配变量来进行看板之间的联动，主要的思路大体如下：\n\n1. 模板看板B中设置好需要的变量\n\n2. 模板看板B查询数据时引用变量\n\n3. 在源图表面板A中设置跳转到模板看板B的链接，链接上引用我们设置或者是查询的变量内容\n\n4. 跳转至目标模板数据看板B时，模板看板B获取从link上带过来的变量值\n\n5. 变量赋值，模板看板B根据变量值刷新数据查询\n\n\n\n经过上面的步骤，那么一个数据看板之间的联动就完成了，剩下的步骤就是丰富变量的设置以及看板内图表面板的内容了。\n\n\n\n那么如何从跳转过来的link上获取到携带过来的变量的值呢？\n\n\n\n在上文我们设置变量来控制数据面板repeat的时候，我们设置了一个变量 url_event\n\n当控制变量为 js_ready的时候，看板的整体URL是\n        \n![Alt text](image-96.png)\n\n\n当控制变量为 css_ready的时候，看板的整体URL是\n\n               \n![Alt text](image-97.png)\n\n\n因此我们可以看到，当我们看板设置变量并且使用的时候，变量的内容是以query的格式显示在URL上的，并且命名的格式如下：\n```\nvar-{your_var_name} = {your_var_value}\n```\n\n当变量在url上面显式的标记的时候，Grafana会主动获取链接上面声明的变量的值并赋值给模板变量。\n\n\n\n因此根据上面的格式，我们可以在link上面构造上述的数据query格式，为模板的看板变量赋值。\n\n\n\n于是实现一个的数据下钻整体流程都变得清晰了，下面我们还是以上文的例子来构造一个简单的数据下钻的例子\n\n\n\n1. 构造一个整体的page render 数据看板 A\n\n将数据格式以table的形式展现，整体性的展示当天项目的render过程的各个事件平均耗时情况，如下图：\n\n               \n![Alt text](image-98.png)\n\n\n2. 设置一个详细指标数据的模板看板 B\n\n新建另一个数据详情的看板，然后建立一个事件的变量\n\n               \n![Alt text](image-99.png)\n\n\n编写具体事件详细数据的查询SQL语句，并引用变量\n\n               \n![Alt text](image-100.png)\n\n\n3. 通过link实现看板之间的联动\n\n配置数据看板A的data link, 使得每一行数据可以进行下钻详情展示\n\n               \n![Alt text](image-101.png)\n\n\n经过上述步骤，就完成可一个简单的数据下钻，实现可一个项目page render过程的整体数据的可视化，并且可以点击具体加载事件查看该事件详细的数据分布趋势\n\n效果如下:\n![Alt text](image-103.png)\n\n\n## 总结\n\nGrafana是一款非常优秀的开源可视化工具，能非常方便的将数据进行可视化，非常适合数据大盘建设，以及做数据监控和数据统计的工作。\n\n本文基于实际业务中建设监控数据大盘的经验，介绍了Grafana基本的一些图表概念和使用方法，并对不同的数据类型选取合适的可视化图表提供了一些建议和思考。\n\n通过三个阶段的介绍，总结了Grafana进行数据可视化入门教程以及一些进阶使用技巧，希望能在未来你的业务中，数据大盘的建设过程中提供一些便利和思路。","source":"_posts/kubernetes/grafana-dashboard.md","raw":"---\ntitle: 看完这篇，成为Grafana高手\ndate: 2023-10-31 10:10:19\ncategories:\n  - [kubernetes]\ntags: grafana\n---\n看完这篇，成为Grafana高手\n原创 huhuli 腾讯VATeam 2022-09-30 14:08 发表于广东\nhttps://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ\n# 背景\n\nQQ直播前端团队接入腾讯云前端性能监控（RUM）后，对目前的监控能力以及上报数据进行了梳理， 并着手进行了前端性能监控的专项建设，其中监控数据大盘建设是不可或缺的一环。\n可视化的监控大盘可以清晰明了的观察到各项目运行情况，宏观上能快速进行项目间的横向对比，也可以非常便捷的进行项目各数据维度的详细展示，纵向的分析各指标数据的统计。\n\n![Alt text](image-30.png)\n\n通过对数据大盘支持能力的调研，我们采用Grafana进行了数据大盘的建设。通过搭建Grafana服务，然后添加监控上报数据，最终使得【QQ直播前端监控数据大盘】得以建设完成。\n\n\n\n那么什么是Grafana？\n\nGrafana 是一款开源的数据可视化工具，使用Grafana可以非常轻松的将数据转成图表(如下图)的展现形式来做到数据监控以及数据统计。\n\n         \n\nGrafana官方提供Linux，Windows，MacOS，Docker版本\n\n下载链接:  https://grafana.com/get/\n\n\n\n本文将依托建设数据大盘的经验，重点介绍一下Grafana的使用，助力小伙伴们成为Grafana高手。\n\n\n\n\n# 数据与图表\n\n数据的可视化都是通过图表为载体的，不同的图表可以将数据进行不同侧重点的展现，要进行数据大盘的建设，首先要对图表有一个简单的了解，这样才能在数据大盘搭建过程中选择合适的图表，合理的进行可视化效果的展示。\n\n\n\n认识Grafana的图表\n✦\n\nGrafana 的图表的选择路径都是 在 Visualization 类目下进行图表的选择\n\n                \n![Alt text](image-31.png)\n\n\n## 1. 折线图\n\n![Alt text](image-32.png)           \n\n示例图表：Time series\n\n图表配置：Graph styles\n\na. style: Lines\n\nb. Fill opacity: 3\n\nc. Gradient mode: scheme\n\n\n\n## 2. 柱状图\n\n![Alt text](image-39.png)         \n\n示例图表：Time series\n\n图表配置：Graph styles\n\na. style: Bars\n\nb. Fill opacity: 3\n\nc. Gradient mode: scheme\n\n\n\n## 3. 点状图\n\n![Alt text](image-33.png)        \n\n示例图表：Time series\n\n图表配置：Graph styles\n\na. style: Points\n\nb. Point size: 5\n\nc. Stack series: Normal\n\n\n\n## 4. 饼状图\n\n![Alt text](image-34.png)          \n\n示例图表：Pie chart\n\n\n\n## 5. 单一状态图\n\n![Alt text](image-35.png)          \n\n示例图表：Stat\n\n图表配置：Graph styles\n\na. style: Bars\n\nb. Fill opacity: 3\n\nc. Gradient mode: scheme\n\n\n\n## 6. 仪表盘\n\n![Alt text](image-36.png)        \n\n示例图表：Gauge\n\n\n\n## 7. 表格\n\n![Alt text](image-37.png)         \n\n示例图表：Table\n\n\n\n## 8. 文本\n\n![Alt text](image-38.png)           \n\n示例图表：Text（支持Markdown 和 HTML两种格式）\n\n\n\n## 9. …\n\n\n\n\n# 数据与图表的搭配\n\n## 按照数据格式区分\n✦\n\n柱状图， 折线图， 饼状图的图表都需要数据具有时间序列，用于展示在一定的时间区间或者是连续的时间范围内，单一数据或者多种分类数据的变化趋势，或者是数量占比。\n\n\n\n状态图， 表格数据，仪表盘等则对数据没有时间序列要求，状态图，仪表盘可用于进行一些总结性的数据展示，例如速度，温度，进度，完成度等， 表格数据则更适合展示复杂数据或者多维度数据\n\n\n\n## 按照使用意图区分\n✦\n\n数据比较：柱状图，折线图比较合适，可以实现单数据，多种类数据的比较，能清晰看到变化趋势\n\n\n\n占比分类：饼图，仪表盘， 单一状态图等比较合适，可以清晰的看到每个数据整体性的占比\n\n\n\n趋势比较：折线图，面积图(折线可设置覆盖面积) 等比较合适，能直观展现数据变化\n\n\n\n分布类：饼图， 散点图 等比较合适\n\n\n\n\n## 其他      ✦\n文字类图表就如同名字含义一样，可用于展示文字相关信息，并且个性化定制程度，灵活性排布支持都非常高（得益于Markdown 和 HTML的强大灵活性）\n\n\n\n表格对于日志类型，或者是其他多维度数据展示较为合适，适用于整体性给出一个报表，并且具备排序等公共功能，方便数据快速比较。\n\n\n\n\n## 数据与图表的添加与扩展\n\n数据源与图表的扩展Grafana都采用插件的形式，因此我们想要扩展某个类型的数据源或者图表时，都需要先在Grafana插件市场找到目标插件，然后进行安装，如下图代码\n\n```\nFROM grafana/grafana:8.3.1\nUSER root\nRUN grafana-cli plugins install grafana-clickhouse-datasource //数据源插件\nRUN grafana-cli plugins install auxmoney-waterfall-panel //图表插\n```\n\n\n\n## 数据源添加\n✦\n\n打开Grafana平台，点击左侧\"设置\"图标，进入DataSource管理面板。\n\n![Alt text](image-40.png)               \n\n在“Add data source\"面板中选择合适的数据源，并配置数据库信息。下图以Promethrus为例，添加数据源需要进行必要的配置，例如数据源的ip，port以及鉴权信息等。\n\n![Alt text](image-41.png)         \n\n![Alt text](image-42.png)        \n\n\n\n## 图表插件添加\n✦\n\n1. 打开Grafana平台，点击左侧\"设置\"图标，进入Plugins管理面板\n\n ![Alt text](image-43.png)          \n\n\n\n2. 在tab 栏筛选已经安装的插件，就可以看到已经安装可以使用的插件\n\n           \n![Alt text](image-44.png)\n\n\n3. 图表面板已经安装，可以直接在创建面板的时候指定类型使用\n\n![Alt text](image-45.png)       \n\n\n\n\n\n\n# Grafana入门使用\n\n这里需要区分两个概念：\n\n看板（dashboard）: 一个或多个数据图表形成的集合\n\n面板（panel）：组成看板的其中一个图表\n\n\n\n## 创建一个看板 (dashboard)\n✦\n\n创建一个数据可视化看板的前提是需要有数据源的接入， 具体具体接入方法见数据与图表的添加与扩展\n\n\n\n1. 打开Grafana平台，点击左侧\"加号\"，点击Create类目下的Dashboard 按钮，新创建一个空表的看板， 会默认弹出四个添加panel的选项        \n\n![Alt text](image-46.png)\n![Alt text](image-47.png)\n\na.添加一个空白面板\n\nb. 添加一个新的行，用于面板的分类\n\nc. 从面板库添加一个面板\n\nd. 从剪贴板添加一个面板，可以用来快速复制一个已有的面板\n\n\n\n2. 点击看板右上角保存看板。        \n![Alt text](image-48.png)\na. 输入看板名称\n\nb. 输入简单描述文字\n\nc. 选择看板所属目录（用来分类管理看板）\n\nd. 可选为看板设置Tag，标记看板的特征，后期可根据Tag来筛选看板\n\ne. 其他选项可按需自主定义\n\n\n\n## 创建面板 (panel)\n✦\n\n![Alt text](image-50.png)         \n\n点击上图所示的图表，会弹出创建面板的四种选择，可以根据自己的需求自主创建，下面我们以创建空白面板为例\n\n点击Add a new panel 按钮， 你就会创建一个空白数据的图表面板，如下图\n\n   \n![Alt text](image-51.png)\n         \n\n## 面板数据的获取\n前文已经提到， 创建一个数据可视化看板的前提是需要有数据源的接入，因此，我们想要获取数据，必须要进行数据源的接入\n\n1. 选择数据源（Data source）\n![Alt text](image-52.png)\n        配置选择自己接入的数据源后，后续才能进行相关数据获取的语法编写，这里不同的数据源之前需要的语法也不一样，因此大家可以自己根据自己的条件自主选择， 因为QQ直播接入的数据源是influxdb, 因此后面的例子将会以influxdb语法为例。\n\n\n\n2. SQL语句的编写\n\nGrafana的面板语法编辑有两种形式， 简易模式与高级模式\n\nGrafana 一个面板支持多条SQL语句\n\n\n\na. 简易模式：简易模式数据的获取主要通过下拉框的形式选择具体的指标以及判断条件， 支持添加多个条件\n\n![Alt text](image-53.png)   \n\n高级模式：通过点击编辑图标可以进行编辑模式的切换，高级模式下为全部的SQL语句的编书写，此模式对于语法有一定的要求，但是获取数据会更加的灵活\n\n![Alt text](image-54.png)\n\n## 面板的基础配置\n在编辑完成数据获取的SQL语句之后，面板上应该已经有了相关数据的展示，此时可以根据自己的数据格式，以及展示诉求来选择对应的图表，图表具体选择参考上文数据与图表的搭配\n\n\n\n我们以默认的Time series的折线图为例，简述一下面板的基础配置\n\n![Alt text](image-55.png)\n\n\n\n1. 面板的基础信息\n\n![Alt text](image-56.png)      \n\n在通过SQL语句选择加载完成数据后，图表会有默认的样式给到我们，此时如果对面板无其他要求，只需配置一下面板的基础信息就可完成Grafana的看板配置\n\n基础信息包括\n\na. 标题\n\nb. 描述\n\nc. 背景是否透明\n\n\n\n2. 数据提示\n\n![Alt text](image-57.png)        \n\nTootip配置项用于配置当鼠标经过（hover）图表数据点的时候的提示信息， 可选为Single单个提醒， All显示所有数据， Hidden都不显示\n\n         \n![Alt text](image-58.png)\n\n\n3. 图例（legend）显示设置\n\n         \n![Alt text](image-59.png)\n\n\n图例显示模式有三种\n\na. List (默认)， 图例数据横向依次展示\n\nb. Table， 图例数据会按照表格形式展示\n\nc. Hidden, 不展示图例\n\n\n\n图例的位置\n\na. Bottom, 陈列在图表底部\n\nb. Right, 陈列在图表的右侧\n\n\n\n 图例值展示\n\n![Alt text](image-60.png)      \n\n此处会有一个下拉列表供我们选择图例的显示数据，默认不展示，用户也可以选择数据展示形式，例如最大值，最小值，平均值等\n\n\n\n4. 坐标轴（Axis）配置\n\n![Alt text](image-61.png)         \n\n坐标轴的基础配置一般只需要设置一下坐标轴的名称（Label）即可，其余的设置可以按照默认值不用修改，下面简述一下配置的含义\n\na. Width选项可以选择设置坐标轴（Label）的占比宽度\n\nb. Soft min 以及 Soft max 用来设置纵坐标的显示的最大值最小值\n\nc. Show gride lines 可以设置是否显示背景的网格线\n\nd. Scale 用来设置是否进行数据的放大，目的是让数据对比更加清晰\n\n\n\n通过以上对一个图表面板的基础配置，我们的一个图表基本上已经成型，可以达到数据可视化的正常显示目的，剩下的就是加强对自己数据格式类型的分析以及基于自己的可视化诉求来进行合适的图表面板的配置选择，就可以通过多个图表的添加来完成自己初版的数据可视化看板。\n\n\n\n\n# Grafana进阶使用\n\n当我们选择一个图表插件进行数据可视化的时候，图表的一些属性会帮我们设置好了默认值，但是基于兼容性更广的特性，这些默认值也许并不是我们选择图表最合适的展示效果，因此为了进一步提升图表的展示性，我们可以通过以下属性来进行面板的进一步美化。\n\n\n\n## 图表属性配置 (Standard options)\n✦\n\n![Alt text](image-62.png)              \n\n此选项框中的属性配置，可以使得我们的数据展示更加的准确，例如纵坐标的单位，我们不想采用通用意义上的在Label上进行命名标注单位例如耗时（ms）, 那么就可以选择此处的单位属性（Unit）进行更精确的展示\n\n\n\n1. 单位（Unit）\n\n![Alt text](image-63.png)              \n\n在单位选项中， 你可以进行非常精细化的选择，选项框中几乎包含了所有品类用到的单位属性，例如百分比，长度单位，时间单位，角度单位等等\n\n\n\n2. 显示范围（Min, Max）\n\n在Min, Max 选项中，允许用户输入一个数字进行显示范围的限制，那么图表上在显示范围之外的数据将不会在图表中显示，例如我将耗时限制在0~3000范围，那么3000以外的数据将会被隐藏\n\n               \n![Alt text](image-64.png)\n\n\n3. Decimals 选项可以用来设置纵坐标数据的小数点范围\n\n\n\n4. Display Name 选项则可以用来设置图例显示名字，但是由于限制，只能在只有一类数据时比较适用，如果数据类别较多，单纯在此处设置会将全部图例数据覆盖，因此图例的名称最好在SQL语句编写的时候就做好展示。当然后面也会讲有别的方法进行多种图例数据别名的单独设置\n\n\n\n5. 图表颜色配置（Color scheme）\n\n一般图表颜色的展示都会有默认值，不过我们想要改变现在图表曲线的颜色分类可以在此处进行设置。\n\n               \n![Alt text](image-65.png)\n\n\n我们可以选择整体图表的颜色走向或者是颜色分布，但是一般曲线展示的颜色还是会根据数据自己适配，因此如果我们想要改变某一条曲线的颜色，可以直接点击图例前面的颜色icon,进行颜色选择。我们可以根据提供选项进行选择，也可以自定义设置颜色。\n\n\n![Alt text](image-66.png)\n                \n\n## 阈值设置 (Thresholds)\n✦\n\n有些图表插件是支持设置阈值的， 阈值的设置可以使得我们对数据的合规程度有清晰的对比，能够直观的衡量出当前数据的质量，因此阈值设置也是面板美化展示的一个重要部分\n\n\n\n![Alt text](image-67.png)              \n\n\n\n如上图示例，我们设置对耗时的图表设置了两个阈值，上图的意义是：\n\n* 在3000ms和5000ms设置阈值\n\n* 3000ms以下将视为健康，颜色标记为绿色\n\n* 3000ms~5000ms视为亚健康，颜色标记黄色\n\n* 5000ms以上视为警示，颜色标记为红色\n\n\n\n阈值的模式有两种选择\n\n1. 绝对值, 即按照标记的阈值数据进行比较\n\n2. 百分比, 阈值为相对于最大值的占比\n\n\n\n阈值展示的形式有四种：\n\n1. 不展示 （off）\n\n2. 只展示阈值线 （as lines）\n\n3. 只展示区域 （as filled regions）\n\n4. 同时展示阈值线和区域 （as filled regions and lines）\n\n\n\n下图为我们选择绝对值模式下，展示线和区域的阈值示例图， 由图可以看出数据在不同阈值区间的分布，以及与阈值的对比，因此我们能直观的评估出数据的质量\n\n\n\n![Alt text](image-68.png)            \n\n\n\n## 数值映射 (Value mappings)\n✦\n\n![Alt text](image-69.png)            \n\n图表的展示都是由许多的值来组成的一个个点，连线，反过来讲，图表就是数据值的展现，在图表中， 有时候有些数据并不是我们理想的数值，或者说我们想特异性的让某些值显示为其他值（写SQL语句也可以实现）， 这时候可以使用数值映射选项\n\n\n![Alt text](image-70.png)\n               \n\n数值映射的形式可以有以下四种\n\n1 单纯的某个值映射\n\n2. 一段范围区间映射\n\n3. 正则表达式映射\n\n4. 针对某类值映射\n\n\n\n例如在示例中，假如我们健康波段数据具体值不关心， 只是关心整体的数据波动范围是否在健康范围之内，我们可以把0~3000ms的范围映射为健康，那么再具体显示的时候，不再会有具体值给到我们，统一会展示健康，如下图：\n\n               \n![Alt text](image-71.png)\n\n\n这个功能更加适用于表格数据，例如我们明确的将空数据映射为空或0的场景，如下图\n\n               \n![Alt text](image-72.png)\n\n\n## 数据覆盖 (Overrides)\n✦\n\n数据覆盖允许我们对之前已经设置好的图表进行个性化设置，它相当于图表更高级的设置，覆盖的范围可以是整个SQL语句获取的数据，也可以是数据中某一类图例数据\n\n![Alt text](image-73.png)         \n\n具体覆盖的数据类别：\n\n1 某一类数据\n\n2. 正则匹配到的数据\n\n3. 某些类型的数据\n\n4. 整个SQL查询的数据\n\n\n\n在设置了一个Override 之后，就可以进一步进行子项的配置，子项里面的属性几乎与上文介绍的图表属性一致\n\n![Alt text](image-74.png)          \n\n我们通过覆盖属性的配置，可以让修改到之前我们已经在整体设置好的图标样式\n\n\n\n例如我们现在经过SQL查询，已经获取到了js_ready和css_ready的耗时数据，但是我们想让这两种数据对比更加明确，既能够清晰的看到整体的趋势，也能看到某类数据单独的变化，这时我们可以通过override属性进行配置，让两个数据的纵坐标分别在左右两边，并且数据展示用折线和柱状图分别表示。\n\n\n\n具体override配置属性如下图：\n\n![Alt text](image-75.png)              \n\n\n\n对css_ready 数据配置：\n\n1. 图表展示为柱状图， 柱状图数据点居中\n\n2. 纵坐标数据靠右展示，颜色为浅绿色\n\n3. 标题设置为CSS耗时（ms）\n\n\n\n对js_ready数据配置：\n\n1. 默认基础配置折线图\n\n2. 默认纵坐标靠左展示\n\n3. 设置颜色红色\n\n4. 标题设置为JS耗时（ms）\n\n\n\n最终结果如下图：                         \n![Alt text](image-76.png)\n\n## 变量与模板\n✦\n\n在Grafana里面，学会使用变量，会发现打开了新世界的大门，用好变量，可能你的工作量就会缩减一半，甚至更多。\n\n\n\n变量的使用场景有很多，例如我们编写SQL语句中的时间选项（$__interval），就是内置的一个变量，通过这个时间变量，可以控制多个图表在不同时间范围内的展示情况，因此一个好的变量的使用，可以让我们只配置一个图表，达到展示不同条件下的数据的目的，而不用去为每一种情况设置一个图表。\n\n\n\n模板在Grafana中最简单的含义就是任何一条包含变量的查询（query)。\n\n\n\n【变量的设置】\n\n变量的设置是基于看板的，看板内设置的变量，对看板内的所有面板是共享的\n\n点击看板设置，进入变量设置页面\n\n               \n![Alt text](image-77.png)\n\n\n![Alt text](image-78.png)            \n\n\n\n【变量的种类】\n\n ![Alt text](image-79.png)              \n\n\n\n在添加一个变量的可选下拉框中，可以选择添加的变量类型，共计有以下几种变量可以选择\n\n\n\n\n\n|变量类型  |      描述|\n|:-----|:-----|\n| query | 查询变量允许编写可以返回指标名称、标签值或键列表的数据源查询。例如，查询变量可能会返回服务器名称, ID 或数据中心的列表。变量值随着数据源查询动态获取选项而变化。|\n|custom | 手动定义变量选项,使用逗号分隔的列表|\n|text box| 显示具有可选默认值的自由文本输入字段|\n|constant|设置一个常量|\n|data source|快速添加一个数据源的变量|\n|interval|代表时间跨度的变量|\n|ad hoc filters|自动添加到数据源的所有指标查询的键/值过滤器（仅限 InfluxDB、Prometheus 和 Elasticsearch）|\n\n\n\n添加变量的其他输入框选项可以直接根据英文的意义非常直白的看出，例如设置面标签信息，描述信息，以及设置是否在看板中隐藏，对于某些变量类型还可以设置是否可以多选或者是否包含所有的值的选项等等，这些设置可以根据自己的需求来选择。\n\n\n\n【变量的使用】\n\n设置完成变量之后，变量的使用有两种形式\n\n$varname， 这是最直接的方式， 但是这种语法会有限制，就是不能在一个词的中间使用例如：apps.frontend.$varname.requests.count\n\n1. ${var_name}， 如果想要在表达式中间插入变量，请使用此语法，另外这种语法还有一些高级用法，${var_name:<format>}，这种格式可以更好地控制 Grafana 如何插入值，具体的用法可以参考官方文档\n\n\n\n【变量简单使用示例】\n\n沿用上文的数据，我们创建一个简单的自定义变量，url_event,如下图\n\n               \n![Alt text](image-80.png)\n\n\n获取数据的时候,sql 语法就可以写成如下\n\n               \n![Alt text](image-81.png)\n\n\n这样，我们只建立了一个图表面板，由于使用了变量，因此可以只用变量的切换就实现看板数据的变化，如下\n\n变量选择 js_ready\n![Alt text](image-82.png)\n变量选择css_ready\n\n![Alt text](image-83.png)\n\n## Link的使用\n✦\n\n在Grafana中，可以使用链接来进行看板的跳转以及外链的跳转，并且link的使用也非常灵活。\n\n在一个数据面板的设置中，link可以的设置主要有两种方式\n\n\n\n1. 整个面板设置链接\n\n![Alt text](image-84.png)              \n\n\n\n在数据面板的设置中，前文我们没有细讲link的选项，这里其实是为整个数据面板设置跳转链接的入口，通过此处设置link，可以在面板上增加一个icon, 实现我们在点击的时候进行跳转, 具体效果如下图\n\n![Alt text](image-85.png)              \n\n\n\n2. 为具体数据设置link(data links)\n\ndata links属性设置一般只在柱状图、折线图、表格面板里才有，并且，如果没有搭配override属性进行个性化设置的话，默认每个数据点都会设置上跳转的链接，效果如下图\n\n               \n![Alt text](image-86.png)\n\n\n这样的设置其实和整个面板设置link类似，因此不同的data links 最好和override属性搭配，来进行个性化的数据链接跳转，以达到不通数据跳转不同链接的目的。\n\n\n\n## Link与变量的搭配\n✦\n\nGrafana的link设置非常灵活，在link设置中，可以直接使用已经设置的看板变量以及系统的变量来进行链接的组合。\n\n\n\n甚至在data links的设置中，还可以直接使用SQL语句查询到的结果来进行链接的组合，这样也可达到不同数值设置不同的跳转链接的功能\n\n\n\n在添加链接的时候，如果想查看可用变量列表，可以直接在数据链接URL字段中键入 $ 来查看变量列表，效果如下图：\n\n               \n![Alt text](image-87.png)\n\n\n变量列表里的变量主要可以分为三个类型\n\na. 全局内建的变量，例如时间变量的 from, to\n\nb. 用户创建的模板变量，例如上文示例创建的 url_event\n\nc. 基于SQL语句查询出来的数据，一般都在fields字段下\n\n\n\n通过引用变量来创建图表面板的跳转链接，可以较为灵活的实现基于数据的外链跳转以及更为高级的数据看板的之间的联动，下文要讲到的数据下钻就是基于data links 与变量的搭配来实现。\n\n\n\n\n# Grafana高级使用\n\n## 妙用Transform\n✦\n\n前面讲的一些Grafana的使用，都是以SQL语句查询到的数据为基础，在图表可视化上进行的设置与操作，而Transform的功能，大部分是更底层的操作，直接对数据的操作，来达到改变图表展示的目的，是数据可视化之前的操作。\n\ntranform 可以实现将我们查询到的数据进行进一步加工，例如可以进行数据筛选，计算，重命名，排序以及控制隐藏等功能。\n\n               \n![Alt text](image-88.png)\n\n\n本文以几个较为典型的功能简单介绍一下\n\n1. 通过计算添加数据（Add field from calculation）\n\n![Alt text](image-89.png)              \n\n\n\n数据的计算有两种模式：\n\na. Reduce row： 分别对选择的特定字段数据的每一行进行聚合计算\n\nb. Binary option： 选定的两个字段的值进行数学运算例如加减乘除\n\n\n\n2. 转换数据的类型(Convert field type)\n\n可以将选择的特定字段的值的类型指定为固定的数据类型\n\n![Alt text](image-90.png)              \n\n\n\n3. 根据名称筛选数据展示(Filter data by name)\n\na. 可以将SQL语句查询出的字段名称陈列，并且自定义数据的展示与否\n\nb. 也可以直接根据正则表达式进行数据筛选\n\n               \n![Alt text](image-91.png)\n\n\n4. 数据合并（Merge）\n\n类似sql中的join，根据时间序列来进行合并不同的字段数据成为个数据表\n\n               \n![Alt text](image-92.png)\n\n\n5. 重命名（Rename by regex）\n\n可以使用这个功能来进行查询结果名称的转换，允许我们使用正则表达式来进行重命名内容的匹配\n\n![Alt text](image-93.png)          \n\ntransform 还有很多实用的功能，这里就不一一陈列，如果有需要用到操作数据的功能，可以考虑transform功能，全部的功能可以直接看官方文档\n\n\n\n## 面板的Repeat\n✦\n\n面板的repeat 也是需要搭配变量功能来使用，图表面板会根据用户选择的变量个数来进行分别加载，因此，此功能使用的前提是变量的值要大于1个，并且设置了允许多个变量可选，见下图示例\n\n               \n![Alt text](image-94.png)\n\n\n当前提条件满足后，可以在面板的repeat属性进行设置\n\n               \n\n\n\nrepeat 可选加载的方向是横向还是纵向，并且可以设置最大的重复个数，来避免造成加载展示问题以及性能问题。\n\n\n\n当设置完成后，并不会马上生效，需要保存然后退出此图表面板然后重新加载一下数据看板，然后数据图表就会根据我们选择的变量的个数来进行分别的展示。\n\n以上文的示例设置之后，效果如图：\n\n               \n![Alt text](image-95.png)\n\n\n## 数据下钻\n✦\n\n要实现一个数据下钻，需要link搭配变量来进行看板之间的联动，主要的思路大体如下：\n\n1. 模板看板B中设置好需要的变量\n\n2. 模板看板B查询数据时引用变量\n\n3. 在源图表面板A中设置跳转到模板看板B的链接，链接上引用我们设置或者是查询的变量内容\n\n4. 跳转至目标模板数据看板B时，模板看板B获取从link上带过来的变量值\n\n5. 变量赋值，模板看板B根据变量值刷新数据查询\n\n\n\n经过上面的步骤，那么一个数据看板之间的联动就完成了，剩下的步骤就是丰富变量的设置以及看板内图表面板的内容了。\n\n\n\n那么如何从跳转过来的link上获取到携带过来的变量的值呢？\n\n\n\n在上文我们设置变量来控制数据面板repeat的时候，我们设置了一个变量 url_event\n\n当控制变量为 js_ready的时候，看板的整体URL是\n        \n![Alt text](image-96.png)\n\n\n当控制变量为 css_ready的时候，看板的整体URL是\n\n               \n![Alt text](image-97.png)\n\n\n因此我们可以看到，当我们看板设置变量并且使用的时候，变量的内容是以query的格式显示在URL上的，并且命名的格式如下：\n```\nvar-{your_var_name} = {your_var_value}\n```\n\n当变量在url上面显式的标记的时候，Grafana会主动获取链接上面声明的变量的值并赋值给模板变量。\n\n\n\n因此根据上面的格式，我们可以在link上面构造上述的数据query格式，为模板的看板变量赋值。\n\n\n\n于是实现一个的数据下钻整体流程都变得清晰了，下面我们还是以上文的例子来构造一个简单的数据下钻的例子\n\n\n\n1. 构造一个整体的page render 数据看板 A\n\n将数据格式以table的形式展现，整体性的展示当天项目的render过程的各个事件平均耗时情况，如下图：\n\n               \n![Alt text](image-98.png)\n\n\n2. 设置一个详细指标数据的模板看板 B\n\n新建另一个数据详情的看板，然后建立一个事件的变量\n\n               \n![Alt text](image-99.png)\n\n\n编写具体事件详细数据的查询SQL语句，并引用变量\n\n               \n![Alt text](image-100.png)\n\n\n3. 通过link实现看板之间的联动\n\n配置数据看板A的data link, 使得每一行数据可以进行下钻详情展示\n\n               \n![Alt text](image-101.png)\n\n\n经过上述步骤，就完成可一个简单的数据下钻，实现可一个项目page render过程的整体数据的可视化，并且可以点击具体加载事件查看该事件详细的数据分布趋势\n\n效果如下:\n![Alt text](image-103.png)\n\n\n## 总结\n\nGrafana是一款非常优秀的开源可视化工具，能非常方便的将数据进行可视化，非常适合数据大盘建设，以及做数据监控和数据统计的工作。\n\n本文基于实际业务中建设监控数据大盘的经验，介绍了Grafana基本的一些图表概念和使用方法，并对不同的数据类型选取合适的可视化图表提供了一些建议和思考。\n\n通过三个阶段的介绍，总结了Grafana进行数据可视化入门教程以及一些进阶使用技巧，希望能在未来你的业务中，数据大盘的建设过程中提供一些便利和思路。","slug":"kubernetes/grafana-dashboard","published":1,"updated":"2023-10-31T02:50:09.089Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0c6000qfmjx3x5h7s26","content":"<p>看完这篇，成为Grafana高手<br>原创 huhuli 腾讯VATeam 2022-09-30 14:08 发表于广东<br><a href=\"https://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ\">https://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ</a></p>\n<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>QQ直播前端团队接入腾讯云前端性能监控（RUM）后，对目前的监控能力以及上报数据进行了梳理， 并着手进行了前端性能监控的专项建设，其中监控数据大盘建设是不可或缺的一环。<br>可视化的监控大盘可以清晰明了的观察到各项目运行情况，宏观上能快速进行项目间的横向对比，也可以非常便捷的进行项目各数据维度的详细展示，纵向的分析各指标数据的统计。</p>\n<p><img src=\"/image-30.png\" alt=\"Alt text\"></p>\n<p>通过对数据大盘支持能力的调研，我们采用Grafana进行了数据大盘的建设。通过搭建Grafana服务，然后添加监控上报数据，最终使得【QQ直播前端监控数据大盘】得以建设完成。</p>\n<p>那么什么是Grafana？</p>\n<p>Grafana 是一款开源的数据可视化工具，使用Grafana可以非常轻松的将数据转成图表(如下图)的展现形式来做到数据监控以及数据统计。</p>\n<p>Grafana官方提供Linux，Windows，MacOS，Docker版本</p>\n<p>下载链接:  <a href=\"https://grafana.com/get/\">https://grafana.com/get/</a></p>\n<p>本文将依托建设数据大盘的经验，重点介绍一下Grafana的使用，助力小伙伴们成为Grafana高手。</p>\n<h1 id=\"数据与图表\"><a href=\"#数据与图表\" class=\"headerlink\" title=\"数据与图表\"></a>数据与图表</h1><p>数据的可视化都是通过图表为载体的，不同的图表可以将数据进行不同侧重点的展现，要进行数据大盘的建设，首先要对图表有一个简单的了解，这样才能在数据大盘搭建过程中选择合适的图表，合理的进行可视化效果的展示。</p>\n<p>认识Grafana的图表<br>✦</p>\n<p>Grafana 的图表的选择路径都是 在 Visualization 类目下进行图表的选择</p>\n<p><img src=\"/image-31.png\" alt=\"Alt text\"></p>\n<h2 id=\"1-折线图\"><a href=\"#1-折线图\" class=\"headerlink\" title=\"1. 折线图\"></a>1. 折线图</h2><p><img src=\"/image-32.png\" alt=\"Alt text\">           </p>\n<p>示例图表：Time series</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Lines</p>\n<p>b. Fill opacity: 3</p>\n<p>c. Gradient mode: scheme</p>\n<h2 id=\"2-柱状图\"><a href=\"#2-柱状图\" class=\"headerlink\" title=\"2. 柱状图\"></a>2. 柱状图</h2><p><img src=\"/image-39.png\" alt=\"Alt text\">         </p>\n<p>示例图表：Time series</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Bars</p>\n<p>b. Fill opacity: 3</p>\n<p>c. Gradient mode: scheme</p>\n<h2 id=\"3-点状图\"><a href=\"#3-点状图\" class=\"headerlink\" title=\"3. 点状图\"></a>3. 点状图</h2><p><img src=\"/image-33.png\" alt=\"Alt text\">        </p>\n<p>示例图表：Time series</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Points</p>\n<p>b. Point size: 5</p>\n<p>c. Stack series: Normal</p>\n<h2 id=\"4-饼状图\"><a href=\"#4-饼状图\" class=\"headerlink\" title=\"4. 饼状图\"></a>4. 饼状图</h2><p><img src=\"/image-34.png\" alt=\"Alt text\">          </p>\n<p>示例图表：Pie chart</p>\n<h2 id=\"5-单一状态图\"><a href=\"#5-单一状态图\" class=\"headerlink\" title=\"5. 单一状态图\"></a>5. 单一状态图</h2><p><img src=\"/image-35.png\" alt=\"Alt text\">          </p>\n<p>示例图表：Stat</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Bars</p>\n<p>b. Fill opacity: 3</p>\n<p>c. Gradient mode: scheme</p>\n<h2 id=\"6-仪表盘\"><a href=\"#6-仪表盘\" class=\"headerlink\" title=\"6. 仪表盘\"></a>6. 仪表盘</h2><p><img src=\"/image-36.png\" alt=\"Alt text\">        </p>\n<p>示例图表：Gauge</p>\n<h2 id=\"7-表格\"><a href=\"#7-表格\" class=\"headerlink\" title=\"7. 表格\"></a>7. 表格</h2><p><img src=\"/image-37.png\" alt=\"Alt text\">         </p>\n<p>示例图表：Table</p>\n<h2 id=\"8-文本\"><a href=\"#8-文本\" class=\"headerlink\" title=\"8. 文本\"></a>8. 文本</h2><p><img src=\"/image-38.png\" alt=\"Alt text\">           </p>\n<p>示例图表：Text（支持Markdown 和 HTML两种格式）</p>\n<h2 id=\"9-…\"><a href=\"#9-…\" class=\"headerlink\" title=\"9. …\"></a>9. …</h2><h1 id=\"数据与图表的搭配\"><a href=\"#数据与图表的搭配\" class=\"headerlink\" title=\"数据与图表的搭配\"></a>数据与图表的搭配</h1><h2 id=\"按照数据格式区分\"><a href=\"#按照数据格式区分\" class=\"headerlink\" title=\"按照数据格式区分\"></a>按照数据格式区分</h2><p>✦</p>\n<p>柱状图， 折线图， 饼状图的图表都需要数据具有时间序列，用于展示在一定的时间区间或者是连续的时间范围内，单一数据或者多种分类数据的变化趋势，或者是数量占比。</p>\n<p>状态图， 表格数据，仪表盘等则对数据没有时间序列要求，状态图，仪表盘可用于进行一些总结性的数据展示，例如速度，温度，进度，完成度等， 表格数据则更适合展示复杂数据或者多维度数据</p>\n<h2 id=\"按照使用意图区分\"><a href=\"#按照使用意图区分\" class=\"headerlink\" title=\"按照使用意图区分\"></a>按照使用意图区分</h2><p>✦</p>\n<p>数据比较：柱状图，折线图比较合适，可以实现单数据，多种类数据的比较，能清晰看到变化趋势</p>\n<p>占比分类：饼图，仪表盘， 单一状态图等比较合适，可以清晰的看到每个数据整体性的占比</p>\n<p>趋势比较：折线图，面积图(折线可设置覆盖面积) 等比较合适，能直观展现数据变化</p>\n<p>分布类：饼图， 散点图 等比较合适</p>\n<h2 id=\"其他-✦\"><a href=\"#其他-✦\" class=\"headerlink\" title=\"其他      ✦\"></a>其他      ✦</h2><p>文字类图表就如同名字含义一样，可用于展示文字相关信息，并且个性化定制程度，灵活性排布支持都非常高（得益于Markdown 和 HTML的强大灵活性）</p>\n<p>表格对于日志类型，或者是其他多维度数据展示较为合适，适用于整体性给出一个报表，并且具备排序等公共功能，方便数据快速比较。</p>\n<h2 id=\"数据与图表的添加与扩展\"><a href=\"#数据与图表的添加与扩展\" class=\"headerlink\" title=\"数据与图表的添加与扩展\"></a>数据与图表的添加与扩展</h2><p>数据源与图表的扩展Grafana都采用插件的形式，因此我们想要扩展某个类型的数据源或者图表时，都需要先在Grafana插件市场找到目标插件，然后进行安装，如下图代码</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM grafana/grafana:8.3.1</span><br><span class=\"line\">USER root</span><br><span class=\"line\">RUN grafana-cli plugins install grafana-clickhouse-datasource //数据源插件</span><br><span class=\"line\">RUN grafana-cli plugins install auxmoney-waterfall-panel //图表插</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"数据源添加\"><a href=\"#数据源添加\" class=\"headerlink\" title=\"数据源添加\"></a>数据源添加</h2><p>✦</p>\n<p>打开Grafana平台，点击左侧”设置”图标，进入DataSource管理面板。</p>\n<p><img src=\"/image-40.png\" alt=\"Alt text\">               </p>\n<p>在“Add data source”面板中选择合适的数据源，并配置数据库信息。下图以Promethrus为例，添加数据源需要进行必要的配置，例如数据源的ip，port以及鉴权信息等。</p>\n<p><img src=\"/image-41.png\" alt=\"Alt text\">         </p>\n<p><img src=\"/image-42.png\" alt=\"Alt text\">        </p>\n<h2 id=\"图表插件添加\"><a href=\"#图表插件添加\" class=\"headerlink\" title=\"图表插件添加\"></a>图表插件添加</h2><p>✦</p>\n<ol>\n<li>打开Grafana平台，点击左侧”设置”图标，进入Plugins管理面板</li>\n</ol>\n<p> <img src=\"/image-43.png\" alt=\"Alt text\">          </p>\n<ol start=\"2\">\n<li>在tab 栏筛选已经安装的插件，就可以看到已经安装可以使用的插件</li>\n</ol>\n<p><img src=\"/image-44.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li>图表面板已经安装，可以直接在创建面板的时候指定类型使用</li>\n</ol>\n<p><img src=\"/image-45.png\" alt=\"Alt text\">       </p>\n<h1 id=\"Grafana入门使用\"><a href=\"#Grafana入门使用\" class=\"headerlink\" title=\"Grafana入门使用\"></a>Grafana入门使用</h1><p>这里需要区分两个概念：</p>\n<p>看板（dashboard）: 一个或多个数据图表形成的集合</p>\n<p>面板（panel）：组成看板的其中一个图表</p>\n<h2 id=\"创建一个看板-dashboard\"><a href=\"#创建一个看板-dashboard\" class=\"headerlink\" title=\"创建一个看板 (dashboard)\"></a>创建一个看板 (dashboard)</h2><p>✦</p>\n<p>创建一个数据可视化看板的前提是需要有数据源的接入， 具体具体接入方法见数据与图表的添加与扩展</p>\n<ol>\n<li>打开Grafana平台，点击左侧”加号”，点击Create类目下的Dashboard 按钮，新创建一个空表的看板， 会默认弹出四个添加panel的选项</li>\n</ol>\n<p><img src=\"/image-46.png\" alt=\"Alt text\"><br><img src=\"/image-47.png\" alt=\"Alt text\"></p>\n<p>a.添加一个空白面板</p>\n<p>b. 添加一个新的行，用于面板的分类</p>\n<p>c. 从面板库添加一个面板</p>\n<p>d. 从剪贴板添加一个面板，可以用来快速复制一个已有的面板</p>\n<ol start=\"2\">\n<li>点击看板右上角保存看板。<br><img src=\"/image-48.png\" alt=\"Alt text\"><br>a. 输入看板名称</li>\n</ol>\n<p>b. 输入简单描述文字</p>\n<p>c. 选择看板所属目录（用来分类管理看板）</p>\n<p>d. 可选为看板设置Tag，标记看板的特征，后期可根据Tag来筛选看板</p>\n<p>e. 其他选项可按需自主定义</p>\n<h2 id=\"创建面板-panel\"><a href=\"#创建面板-panel\" class=\"headerlink\" title=\"创建面板 (panel)\"></a>创建面板 (panel)</h2><p>✦</p>\n<p><img src=\"/image-50.png\" alt=\"Alt text\">         </p>\n<p>点击上图所示的图表，会弹出创建面板的四种选择，可以根据自己的需求自主创建，下面我们以创建空白面板为例</p>\n<p>点击Add a new panel 按钮， 你就会创建一个空白数据的图表面板，如下图</p>\n<p><img src=\"/image-51.png\" alt=\"Alt text\"></p>\n<h2 id=\"面板数据的获取\"><a href=\"#面板数据的获取\" class=\"headerlink\" title=\"面板数据的获取\"></a>面板数据的获取</h2><p>前文已经提到， 创建一个数据可视化看板的前提是需要有数据源的接入，因此，我们想要获取数据，必须要进行数据源的接入</p>\n<ol>\n<li><p>选择数据源（Data source）<br><img src=\"/image-52.png\" alt=\"Alt text\"><br> 配置选择自己接入的数据源后，后续才能进行相关数据获取的语法编写，这里不同的数据源之前需要的语法也不一样，因此大家可以自己根据自己的条件自主选择， 因为QQ直播接入的数据源是influxdb, 因此后面的例子将会以influxdb语法为例。</p>\n</li>\n<li><p>SQL语句的编写</p>\n</li>\n</ol>\n<p>Grafana的面板语法编辑有两种形式， 简易模式与高级模式</p>\n<p>Grafana 一个面板支持多条SQL语句</p>\n<p>a. 简易模式：简易模式数据的获取主要通过下拉框的形式选择具体的指标以及判断条件， 支持添加多个条件</p>\n<p><img src=\"/image-53.png\" alt=\"Alt text\">   </p>\n<p>高级模式：通过点击编辑图标可以进行编辑模式的切换，高级模式下为全部的SQL语句的编书写，此模式对于语法有一定的要求，但是获取数据会更加的灵活</p>\n<p><img src=\"/image-54.png\" alt=\"Alt text\"></p>\n<h2 id=\"面板的基础配置\"><a href=\"#面板的基础配置\" class=\"headerlink\" title=\"面板的基础配置\"></a>面板的基础配置</h2><p>在编辑完成数据获取的SQL语句之后，面板上应该已经有了相关数据的展示，此时可以根据自己的数据格式，以及展示诉求来选择对应的图表，图表具体选择参考上文数据与图表的搭配</p>\n<p>我们以默认的Time series的折线图为例，简述一下面板的基础配置</p>\n<p><img src=\"/image-55.png\" alt=\"Alt text\"></p>\n<ol>\n<li>面板的基础信息</li>\n</ol>\n<p><img src=\"/image-56.png\" alt=\"Alt text\">      </p>\n<p>在通过SQL语句选择加载完成数据后，图表会有默认的样式给到我们，此时如果对面板无其他要求，只需配置一下面板的基础信息就可完成Grafana的看板配置</p>\n<p>基础信息包括</p>\n<p>a. 标题</p>\n<p>b. 描述</p>\n<p>c. 背景是否透明</p>\n<ol start=\"2\">\n<li>数据提示</li>\n</ol>\n<p><img src=\"/image-57.png\" alt=\"Alt text\">        </p>\n<p>Tootip配置项用于配置当鼠标经过（hover）图表数据点的时候的提示信息， 可选为Single单个提醒， All显示所有数据， Hidden都不显示</p>\n<p><img src=\"/image-58.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li>图例（legend）显示设置</li>\n</ol>\n<p><img src=\"/image-59.png\" alt=\"Alt text\"></p>\n<p>图例显示模式有三种</p>\n<p>a. List (默认)， 图例数据横向依次展示</p>\n<p>b. Table， 图例数据会按照表格形式展示</p>\n<p>c. Hidden, 不展示图例</p>\n<p>图例的位置</p>\n<p>a. Bottom, 陈列在图表底部</p>\n<p>b. Right, 陈列在图表的右侧</p>\n<p> 图例值展示</p>\n<p><img src=\"/image-60.png\" alt=\"Alt text\">      </p>\n<p>此处会有一个下拉列表供我们选择图例的显示数据，默认不展示，用户也可以选择数据展示形式，例如最大值，最小值，平均值等</p>\n<ol start=\"4\">\n<li>坐标轴（Axis）配置</li>\n</ol>\n<p><img src=\"/image-61.png\" alt=\"Alt text\">         </p>\n<p>坐标轴的基础配置一般只需要设置一下坐标轴的名称（Label）即可，其余的设置可以按照默认值不用修改，下面简述一下配置的含义</p>\n<p>a. Width选项可以选择设置坐标轴（Label）的占比宽度</p>\n<p>b. Soft min 以及 Soft max 用来设置纵坐标的显示的最大值最小值</p>\n<p>c. Show gride lines 可以设置是否显示背景的网格线</p>\n<p>d. Scale 用来设置是否进行数据的放大，目的是让数据对比更加清晰</p>\n<p>通过以上对一个图表面板的基础配置，我们的一个图表基本上已经成型，可以达到数据可视化的正常显示目的，剩下的就是加强对自己数据格式类型的分析以及基于自己的可视化诉求来进行合适的图表面板的配置选择，就可以通过多个图表的添加来完成自己初版的数据可视化看板。</p>\n<h1 id=\"Grafana进阶使用\"><a href=\"#Grafana进阶使用\" class=\"headerlink\" title=\"Grafana进阶使用\"></a>Grafana进阶使用</h1><p>当我们选择一个图表插件进行数据可视化的时候，图表的一些属性会帮我们设置好了默认值，但是基于兼容性更广的特性，这些默认值也许并不是我们选择图表最合适的展示效果，因此为了进一步提升图表的展示性，我们可以通过以下属性来进行面板的进一步美化。</p>\n<h2 id=\"图表属性配置-Standard-options\"><a href=\"#图表属性配置-Standard-options\" class=\"headerlink\" title=\"图表属性配置 (Standard options)\"></a>图表属性配置 (Standard options)</h2><p>✦</p>\n<p><img src=\"/image-62.png\" alt=\"Alt text\">              </p>\n<p>此选项框中的属性配置，可以使得我们的数据展示更加的准确，例如纵坐标的单位，我们不想采用通用意义上的在Label上进行命名标注单位例如耗时（ms）, 那么就可以选择此处的单位属性（Unit）进行更精确的展示</p>\n<ol>\n<li>单位（Unit）</li>\n</ol>\n<p><img src=\"/image-63.png\" alt=\"Alt text\">              </p>\n<p>在单位选项中， 你可以进行非常精细化的选择，选项框中几乎包含了所有品类用到的单位属性，例如百分比，长度单位，时间单位，角度单位等等</p>\n<ol start=\"2\">\n<li>显示范围（Min, Max）</li>\n</ol>\n<p>在Min, Max 选项中，允许用户输入一个数字进行显示范围的限制，那么图表上在显示范围之外的数据将不会在图表中显示，例如我将耗时限制在0~3000范围，那么3000以外的数据将会被隐藏</p>\n<p><img src=\"/image-64.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li><p>Decimals 选项可以用来设置纵坐标数据的小数点范围</p>\n</li>\n<li><p>Display Name 选项则可以用来设置图例显示名字，但是由于限制，只能在只有一类数据时比较适用，如果数据类别较多，单纯在此处设置会将全部图例数据覆盖，因此图例的名称最好在SQL语句编写的时候就做好展示。当然后面也会讲有别的方法进行多种图例数据别名的单独设置</p>\n</li>\n<li><p>图表颜色配置（Color scheme）</p>\n</li>\n</ol>\n<p>一般图表颜色的展示都会有默认值，不过我们想要改变现在图表曲线的颜色分类可以在此处进行设置。</p>\n<p><img src=\"/image-65.png\" alt=\"Alt text\"></p>\n<p>我们可以选择整体图表的颜色走向或者是颜色分布，但是一般曲线展示的颜色还是会根据数据自己适配，因此如果我们想要改变某一条曲线的颜色，可以直接点击图例前面的颜色icon,进行颜色选择。我们可以根据提供选项进行选择，也可以自定义设置颜色。</p>\n<p><img src=\"/image-66.png\" alt=\"Alt text\"></p>\n<h2 id=\"阈值设置-Thresholds\"><a href=\"#阈值设置-Thresholds\" class=\"headerlink\" title=\"阈值设置 (Thresholds)\"></a>阈值设置 (Thresholds)</h2><p>✦</p>\n<p>有些图表插件是支持设置阈值的， 阈值的设置可以使得我们对数据的合规程度有清晰的对比，能够直观的衡量出当前数据的质量，因此阈值设置也是面板美化展示的一个重要部分</p>\n<p><img src=\"/image-67.png\" alt=\"Alt text\">              </p>\n<p>如上图示例，我们设置对耗时的图表设置了两个阈值，上图的意义是：</p>\n<ul>\n<li><p>在3000ms和5000ms设置阈值</p>\n</li>\n<li><p>3000ms以下将视为健康，颜色标记为绿色</p>\n</li>\n<li><p>3000ms~5000ms视为亚健康，颜色标记黄色</p>\n</li>\n<li><p>5000ms以上视为警示，颜色标记为红色</p>\n</li>\n</ul>\n<p>阈值的模式有两种选择</p>\n<ol>\n<li><p>绝对值, 即按照标记的阈值数据进行比较</p>\n</li>\n<li><p>百分比, 阈值为相对于最大值的占比</p>\n</li>\n</ol>\n<p>阈值展示的形式有四种：</p>\n<ol>\n<li><p>不展示 （off）</p>\n</li>\n<li><p>只展示阈值线 （as lines）</p>\n</li>\n<li><p>只展示区域 （as filled regions）</p>\n</li>\n<li><p>同时展示阈值线和区域 （as filled regions and lines）</p>\n</li>\n</ol>\n<p>下图为我们选择绝对值模式下，展示线和区域的阈值示例图， 由图可以看出数据在不同阈值区间的分布，以及与阈值的对比，因此我们能直观的评估出数据的质量</p>\n<p><img src=\"/image-68.png\" alt=\"Alt text\">            </p>\n<h2 id=\"数值映射-Value-mappings\"><a href=\"#数值映射-Value-mappings\" class=\"headerlink\" title=\"数值映射 (Value mappings)\"></a>数值映射 (Value mappings)</h2><p>✦</p>\n<p><img src=\"/image-69.png\" alt=\"Alt text\">            </p>\n<p>图表的展示都是由许多的值来组成的一个个点，连线，反过来讲，图表就是数据值的展现，在图表中， 有时候有些数据并不是我们理想的数值，或者说我们想特异性的让某些值显示为其他值（写SQL语句也可以实现）， 这时候可以使用数值映射选项</p>\n<p><img src=\"/image-70.png\" alt=\"Alt text\"></p>\n<p>数值映射的形式可以有以下四种</p>\n<p>1 单纯的某个值映射</p>\n<ol start=\"2\">\n<li><p>一段范围区间映射</p>\n</li>\n<li><p>正则表达式映射</p>\n</li>\n<li><p>针对某类值映射</p>\n</li>\n</ol>\n<p>例如在示例中，假如我们健康波段数据具体值不关心， 只是关心整体的数据波动范围是否在健康范围之内，我们可以把0~3000ms的范围映射为健康，那么再具体显示的时候，不再会有具体值给到我们，统一会展示健康，如下图：</p>\n<p><img src=\"/image-71.png\" alt=\"Alt text\"></p>\n<p>这个功能更加适用于表格数据，例如我们明确的将空数据映射为空或0的场景，如下图</p>\n<p><img src=\"/image-72.png\" alt=\"Alt text\"></p>\n<h2 id=\"数据覆盖-Overrides\"><a href=\"#数据覆盖-Overrides\" class=\"headerlink\" title=\"数据覆盖 (Overrides)\"></a>数据覆盖 (Overrides)</h2><p>✦</p>\n<p>数据覆盖允许我们对之前已经设置好的图表进行个性化设置，它相当于图表更高级的设置，覆盖的范围可以是整个SQL语句获取的数据，也可以是数据中某一类图例数据</p>\n<p><img src=\"/image-73.png\" alt=\"Alt text\">         </p>\n<p>具体覆盖的数据类别：</p>\n<p>1 某一类数据</p>\n<ol start=\"2\">\n<li><p>正则匹配到的数据</p>\n</li>\n<li><p>某些类型的数据</p>\n</li>\n<li><p>整个SQL查询的数据</p>\n</li>\n</ol>\n<p>在设置了一个Override 之后，就可以进一步进行子项的配置，子项里面的属性几乎与上文介绍的图表属性一致</p>\n<p><img src=\"/image-74.png\" alt=\"Alt text\">          </p>\n<p>我们通过覆盖属性的配置，可以让修改到之前我们已经在整体设置好的图标样式</p>\n<p>例如我们现在经过SQL查询，已经获取到了js_ready和css_ready的耗时数据，但是我们想让这两种数据对比更加明确，既能够清晰的看到整体的趋势，也能看到某类数据单独的变化，这时我们可以通过override属性进行配置，让两个数据的纵坐标分别在左右两边，并且数据展示用折线和柱状图分别表示。</p>\n<p>具体override配置属性如下图：</p>\n<p><img src=\"/image-75.png\" alt=\"Alt text\">              </p>\n<p>对css_ready 数据配置：</p>\n<ol>\n<li><p>图表展示为柱状图， 柱状图数据点居中</p>\n</li>\n<li><p>纵坐标数据靠右展示，颜色为浅绿色</p>\n</li>\n<li><p>标题设置为CSS耗时（ms）</p>\n</li>\n</ol>\n<p>对js_ready数据配置：</p>\n<ol>\n<li><p>默认基础配置折线图</p>\n</li>\n<li><p>默认纵坐标靠左展示</p>\n</li>\n<li><p>设置颜色红色</p>\n</li>\n<li><p>标题设置为JS耗时（ms）</p>\n</li>\n</ol>\n<p>最终结果如下图：<br><img src=\"/image-76.png\" alt=\"Alt text\"></p>\n<h2 id=\"变量与模板\"><a href=\"#变量与模板\" class=\"headerlink\" title=\"变量与模板\"></a>变量与模板</h2><p>✦</p>\n<p>在Grafana里面，学会使用变量，会发现打开了新世界的大门，用好变量，可能你的工作量就会缩减一半，甚至更多。</p>\n<p>变量的使用场景有很多，例如我们编写SQL语句中的时间选项（$__interval），就是内置的一个变量，通过这个时间变量，可以控制多个图表在不同时间范围内的展示情况，因此一个好的变量的使用，可以让我们只配置一个图表，达到展示不同条件下的数据的目的，而不用去为每一种情况设置一个图表。</p>\n<p>模板在Grafana中最简单的含义就是任何一条包含变量的查询（query)。</p>\n<p>【变量的设置】</p>\n<p>变量的设置是基于看板的，看板内设置的变量，对看板内的所有面板是共享的</p>\n<p>点击看板设置，进入变量设置页面</p>\n<p><img src=\"/image-77.png\" alt=\"Alt text\"></p>\n<p><img src=\"/image-78.png\" alt=\"Alt text\">            </p>\n<p>【变量的种类】</p>\n<p> <img src=\"/image-79.png\" alt=\"Alt text\">              </p>\n<p>在添加一个变量的可选下拉框中，可以选择添加的变量类型，共计有以下几种变量可以选择</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">变量类型</th>\n<th align=\"left\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">query</td>\n<td align=\"left\">查询变量允许编写可以返回指标名称、标签值或键列表的数据源查询。例如，查询变量可能会返回服务器名称, ID 或数据中心的列表。变量值随着数据源查询动态获取选项而变化。</td>\n</tr>\n<tr>\n<td align=\"left\">custom</td>\n<td align=\"left\">手动定义变量选项,使用逗号分隔的列表</td>\n</tr>\n<tr>\n<td align=\"left\">text box</td>\n<td align=\"left\">显示具有可选默认值的自由文本输入字段</td>\n</tr>\n<tr>\n<td align=\"left\">constant</td>\n<td align=\"left\">设置一个常量</td>\n</tr>\n<tr>\n<td align=\"left\">data source</td>\n<td align=\"left\">快速添加一个数据源的变量</td>\n</tr>\n<tr>\n<td align=\"left\">interval</td>\n<td align=\"left\">代表时间跨度的变量</td>\n</tr>\n<tr>\n<td align=\"left\">ad hoc filters</td>\n<td align=\"left\">自动添加到数据源的所有指标查询的键&#x2F;值过滤器（仅限 InfluxDB、Prometheus 和 Elasticsearch）</td>\n</tr>\n</tbody></table>\n<p>添加变量的其他输入框选项可以直接根据英文的意义非常直白的看出，例如设置面标签信息，描述信息，以及设置是否在看板中隐藏，对于某些变量类型还可以设置是否可以多选或者是否包含所有的值的选项等等，这些设置可以根据自己的需求来选择。</p>\n<p>【变量的使用】</p>\n<p>设置完成变量之后，变量的使用有两种形式</p>\n<p>$varname， 这是最直接的方式， 但是这种语法会有限制，就是不能在一个词的中间使用例如：apps.frontend.$varname.requests.count</p>\n<ol>\n<li>${var_name}， 如果想要在表达式中间插入变量，请使用此语法，另外这种语法还有一些高级用法，${var_name:<format>}，这种格式可以更好地控制 Grafana 如何插入值，具体的用法可以参考官方文档</li>\n</ol>\n<p>【变量简单使用示例】</p>\n<p>沿用上文的数据，我们创建一个简单的自定义变量，url_event,如下图</p>\n<p><img src=\"/image-80.png\" alt=\"Alt text\"></p>\n<p>获取数据的时候,sql 语法就可以写成如下</p>\n<p><img src=\"/image-81.png\" alt=\"Alt text\"></p>\n<p>这样，我们只建立了一个图表面板，由于使用了变量，因此可以只用变量的切换就实现看板数据的变化，如下</p>\n<p>变量选择 js_ready<br><img src=\"/image-82.png\" alt=\"Alt text\"><br>变量选择css_ready</p>\n<p><img src=\"/image-83.png\" alt=\"Alt text\"></p>\n<h2 id=\"Link的使用\"><a href=\"#Link的使用\" class=\"headerlink\" title=\"Link的使用\"></a>Link的使用</h2><p>✦</p>\n<p>在Grafana中，可以使用链接来进行看板的跳转以及外链的跳转，并且link的使用也非常灵活。</p>\n<p>在一个数据面板的设置中，link可以的设置主要有两种方式</p>\n<ol>\n<li>整个面板设置链接</li>\n</ol>\n<p><img src=\"/image-84.png\" alt=\"Alt text\">              </p>\n<p>在数据面板的设置中，前文我们没有细讲link的选项，这里其实是为整个数据面板设置跳转链接的入口，通过此处设置link，可以在面板上增加一个icon, 实现我们在点击的时候进行跳转, 具体效果如下图</p>\n<p><img src=\"/image-85.png\" alt=\"Alt text\">              </p>\n<ol start=\"2\">\n<li>为具体数据设置link(data links)</li>\n</ol>\n<p>data links属性设置一般只在柱状图、折线图、表格面板里才有，并且，如果没有搭配override属性进行个性化设置的话，默认每个数据点都会设置上跳转的链接，效果如下图</p>\n<p><img src=\"/image-86.png\" alt=\"Alt text\"></p>\n<p>这样的设置其实和整个面板设置link类似，因此不同的data links 最好和override属性搭配，来进行个性化的数据链接跳转，以达到不通数据跳转不同链接的目的。</p>\n<h2 id=\"Link与变量的搭配\"><a href=\"#Link与变量的搭配\" class=\"headerlink\" title=\"Link与变量的搭配\"></a>Link与变量的搭配</h2><p>✦</p>\n<p>Grafana的link设置非常灵活，在link设置中，可以直接使用已经设置的看板变量以及系统的变量来进行链接的组合。</p>\n<p>甚至在data links的设置中，还可以直接使用SQL语句查询到的结果来进行链接的组合，这样也可达到不同数值设置不同的跳转链接的功能</p>\n<p>在添加链接的时候，如果想查看可用变量列表，可以直接在数据链接URL字段中键入 $ 来查看变量列表，效果如下图：</p>\n<p><img src=\"/image-87.png\" alt=\"Alt text\"></p>\n<p>变量列表里的变量主要可以分为三个类型</p>\n<p>a. 全局内建的变量，例如时间变量的 from, to</p>\n<p>b. 用户创建的模板变量，例如上文示例创建的 url_event</p>\n<p>c. 基于SQL语句查询出来的数据，一般都在fields字段下</p>\n<p>通过引用变量来创建图表面板的跳转链接，可以较为灵活的实现基于数据的外链跳转以及更为高级的数据看板的之间的联动，下文要讲到的数据下钻就是基于data links 与变量的搭配来实现。</p>\n<h1 id=\"Grafana高级使用\"><a href=\"#Grafana高级使用\" class=\"headerlink\" title=\"Grafana高级使用\"></a>Grafana高级使用</h1><h2 id=\"妙用Transform\"><a href=\"#妙用Transform\" class=\"headerlink\" title=\"妙用Transform\"></a>妙用Transform</h2><p>✦</p>\n<p>前面讲的一些Grafana的使用，都是以SQL语句查询到的数据为基础，在图表可视化上进行的设置与操作，而Transform的功能，大部分是更底层的操作，直接对数据的操作，来达到改变图表展示的目的，是数据可视化之前的操作。</p>\n<p>tranform 可以实现将我们查询到的数据进行进一步加工，例如可以进行数据筛选，计算，重命名，排序以及控制隐藏等功能。</p>\n<p><img src=\"/image-88.png\" alt=\"Alt text\"></p>\n<p>本文以几个较为典型的功能简单介绍一下</p>\n<ol>\n<li>通过计算添加数据（Add field from calculation）</li>\n</ol>\n<p><img src=\"/image-89.png\" alt=\"Alt text\">              </p>\n<p>数据的计算有两种模式：</p>\n<p>a. Reduce row： 分别对选择的特定字段数据的每一行进行聚合计算</p>\n<p>b. Binary option： 选定的两个字段的值进行数学运算例如加减乘除</p>\n<ol start=\"2\">\n<li>转换数据的类型(Convert field type)</li>\n</ol>\n<p>可以将选择的特定字段的值的类型指定为固定的数据类型</p>\n<p><img src=\"/image-90.png\" alt=\"Alt text\">              </p>\n<ol start=\"3\">\n<li>根据名称筛选数据展示(Filter data by name)</li>\n</ol>\n<p>a. 可以将SQL语句查询出的字段名称陈列，并且自定义数据的展示与否</p>\n<p>b. 也可以直接根据正则表达式进行数据筛选</p>\n<p><img src=\"/image-91.png\" alt=\"Alt text\"></p>\n<ol start=\"4\">\n<li>数据合并（Merge）</li>\n</ol>\n<p>类似sql中的join，根据时间序列来进行合并不同的字段数据成为个数据表</p>\n<p><img src=\"/image-92.png\" alt=\"Alt text\"></p>\n<ol start=\"5\">\n<li>重命名（Rename by regex）</li>\n</ol>\n<p>可以使用这个功能来进行查询结果名称的转换，允许我们使用正则表达式来进行重命名内容的匹配</p>\n<p><img src=\"/image-93.png\" alt=\"Alt text\">          </p>\n<p>transform 还有很多实用的功能，这里就不一一陈列，如果有需要用到操作数据的功能，可以考虑transform功能，全部的功能可以直接看官方文档</p>\n<h2 id=\"面板的Repeat\"><a href=\"#面板的Repeat\" class=\"headerlink\" title=\"面板的Repeat\"></a>面板的Repeat</h2><p>✦</p>\n<p>面板的repeat 也是需要搭配变量功能来使用，图表面板会根据用户选择的变量个数来进行分别加载，因此，此功能使用的前提是变量的值要大于1个，并且设置了允许多个变量可选，见下图示例</p>\n<p><img src=\"/image-94.png\" alt=\"Alt text\"></p>\n<p>当前提条件满足后，可以在面板的repeat属性进行设置</p>\n<p>repeat 可选加载的方向是横向还是纵向，并且可以设置最大的重复个数，来避免造成加载展示问题以及性能问题。</p>\n<p>当设置完成后，并不会马上生效，需要保存然后退出此图表面板然后重新加载一下数据看板，然后数据图表就会根据我们选择的变量的个数来进行分别的展示。</p>\n<p>以上文的示例设置之后，效果如图：</p>\n<p><img src=\"/image-95.png\" alt=\"Alt text\"></p>\n<h2 id=\"数据下钻\"><a href=\"#数据下钻\" class=\"headerlink\" title=\"数据下钻\"></a>数据下钻</h2><p>✦</p>\n<p>要实现一个数据下钻，需要link搭配变量来进行看板之间的联动，主要的思路大体如下：</p>\n<ol>\n<li><p>模板看板B中设置好需要的变量</p>\n</li>\n<li><p>模板看板B查询数据时引用变量</p>\n</li>\n<li><p>在源图表面板A中设置跳转到模板看板B的链接，链接上引用我们设置或者是查询的变量内容</p>\n</li>\n<li><p>跳转至目标模板数据看板B时，模板看板B获取从link上带过来的变量值</p>\n</li>\n<li><p>变量赋值，模板看板B根据变量值刷新数据查询</p>\n</li>\n</ol>\n<p>经过上面的步骤，那么一个数据看板之间的联动就完成了，剩下的步骤就是丰富变量的设置以及看板内图表面板的内容了。</p>\n<p>那么如何从跳转过来的link上获取到携带过来的变量的值呢？</p>\n<p>在上文我们设置变量来控制数据面板repeat的时候，我们设置了一个变量 url_event</p>\n<p>当控制变量为 js_ready的时候，看板的整体URL是</p>\n<p><img src=\"/image-96.png\" alt=\"Alt text\"></p>\n<p>当控制变量为 css_ready的时候，看板的整体URL是</p>\n<p><img src=\"/image-97.png\" alt=\"Alt text\"></p>\n<p>因此我们可以看到，当我们看板设置变量并且使用的时候，变量的内容是以query的格式显示在URL上的，并且命名的格式如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var-&#123;your_var_name&#125; = &#123;your_var_value&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当变量在url上面显式的标记的时候，Grafana会主动获取链接上面声明的变量的值并赋值给模板变量。</p>\n<p>因此根据上面的格式，我们可以在link上面构造上述的数据query格式，为模板的看板变量赋值。</p>\n<p>于是实现一个的数据下钻整体流程都变得清晰了，下面我们还是以上文的例子来构造一个简单的数据下钻的例子</p>\n<ol>\n<li>构造一个整体的page render 数据看板 A</li>\n</ol>\n<p>将数据格式以table的形式展现，整体性的展示当天项目的render过程的各个事件平均耗时情况，如下图：</p>\n<p><img src=\"/image-98.png\" alt=\"Alt text\"></p>\n<ol start=\"2\">\n<li>设置一个详细指标数据的模板看板 B</li>\n</ol>\n<p>新建另一个数据详情的看板，然后建立一个事件的变量</p>\n<p><img src=\"/image-99.png\" alt=\"Alt text\"></p>\n<p>编写具体事件详细数据的查询SQL语句，并引用变量</p>\n<p><img src=\"/image-100.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li>通过link实现看板之间的联动</li>\n</ol>\n<p>配置数据看板A的data link, 使得每一行数据可以进行下钻详情展示</p>\n<p><img src=\"/image-101.png\" alt=\"Alt text\"></p>\n<p>经过上述步骤，就完成可一个简单的数据下钻，实现可一个项目page render过程的整体数据的可视化，并且可以点击具体加载事件查看该事件详细的数据分布趋势</p>\n<p>效果如下:<br><img src=\"/image-103.png\" alt=\"Alt text\"></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Grafana是一款非常优秀的开源可视化工具，能非常方便的将数据进行可视化，非常适合数据大盘建设，以及做数据监控和数据统计的工作。</p>\n<p>本文基于实际业务中建设监控数据大盘的经验，介绍了Grafana基本的一些图表概念和使用方法，并对不同的数据类型选取合适的可视化图表提供了一些建议和思考。</p>\n<p>通过三个阶段的介绍，总结了Grafana进行数据可视化入门教程以及一些进阶使用技巧，希望能在未来你的业务中，数据大盘的建设过程中提供一些便利和思路。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>看完这篇，成为Grafana高手<br>原创 huhuli 腾讯VATeam 2022-09-30 14:08 发表于广东<br><a href=\"https://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ\">https://mp.weixin.qq.com/s/ZhBlCjJVhm0dDSCrJFGtfQ</a></p>\n<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>QQ直播前端团队接入腾讯云前端性能监控（RUM）后，对目前的监控能力以及上报数据进行了梳理， 并着手进行了前端性能监控的专项建设，其中监控数据大盘建设是不可或缺的一环。<br>可视化的监控大盘可以清晰明了的观察到各项目运行情况，宏观上能快速进行项目间的横向对比，也可以非常便捷的进行项目各数据维度的详细展示，纵向的分析各指标数据的统计。</p>\n<p><img src=\"/image-30.png\" alt=\"Alt text\"></p>\n<p>通过对数据大盘支持能力的调研，我们采用Grafana进行了数据大盘的建设。通过搭建Grafana服务，然后添加监控上报数据，最终使得【QQ直播前端监控数据大盘】得以建设完成。</p>\n<p>那么什么是Grafana？</p>\n<p>Grafana 是一款开源的数据可视化工具，使用Grafana可以非常轻松的将数据转成图表(如下图)的展现形式来做到数据监控以及数据统计。</p>\n<p>Grafana官方提供Linux，Windows，MacOS，Docker版本</p>\n<p>下载链接:  <a href=\"https://grafana.com/get/\">https://grafana.com/get/</a></p>\n<p>本文将依托建设数据大盘的经验，重点介绍一下Grafana的使用，助力小伙伴们成为Grafana高手。</p>\n<h1 id=\"数据与图表\"><a href=\"#数据与图表\" class=\"headerlink\" title=\"数据与图表\"></a>数据与图表</h1><p>数据的可视化都是通过图表为载体的，不同的图表可以将数据进行不同侧重点的展现，要进行数据大盘的建设，首先要对图表有一个简单的了解，这样才能在数据大盘搭建过程中选择合适的图表，合理的进行可视化效果的展示。</p>\n<p>认识Grafana的图表<br>✦</p>\n<p>Grafana 的图表的选择路径都是 在 Visualization 类目下进行图表的选择</p>\n<p><img src=\"/image-31.png\" alt=\"Alt text\"></p>\n<h2 id=\"1-折线图\"><a href=\"#1-折线图\" class=\"headerlink\" title=\"1. 折线图\"></a>1. 折线图</h2><p><img src=\"/image-32.png\" alt=\"Alt text\">           </p>\n<p>示例图表：Time series</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Lines</p>\n<p>b. Fill opacity: 3</p>\n<p>c. Gradient mode: scheme</p>\n<h2 id=\"2-柱状图\"><a href=\"#2-柱状图\" class=\"headerlink\" title=\"2. 柱状图\"></a>2. 柱状图</h2><p><img src=\"/image-39.png\" alt=\"Alt text\">         </p>\n<p>示例图表：Time series</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Bars</p>\n<p>b. Fill opacity: 3</p>\n<p>c. Gradient mode: scheme</p>\n<h2 id=\"3-点状图\"><a href=\"#3-点状图\" class=\"headerlink\" title=\"3. 点状图\"></a>3. 点状图</h2><p><img src=\"/image-33.png\" alt=\"Alt text\">        </p>\n<p>示例图表：Time series</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Points</p>\n<p>b. Point size: 5</p>\n<p>c. Stack series: Normal</p>\n<h2 id=\"4-饼状图\"><a href=\"#4-饼状图\" class=\"headerlink\" title=\"4. 饼状图\"></a>4. 饼状图</h2><p><img src=\"/image-34.png\" alt=\"Alt text\">          </p>\n<p>示例图表：Pie chart</p>\n<h2 id=\"5-单一状态图\"><a href=\"#5-单一状态图\" class=\"headerlink\" title=\"5. 单一状态图\"></a>5. 单一状态图</h2><p><img src=\"/image-35.png\" alt=\"Alt text\">          </p>\n<p>示例图表：Stat</p>\n<p>图表配置：Graph styles</p>\n<p>a. style: Bars</p>\n<p>b. Fill opacity: 3</p>\n<p>c. Gradient mode: scheme</p>\n<h2 id=\"6-仪表盘\"><a href=\"#6-仪表盘\" class=\"headerlink\" title=\"6. 仪表盘\"></a>6. 仪表盘</h2><p><img src=\"/image-36.png\" alt=\"Alt text\">        </p>\n<p>示例图表：Gauge</p>\n<h2 id=\"7-表格\"><a href=\"#7-表格\" class=\"headerlink\" title=\"7. 表格\"></a>7. 表格</h2><p><img src=\"/image-37.png\" alt=\"Alt text\">         </p>\n<p>示例图表：Table</p>\n<h2 id=\"8-文本\"><a href=\"#8-文本\" class=\"headerlink\" title=\"8. 文本\"></a>8. 文本</h2><p><img src=\"/image-38.png\" alt=\"Alt text\">           </p>\n<p>示例图表：Text（支持Markdown 和 HTML两种格式）</p>\n<h2 id=\"9-…\"><a href=\"#9-…\" class=\"headerlink\" title=\"9. …\"></a>9. …</h2><h1 id=\"数据与图表的搭配\"><a href=\"#数据与图表的搭配\" class=\"headerlink\" title=\"数据与图表的搭配\"></a>数据与图表的搭配</h1><h2 id=\"按照数据格式区分\"><a href=\"#按照数据格式区分\" class=\"headerlink\" title=\"按照数据格式区分\"></a>按照数据格式区分</h2><p>✦</p>\n<p>柱状图， 折线图， 饼状图的图表都需要数据具有时间序列，用于展示在一定的时间区间或者是连续的时间范围内，单一数据或者多种分类数据的变化趋势，或者是数量占比。</p>\n<p>状态图， 表格数据，仪表盘等则对数据没有时间序列要求，状态图，仪表盘可用于进行一些总结性的数据展示，例如速度，温度，进度，完成度等， 表格数据则更适合展示复杂数据或者多维度数据</p>\n<h2 id=\"按照使用意图区分\"><a href=\"#按照使用意图区分\" class=\"headerlink\" title=\"按照使用意图区分\"></a>按照使用意图区分</h2><p>✦</p>\n<p>数据比较：柱状图，折线图比较合适，可以实现单数据，多种类数据的比较，能清晰看到变化趋势</p>\n<p>占比分类：饼图，仪表盘， 单一状态图等比较合适，可以清晰的看到每个数据整体性的占比</p>\n<p>趋势比较：折线图，面积图(折线可设置覆盖面积) 等比较合适，能直观展现数据变化</p>\n<p>分布类：饼图， 散点图 等比较合适</p>\n<h2 id=\"其他-✦\"><a href=\"#其他-✦\" class=\"headerlink\" title=\"其他      ✦\"></a>其他      ✦</h2><p>文字类图表就如同名字含义一样，可用于展示文字相关信息，并且个性化定制程度，灵活性排布支持都非常高（得益于Markdown 和 HTML的强大灵活性）</p>\n<p>表格对于日志类型，或者是其他多维度数据展示较为合适，适用于整体性给出一个报表，并且具备排序等公共功能，方便数据快速比较。</p>\n<h2 id=\"数据与图表的添加与扩展\"><a href=\"#数据与图表的添加与扩展\" class=\"headerlink\" title=\"数据与图表的添加与扩展\"></a>数据与图表的添加与扩展</h2><p>数据源与图表的扩展Grafana都采用插件的形式，因此我们想要扩展某个类型的数据源或者图表时，都需要先在Grafana插件市场找到目标插件，然后进行安装，如下图代码</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM grafana/grafana:8.3.1</span><br><span class=\"line\">USER root</span><br><span class=\"line\">RUN grafana-cli plugins install grafana-clickhouse-datasource //数据源插件</span><br><span class=\"line\">RUN grafana-cli plugins install auxmoney-waterfall-panel //图表插</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"数据源添加\"><a href=\"#数据源添加\" class=\"headerlink\" title=\"数据源添加\"></a>数据源添加</h2><p>✦</p>\n<p>打开Grafana平台，点击左侧”设置”图标，进入DataSource管理面板。</p>\n<p><img src=\"/image-40.png\" alt=\"Alt text\">               </p>\n<p>在“Add data source”面板中选择合适的数据源，并配置数据库信息。下图以Promethrus为例，添加数据源需要进行必要的配置，例如数据源的ip，port以及鉴权信息等。</p>\n<p><img src=\"/image-41.png\" alt=\"Alt text\">         </p>\n<p><img src=\"/image-42.png\" alt=\"Alt text\">        </p>\n<h2 id=\"图表插件添加\"><a href=\"#图表插件添加\" class=\"headerlink\" title=\"图表插件添加\"></a>图表插件添加</h2><p>✦</p>\n<ol>\n<li>打开Grafana平台，点击左侧”设置”图标，进入Plugins管理面板</li>\n</ol>\n<p> <img src=\"/image-43.png\" alt=\"Alt text\">          </p>\n<ol start=\"2\">\n<li>在tab 栏筛选已经安装的插件，就可以看到已经安装可以使用的插件</li>\n</ol>\n<p><img src=\"/image-44.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li>图表面板已经安装，可以直接在创建面板的时候指定类型使用</li>\n</ol>\n<p><img src=\"/image-45.png\" alt=\"Alt text\">       </p>\n<h1 id=\"Grafana入门使用\"><a href=\"#Grafana入门使用\" class=\"headerlink\" title=\"Grafana入门使用\"></a>Grafana入门使用</h1><p>这里需要区分两个概念：</p>\n<p>看板（dashboard）: 一个或多个数据图表形成的集合</p>\n<p>面板（panel）：组成看板的其中一个图表</p>\n<h2 id=\"创建一个看板-dashboard\"><a href=\"#创建一个看板-dashboard\" class=\"headerlink\" title=\"创建一个看板 (dashboard)\"></a>创建一个看板 (dashboard)</h2><p>✦</p>\n<p>创建一个数据可视化看板的前提是需要有数据源的接入， 具体具体接入方法见数据与图表的添加与扩展</p>\n<ol>\n<li>打开Grafana平台，点击左侧”加号”，点击Create类目下的Dashboard 按钮，新创建一个空表的看板， 会默认弹出四个添加panel的选项</li>\n</ol>\n<p><img src=\"/image-46.png\" alt=\"Alt text\"><br><img src=\"/image-47.png\" alt=\"Alt text\"></p>\n<p>a.添加一个空白面板</p>\n<p>b. 添加一个新的行，用于面板的分类</p>\n<p>c. 从面板库添加一个面板</p>\n<p>d. 从剪贴板添加一个面板，可以用来快速复制一个已有的面板</p>\n<ol start=\"2\">\n<li>点击看板右上角保存看板。<br><img src=\"/image-48.png\" alt=\"Alt text\"><br>a. 输入看板名称</li>\n</ol>\n<p>b. 输入简单描述文字</p>\n<p>c. 选择看板所属目录（用来分类管理看板）</p>\n<p>d. 可选为看板设置Tag，标记看板的特征，后期可根据Tag来筛选看板</p>\n<p>e. 其他选项可按需自主定义</p>\n<h2 id=\"创建面板-panel\"><a href=\"#创建面板-panel\" class=\"headerlink\" title=\"创建面板 (panel)\"></a>创建面板 (panel)</h2><p>✦</p>\n<p><img src=\"/image-50.png\" alt=\"Alt text\">         </p>\n<p>点击上图所示的图表，会弹出创建面板的四种选择，可以根据自己的需求自主创建，下面我们以创建空白面板为例</p>\n<p>点击Add a new panel 按钮， 你就会创建一个空白数据的图表面板，如下图</p>\n<p><img src=\"/image-51.png\" alt=\"Alt text\"></p>\n<h2 id=\"面板数据的获取\"><a href=\"#面板数据的获取\" class=\"headerlink\" title=\"面板数据的获取\"></a>面板数据的获取</h2><p>前文已经提到， 创建一个数据可视化看板的前提是需要有数据源的接入，因此，我们想要获取数据，必须要进行数据源的接入</p>\n<ol>\n<li><p>选择数据源（Data source）<br><img src=\"/image-52.png\" alt=\"Alt text\"><br> 配置选择自己接入的数据源后，后续才能进行相关数据获取的语法编写，这里不同的数据源之前需要的语法也不一样，因此大家可以自己根据自己的条件自主选择， 因为QQ直播接入的数据源是influxdb, 因此后面的例子将会以influxdb语法为例。</p>\n</li>\n<li><p>SQL语句的编写</p>\n</li>\n</ol>\n<p>Grafana的面板语法编辑有两种形式， 简易模式与高级模式</p>\n<p>Grafana 一个面板支持多条SQL语句</p>\n<p>a. 简易模式：简易模式数据的获取主要通过下拉框的形式选择具体的指标以及判断条件， 支持添加多个条件</p>\n<p><img src=\"/image-53.png\" alt=\"Alt text\">   </p>\n<p>高级模式：通过点击编辑图标可以进行编辑模式的切换，高级模式下为全部的SQL语句的编书写，此模式对于语法有一定的要求，但是获取数据会更加的灵活</p>\n<p><img src=\"/image-54.png\" alt=\"Alt text\"></p>\n<h2 id=\"面板的基础配置\"><a href=\"#面板的基础配置\" class=\"headerlink\" title=\"面板的基础配置\"></a>面板的基础配置</h2><p>在编辑完成数据获取的SQL语句之后，面板上应该已经有了相关数据的展示，此时可以根据自己的数据格式，以及展示诉求来选择对应的图表，图表具体选择参考上文数据与图表的搭配</p>\n<p>我们以默认的Time series的折线图为例，简述一下面板的基础配置</p>\n<p><img src=\"/image-55.png\" alt=\"Alt text\"></p>\n<ol>\n<li>面板的基础信息</li>\n</ol>\n<p><img src=\"/image-56.png\" alt=\"Alt text\">      </p>\n<p>在通过SQL语句选择加载完成数据后，图表会有默认的样式给到我们，此时如果对面板无其他要求，只需配置一下面板的基础信息就可完成Grafana的看板配置</p>\n<p>基础信息包括</p>\n<p>a. 标题</p>\n<p>b. 描述</p>\n<p>c. 背景是否透明</p>\n<ol start=\"2\">\n<li>数据提示</li>\n</ol>\n<p><img src=\"/image-57.png\" alt=\"Alt text\">        </p>\n<p>Tootip配置项用于配置当鼠标经过（hover）图表数据点的时候的提示信息， 可选为Single单个提醒， All显示所有数据， Hidden都不显示</p>\n<p><img src=\"/image-58.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li>图例（legend）显示设置</li>\n</ol>\n<p><img src=\"/image-59.png\" alt=\"Alt text\"></p>\n<p>图例显示模式有三种</p>\n<p>a. List (默认)， 图例数据横向依次展示</p>\n<p>b. Table， 图例数据会按照表格形式展示</p>\n<p>c. Hidden, 不展示图例</p>\n<p>图例的位置</p>\n<p>a. Bottom, 陈列在图表底部</p>\n<p>b. Right, 陈列在图表的右侧</p>\n<p> 图例值展示</p>\n<p><img src=\"/image-60.png\" alt=\"Alt text\">      </p>\n<p>此处会有一个下拉列表供我们选择图例的显示数据，默认不展示，用户也可以选择数据展示形式，例如最大值，最小值，平均值等</p>\n<ol start=\"4\">\n<li>坐标轴（Axis）配置</li>\n</ol>\n<p><img src=\"/image-61.png\" alt=\"Alt text\">         </p>\n<p>坐标轴的基础配置一般只需要设置一下坐标轴的名称（Label）即可，其余的设置可以按照默认值不用修改，下面简述一下配置的含义</p>\n<p>a. Width选项可以选择设置坐标轴（Label）的占比宽度</p>\n<p>b. Soft min 以及 Soft max 用来设置纵坐标的显示的最大值最小值</p>\n<p>c. Show gride lines 可以设置是否显示背景的网格线</p>\n<p>d. Scale 用来设置是否进行数据的放大，目的是让数据对比更加清晰</p>\n<p>通过以上对一个图表面板的基础配置，我们的一个图表基本上已经成型，可以达到数据可视化的正常显示目的，剩下的就是加强对自己数据格式类型的分析以及基于自己的可视化诉求来进行合适的图表面板的配置选择，就可以通过多个图表的添加来完成自己初版的数据可视化看板。</p>\n<h1 id=\"Grafana进阶使用\"><a href=\"#Grafana进阶使用\" class=\"headerlink\" title=\"Grafana进阶使用\"></a>Grafana进阶使用</h1><p>当我们选择一个图表插件进行数据可视化的时候，图表的一些属性会帮我们设置好了默认值，但是基于兼容性更广的特性，这些默认值也许并不是我们选择图表最合适的展示效果，因此为了进一步提升图表的展示性，我们可以通过以下属性来进行面板的进一步美化。</p>\n<h2 id=\"图表属性配置-Standard-options\"><a href=\"#图表属性配置-Standard-options\" class=\"headerlink\" title=\"图表属性配置 (Standard options)\"></a>图表属性配置 (Standard options)</h2><p>✦</p>\n<p><img src=\"/image-62.png\" alt=\"Alt text\">              </p>\n<p>此选项框中的属性配置，可以使得我们的数据展示更加的准确，例如纵坐标的单位，我们不想采用通用意义上的在Label上进行命名标注单位例如耗时（ms）, 那么就可以选择此处的单位属性（Unit）进行更精确的展示</p>\n<ol>\n<li>单位（Unit）</li>\n</ol>\n<p><img src=\"/image-63.png\" alt=\"Alt text\">              </p>\n<p>在单位选项中， 你可以进行非常精细化的选择，选项框中几乎包含了所有品类用到的单位属性，例如百分比，长度单位，时间单位，角度单位等等</p>\n<ol start=\"2\">\n<li>显示范围（Min, Max）</li>\n</ol>\n<p>在Min, Max 选项中，允许用户输入一个数字进行显示范围的限制，那么图表上在显示范围之外的数据将不会在图表中显示，例如我将耗时限制在0~3000范围，那么3000以外的数据将会被隐藏</p>\n<p><img src=\"/image-64.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li><p>Decimals 选项可以用来设置纵坐标数据的小数点范围</p>\n</li>\n<li><p>Display Name 选项则可以用来设置图例显示名字，但是由于限制，只能在只有一类数据时比较适用，如果数据类别较多，单纯在此处设置会将全部图例数据覆盖，因此图例的名称最好在SQL语句编写的时候就做好展示。当然后面也会讲有别的方法进行多种图例数据别名的单独设置</p>\n</li>\n<li><p>图表颜色配置（Color scheme）</p>\n</li>\n</ol>\n<p>一般图表颜色的展示都会有默认值，不过我们想要改变现在图表曲线的颜色分类可以在此处进行设置。</p>\n<p><img src=\"/image-65.png\" alt=\"Alt text\"></p>\n<p>我们可以选择整体图表的颜色走向或者是颜色分布，但是一般曲线展示的颜色还是会根据数据自己适配，因此如果我们想要改变某一条曲线的颜色，可以直接点击图例前面的颜色icon,进行颜色选择。我们可以根据提供选项进行选择，也可以自定义设置颜色。</p>\n<p><img src=\"/image-66.png\" alt=\"Alt text\"></p>\n<h2 id=\"阈值设置-Thresholds\"><a href=\"#阈值设置-Thresholds\" class=\"headerlink\" title=\"阈值设置 (Thresholds)\"></a>阈值设置 (Thresholds)</h2><p>✦</p>\n<p>有些图表插件是支持设置阈值的， 阈值的设置可以使得我们对数据的合规程度有清晰的对比，能够直观的衡量出当前数据的质量，因此阈值设置也是面板美化展示的一个重要部分</p>\n<p><img src=\"/image-67.png\" alt=\"Alt text\">              </p>\n<p>如上图示例，我们设置对耗时的图表设置了两个阈值，上图的意义是：</p>\n<ul>\n<li><p>在3000ms和5000ms设置阈值</p>\n</li>\n<li><p>3000ms以下将视为健康，颜色标记为绿色</p>\n</li>\n<li><p>3000ms~5000ms视为亚健康，颜色标记黄色</p>\n</li>\n<li><p>5000ms以上视为警示，颜色标记为红色</p>\n</li>\n</ul>\n<p>阈值的模式有两种选择</p>\n<ol>\n<li><p>绝对值, 即按照标记的阈值数据进行比较</p>\n</li>\n<li><p>百分比, 阈值为相对于最大值的占比</p>\n</li>\n</ol>\n<p>阈值展示的形式有四种：</p>\n<ol>\n<li><p>不展示 （off）</p>\n</li>\n<li><p>只展示阈值线 （as lines）</p>\n</li>\n<li><p>只展示区域 （as filled regions）</p>\n</li>\n<li><p>同时展示阈值线和区域 （as filled regions and lines）</p>\n</li>\n</ol>\n<p>下图为我们选择绝对值模式下，展示线和区域的阈值示例图， 由图可以看出数据在不同阈值区间的分布，以及与阈值的对比，因此我们能直观的评估出数据的质量</p>\n<p><img src=\"/image-68.png\" alt=\"Alt text\">            </p>\n<h2 id=\"数值映射-Value-mappings\"><a href=\"#数值映射-Value-mappings\" class=\"headerlink\" title=\"数值映射 (Value mappings)\"></a>数值映射 (Value mappings)</h2><p>✦</p>\n<p><img src=\"/image-69.png\" alt=\"Alt text\">            </p>\n<p>图表的展示都是由许多的值来组成的一个个点，连线，反过来讲，图表就是数据值的展现，在图表中， 有时候有些数据并不是我们理想的数值，或者说我们想特异性的让某些值显示为其他值（写SQL语句也可以实现）， 这时候可以使用数值映射选项</p>\n<p><img src=\"/image-70.png\" alt=\"Alt text\"></p>\n<p>数值映射的形式可以有以下四种</p>\n<p>1 单纯的某个值映射</p>\n<ol start=\"2\">\n<li><p>一段范围区间映射</p>\n</li>\n<li><p>正则表达式映射</p>\n</li>\n<li><p>针对某类值映射</p>\n</li>\n</ol>\n<p>例如在示例中，假如我们健康波段数据具体值不关心， 只是关心整体的数据波动范围是否在健康范围之内，我们可以把0~3000ms的范围映射为健康，那么再具体显示的时候，不再会有具体值给到我们，统一会展示健康，如下图：</p>\n<p><img src=\"/image-71.png\" alt=\"Alt text\"></p>\n<p>这个功能更加适用于表格数据，例如我们明确的将空数据映射为空或0的场景，如下图</p>\n<p><img src=\"/image-72.png\" alt=\"Alt text\"></p>\n<h2 id=\"数据覆盖-Overrides\"><a href=\"#数据覆盖-Overrides\" class=\"headerlink\" title=\"数据覆盖 (Overrides)\"></a>数据覆盖 (Overrides)</h2><p>✦</p>\n<p>数据覆盖允许我们对之前已经设置好的图表进行个性化设置，它相当于图表更高级的设置，覆盖的范围可以是整个SQL语句获取的数据，也可以是数据中某一类图例数据</p>\n<p><img src=\"/image-73.png\" alt=\"Alt text\">         </p>\n<p>具体覆盖的数据类别：</p>\n<p>1 某一类数据</p>\n<ol start=\"2\">\n<li><p>正则匹配到的数据</p>\n</li>\n<li><p>某些类型的数据</p>\n</li>\n<li><p>整个SQL查询的数据</p>\n</li>\n</ol>\n<p>在设置了一个Override 之后，就可以进一步进行子项的配置，子项里面的属性几乎与上文介绍的图表属性一致</p>\n<p><img src=\"/image-74.png\" alt=\"Alt text\">          </p>\n<p>我们通过覆盖属性的配置，可以让修改到之前我们已经在整体设置好的图标样式</p>\n<p>例如我们现在经过SQL查询，已经获取到了js_ready和css_ready的耗时数据，但是我们想让这两种数据对比更加明确，既能够清晰的看到整体的趋势，也能看到某类数据单独的变化，这时我们可以通过override属性进行配置，让两个数据的纵坐标分别在左右两边，并且数据展示用折线和柱状图分别表示。</p>\n<p>具体override配置属性如下图：</p>\n<p><img src=\"/image-75.png\" alt=\"Alt text\">              </p>\n<p>对css_ready 数据配置：</p>\n<ol>\n<li><p>图表展示为柱状图， 柱状图数据点居中</p>\n</li>\n<li><p>纵坐标数据靠右展示，颜色为浅绿色</p>\n</li>\n<li><p>标题设置为CSS耗时（ms）</p>\n</li>\n</ol>\n<p>对js_ready数据配置：</p>\n<ol>\n<li><p>默认基础配置折线图</p>\n</li>\n<li><p>默认纵坐标靠左展示</p>\n</li>\n<li><p>设置颜色红色</p>\n</li>\n<li><p>标题设置为JS耗时（ms）</p>\n</li>\n</ol>\n<p>最终结果如下图：<br><img src=\"/image-76.png\" alt=\"Alt text\"></p>\n<h2 id=\"变量与模板\"><a href=\"#变量与模板\" class=\"headerlink\" title=\"变量与模板\"></a>变量与模板</h2><p>✦</p>\n<p>在Grafana里面，学会使用变量，会发现打开了新世界的大门，用好变量，可能你的工作量就会缩减一半，甚至更多。</p>\n<p>变量的使用场景有很多，例如我们编写SQL语句中的时间选项（$__interval），就是内置的一个变量，通过这个时间变量，可以控制多个图表在不同时间范围内的展示情况，因此一个好的变量的使用，可以让我们只配置一个图表，达到展示不同条件下的数据的目的，而不用去为每一种情况设置一个图表。</p>\n<p>模板在Grafana中最简单的含义就是任何一条包含变量的查询（query)。</p>\n<p>【变量的设置】</p>\n<p>变量的设置是基于看板的，看板内设置的变量，对看板内的所有面板是共享的</p>\n<p>点击看板设置，进入变量设置页面</p>\n<p><img src=\"/image-77.png\" alt=\"Alt text\"></p>\n<p><img src=\"/image-78.png\" alt=\"Alt text\">            </p>\n<p>【变量的种类】</p>\n<p> <img src=\"/image-79.png\" alt=\"Alt text\">              </p>\n<p>在添加一个变量的可选下拉框中，可以选择添加的变量类型，共计有以下几种变量可以选择</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">变量类型</th>\n<th align=\"left\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">query</td>\n<td align=\"left\">查询变量允许编写可以返回指标名称、标签值或键列表的数据源查询。例如，查询变量可能会返回服务器名称, ID 或数据中心的列表。变量值随着数据源查询动态获取选项而变化。</td>\n</tr>\n<tr>\n<td align=\"left\">custom</td>\n<td align=\"left\">手动定义变量选项,使用逗号分隔的列表</td>\n</tr>\n<tr>\n<td align=\"left\">text box</td>\n<td align=\"left\">显示具有可选默认值的自由文本输入字段</td>\n</tr>\n<tr>\n<td align=\"left\">constant</td>\n<td align=\"left\">设置一个常量</td>\n</tr>\n<tr>\n<td align=\"left\">data source</td>\n<td align=\"left\">快速添加一个数据源的变量</td>\n</tr>\n<tr>\n<td align=\"left\">interval</td>\n<td align=\"left\">代表时间跨度的变量</td>\n</tr>\n<tr>\n<td align=\"left\">ad hoc filters</td>\n<td align=\"left\">自动添加到数据源的所有指标查询的键&#x2F;值过滤器（仅限 InfluxDB、Prometheus 和 Elasticsearch）</td>\n</tr>\n</tbody></table>\n<p>添加变量的其他输入框选项可以直接根据英文的意义非常直白的看出，例如设置面标签信息，描述信息，以及设置是否在看板中隐藏，对于某些变量类型还可以设置是否可以多选或者是否包含所有的值的选项等等，这些设置可以根据自己的需求来选择。</p>\n<p>【变量的使用】</p>\n<p>设置完成变量之后，变量的使用有两种形式</p>\n<p>$varname， 这是最直接的方式， 但是这种语法会有限制，就是不能在一个词的中间使用例如：apps.frontend.$varname.requests.count</p>\n<ol>\n<li>${var_name}， 如果想要在表达式中间插入变量，请使用此语法，另外这种语法还有一些高级用法，${var_name:<format>}，这种格式可以更好地控制 Grafana 如何插入值，具体的用法可以参考官方文档</li>\n</ol>\n<p>【变量简单使用示例】</p>\n<p>沿用上文的数据，我们创建一个简单的自定义变量，url_event,如下图</p>\n<p><img src=\"/image-80.png\" alt=\"Alt text\"></p>\n<p>获取数据的时候,sql 语法就可以写成如下</p>\n<p><img src=\"/image-81.png\" alt=\"Alt text\"></p>\n<p>这样，我们只建立了一个图表面板，由于使用了变量，因此可以只用变量的切换就实现看板数据的变化，如下</p>\n<p>变量选择 js_ready<br><img src=\"/image-82.png\" alt=\"Alt text\"><br>变量选择css_ready</p>\n<p><img src=\"/image-83.png\" alt=\"Alt text\"></p>\n<h2 id=\"Link的使用\"><a href=\"#Link的使用\" class=\"headerlink\" title=\"Link的使用\"></a>Link的使用</h2><p>✦</p>\n<p>在Grafana中，可以使用链接来进行看板的跳转以及外链的跳转，并且link的使用也非常灵活。</p>\n<p>在一个数据面板的设置中，link可以的设置主要有两种方式</p>\n<ol>\n<li>整个面板设置链接</li>\n</ol>\n<p><img src=\"/image-84.png\" alt=\"Alt text\">              </p>\n<p>在数据面板的设置中，前文我们没有细讲link的选项，这里其实是为整个数据面板设置跳转链接的入口，通过此处设置link，可以在面板上增加一个icon, 实现我们在点击的时候进行跳转, 具体效果如下图</p>\n<p><img src=\"/image-85.png\" alt=\"Alt text\">              </p>\n<ol start=\"2\">\n<li>为具体数据设置link(data links)</li>\n</ol>\n<p>data links属性设置一般只在柱状图、折线图、表格面板里才有，并且，如果没有搭配override属性进行个性化设置的话，默认每个数据点都会设置上跳转的链接，效果如下图</p>\n<p><img src=\"/image-86.png\" alt=\"Alt text\"></p>\n<p>这样的设置其实和整个面板设置link类似，因此不同的data links 最好和override属性搭配，来进行个性化的数据链接跳转，以达到不通数据跳转不同链接的目的。</p>\n<h2 id=\"Link与变量的搭配\"><a href=\"#Link与变量的搭配\" class=\"headerlink\" title=\"Link与变量的搭配\"></a>Link与变量的搭配</h2><p>✦</p>\n<p>Grafana的link设置非常灵活，在link设置中，可以直接使用已经设置的看板变量以及系统的变量来进行链接的组合。</p>\n<p>甚至在data links的设置中，还可以直接使用SQL语句查询到的结果来进行链接的组合，这样也可达到不同数值设置不同的跳转链接的功能</p>\n<p>在添加链接的时候，如果想查看可用变量列表，可以直接在数据链接URL字段中键入 $ 来查看变量列表，效果如下图：</p>\n<p><img src=\"/image-87.png\" alt=\"Alt text\"></p>\n<p>变量列表里的变量主要可以分为三个类型</p>\n<p>a. 全局内建的变量，例如时间变量的 from, to</p>\n<p>b. 用户创建的模板变量，例如上文示例创建的 url_event</p>\n<p>c. 基于SQL语句查询出来的数据，一般都在fields字段下</p>\n<p>通过引用变量来创建图表面板的跳转链接，可以较为灵活的实现基于数据的外链跳转以及更为高级的数据看板的之间的联动，下文要讲到的数据下钻就是基于data links 与变量的搭配来实现。</p>\n<h1 id=\"Grafana高级使用\"><a href=\"#Grafana高级使用\" class=\"headerlink\" title=\"Grafana高级使用\"></a>Grafana高级使用</h1><h2 id=\"妙用Transform\"><a href=\"#妙用Transform\" class=\"headerlink\" title=\"妙用Transform\"></a>妙用Transform</h2><p>✦</p>\n<p>前面讲的一些Grafana的使用，都是以SQL语句查询到的数据为基础，在图表可视化上进行的设置与操作，而Transform的功能，大部分是更底层的操作，直接对数据的操作，来达到改变图表展示的目的，是数据可视化之前的操作。</p>\n<p>tranform 可以实现将我们查询到的数据进行进一步加工，例如可以进行数据筛选，计算，重命名，排序以及控制隐藏等功能。</p>\n<p><img src=\"/image-88.png\" alt=\"Alt text\"></p>\n<p>本文以几个较为典型的功能简单介绍一下</p>\n<ol>\n<li>通过计算添加数据（Add field from calculation）</li>\n</ol>\n<p><img src=\"/image-89.png\" alt=\"Alt text\">              </p>\n<p>数据的计算有两种模式：</p>\n<p>a. Reduce row： 分别对选择的特定字段数据的每一行进行聚合计算</p>\n<p>b. Binary option： 选定的两个字段的值进行数学运算例如加减乘除</p>\n<ol start=\"2\">\n<li>转换数据的类型(Convert field type)</li>\n</ol>\n<p>可以将选择的特定字段的值的类型指定为固定的数据类型</p>\n<p><img src=\"/image-90.png\" alt=\"Alt text\">              </p>\n<ol start=\"3\">\n<li>根据名称筛选数据展示(Filter data by name)</li>\n</ol>\n<p>a. 可以将SQL语句查询出的字段名称陈列，并且自定义数据的展示与否</p>\n<p>b. 也可以直接根据正则表达式进行数据筛选</p>\n<p><img src=\"/image-91.png\" alt=\"Alt text\"></p>\n<ol start=\"4\">\n<li>数据合并（Merge）</li>\n</ol>\n<p>类似sql中的join，根据时间序列来进行合并不同的字段数据成为个数据表</p>\n<p><img src=\"/image-92.png\" alt=\"Alt text\"></p>\n<ol start=\"5\">\n<li>重命名（Rename by regex）</li>\n</ol>\n<p>可以使用这个功能来进行查询结果名称的转换，允许我们使用正则表达式来进行重命名内容的匹配</p>\n<p><img src=\"/image-93.png\" alt=\"Alt text\">          </p>\n<p>transform 还有很多实用的功能，这里就不一一陈列，如果有需要用到操作数据的功能，可以考虑transform功能，全部的功能可以直接看官方文档</p>\n<h2 id=\"面板的Repeat\"><a href=\"#面板的Repeat\" class=\"headerlink\" title=\"面板的Repeat\"></a>面板的Repeat</h2><p>✦</p>\n<p>面板的repeat 也是需要搭配变量功能来使用，图表面板会根据用户选择的变量个数来进行分别加载，因此，此功能使用的前提是变量的值要大于1个，并且设置了允许多个变量可选，见下图示例</p>\n<p><img src=\"/image-94.png\" alt=\"Alt text\"></p>\n<p>当前提条件满足后，可以在面板的repeat属性进行设置</p>\n<p>repeat 可选加载的方向是横向还是纵向，并且可以设置最大的重复个数，来避免造成加载展示问题以及性能问题。</p>\n<p>当设置完成后，并不会马上生效，需要保存然后退出此图表面板然后重新加载一下数据看板，然后数据图表就会根据我们选择的变量的个数来进行分别的展示。</p>\n<p>以上文的示例设置之后，效果如图：</p>\n<p><img src=\"/image-95.png\" alt=\"Alt text\"></p>\n<h2 id=\"数据下钻\"><a href=\"#数据下钻\" class=\"headerlink\" title=\"数据下钻\"></a>数据下钻</h2><p>✦</p>\n<p>要实现一个数据下钻，需要link搭配变量来进行看板之间的联动，主要的思路大体如下：</p>\n<ol>\n<li><p>模板看板B中设置好需要的变量</p>\n</li>\n<li><p>模板看板B查询数据时引用变量</p>\n</li>\n<li><p>在源图表面板A中设置跳转到模板看板B的链接，链接上引用我们设置或者是查询的变量内容</p>\n</li>\n<li><p>跳转至目标模板数据看板B时，模板看板B获取从link上带过来的变量值</p>\n</li>\n<li><p>变量赋值，模板看板B根据变量值刷新数据查询</p>\n</li>\n</ol>\n<p>经过上面的步骤，那么一个数据看板之间的联动就完成了，剩下的步骤就是丰富变量的设置以及看板内图表面板的内容了。</p>\n<p>那么如何从跳转过来的link上获取到携带过来的变量的值呢？</p>\n<p>在上文我们设置变量来控制数据面板repeat的时候，我们设置了一个变量 url_event</p>\n<p>当控制变量为 js_ready的时候，看板的整体URL是</p>\n<p><img src=\"/image-96.png\" alt=\"Alt text\"></p>\n<p>当控制变量为 css_ready的时候，看板的整体URL是</p>\n<p><img src=\"/image-97.png\" alt=\"Alt text\"></p>\n<p>因此我们可以看到，当我们看板设置变量并且使用的时候，变量的内容是以query的格式显示在URL上的，并且命名的格式如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var-&#123;your_var_name&#125; = &#123;your_var_value&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当变量在url上面显式的标记的时候，Grafana会主动获取链接上面声明的变量的值并赋值给模板变量。</p>\n<p>因此根据上面的格式，我们可以在link上面构造上述的数据query格式，为模板的看板变量赋值。</p>\n<p>于是实现一个的数据下钻整体流程都变得清晰了，下面我们还是以上文的例子来构造一个简单的数据下钻的例子</p>\n<ol>\n<li>构造一个整体的page render 数据看板 A</li>\n</ol>\n<p>将数据格式以table的形式展现，整体性的展示当天项目的render过程的各个事件平均耗时情况，如下图：</p>\n<p><img src=\"/image-98.png\" alt=\"Alt text\"></p>\n<ol start=\"2\">\n<li>设置一个详细指标数据的模板看板 B</li>\n</ol>\n<p>新建另一个数据详情的看板，然后建立一个事件的变量</p>\n<p><img src=\"/image-99.png\" alt=\"Alt text\"></p>\n<p>编写具体事件详细数据的查询SQL语句，并引用变量</p>\n<p><img src=\"/image-100.png\" alt=\"Alt text\"></p>\n<ol start=\"3\">\n<li>通过link实现看板之间的联动</li>\n</ol>\n<p>配置数据看板A的data link, 使得每一行数据可以进行下钻详情展示</p>\n<p><img src=\"/image-101.png\" alt=\"Alt text\"></p>\n<p>经过上述步骤，就完成可一个简单的数据下钻，实现可一个项目page render过程的整体数据的可视化，并且可以点击具体加载事件查看该事件详细的数据分布趋势</p>\n<p>效果如下:<br><img src=\"/image-103.png\" alt=\"Alt text\"></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Grafana是一款非常优秀的开源可视化工具，能非常方便的将数据进行可视化，非常适合数据大盘建设，以及做数据监控和数据统计的工作。</p>\n<p>本文基于实际业务中建设监控数据大盘的经验，介绍了Grafana基本的一些图表概念和使用方法，并对不同的数据类型选取合适的可视化图表提供了一些建议和思考。</p>\n<p>通过三个阶段的介绍，总结了Grafana进行数据可视化入门教程以及一些进阶使用技巧，希望能在未来你的业务中，数据大盘的建设过程中提供一些便利和思路。</p>\n"},{"title":"kibana create ILM","date":"2023-09-05T08:14:39.000Z","_content":"# kibana设置ILM\n\n## 1. 背景\n\nkibana version: v7.9.3\n\n## 2. 设置ILM\n\n### 2.1 创建索引生命周期策略\n\n#### 2.1.1 热阶段\n\n首先需要先创建索引生命周期策略，在索引模板中可以引用创建好的索引生命周期策略。\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm01.png)\n\n- 策略名称： 引用该策略是需要用，例如设置为：filebeat-index-ilm\n  \n- 最大索引大小：设置单个索引最大字节数，此处为50千兆字节，即50G.\n  \n- 最大文档数：设置单个索引所内容乃的最大文档数，超过该数则创建新的索引。\n  \n- 最大存在时间： 指的是索引在温热阶段中可以存在的最长时间。一旦索引达到这个时间限制，它将被自动转移到冷却阶段，并最终被归档或删除。\n  \n  \"最大存在时间\"是一个可选的参数，你可以根据实际需求来决定是否设置这个参数。如果你没有设置这个参数，索引将会一直保持在温热阶段，直到你手动将其转移到冷却阶段或删除。\n  \n  在设置\"最大存在时间\"时，你可以选择一个固定的时间长度，例如30天。这意味着索引在温热阶段中最多存在30天，之后它将被自动转移到冷却阶段。这个参数可以帮助你控制索引的生命周期，避免过多的旧索引占用存储空间和资源。\n  \n  需要注意的是，具体的索引生命周期策略还受到其他参数的影响，例如滚动布署的频率、索引模板、索引生命周期策略等。因此，在实际应用中，需要根据具体的业务需求和数据量来调整和优化这些参数。\n  \n\n#### 2.1.2 温阶段和冷阶段\n\n温阶段和冷阶段不再设置，解释一下这两个阶段：\n\n在 Kibana 中创建索引生命周期策略时，warm phase和Cold phase的存在有意义，它们适用于不同的场景。\n\n1. Warm phase（温阶段）：\n  Warm phase是索引生命周期的中间阶段，适用于处理活跃但不再频繁更改的数据。在这个阶段，索引被用于的搜索和查询操作较多，因此需要保持良好的搜索性能。在温阶段，索引可以被滚动更新，以保持其当前的索引结构、映射和设置。\n  \n  温阶段适用于以下场景：\n  \n  - 数据检索：如果您的应用程序需要从历史数据中检索信息，并且这些数据已经过了一段时间但仍然活跃，那么可以将索引设置为在温阶段。\n  - 数据归档和分析：如果您的应用程序需要将数据存储一段时间以便进行进一步的分析、报告或可视化，那么可以将索引设置为在温阶段。\n2. Cold phase（冷阶段）：\n  Cold phase是索引生命周期的后期阶段，适用于处理不再活跃的数据。在这个阶段，索引被用于的搜索和查询操作较少，因此可以降低存储成本和索引维护开销。在冷阶段，索引可以被归档和压缩，以进一步降低存储成本。\n  \n  冷阶段适用于以下场景：\n  \n  - 数据归档：如果您的应用程序需要长期存储数据，并且这些数据不再被频繁地搜索和查询，那么可以将索引设置为在冷阶段。\n  - 数据保留策略：如果您的应用程序需要保留某些数据一段时间后将其删除，那么可以将索引设置为在冷阶段，并在达到保留期限时自动删除索引。\n  \n  综上所述，温阶段和冷阶段的存在意义在于进一步优化索引生命周期的管理。通过将索引分阶段管理，可以更好地平衡性能、存储成本和维护开销，以满足不同的业务需求。\n  \n\n#### 2.1.3 删除阶段\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm03.png)\n\n- 删除倒计时： 设置日志多久之后删除。\n  \n\n### 2.2 创建索引模板\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template01.png)\n\n- 名称：索引模板名\n  \n- 索引模式： 用来匹配应用于哪些索引，例如匹配filebeat-开头的索引;filebeat-*\n  \n- 优先级：是一个整数值，用于确定索引模板的优先级。较高的优先级值表示该索引模板具有更高的优先级。当多个索引模板匹配到同一个索引时，优先级最高的索引模板将被应用。\n  \n- 版本：是一个整数值，用于跟踪索引模板的版本号。你可以根据需要为每个索引模板设置一个唯一的版本号。当索引模板需要更新时，你可以增加版本号以确保新版本的索引模板被应用。\n  \n- _meta 字段：_meta 字段是一个 JSON 对象，用于存储与索引模板相关的元数据。你可以在 _meta 字段中添加自定义的键值对，例如索引模板的创建时间、作者等信息。这些元数据可以在使用 Elasticsearch API 管理索引模板时进行访问和操作。\n  \n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template02.png)\n\n- 选择组件： 引用已经创建好的组件模板\n  \n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template03.png)\n\n- 索引设置: 图中设置了生命周期相关内容，lifecycle：指的就是索引的生命周期，这里就是我们之前创建的索引生命周期；rollover_alias：滚动别名，当我们配置了索引大小，超过这个大小后，会以这个名称命名。\n  \n\n1. 映射字段：  \n  映射字段是指将文档中的字段与特定的数据类型和属性进行映射。在创建索引模板时，可以手动添加映射字段，以便在索引文档时将字段映射为指定的数据类型和属性。例如，可以添加一个名为 \"message\" 的映射字段，将其映射为文本类型，并设置其分析器为 \"standard\"。\n\n映射字段适用于以下场景：\n\n- 数据类型已知且固定的场景：当文档中的字段类型固定且已知时，可以手动添加映射字段，以确保索引的准确性和性能。\n  \n- 需要自定义数据类型的场景：当文档中存在自定义的数据类型时，可以手动添加映射字段，并将其映射为相应的数据类型，以便在查询和聚合时能够正确地处理数据。\n  \n\n2. 动态模板：  \n  动态模板是指根据文档中的字段名、数据类型等动态地设定字段类型。在创建索引模板时，可以定义动态模板规则，以便根据文档的实际情况动态地设定字段类型。例如，可以定义一个名为 \"text\" 的动态模板，将所有以 \"message\" 开头的字段映射为文本类型。\n\n动态模板适用于以下场景：\n\n- 数据类型未知或动态变化的场景：当文档中的字段类型未知或动态变化时，可以使用动态模板来自动识别字段类型，并将其映射为相应的数据类型。\n  \n- 需要灵活处理不同数据类型的场景：当文档中存在多种数据类型时，可以使用动态模板来根据字段名、数据类型等信息动态设定字段类型，以便在查询和聚合时能够正确地处理数据。\n  \n\n3. 高级选项：  \n  高级选项是指在创建索引模板时可以配置的一些高级设置，例如索引分片数、索引副本数、分析器等。这些设置可以优化索引的性能和存储效率。\n\n高级选项适用于以下场景：\n\n- 需要优化索引性能的场景：可以通过配置索引分片数和索引副本数来优化索引的性能，提高查询和聚合的速度。\n- 需要优化存储效率的场景：可以通过配置存储设置和分析器来优化索引的存储效率，减少存储空间的使用.。\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template05.png)\n\n- 设置索引别名\n  \n  1. 方便对多个索引进行查询：如果你有许多索引并且经常需要同时查询这些索引，使用别名可以方便地将这些索引组合在一起进行查询。\n  2. 简化索引引用：在查询时，只需要引用别名，而不需要写出完整的索引名称，这使得查询语句更加简洁。\n  3. 方便索引的版本控制：如果你在系统中对索引进行更新或替换，使用别名可以使得对已有查询的影响最小化。例如，你可以创建一个别名，使其始终映射到最新的索引版本，这样在更新索引时，不需要更改所有查询。\n  \n  在 Elasticsearch 中创建别名的方法是通过使用 \"alias\" API。例如，如果你有一个索引 \"test-20190120\"，并想为其创建一个别名 \"test\"，你可以使用以下的请求：\n  \n  ```bash\n  PUT /_aliases  {    \"actions\": [      {        \"add\": {          \"index\": \"test-20190120\",          \"alias\": \"test\"        }      }    ]  }\n  ```\n  \n  在上述请求中，\"add\" 动作告诉 Elasticsearch 将别名 \"test\" 添加到索引 \"test-20190120\" 上。之后，你可以使用别名 \"test\" 来查询该索引的内容。\n  \n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template06.png)\n\n完成模板创建。\n\n## 3. 生效\n\n创建索引生命周期之前的创建的索引不会受索引生命周期影响，之后创建的索引会进入到索引生命周期的策略管理中。","source":"_posts/kubernetes/kibana-ilm.md","raw":"---\ntitle: kibana create ILM\ndate: 2023-09-05 16:14:39\ncategories:\n  - [kubernetes]\ntags: kibana\n---\n# kibana设置ILM\n\n## 1. 背景\n\nkibana version: v7.9.3\n\n## 2. 设置ILM\n\n### 2.1 创建索引生命周期策略\n\n#### 2.1.1 热阶段\n\n首先需要先创建索引生命周期策略，在索引模板中可以引用创建好的索引生命周期策略。\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm01.png)\n\n- 策略名称： 引用该策略是需要用，例如设置为：filebeat-index-ilm\n  \n- 最大索引大小：设置单个索引最大字节数，此处为50千兆字节，即50G.\n  \n- 最大文档数：设置单个索引所内容乃的最大文档数，超过该数则创建新的索引。\n  \n- 最大存在时间： 指的是索引在温热阶段中可以存在的最长时间。一旦索引达到这个时间限制，它将被自动转移到冷却阶段，并最终被归档或删除。\n  \n  \"最大存在时间\"是一个可选的参数，你可以根据实际需求来决定是否设置这个参数。如果你没有设置这个参数，索引将会一直保持在温热阶段，直到你手动将其转移到冷却阶段或删除。\n  \n  在设置\"最大存在时间\"时，你可以选择一个固定的时间长度，例如30天。这意味着索引在温热阶段中最多存在30天，之后它将被自动转移到冷却阶段。这个参数可以帮助你控制索引的生命周期，避免过多的旧索引占用存储空间和资源。\n  \n  需要注意的是，具体的索引生命周期策略还受到其他参数的影响，例如滚动布署的频率、索引模板、索引生命周期策略等。因此，在实际应用中，需要根据具体的业务需求和数据量来调整和优化这些参数。\n  \n\n#### 2.1.2 温阶段和冷阶段\n\n温阶段和冷阶段不再设置，解释一下这两个阶段：\n\n在 Kibana 中创建索引生命周期策略时，warm phase和Cold phase的存在有意义，它们适用于不同的场景。\n\n1. Warm phase（温阶段）：\n  Warm phase是索引生命周期的中间阶段，适用于处理活跃但不再频繁更改的数据。在这个阶段，索引被用于的搜索和查询操作较多，因此需要保持良好的搜索性能。在温阶段，索引可以被滚动更新，以保持其当前的索引结构、映射和设置。\n  \n  温阶段适用于以下场景：\n  \n  - 数据检索：如果您的应用程序需要从历史数据中检索信息，并且这些数据已经过了一段时间但仍然活跃，那么可以将索引设置为在温阶段。\n  - 数据归档和分析：如果您的应用程序需要将数据存储一段时间以便进行进一步的分析、报告或可视化，那么可以将索引设置为在温阶段。\n2. Cold phase（冷阶段）：\n  Cold phase是索引生命周期的后期阶段，适用于处理不再活跃的数据。在这个阶段，索引被用于的搜索和查询操作较少，因此可以降低存储成本和索引维护开销。在冷阶段，索引可以被归档和压缩，以进一步降低存储成本。\n  \n  冷阶段适用于以下场景：\n  \n  - 数据归档：如果您的应用程序需要长期存储数据，并且这些数据不再被频繁地搜索和查询，那么可以将索引设置为在冷阶段。\n  - 数据保留策略：如果您的应用程序需要保留某些数据一段时间后将其删除，那么可以将索引设置为在冷阶段，并在达到保留期限时自动删除索引。\n  \n  综上所述，温阶段和冷阶段的存在意义在于进一步优化索引生命周期的管理。通过将索引分阶段管理，可以更好地平衡性能、存储成本和维护开销，以满足不同的业务需求。\n  \n\n#### 2.1.3 删除阶段\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm03.png)\n\n- 删除倒计时： 设置日志多久之后删除。\n  \n\n### 2.2 创建索引模板\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template01.png)\n\n- 名称：索引模板名\n  \n- 索引模式： 用来匹配应用于哪些索引，例如匹配filebeat-开头的索引;filebeat-*\n  \n- 优先级：是一个整数值，用于确定索引模板的优先级。较高的优先级值表示该索引模板具有更高的优先级。当多个索引模板匹配到同一个索引时，优先级最高的索引模板将被应用。\n  \n- 版本：是一个整数值，用于跟踪索引模板的版本号。你可以根据需要为每个索引模板设置一个唯一的版本号。当索引模板需要更新时，你可以增加版本号以确保新版本的索引模板被应用。\n  \n- _meta 字段：_meta 字段是一个 JSON 对象，用于存储与索引模板相关的元数据。你可以在 _meta 字段中添加自定义的键值对，例如索引模板的创建时间、作者等信息。这些元数据可以在使用 Elasticsearch API 管理索引模板时进行访问和操作。\n  \n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template02.png)\n\n- 选择组件： 引用已经创建好的组件模板\n  \n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template03.png)\n\n- 索引设置: 图中设置了生命周期相关内容，lifecycle：指的就是索引的生命周期，这里就是我们之前创建的索引生命周期；rollover_alias：滚动别名，当我们配置了索引大小，超过这个大小后，会以这个名称命名。\n  \n\n1. 映射字段：  \n  映射字段是指将文档中的字段与特定的数据类型和属性进行映射。在创建索引模板时，可以手动添加映射字段，以便在索引文档时将字段映射为指定的数据类型和属性。例如，可以添加一个名为 \"message\" 的映射字段，将其映射为文本类型，并设置其分析器为 \"standard\"。\n\n映射字段适用于以下场景：\n\n- 数据类型已知且固定的场景：当文档中的字段类型固定且已知时，可以手动添加映射字段，以确保索引的准确性和性能。\n  \n- 需要自定义数据类型的场景：当文档中存在自定义的数据类型时，可以手动添加映射字段，并将其映射为相应的数据类型，以便在查询和聚合时能够正确地处理数据。\n  \n\n2. 动态模板：  \n  动态模板是指根据文档中的字段名、数据类型等动态地设定字段类型。在创建索引模板时，可以定义动态模板规则，以便根据文档的实际情况动态地设定字段类型。例如，可以定义一个名为 \"text\" 的动态模板，将所有以 \"message\" 开头的字段映射为文本类型。\n\n动态模板适用于以下场景：\n\n- 数据类型未知或动态变化的场景：当文档中的字段类型未知或动态变化时，可以使用动态模板来自动识别字段类型，并将其映射为相应的数据类型。\n  \n- 需要灵活处理不同数据类型的场景：当文档中存在多种数据类型时，可以使用动态模板来根据字段名、数据类型等信息动态设定字段类型，以便在查询和聚合时能够正确地处理数据。\n  \n\n3. 高级选项：  \n  高级选项是指在创建索引模板时可以配置的一些高级设置，例如索引分片数、索引副本数、分析器等。这些设置可以优化索引的性能和存储效率。\n\n高级选项适用于以下场景：\n\n- 需要优化索引性能的场景：可以通过配置索引分片数和索引副本数来优化索引的性能，提高查询和聚合的速度。\n- 需要优化存储效率的场景：可以通过配置存储设置和分析器来优化索引的存储效率，减少存储空间的使用.。\n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template05.png)\n\n- 设置索引别名\n  \n  1. 方便对多个索引进行查询：如果你有许多索引并且经常需要同时查询这些索引，使用别名可以方便地将这些索引组合在一起进行查询。\n  2. 简化索引引用：在查询时，只需要引用别名，而不需要写出完整的索引名称，这使得查询语句更加简洁。\n  3. 方便索引的版本控制：如果你在系统中对索引进行更新或替换，使用别名可以使得对已有查询的影响最小化。例如，你可以创建一个别名，使其始终映射到最新的索引版本，这样在更新索引时，不需要更改所有查询。\n  \n  在 Elasticsearch 中创建别名的方法是通过使用 \"alias\" API。例如，如果你有一个索引 \"test-20190120\"，并想为其创建一个别名 \"test\"，你可以使用以下的请求：\n  \n  ```bash\n  PUT /_aliases  {    \"actions\": [      {        \"add\": {          \"index\": \"test-20190120\",          \"alias\": \"test\"        }      }    ]  }\n  ```\n  \n  在上述请求中，\"add\" 动作告诉 Elasticsearch 将别名 \"test\" 添加到索引 \"test-20190120\" 上。之后，你可以使用别名 \"test\" 来查询该索引的内容。\n  \n\n![](https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template06.png)\n\n完成模板创建。\n\n## 3. 生效\n\n创建索引生命周期之前的创建的索引不会受索引生命周期影响，之后创建的索引会进入到索引生命周期的策略管理中。","slug":"kubernetes/kibana-ilm","published":1,"updated":"2023-11-07T02:41:52.152Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0c7000tfmjx4o9g38rw","content":"<h1 id=\"kibana设置ILM\"><a href=\"#kibana设置ILM\" class=\"headerlink\" title=\"kibana设置ILM\"></a>kibana设置ILM</h1><h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h2><p>kibana version: v7.9.3</p>\n<h2 id=\"2-设置ILM\"><a href=\"#2-设置ILM\" class=\"headerlink\" title=\"2. 设置ILM\"></a>2. 设置ILM</h2><h3 id=\"2-1-创建索引生命周期策略\"><a href=\"#2-1-创建索引生命周期策略\" class=\"headerlink\" title=\"2.1 创建索引生命周期策略\"></a>2.1 创建索引生命周期策略</h3><h4 id=\"2-1-1-热阶段\"><a href=\"#2-1-1-热阶段\" class=\"headerlink\" title=\"2.1.1 热阶段\"></a>2.1.1 热阶段</h4><p>首先需要先创建索引生命周期策略，在索引模板中可以引用创建好的索引生命周期策略。</p>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm01.png\"></p>\n<ul>\n<li><p>策略名称： 引用该策略是需要用，例如设置为：filebeat-index-ilm</p>\n</li>\n<li><p>最大索引大小：设置单个索引最大字节数，此处为50千兆字节，即50G.</p>\n</li>\n<li><p>最大文档数：设置单个索引所内容乃的最大文档数，超过该数则创建新的索引。</p>\n</li>\n<li><p>最大存在时间： 指的是索引在温热阶段中可以存在的最长时间。一旦索引达到这个时间限制，它将被自动转移到冷却阶段，并最终被归档或删除。</p>\n<p>“最大存在时间”是一个可选的参数，你可以根据实际需求来决定是否设置这个参数。如果你没有设置这个参数，索引将会一直保持在温热阶段，直到你手动将其转移到冷却阶段或删除。</p>\n<p>在设置”最大存在时间”时，你可以选择一个固定的时间长度，例如30天。这意味着索引在温热阶段中最多存在30天，之后它将被自动转移到冷却阶段。这个参数可以帮助你控制索引的生命周期，避免过多的旧索引占用存储空间和资源。</p>\n<p>需要注意的是，具体的索引生命周期策略还受到其他参数的影响，例如滚动布署的频率、索引模板、索引生命周期策略等。因此，在实际应用中，需要根据具体的业务需求和数据量来调整和优化这些参数。</p>\n</li>\n</ul>\n<h4 id=\"2-1-2-温阶段和冷阶段\"><a href=\"#2-1-2-温阶段和冷阶段\" class=\"headerlink\" title=\"2.1.2 温阶段和冷阶段\"></a>2.1.2 温阶段和冷阶段</h4><p>温阶段和冷阶段不再设置，解释一下这两个阶段：</p>\n<p>在 Kibana 中创建索引生命周期策略时，warm phase和Cold phase的存在有意义，它们适用于不同的场景。</p>\n<ol>\n<li>Warm phase（温阶段）：<br>  Warm phase是索引生命周期的中间阶段，适用于处理活跃但不再频繁更改的数据。在这个阶段，索引被用于的搜索和查询操作较多，因此需要保持良好的搜索性能。在温阶段，索引可以被滚动更新，以保持其当前的索引结构、映射和设置。</li>\n</ol>\n<p>  温阶段适用于以下场景：</p>\n<ul>\n<li>数据检索：如果您的应用程序需要从历史数据中检索信息，并且这些数据已经过了一段时间但仍然活跃，那么可以将索引设置为在温阶段。</li>\n<li>数据归档和分析：如果您的应用程序需要将数据存储一段时间以便进行进一步的分析、报告或可视化，那么可以将索引设置为在温阶段。</li>\n</ul>\n<ol start=\"2\">\n<li>Cold phase（冷阶段）：<br>  Cold phase是索引生命周期的后期阶段，适用于处理不再活跃的数据。在这个阶段，索引被用于的搜索和查询操作较少，因此可以降低存储成本和索引维护开销。在冷阶段，索引可以被归档和压缩，以进一步降低存储成本。</li>\n</ol>\n<p>  冷阶段适用于以下场景：</p>\n<ul>\n<li>数据归档：如果您的应用程序需要长期存储数据，并且这些数据不再被频繁地搜索和查询，那么可以将索引设置为在冷阶段。</li>\n<li>数据保留策略：如果您的应用程序需要保留某些数据一段时间后将其删除，那么可以将索引设置为在冷阶段，并在达到保留期限时自动删除索引。</li>\n</ul>\n<p>  综上所述，温阶段和冷阶段的存在意义在于进一步优化索引生命周期的管理。通过将索引分阶段管理，可以更好地平衡性能、存储成本和维护开销，以满足不同的业务需求。</p>\n<h4 id=\"2-1-3-删除阶段\"><a href=\"#2-1-3-删除阶段\" class=\"headerlink\" title=\"2.1.3 删除阶段\"></a>2.1.3 删除阶段</h4><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm03.png\"></p>\n<ul>\n<li>删除倒计时： 设置日志多久之后删除。</li>\n</ul>\n<h3 id=\"2-2-创建索引模板\"><a href=\"#2-2-创建索引模板\" class=\"headerlink\" title=\"2.2 创建索引模板\"></a>2.2 创建索引模板</h3><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template01.png\"></p>\n<ul>\n<li><p>名称：索引模板名</p>\n</li>\n<li><p>索引模式： 用来匹配应用于哪些索引，例如匹配filebeat-开头的索引;filebeat-*</p>\n</li>\n<li><p>优先级：是一个整数值，用于确定索引模板的优先级。较高的优先级值表示该索引模板具有更高的优先级。当多个索引模板匹配到同一个索引时，优先级最高的索引模板将被应用。</p>\n</li>\n<li><p>版本：是一个整数值，用于跟踪索引模板的版本号。你可以根据需要为每个索引模板设置一个唯一的版本号。当索引模板需要更新时，你可以增加版本号以确保新版本的索引模板被应用。</p>\n</li>\n<li><p>_meta 字段：_meta 字段是一个 JSON 对象，用于存储与索引模板相关的元数据。你可以在 _meta 字段中添加自定义的键值对，例如索引模板的创建时间、作者等信息。这些元数据可以在使用 Elasticsearch API 管理索引模板时进行访问和操作。</p>\n</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template02.png\"></p>\n<ul>\n<li>选择组件： 引用已经创建好的组件模板</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template03.png\"></p>\n<ul>\n<li>索引设置: 图中设置了生命周期相关内容，lifecycle：指的就是索引的生命周期，这里就是我们之前创建的索引生命周期；rollover_alias：滚动别名，当我们配置了索引大小，超过这个大小后，会以这个名称命名。</li>\n</ul>\n<ol>\n<li>映射字段：<br>  映射字段是指将文档中的字段与特定的数据类型和属性进行映射。在创建索引模板时，可以手动添加映射字段，以便在索引文档时将字段映射为指定的数据类型和属性。例如，可以添加一个名为 “message” 的映射字段，将其映射为文本类型，并设置其分析器为 “standard”。</li>\n</ol>\n<p>映射字段适用于以下场景：</p>\n<ul>\n<li><p>数据类型已知且固定的场景：当文档中的字段类型固定且已知时，可以手动添加映射字段，以确保索引的准确性和性能。</p>\n</li>\n<li><p>需要自定义数据类型的场景：当文档中存在自定义的数据类型时，可以手动添加映射字段，并将其映射为相应的数据类型，以便在查询和聚合时能够正确地处理数据。</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>动态模板：<br>  动态模板是指根据文档中的字段名、数据类型等动态地设定字段类型。在创建索引模板时，可以定义动态模板规则，以便根据文档的实际情况动态地设定字段类型。例如，可以定义一个名为 “text” 的动态模板，将所有以 “message” 开头的字段映射为文本类型。</li>\n</ol>\n<p>动态模板适用于以下场景：</p>\n<ul>\n<li><p>数据类型未知或动态变化的场景：当文档中的字段类型未知或动态变化时，可以使用动态模板来自动识别字段类型，并将其映射为相应的数据类型。</p>\n</li>\n<li><p>需要灵活处理不同数据类型的场景：当文档中存在多种数据类型时，可以使用动态模板来根据字段名、数据类型等信息动态设定字段类型，以便在查询和聚合时能够正确地处理数据。</p>\n</li>\n</ul>\n<ol start=\"3\">\n<li>高级选项：<br>  高级选项是指在创建索引模板时可以配置的一些高级设置，例如索引分片数、索引副本数、分析器等。这些设置可以优化索引的性能和存储效率。</li>\n</ol>\n<p>高级选项适用于以下场景：</p>\n<ul>\n<li>需要优化索引性能的场景：可以通过配置索引分片数和索引副本数来优化索引的性能，提高查询和聚合的速度。</li>\n<li>需要优化存储效率的场景：可以通过配置存储设置和分析器来优化索引的存储效率，减少存储空间的使用.。</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template05.png\"></p>\n<ul>\n<li><p>设置索引别名</p>\n<ol>\n<li>方便对多个索引进行查询：如果你有许多索引并且经常需要同时查询这些索引，使用别名可以方便地将这些索引组合在一起进行查询。</li>\n<li>简化索引引用：在查询时，只需要引用别名，而不需要写出完整的索引名称，这使得查询语句更加简洁。</li>\n<li>方便索引的版本控制：如果你在系统中对索引进行更新或替换，使用别名可以使得对已有查询的影响最小化。例如，你可以创建一个别名，使其始终映射到最新的索引版本，这样在更新索引时，不需要更改所有查询。</li>\n</ol>\n<p>在 Elasticsearch 中创建别名的方法是通过使用 “alias” API。例如，如果你有一个索引 “test-20190120”，并想为其创建一个别名 “test”，你可以使用以下的请求：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /_aliases  &#123;    <span class=\"string\">&quot;actions&quot;</span>: [      &#123;        <span class=\"string\">&quot;add&quot;</span>: &#123;          <span class=\"string\">&quot;index&quot;</span>: <span class=\"string\">&quot;test-20190120&quot;</span>,          <span class=\"string\">&quot;alias&quot;</span>: <span class=\"string\">&quot;test&quot;</span>        &#125;      &#125;    ]  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>在上述请求中，”add” 动作告诉 Elasticsearch 将别名 “test” 添加到索引 “test-20190120” 上。之后，你可以使用别名 “test” 来查询该索引的内容。</p>\n</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template06.png\"></p>\n<p>完成模板创建。</p>\n<h2 id=\"3-生效\"><a href=\"#3-生效\" class=\"headerlink\" title=\"3. 生效\"></a>3. 生效</h2><p>创建索引生命周期之前的创建的索引不会受索引生命周期影响，之后创建的索引会进入到索引生命周期的策略管理中。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<h1 id=\"kibana设置ILM\"><a href=\"#kibana设置ILM\" class=\"headerlink\" title=\"kibana设置ILM\"></a>kibana设置ILM</h1><h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h2><p>kibana version: v7.9.3</p>\n<h2 id=\"2-设置ILM\"><a href=\"#2-设置ILM\" class=\"headerlink\" title=\"2. 设置ILM\"></a>2. 设置ILM</h2><h3 id=\"2-1-创建索引生命周期策略\"><a href=\"#2-1-创建索引生命周期策略\" class=\"headerlink\" title=\"2.1 创建索引生命周期策略\"></a>2.1 创建索引生命周期策略</h3><h4 id=\"2-1-1-热阶段\"><a href=\"#2-1-1-热阶段\" class=\"headerlink\" title=\"2.1.1 热阶段\"></a>2.1.1 热阶段</h4><p>首先需要先创建索引生命周期策略，在索引模板中可以引用创建好的索引生命周期策略。</p>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm01.png\"></p>\n<ul>\n<li><p>策略名称： 引用该策略是需要用，例如设置为：filebeat-index-ilm</p>\n</li>\n<li><p>最大索引大小：设置单个索引最大字节数，此处为50千兆字节，即50G.</p>\n</li>\n<li><p>最大文档数：设置单个索引所内容乃的最大文档数，超过该数则创建新的索引。</p>\n</li>\n<li><p>最大存在时间： 指的是索引在温热阶段中可以存在的最长时间。一旦索引达到这个时间限制，它将被自动转移到冷却阶段，并最终被归档或删除。</p>\n<p>“最大存在时间”是一个可选的参数，你可以根据实际需求来决定是否设置这个参数。如果你没有设置这个参数，索引将会一直保持在温热阶段，直到你手动将其转移到冷却阶段或删除。</p>\n<p>在设置”最大存在时间”时，你可以选择一个固定的时间长度，例如30天。这意味着索引在温热阶段中最多存在30天，之后它将被自动转移到冷却阶段。这个参数可以帮助你控制索引的生命周期，避免过多的旧索引占用存储空间和资源。</p>\n<p>需要注意的是，具体的索引生命周期策略还受到其他参数的影响，例如滚动布署的频率、索引模板、索引生命周期策略等。因此，在实际应用中，需要根据具体的业务需求和数据量来调整和优化这些参数。</p>\n</li>\n</ul>\n<h4 id=\"2-1-2-温阶段和冷阶段\"><a href=\"#2-1-2-温阶段和冷阶段\" class=\"headerlink\" title=\"2.1.2 温阶段和冷阶段\"></a>2.1.2 温阶段和冷阶段</h4><p>温阶段和冷阶段不再设置，解释一下这两个阶段：</p>\n<p>在 Kibana 中创建索引生命周期策略时，warm phase和Cold phase的存在有意义，它们适用于不同的场景。</p>\n<ol>\n<li>Warm phase（温阶段）：<br>  Warm phase是索引生命周期的中间阶段，适用于处理活跃但不再频繁更改的数据。在这个阶段，索引被用于的搜索和查询操作较多，因此需要保持良好的搜索性能。在温阶段，索引可以被滚动更新，以保持其当前的索引结构、映射和设置。</li>\n</ol>\n<p>  温阶段适用于以下场景：</p>\n<ul>\n<li>数据检索：如果您的应用程序需要从历史数据中检索信息，并且这些数据已经过了一段时间但仍然活跃，那么可以将索引设置为在温阶段。</li>\n<li>数据归档和分析：如果您的应用程序需要将数据存储一段时间以便进行进一步的分析、报告或可视化，那么可以将索引设置为在温阶段。</li>\n</ul>\n<ol start=\"2\">\n<li>Cold phase（冷阶段）：<br>  Cold phase是索引生命周期的后期阶段，适用于处理不再活跃的数据。在这个阶段，索引被用于的搜索和查询操作较少，因此可以降低存储成本和索引维护开销。在冷阶段，索引可以被归档和压缩，以进一步降低存储成本。</li>\n</ol>\n<p>  冷阶段适用于以下场景：</p>\n<ul>\n<li>数据归档：如果您的应用程序需要长期存储数据，并且这些数据不再被频繁地搜索和查询，那么可以将索引设置为在冷阶段。</li>\n<li>数据保留策略：如果您的应用程序需要保留某些数据一段时间后将其删除，那么可以将索引设置为在冷阶段，并在达到保留期限时自动删除索引。</li>\n</ul>\n<p>  综上所述，温阶段和冷阶段的存在意义在于进一步优化索引生命周期的管理。通过将索引分阶段管理，可以更好地平衡性能、存储成本和维护开销，以满足不同的业务需求。</p>\n<h4 id=\"2-1-3-删除阶段\"><a href=\"#2-1-3-删除阶段\" class=\"headerlink\" title=\"2.1.3 删除阶段\"></a>2.1.3 删除阶段</h4><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/ilm03.png\"></p>\n<ul>\n<li>删除倒计时： 设置日志多久之后删除。</li>\n</ul>\n<h3 id=\"2-2-创建索引模板\"><a href=\"#2-2-创建索引模板\" class=\"headerlink\" title=\"2.2 创建索引模板\"></a>2.2 创建索引模板</h3><p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template01.png\"></p>\n<ul>\n<li><p>名称：索引模板名</p>\n</li>\n<li><p>索引模式： 用来匹配应用于哪些索引，例如匹配filebeat-开头的索引;filebeat-*</p>\n</li>\n<li><p>优先级：是一个整数值，用于确定索引模板的优先级。较高的优先级值表示该索引模板具有更高的优先级。当多个索引模板匹配到同一个索引时，优先级最高的索引模板将被应用。</p>\n</li>\n<li><p>版本：是一个整数值，用于跟踪索引模板的版本号。你可以根据需要为每个索引模板设置一个唯一的版本号。当索引模板需要更新时，你可以增加版本号以确保新版本的索引模板被应用。</p>\n</li>\n<li><p>_meta 字段：_meta 字段是一个 JSON 对象，用于存储与索引模板相关的元数据。你可以在 _meta 字段中添加自定义的键值对，例如索引模板的创建时间、作者等信息。这些元数据可以在使用 Elasticsearch API 管理索引模板时进行访问和操作。</p>\n</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template02.png\"></p>\n<ul>\n<li>选择组件： 引用已经创建好的组件模板</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template03.png\"></p>\n<ul>\n<li>索引设置: 图中设置了生命周期相关内容，lifecycle：指的就是索引的生命周期，这里就是我们之前创建的索引生命周期；rollover_alias：滚动别名，当我们配置了索引大小，超过这个大小后，会以这个名称命名。</li>\n</ul>\n<ol>\n<li>映射字段：<br>  映射字段是指将文档中的字段与特定的数据类型和属性进行映射。在创建索引模板时，可以手动添加映射字段，以便在索引文档时将字段映射为指定的数据类型和属性。例如，可以添加一个名为 “message” 的映射字段，将其映射为文本类型，并设置其分析器为 “standard”。</li>\n</ol>\n<p>映射字段适用于以下场景：</p>\n<ul>\n<li><p>数据类型已知且固定的场景：当文档中的字段类型固定且已知时，可以手动添加映射字段，以确保索引的准确性和性能。</p>\n</li>\n<li><p>需要自定义数据类型的场景：当文档中存在自定义的数据类型时，可以手动添加映射字段，并将其映射为相应的数据类型，以便在查询和聚合时能够正确地处理数据。</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>动态模板：<br>  动态模板是指根据文档中的字段名、数据类型等动态地设定字段类型。在创建索引模板时，可以定义动态模板规则，以便根据文档的实际情况动态地设定字段类型。例如，可以定义一个名为 “text” 的动态模板，将所有以 “message” 开头的字段映射为文本类型。</li>\n</ol>\n<p>动态模板适用于以下场景：</p>\n<ul>\n<li><p>数据类型未知或动态变化的场景：当文档中的字段类型未知或动态变化时，可以使用动态模板来自动识别字段类型，并将其映射为相应的数据类型。</p>\n</li>\n<li><p>需要灵活处理不同数据类型的场景：当文档中存在多种数据类型时，可以使用动态模板来根据字段名、数据类型等信息动态设定字段类型，以便在查询和聚合时能够正确地处理数据。</p>\n</li>\n</ul>\n<ol start=\"3\">\n<li>高级选项：<br>  高级选项是指在创建索引模板时可以配置的一些高级设置，例如索引分片数、索引副本数、分析器等。这些设置可以优化索引的性能和存储效率。</li>\n</ol>\n<p>高级选项适用于以下场景：</p>\n<ul>\n<li>需要优化索引性能的场景：可以通过配置索引分片数和索引副本数来优化索引的性能，提高查询和聚合的速度。</li>\n<li>需要优化存储效率的场景：可以通过配置存储设置和分析器来优化索引的存储效率，减少存储空间的使用.。</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template05.png\"></p>\n<ul>\n<li><p>设置索引别名</p>\n<ol>\n<li>方便对多个索引进行查询：如果你有许多索引并且经常需要同时查询这些索引，使用别名可以方便地将这些索引组合在一起进行查询。</li>\n<li>简化索引引用：在查询时，只需要引用别名，而不需要写出完整的索引名称，这使得查询语句更加简洁。</li>\n<li>方便索引的版本控制：如果你在系统中对索引进行更新或替换，使用别名可以使得对已有查询的影响最小化。例如，你可以创建一个别名，使其始终映射到最新的索引版本，这样在更新索引时，不需要更改所有查询。</li>\n</ol>\n<p>在 Elasticsearch 中创建别名的方法是通过使用 “alias” API。例如，如果你有一个索引 “test-20190120”，并想为其创建一个别名 “test”，你可以使用以下的请求：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /_aliases  &#123;    <span class=\"string\">&quot;actions&quot;</span>: [      &#123;        <span class=\"string\">&quot;add&quot;</span>: &#123;          <span class=\"string\">&quot;index&quot;</span>: <span class=\"string\">&quot;test-20190120&quot;</span>,          <span class=\"string\">&quot;alias&quot;</span>: <span class=\"string\">&quot;test&quot;</span>        &#125;      &#125;    ]  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>在上述请求中，”add” 动作告诉 Elasticsearch 将别名 “test” 添加到索引 “test-20190120” 上。之后，你可以使用别名 “test” 来查询该索引的内容。</p>\n</li>\n</ul>\n<p><img src=\"https://gh-proxy.com/https://github.com/wongearl/mypic/blob/main/kibana/index-template06.png\"></p>\n<p>完成模板创建。</p>\n<h2 id=\"3-生效\"><a href=\"#3-生效\" class=\"headerlink\" title=\"3. 生效\"></a>3. 生效</h2><p>创建索引生命周期之前的创建的索引不会受索引生命周期影响，之后创建的索引会进入到索引生命周期的策略管理中。</p>\n"},{"title":"kubeovn underlay 相关概念","date":"2023-11-02T02:21:20.190Z","_content":"在计算机网络中，Provider Network（提供商网络）是一个由服务提供商或网络管理员管理的网络，它为用户提供网络连接和服务。Provider Network通常包含多个VLAN（虚拟局域网）和Subnet（子网）。\n\nVLAN是一种逻辑上的局域网，它可以将物理网络中的设备划分为不同的逻辑组，以便进行管理和访问控制。在Provider Network中，VLAN通常用于将用户设备划分为不同的逻辑子网，以便提供更好的隔离和管理。\n\nSubnet是IP网络的一部分，它使用子网掩码来划分网络地址空间。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。在Provider Network中，Subnet通常用于将不同的用户设备分配到不同的IP子网中，以便进行路由和访问控制。\n\nProvider Network、VLAN和Subnet之间的关系和作用如下：\n\nProvider Network是整个网络的框架，它提供了用户设备与外部网络或服务之间的连接。\nVLAN在Provider Network中起到了逻辑隔离的作用，它将用户设备划分为不同的逻辑子网，以便更好地管理和控制网络流量。\nSubnet是IP网络的一部分，它在Provider Network中定义了IP地址的分配范围和子网掩码。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。\nVLAN和Subnet之间存在一定的关联。一个VLAN可以包含多个Subnet，每个Subnet都是IP网络的一部分。在Provider Network中，VLAN和Subnet的组合使用可以更好地管理网络流量和控制访问权限。\n总之，Provider Network、VLAN和Subnet之间的关系是相互依存的。Provider Network提供了整个网络的框架和连接能力，VLAN起到了逻辑隔离的作用，而Subnet则定义了IP地址的分配范围和子网掩码。这些技术的组合使用可以提供更好的网络管理和控制能力。","source":"_posts/kubernetes/kube-ovn-underlay.md","raw":"---\ntitle: kubeovn underlay 相关概念\ndate: 2023-11-02 10:21:20\n  - [kubernetes]\ntags: kubeovn\n---\n在计算机网络中，Provider Network（提供商网络）是一个由服务提供商或网络管理员管理的网络，它为用户提供网络连接和服务。Provider Network通常包含多个VLAN（虚拟局域网）和Subnet（子网）。\n\nVLAN是一种逻辑上的局域网，它可以将物理网络中的设备划分为不同的逻辑组，以便进行管理和访问控制。在Provider Network中，VLAN通常用于将用户设备划分为不同的逻辑子网，以便提供更好的隔离和管理。\n\nSubnet是IP网络的一部分，它使用子网掩码来划分网络地址空间。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。在Provider Network中，Subnet通常用于将不同的用户设备分配到不同的IP子网中，以便进行路由和访问控制。\n\nProvider Network、VLAN和Subnet之间的关系和作用如下：\n\nProvider Network是整个网络的框架，它提供了用户设备与外部网络或服务之间的连接。\nVLAN在Provider Network中起到了逻辑隔离的作用，它将用户设备划分为不同的逻辑子网，以便更好地管理和控制网络流量。\nSubnet是IP网络的一部分，它在Provider Network中定义了IP地址的分配范围和子网掩码。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。\nVLAN和Subnet之间存在一定的关联。一个VLAN可以包含多个Subnet，每个Subnet都是IP网络的一部分。在Provider Network中，VLAN和Subnet的组合使用可以更好地管理网络流量和控制访问权限。\n总之，Provider Network、VLAN和Subnet之间的关系是相互依存的。Provider Network提供了整个网络的框架和连接能力，VLAN起到了逻辑隔离的作用，而Subnet则定义了IP地址的分配范围和子网掩码。这些技术的组合使用可以提供更好的网络管理和控制能力。","slug":"kubernetes/kube-ovn-underlay","published":1,"updated":"2023-11-02T02:22:33.396Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0c8000wfmjx0acj7l1m","content":"<p>在计算机网络中，Provider Network（提供商网络）是一个由服务提供商或网络管理员管理的网络，它为用户提供网络连接和服务。Provider Network通常包含多个VLAN（虚拟局域网）和Subnet（子网）。</p>\n<p>VLAN是一种逻辑上的局域网，它可以将物理网络中的设备划分为不同的逻辑组，以便进行管理和访问控制。在Provider Network中，VLAN通常用于将用户设备划分为不同的逻辑子网，以便提供更好的隔离和管理。</p>\n<p>Subnet是IP网络的一部分，它使用子网掩码来划分网络地址空间。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。在Provider Network中，Subnet通常用于将不同的用户设备分配到不同的IP子网中，以便进行路由和访问控制。</p>\n<p>Provider Network、VLAN和Subnet之间的关系和作用如下：</p>\n<p>Provider Network是整个网络的框架，它提供了用户设备与外部网络或服务之间的连接。<br>VLAN在Provider Network中起到了逻辑隔离的作用，它将用户设备划分为不同的逻辑子网，以便更好地管理和控制网络流量。<br>Subnet是IP网络的一部分，它在Provider Network中定义了IP地址的分配范围和子网掩码。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。<br>VLAN和Subnet之间存在一定的关联。一个VLAN可以包含多个Subnet，每个Subnet都是IP网络的一部分。在Provider Network中，VLAN和Subnet的组合使用可以更好地管理网络流量和控制访问权限。<br>总之，Provider Network、VLAN和Subnet之间的关系是相互依存的。Provider Network提供了整个网络的框架和连接能力，VLAN起到了逻辑隔离的作用，而Subnet则定义了IP地址的分配范围和子网掩码。这些技术的组合使用可以提供更好的网络管理和控制能力。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>在计算机网络中，Provider Network（提供商网络）是一个由服务提供商或网络管理员管理的网络，它为用户提供网络连接和服务。Provider Network通常包含多个VLAN（虚拟局域网）和Subnet（子网）。</p>\n<p>VLAN是一种逻辑上的局域网，它可以将物理网络中的设备划分为不同的逻辑组，以便进行管理和访问控制。在Provider Network中，VLAN通常用于将用户设备划分为不同的逻辑子网，以便提供更好的隔离和管理。</p>\n<p>Subnet是IP网络的一部分，它使用子网掩码来划分网络地址空间。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。在Provider Network中，Subnet通常用于将不同的用户设备分配到不同的IP子网中，以便进行路由和访问控制。</p>\n<p>Provider Network、VLAN和Subnet之间的关系和作用如下：</p>\n<p>Provider Network是整个网络的框架，它提供了用户设备与外部网络或服务之间的连接。<br>VLAN在Provider Network中起到了逻辑隔离的作用，它将用户设备划分为不同的逻辑子网，以便更好地管理和控制网络流量。<br>Subnet是IP网络的一部分，它在Provider Network中定义了IP地址的分配范围和子网掩码。Subnet可以进一步划分为更小的网络段，以便更好地管理和控制网络流量。<br>VLAN和Subnet之间存在一定的关联。一个VLAN可以包含多个Subnet，每个Subnet都是IP网络的一部分。在Provider Network中，VLAN和Subnet的组合使用可以更好地管理网络流量和控制访问权限。<br>总之，Provider Network、VLAN和Subnet之间的关系是相互依存的。Provider Network提供了整个网络的框架和连接能力，VLAN起到了逻辑隔离的作用，而Subnet则定义了IP地址的分配范围和子网掩码。这些技术的组合使用可以提供更好的网络管理和控制能力。</p>\n"},{"title":"kubevirt expose vm by svc","date":"2023-09-01T09:36:42.000Z","_content":"# 背景\n存在kubevit存在的三个虚机：\n\n```\nubuntu-4tlg7   7d22h   Running   True\nubuntu-7kgrk   7d22h   Running   True\nubuntu-94kg2   7d22h   Running   True\n```\n\n网络没有做透传，pod也不是underlay网络想要通过NodePort方式暴露虚机22端口进行远程登录。\n\n# 方法\n1. 修改vm资源实例，在spec.template.metada下添加labels设置,已存在的则不用添加。例如如下：\n```\n  spec:\n    runStrategy: RerunOnFailure\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          kubevirtvm01: kubevirtvm01\n```\n2. 重启虚机\n\n```\nvirtctl -n wyl-vm restart ubuntu-4tlg7\n```\n\n3. 暴露端口\n```\nvirtctl expose vm ubuntu-4tlg7 --name ubuntu-4tlg7-ssh --port 22 --target-port 22 --type NodePort -n wyl-vm\n```\n\n4. 查看svc\n\n```\nNAME               TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE\nubuntu-4tlg7-ssh   NodePort   10.96.23.17   <none>        22:32581/TCP   14m\n```\n使用节点ip地址加svc nodeport即可访问虚机。\n","source":"_posts/kubernetes/kubevirt-vm-expose.md","raw":"---\ntitle: kubevirt expose vm by svc\ndate: 2023-09-01 17:36:42\ncategories:\n  - [kubernetes]\ntags: kubevirt\n---\n# 背景\n存在kubevit存在的三个虚机：\n\n```\nubuntu-4tlg7   7d22h   Running   True\nubuntu-7kgrk   7d22h   Running   True\nubuntu-94kg2   7d22h   Running   True\n```\n\n网络没有做透传，pod也不是underlay网络想要通过NodePort方式暴露虚机22端口进行远程登录。\n\n# 方法\n1. 修改vm资源实例，在spec.template.metada下添加labels设置,已存在的则不用添加。例如如下：\n```\n  spec:\n    runStrategy: RerunOnFailure\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          kubevirtvm01: kubevirtvm01\n```\n2. 重启虚机\n\n```\nvirtctl -n wyl-vm restart ubuntu-4tlg7\n```\n\n3. 暴露端口\n```\nvirtctl expose vm ubuntu-4tlg7 --name ubuntu-4tlg7-ssh --port 22 --target-port 22 --type NodePort -n wyl-vm\n```\n\n4. 查看svc\n\n```\nNAME               TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE\nubuntu-4tlg7-ssh   NodePort   10.96.23.17   <none>        22:32581/TCP   14m\n```\n使用节点ip地址加svc nodeport即可访问虚机。\n","slug":"kubernetes/kubevirt-vm-expose","published":1,"updated":"2023-09-01T09:38:58.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0c9000zfmjx4z944fss","content":"<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>存在kubevit存在的三个虚机：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ubuntu-4tlg7   7d22h   Running   True</span><br><span class=\"line\">ubuntu-7kgrk   7d22h   Running   True</span><br><span class=\"line\">ubuntu-94kg2   7d22h   Running   True</span><br></pre></td></tr></table></figure>\n\n<p>网络没有做透传，pod也不是underlay网络想要通过NodePort方式暴露虚机22端口进行远程登录。</p>\n<h1 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h1><ol>\n<li>修改vm资源实例，在spec.template.metada下添加labels设置,已存在的则不用添加。例如如下：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spec:</span><br><span class=\"line\">  runStrategy: RerunOnFailure</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        kubevirtvm01: kubevirtvm01</span><br></pre></td></tr></table></figure></li>\n<li>重启虚机</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">virtctl -n wyl-vm restart ubuntu-4tlg7</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><p>暴露端口</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">virtctl expose vm ubuntu-4tlg7 --name ubuntu-4tlg7-ssh --port 22 --target-port 22 --type NodePort -n wyl-vm</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看svc</p>\n</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NAME               TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">ubuntu-4tlg7-ssh   NodePort   10.96.23.17   &lt;none&gt;        22:32581/TCP   14m</span><br></pre></td></tr></table></figure>\n<p>使用节点ip地址加svc nodeport即可访问虚机。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>存在kubevit存在的三个虚机：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ubuntu-4tlg7   7d22h   Running   True</span><br><span class=\"line\">ubuntu-7kgrk   7d22h   Running   True</span><br><span class=\"line\">ubuntu-94kg2   7d22h   Running   True</span><br></pre></td></tr></table></figure>\n\n<p>网络没有做透传，pod也不是underlay网络想要通过NodePort方式暴露虚机22端口进行远程登录。</p>\n<h1 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h1><ol>\n<li>修改vm资源实例，在spec.template.metada下添加labels设置,已存在的则不用添加。例如如下：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spec:</span><br><span class=\"line\">  runStrategy: RerunOnFailure</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        kubevirtvm01: kubevirtvm01</span><br></pre></td></tr></table></figure></li>\n<li>重启虚机</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">virtctl -n wyl-vm restart ubuntu-4tlg7</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><p>暴露端口</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">virtctl expose vm ubuntu-4tlg7 --name ubuntu-4tlg7-ssh --port 22 --target-port 22 --type NodePort -n wyl-vm</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看svc</p>\n</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NAME               TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">ubuntu-4tlg7-ssh   NodePort   10.96.23.17   &lt;none&gt;        22:32581/TCP   14m</span><br></pre></td></tr></table></figure>\n<p>使用节点ip地址加svc nodeport即可访问虚机。</p>\n"},{"title":"metrics/cadvisor,kube-state-metrics,node-exporter","date":"2023-08-18T10:30:53.000Z","_content":"# kubelet的metrics/cadvisor\nKubelet是Kubernetes主节点的一个核心组件，负责管理节点上的容器，以及与主控平面进行通信。Kubelet通过提供不同的接口和嵌入式组件来收集和暴露节点和容器的监控指标。\n\n1. Kubelet监控指标：\n   - Kubelet启动的Pod数目\n   - Kubelet已经完成的Pod数目\n   - Kubelet当前正在运行的Pod数目\n   - Kubelet拒绝启动的Pod数目\n   - Kubelet处理错误的Pod数目\n   - Kubelet未知状态的Pod数目\n   - Kubelet容器运行时间\n   - Kubelet容器CPU使用率\n   - Kubelet容器内存使用率\n   - Kubelet存储设备使用率\n   - Kubelet网络上行流量\n   - Kubelet网络下行流量\n   - Kubelet容器磁盘使用量\n   - Kubelet容器文件系统使用率\n   - Kubelet容器日志记录量\n\n2. cAdvisor监控指标：\n   - 容器的CPU使用率\n   - 容器的内存使用率\n   - 容器的磁盘使用率\n   - 容器的网络上行流量\n   - 容器的网络下行流量\n   - 容器的文件系统使用率\n   - 容器的日志记录量\n   - 容器的进程数\n   - 容器的打开文件数\n   - 容器的线程数\n   - 容器的磁盘I/O使用率\n   - 容器的网络延迟\n   - 容器的网络吞吐量\n   - 容器的内存压缩率\n   - 容器的内存丢失\n   - 容器的CPU限制与请求\n\n总体来说，Kubelet和cAdvisor提供了丰富的监控指标，可以用于监视节点和容器的资源使用情况、运行状态及性能状况。这些指标对于在Kubernetes集群中管理和优化容器化应用程序的性能和可靠性非常有帮助。\n# kube-state-metrics\nkube-state-metrics（KSM）是一个用于将Kubernetes集群的状态信息转换为Prometheus指标的开源项目。它可以提供丰富的监控指标，用于监控Kubernetes集群中的各种资源和对象。以下是Kube-state-metrics提供的一些主要监控指标：\n\n1. 节点指标（Node Metrics）：包括节点的CPU利用率、内存利用率、磁盘空间利用率等信息。\n\n2. Pod指标（Pod Metrics）：包括Pod的CPU利用率、内存利用率、网络流量等信息。\n\n3. 命名空间指标（Namespace Metrics）：包括命名空间中的Pod、Replication Controller、Deployment、DaemonSet等资源的数量和状态信息。\n\n4. 服务指标（Service Metrics）：包括服务的连接数、请求流量、响应时间等信息。\n\n5. 部署指标（Deployment Metrics）：包括部署的副本数量、可用副本数量、滚动更新状态等信息。\n\n6. 容器指标（Container Metrics）：包括容器的CPU利用率、内存利用率、文件系统使用情况等信息。\n\n7. StatefulSet指标（StatefulSet Metrics）：包括StatefulSet的副本数量、可用副本数量、当前状态等信息。\n\n8. 守护进程指标（DaemonSet Metrics）：包括DaemonSet的副本数量、可用副本数量、当前状态等信息。\n\n9. 任务指标（Job Metrics）：包括任务的运行状态、副本数量、成功和失败的次数等信息。\n\n这些指标可以提供关于Kubernetes集群和其中资源的性能、状态和健康状况的详细信息。使用这些指标，可以进行实时监控、性能优化、故障排除和容量规划，以确保集群的稳定性和可靠性。\n# node-exporter\nNode Exporter 是一种用于 Prometheus 的开源代理，用于暴露各种系统级监控指标。它可以在 Linux 系统上工作，并提供以下类型的监控指标：\n\n1. 系统指标：包括 CPU 使用率、内存使用率、磁盘使用率、磁盘 I/O 情况、网络流量、文件系统使用率等。这些指标可以帮助管理员了解系统的整体状态和资源利用情况。\n\n2. 进程指标：可以获取正在运行的进程数、进程CPU和内存使用情况、进程网络连接数等信息。通过这些指标，可以监控和识别系统中资源占用较多的进程，从而及时调整和优化。\n\n3. 网络指标：包括网络接口的带宽利用率、传输速率、丢包率和错误率等。这些指标可以帮助了解网络流量情况，监控网络性能和及时发现问题。\n\n4. 磁盘指标：包括磁盘使用率、磁盘读写速度、磁盘IO等。这些指标可以帮助监控磁盘的健康状况、数据读写速度和IO性能。\n\n5. 内存指标：包括内存使用量、内存交换情况、内存分页等。这些指标可以帮助了解内存的使用情况和性能。\n\n6. CPU 指标：包括 CPU 使用率、CPU 温度、CPU 核心数等。这些指标可以帮助监控系统的负载情况和CPU性能。\n\n7. 运行时间指标：包括系统的运行时间以及系统启动后的负载状况。这些指标可以帮助了解系统的稳定性和运行时间。\n\n除了以上列举的指标，Node Exporter 还提供了其他许多监控指标，以及一些自定义指标的扩展方式。用户可以根据需要选择性地监控和收集这些指标，以满足对系统性能和资源利用的需求。","source":"_posts/kubernetes/monitor.md","raw":"---\ntitle: metrics/cadvisor,kube-state-metrics,node-exporter\ndate: 2023-08-18 18:30:53\ncategories:\n  - [kubernetes]\ntags: kubernetes\n---\n# kubelet的metrics/cadvisor\nKubelet是Kubernetes主节点的一个核心组件，负责管理节点上的容器，以及与主控平面进行通信。Kubelet通过提供不同的接口和嵌入式组件来收集和暴露节点和容器的监控指标。\n\n1. Kubelet监控指标：\n   - Kubelet启动的Pod数目\n   - Kubelet已经完成的Pod数目\n   - Kubelet当前正在运行的Pod数目\n   - Kubelet拒绝启动的Pod数目\n   - Kubelet处理错误的Pod数目\n   - Kubelet未知状态的Pod数目\n   - Kubelet容器运行时间\n   - Kubelet容器CPU使用率\n   - Kubelet容器内存使用率\n   - Kubelet存储设备使用率\n   - Kubelet网络上行流量\n   - Kubelet网络下行流量\n   - Kubelet容器磁盘使用量\n   - Kubelet容器文件系统使用率\n   - Kubelet容器日志记录量\n\n2. cAdvisor监控指标：\n   - 容器的CPU使用率\n   - 容器的内存使用率\n   - 容器的磁盘使用率\n   - 容器的网络上行流量\n   - 容器的网络下行流量\n   - 容器的文件系统使用率\n   - 容器的日志记录量\n   - 容器的进程数\n   - 容器的打开文件数\n   - 容器的线程数\n   - 容器的磁盘I/O使用率\n   - 容器的网络延迟\n   - 容器的网络吞吐量\n   - 容器的内存压缩率\n   - 容器的内存丢失\n   - 容器的CPU限制与请求\n\n总体来说，Kubelet和cAdvisor提供了丰富的监控指标，可以用于监视节点和容器的资源使用情况、运行状态及性能状况。这些指标对于在Kubernetes集群中管理和优化容器化应用程序的性能和可靠性非常有帮助。\n# kube-state-metrics\nkube-state-metrics（KSM）是一个用于将Kubernetes集群的状态信息转换为Prometheus指标的开源项目。它可以提供丰富的监控指标，用于监控Kubernetes集群中的各种资源和对象。以下是Kube-state-metrics提供的一些主要监控指标：\n\n1. 节点指标（Node Metrics）：包括节点的CPU利用率、内存利用率、磁盘空间利用率等信息。\n\n2. Pod指标（Pod Metrics）：包括Pod的CPU利用率、内存利用率、网络流量等信息。\n\n3. 命名空间指标（Namespace Metrics）：包括命名空间中的Pod、Replication Controller、Deployment、DaemonSet等资源的数量和状态信息。\n\n4. 服务指标（Service Metrics）：包括服务的连接数、请求流量、响应时间等信息。\n\n5. 部署指标（Deployment Metrics）：包括部署的副本数量、可用副本数量、滚动更新状态等信息。\n\n6. 容器指标（Container Metrics）：包括容器的CPU利用率、内存利用率、文件系统使用情况等信息。\n\n7. StatefulSet指标（StatefulSet Metrics）：包括StatefulSet的副本数量、可用副本数量、当前状态等信息。\n\n8. 守护进程指标（DaemonSet Metrics）：包括DaemonSet的副本数量、可用副本数量、当前状态等信息。\n\n9. 任务指标（Job Metrics）：包括任务的运行状态、副本数量、成功和失败的次数等信息。\n\n这些指标可以提供关于Kubernetes集群和其中资源的性能、状态和健康状况的详细信息。使用这些指标，可以进行实时监控、性能优化、故障排除和容量规划，以确保集群的稳定性和可靠性。\n# node-exporter\nNode Exporter 是一种用于 Prometheus 的开源代理，用于暴露各种系统级监控指标。它可以在 Linux 系统上工作，并提供以下类型的监控指标：\n\n1. 系统指标：包括 CPU 使用率、内存使用率、磁盘使用率、磁盘 I/O 情况、网络流量、文件系统使用率等。这些指标可以帮助管理员了解系统的整体状态和资源利用情况。\n\n2. 进程指标：可以获取正在运行的进程数、进程CPU和内存使用情况、进程网络连接数等信息。通过这些指标，可以监控和识别系统中资源占用较多的进程，从而及时调整和优化。\n\n3. 网络指标：包括网络接口的带宽利用率、传输速率、丢包率和错误率等。这些指标可以帮助了解网络流量情况，监控网络性能和及时发现问题。\n\n4. 磁盘指标：包括磁盘使用率、磁盘读写速度、磁盘IO等。这些指标可以帮助监控磁盘的健康状况、数据读写速度和IO性能。\n\n5. 内存指标：包括内存使用量、内存交换情况、内存分页等。这些指标可以帮助了解内存的使用情况和性能。\n\n6. CPU 指标：包括 CPU 使用率、CPU 温度、CPU 核心数等。这些指标可以帮助监控系统的负载情况和CPU性能。\n\n7. 运行时间指标：包括系统的运行时间以及系统启动后的负载状况。这些指标可以帮助了解系统的稳定性和运行时间。\n\n除了以上列举的指标，Node Exporter 还提供了其他许多监控指标，以及一些自定义指标的扩展方式。用户可以根据需要选择性地监控和收集这些指标，以满足对系统性能和资源利用的需求。","slug":"kubernetes/monitor","published":1,"updated":"2023-08-23T06:55:44.756Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0ca0012fmjx0wi23y24","content":"<h1 id=\"kubelet的metrics-cadvisor\"><a href=\"#kubelet的metrics-cadvisor\" class=\"headerlink\" title=\"kubelet的metrics&#x2F;cadvisor\"></a>kubelet的metrics&#x2F;cadvisor</h1><p>Kubelet是Kubernetes主节点的一个核心组件，负责管理节点上的容器，以及与主控平面进行通信。Kubelet通过提供不同的接口和嵌入式组件来收集和暴露节点和容器的监控指标。</p>\n<ol>\n<li><p>Kubelet监控指标：</p>\n<ul>\n<li>Kubelet启动的Pod数目</li>\n<li>Kubelet已经完成的Pod数目</li>\n<li>Kubelet当前正在运行的Pod数目</li>\n<li>Kubelet拒绝启动的Pod数目</li>\n<li>Kubelet处理错误的Pod数目</li>\n<li>Kubelet未知状态的Pod数目</li>\n<li>Kubelet容器运行时间</li>\n<li>Kubelet容器CPU使用率</li>\n<li>Kubelet容器内存使用率</li>\n<li>Kubelet存储设备使用率</li>\n<li>Kubelet网络上行流量</li>\n<li>Kubelet网络下行流量</li>\n<li>Kubelet容器磁盘使用量</li>\n<li>Kubelet容器文件系统使用率</li>\n<li>Kubelet容器日志记录量</li>\n</ul>\n</li>\n<li><p>cAdvisor监控指标：</p>\n<ul>\n<li>容器的CPU使用率</li>\n<li>容器的内存使用率</li>\n<li>容器的磁盘使用率</li>\n<li>容器的网络上行流量</li>\n<li>容器的网络下行流量</li>\n<li>容器的文件系统使用率</li>\n<li>容器的日志记录量</li>\n<li>容器的进程数</li>\n<li>容器的打开文件数</li>\n<li>容器的线程数</li>\n<li>容器的磁盘I&#x2F;O使用率</li>\n<li>容器的网络延迟</li>\n<li>容器的网络吞吐量</li>\n<li>容器的内存压缩率</li>\n<li>容器的内存丢失</li>\n<li>容器的CPU限制与请求</li>\n</ul>\n</li>\n</ol>\n<p>总体来说，Kubelet和cAdvisor提供了丰富的监控指标，可以用于监视节点和容器的资源使用情况、运行状态及性能状况。这些指标对于在Kubernetes集群中管理和优化容器化应用程序的性能和可靠性非常有帮助。</p>\n<h1 id=\"kube-state-metrics\"><a href=\"#kube-state-metrics\" class=\"headerlink\" title=\"kube-state-metrics\"></a>kube-state-metrics</h1><p>kube-state-metrics（KSM）是一个用于将Kubernetes集群的状态信息转换为Prometheus指标的开源项目。它可以提供丰富的监控指标，用于监控Kubernetes集群中的各种资源和对象。以下是Kube-state-metrics提供的一些主要监控指标：</p>\n<ol>\n<li><p>节点指标（Node Metrics）：包括节点的CPU利用率、内存利用率、磁盘空间利用率等信息。</p>\n</li>\n<li><p>Pod指标（Pod Metrics）：包括Pod的CPU利用率、内存利用率、网络流量等信息。</p>\n</li>\n<li><p>命名空间指标（Namespace Metrics）：包括命名空间中的Pod、Replication Controller、Deployment、DaemonSet等资源的数量和状态信息。</p>\n</li>\n<li><p>服务指标（Service Metrics）：包括服务的连接数、请求流量、响应时间等信息。</p>\n</li>\n<li><p>部署指标（Deployment Metrics）：包括部署的副本数量、可用副本数量、滚动更新状态等信息。</p>\n</li>\n<li><p>容器指标（Container Metrics）：包括容器的CPU利用率、内存利用率、文件系统使用情况等信息。</p>\n</li>\n<li><p>StatefulSet指标（StatefulSet Metrics）：包括StatefulSet的副本数量、可用副本数量、当前状态等信息。</p>\n</li>\n<li><p>守护进程指标（DaemonSet Metrics）：包括DaemonSet的副本数量、可用副本数量、当前状态等信息。</p>\n</li>\n<li><p>任务指标（Job Metrics）：包括任务的运行状态、副本数量、成功和失败的次数等信息。</p>\n</li>\n</ol>\n<p>这些指标可以提供关于Kubernetes集群和其中资源的性能、状态和健康状况的详细信息。使用这些指标，可以进行实时监控、性能优化、故障排除和容量规划，以确保集群的稳定性和可靠性。</p>\n<h1 id=\"node-exporter\"><a href=\"#node-exporter\" class=\"headerlink\" title=\"node-exporter\"></a>node-exporter</h1><p>Node Exporter 是一种用于 Prometheus 的开源代理，用于暴露各种系统级监控指标。它可以在 Linux 系统上工作，并提供以下类型的监控指标：</p>\n<ol>\n<li><p>系统指标：包括 CPU 使用率、内存使用率、磁盘使用率、磁盘 I&#x2F;O 情况、网络流量、文件系统使用率等。这些指标可以帮助管理员了解系统的整体状态和资源利用情况。</p>\n</li>\n<li><p>进程指标：可以获取正在运行的进程数、进程CPU和内存使用情况、进程网络连接数等信息。通过这些指标，可以监控和识别系统中资源占用较多的进程，从而及时调整和优化。</p>\n</li>\n<li><p>网络指标：包括网络接口的带宽利用率、传输速率、丢包率和错误率等。这些指标可以帮助了解网络流量情况，监控网络性能和及时发现问题。</p>\n</li>\n<li><p>磁盘指标：包括磁盘使用率、磁盘读写速度、磁盘IO等。这些指标可以帮助监控磁盘的健康状况、数据读写速度和IO性能。</p>\n</li>\n<li><p>内存指标：包括内存使用量、内存交换情况、内存分页等。这些指标可以帮助了解内存的使用情况和性能。</p>\n</li>\n<li><p>CPU 指标：包括 CPU 使用率、CPU 温度、CPU 核心数等。这些指标可以帮助监控系统的负载情况和CPU性能。</p>\n</li>\n<li><p>运行时间指标：包括系统的运行时间以及系统启动后的负载状况。这些指标可以帮助了解系统的稳定性和运行时间。</p>\n</li>\n</ol>\n<p>除了以上列举的指标，Node Exporter 还提供了其他许多监控指标，以及一些自定义指标的扩展方式。用户可以根据需要选择性地监控和收集这些指标，以满足对系统性能和资源利用的需求。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<h1 id=\"kubelet的metrics-cadvisor\"><a href=\"#kubelet的metrics-cadvisor\" class=\"headerlink\" title=\"kubelet的metrics&#x2F;cadvisor\"></a>kubelet的metrics&#x2F;cadvisor</h1><p>Kubelet是Kubernetes主节点的一个核心组件，负责管理节点上的容器，以及与主控平面进行通信。Kubelet通过提供不同的接口和嵌入式组件来收集和暴露节点和容器的监控指标。</p>\n<ol>\n<li><p>Kubelet监控指标：</p>\n<ul>\n<li>Kubelet启动的Pod数目</li>\n<li>Kubelet已经完成的Pod数目</li>\n<li>Kubelet当前正在运行的Pod数目</li>\n<li>Kubelet拒绝启动的Pod数目</li>\n<li>Kubelet处理错误的Pod数目</li>\n<li>Kubelet未知状态的Pod数目</li>\n<li>Kubelet容器运行时间</li>\n<li>Kubelet容器CPU使用率</li>\n<li>Kubelet容器内存使用率</li>\n<li>Kubelet存储设备使用率</li>\n<li>Kubelet网络上行流量</li>\n<li>Kubelet网络下行流量</li>\n<li>Kubelet容器磁盘使用量</li>\n<li>Kubelet容器文件系统使用率</li>\n<li>Kubelet容器日志记录量</li>\n</ul>\n</li>\n<li><p>cAdvisor监控指标：</p>\n<ul>\n<li>容器的CPU使用率</li>\n<li>容器的内存使用率</li>\n<li>容器的磁盘使用率</li>\n<li>容器的网络上行流量</li>\n<li>容器的网络下行流量</li>\n<li>容器的文件系统使用率</li>\n<li>容器的日志记录量</li>\n<li>容器的进程数</li>\n<li>容器的打开文件数</li>\n<li>容器的线程数</li>\n<li>容器的磁盘I&#x2F;O使用率</li>\n<li>容器的网络延迟</li>\n<li>容器的网络吞吐量</li>\n<li>容器的内存压缩率</li>\n<li>容器的内存丢失</li>\n<li>容器的CPU限制与请求</li>\n</ul>\n</li>\n</ol>\n<p>总体来说，Kubelet和cAdvisor提供了丰富的监控指标，可以用于监视节点和容器的资源使用情况、运行状态及性能状况。这些指标对于在Kubernetes集群中管理和优化容器化应用程序的性能和可靠性非常有帮助。</p>\n<h1 id=\"kube-state-metrics\"><a href=\"#kube-state-metrics\" class=\"headerlink\" title=\"kube-state-metrics\"></a>kube-state-metrics</h1><p>kube-state-metrics（KSM）是一个用于将Kubernetes集群的状态信息转换为Prometheus指标的开源项目。它可以提供丰富的监控指标，用于监控Kubernetes集群中的各种资源和对象。以下是Kube-state-metrics提供的一些主要监控指标：</p>\n<ol>\n<li><p>节点指标（Node Metrics）：包括节点的CPU利用率、内存利用率、磁盘空间利用率等信息。</p>\n</li>\n<li><p>Pod指标（Pod Metrics）：包括Pod的CPU利用率、内存利用率、网络流量等信息。</p>\n</li>\n<li><p>命名空间指标（Namespace Metrics）：包括命名空间中的Pod、Replication Controller、Deployment、DaemonSet等资源的数量和状态信息。</p>\n</li>\n<li><p>服务指标（Service Metrics）：包括服务的连接数、请求流量、响应时间等信息。</p>\n</li>\n<li><p>部署指标（Deployment Metrics）：包括部署的副本数量、可用副本数量、滚动更新状态等信息。</p>\n</li>\n<li><p>容器指标（Container Metrics）：包括容器的CPU利用率、内存利用率、文件系统使用情况等信息。</p>\n</li>\n<li><p>StatefulSet指标（StatefulSet Metrics）：包括StatefulSet的副本数量、可用副本数量、当前状态等信息。</p>\n</li>\n<li><p>守护进程指标（DaemonSet Metrics）：包括DaemonSet的副本数量、可用副本数量、当前状态等信息。</p>\n</li>\n<li><p>任务指标（Job Metrics）：包括任务的运行状态、副本数量、成功和失败的次数等信息。</p>\n</li>\n</ol>\n<p>这些指标可以提供关于Kubernetes集群和其中资源的性能、状态和健康状况的详细信息。使用这些指标，可以进行实时监控、性能优化、故障排除和容量规划，以确保集群的稳定性和可靠性。</p>\n<h1 id=\"node-exporter\"><a href=\"#node-exporter\" class=\"headerlink\" title=\"node-exporter\"></a>node-exporter</h1><p>Node Exporter 是一种用于 Prometheus 的开源代理，用于暴露各种系统级监控指标。它可以在 Linux 系统上工作，并提供以下类型的监控指标：</p>\n<ol>\n<li><p>系统指标：包括 CPU 使用率、内存使用率、磁盘使用率、磁盘 I&#x2F;O 情况、网络流量、文件系统使用率等。这些指标可以帮助管理员了解系统的整体状态和资源利用情况。</p>\n</li>\n<li><p>进程指标：可以获取正在运行的进程数、进程CPU和内存使用情况、进程网络连接数等信息。通过这些指标，可以监控和识别系统中资源占用较多的进程，从而及时调整和优化。</p>\n</li>\n<li><p>网络指标：包括网络接口的带宽利用率、传输速率、丢包率和错误率等。这些指标可以帮助了解网络流量情况，监控网络性能和及时发现问题。</p>\n</li>\n<li><p>磁盘指标：包括磁盘使用率、磁盘读写速度、磁盘IO等。这些指标可以帮助监控磁盘的健康状况、数据读写速度和IO性能。</p>\n</li>\n<li><p>内存指标：包括内存使用量、内存交换情况、内存分页等。这些指标可以帮助了解内存的使用情况和性能。</p>\n</li>\n<li><p>CPU 指标：包括 CPU 使用率、CPU 温度、CPU 核心数等。这些指标可以帮助监控系统的负载情况和CPU性能。</p>\n</li>\n<li><p>运行时间指标：包括系统的运行时间以及系统启动后的负载状况。这些指标可以帮助了解系统的稳定性和运行时间。</p>\n</li>\n</ol>\n<p>除了以上列举的指标，Node Exporter 还提供了其他许多监控指标，以及一些自定义指标的扩展方式。用户可以根据需要选择性地监控和收集这些指标，以满足对系统性能和资源利用的需求。</p>\n"},{"title":"install metrics-server","date":"2023-08-25T02:25:58.000Z","_content":"使用kubectl top命名需要安装metrics-server,否则会报错: error: Metrics API not available\n使用如下yaml文件安装metrics-server:\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    k8s-app: metrics-server\n    rbac.authorization.k8s.io/aggregate-to-admin: \"true\"\n    rbac.authorization.k8s.io/aggregate-to-edit: \"true\"\n    rbac.authorization.k8s.io/aggregate-to-view: \"true\"\n  name: system:aggregated-metrics-reader\nrules:\n- apiGroups:\n  - metrics.k8s.io\n  resources:\n  - pods\n  - nodes\n  verbs:\n  - get\n  - list\n  - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: system:metrics-server\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes/metrics\n  verbs:\n  - get\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  - nodes\n  verbs:\n  - get\n  - list\n  - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server-auth-reader\n  namespace: kube-system\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: extension-apiserver-authentication-reader\nsubjects:\n- kind: ServiceAccount\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server:system:auth-delegator\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:auth-delegator\nsubjects:\n- kind: ServiceAccount\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: system:metrics-server\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:metrics-server\nsubjects:\n- kind: ServiceAccount\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server\n  namespace: kube-system\nspec:\n  ports:\n  - name: https\n    port: 443\n    protocol: TCP\n    targetPort: https\n  selector:\n    k8s-app: metrics-server\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: metrics-server\n  strategy:\n    rollingUpdate:\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        k8s-app: metrics-server\n    spec:\n      containers:\n      - args:\n        - --cert-dir=/tmp\n        - --secure-port=4443\n        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\n        - --kubelet-use-node-status-port\n        - --metric-resolution=15s\n        - --kubelet-insecure-tls\n        image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.6.4\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /livez\n            port: https\n            scheme: HTTPS\n          periodSeconds: 10\n        name: metrics-server\n        ports:\n        - containerPort: 4443\n          name: https\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /readyz\n            port: https\n            scheme: HTTPS\n          initialDelaySeconds: 20\n          periodSeconds: 10\n        resources:\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 1000\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-dir\n      nodeSelector:\n        kubernetes.io/os: linux\n      priorityClassName: system-cluster-critical\n      serviceAccountName: metrics-server\n      volumes:\n      - emptyDir: {}\n        name: tmp-dir\n---\napiVersion: apiregistration.k8s.io/v1\nkind: APIService\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: v1beta1.metrics.k8s.io\nspec:\n  group: metrics.k8s.io\n  groupPriorityMinimum: 100\n  insecureSkipTLSVerify: true\n  service:\n    name: metrics-server\n    namespace: kube-system\n  version: v1beta1\n  versionPriority: 100\n```\n\n```shell\nkubectl apply -f metrics-server.yaml\n```","source":"_posts/kubernetes/metrics-server.md","raw":"---\ntitle: install metrics-server\ndate: 2023-08-25 10:25:58\ncategories:\n  - [kubernetes]\ntags: kubernetes\n---\n使用kubectl top命名需要安装metrics-server,否则会报错: error: Metrics API not available\n使用如下yaml文件安装metrics-server:\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    k8s-app: metrics-server\n    rbac.authorization.k8s.io/aggregate-to-admin: \"true\"\n    rbac.authorization.k8s.io/aggregate-to-edit: \"true\"\n    rbac.authorization.k8s.io/aggregate-to-view: \"true\"\n  name: system:aggregated-metrics-reader\nrules:\n- apiGroups:\n  - metrics.k8s.io\n  resources:\n  - pods\n  - nodes\n  verbs:\n  - get\n  - list\n  - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: system:metrics-server\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes/metrics\n  verbs:\n  - get\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  - nodes\n  verbs:\n  - get\n  - list\n  - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server-auth-reader\n  namespace: kube-system\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: extension-apiserver-authentication-reader\nsubjects:\n- kind: ServiceAccount\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server:system:auth-delegator\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:auth-delegator\nsubjects:\n- kind: ServiceAccount\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: system:metrics-server\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:metrics-server\nsubjects:\n- kind: ServiceAccount\n  name: metrics-server\n  namespace: kube-system\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server\n  namespace: kube-system\nspec:\n  ports:\n  - name: https\n    port: 443\n    protocol: TCP\n    targetPort: https\n  selector:\n    k8s-app: metrics-server\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: metrics-server\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: metrics-server\n  strategy:\n    rollingUpdate:\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        k8s-app: metrics-server\n    spec:\n      containers:\n      - args:\n        - --cert-dir=/tmp\n        - --secure-port=4443\n        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\n        - --kubelet-use-node-status-port\n        - --metric-resolution=15s\n        - --kubelet-insecure-tls\n        image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.6.4\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /livez\n            port: https\n            scheme: HTTPS\n          periodSeconds: 10\n        name: metrics-server\n        ports:\n        - containerPort: 4443\n          name: https\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /readyz\n            port: https\n            scheme: HTTPS\n          initialDelaySeconds: 20\n          periodSeconds: 10\n        resources:\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 1000\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp-dir\n      nodeSelector:\n        kubernetes.io/os: linux\n      priorityClassName: system-cluster-critical\n      serviceAccountName: metrics-server\n      volumes:\n      - emptyDir: {}\n        name: tmp-dir\n---\napiVersion: apiregistration.k8s.io/v1\nkind: APIService\nmetadata:\n  labels:\n    k8s-app: metrics-server\n  name: v1beta1.metrics.k8s.io\nspec:\n  group: metrics.k8s.io\n  groupPriorityMinimum: 100\n  insecureSkipTLSVerify: true\n  service:\n    name: metrics-server\n    namespace: kube-system\n  version: v1beta1\n  versionPriority: 100\n```\n\n```shell\nkubectl apply -f metrics-server.yaml\n```","slug":"kubernetes/metrics-server","published":1,"updated":"2023-08-25T02:33:13.160Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0cb0015fmjxcmni16wm","content":"<p>使用kubectl top命名需要安装metrics-server,否则会报错: error: Metrics API not available<br>使用如下yaml文件安装metrics-server:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">    <span class=\"attr\">rbac.authorization.k8s.io/aggregate-to-admin:</span> <span class=\"string\">&quot;true&quot;</span></span><br><span class=\"line\">    <span class=\"attr\">rbac.authorization.k8s.io/aggregate-to-edit:</span> <span class=\"string\">&quot;true&quot;</span></span><br><span class=\"line\">    <span class=\"attr\">rbac.authorization.k8s.io/aggregate-to-view:</span> <span class=\"string\">&quot;true&quot;</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:aggregated-metrics-reader</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">metrics.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">resources:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">pods</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">nodes</span></span><br><span class=\"line\">  <span class=\"attr\">verbs:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">get</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">list</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">watch</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:metrics-server</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">  <span class=\"attr\">resources:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">nodes/metrics</span></span><br><span class=\"line\">  <span class=\"attr\">verbs:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">get</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">  <span class=\"attr\">resources:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">pods</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">nodes</span></span><br><span class=\"line\">  <span class=\"attr\">verbs:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">get</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">list</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">watch</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">RoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server-auth-reader</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">Role</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">extension-apiserver-authentication-reader</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server:system:auth-delegator</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:auth-delegator</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:metrics-server</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:metrics-server</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">ports:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">https</span></span><br><span class=\"line\">    <span class=\"attr\">port:</span> <span class=\"number\">443</span></span><br><span class=\"line\">    <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">    <span class=\"attr\">targetPort:</span> <span class=\"string\">https</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">strategy:</span></span><br><span class=\"line\">    <span class=\"attr\">rollingUpdate:</span></span><br><span class=\"line\">      <span class=\"attr\">maxUnavailable:</span> <span class=\"number\">0</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">args:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--cert-dir=/tmp</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--secure-port=4443</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--kubelet-use-node-status-port</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--metric-resolution=15s</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--kubelet-insecure-tls</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.6.4</span></span><br><span class=\"line\">        <span class=\"attr\">imagePullPolicy:</span> <span class=\"string\">IfNotPresent</span></span><br><span class=\"line\">        <span class=\"attr\">livenessProbe:</span></span><br><span class=\"line\">          <span class=\"attr\">failureThreshold:</span> <span class=\"number\">3</span></span><br><span class=\"line\">          <span class=\"attr\">httpGet:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/livez</span></span><br><span class=\"line\">            <span class=\"attr\">port:</span> <span class=\"string\">https</span></span><br><span class=\"line\">            <span class=\"attr\">scheme:</span> <span class=\"string\">HTTPS</span></span><br><span class=\"line\">          <span class=\"attr\">periodSeconds:</span> <span class=\"number\">10</span></span><br><span class=\"line\">        <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">4443</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span> <span class=\"string\">https</span></span><br><span class=\"line\">          <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">        <span class=\"attr\">readinessProbe:</span></span><br><span class=\"line\">          <span class=\"attr\">failureThreshold:</span> <span class=\"number\">3</span></span><br><span class=\"line\">          <span class=\"attr\">httpGet:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/readyz</span></span><br><span class=\"line\">            <span class=\"attr\">port:</span> <span class=\"string\">https</span></span><br><span class=\"line\">            <span class=\"attr\">scheme:</span> <span class=\"string\">HTTPS</span></span><br><span class=\"line\">          <span class=\"attr\">initialDelaySeconds:</span> <span class=\"number\">20</span></span><br><span class=\"line\">          <span class=\"attr\">periodSeconds:</span> <span class=\"number\">10</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"string\">100m</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">200Mi</span></span><br><span class=\"line\">        <span class=\"attr\">securityContext:</span></span><br><span class=\"line\">          <span class=\"attr\">allowPrivilegeEscalation:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">          <span class=\"attr\">readOnlyRootFilesystem:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">          <span class=\"attr\">runAsNonRoot:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">          <span class=\"attr\">runAsUser:</span> <span class=\"number\">1000</span></span><br><span class=\"line\">        <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">mountPath:</span> <span class=\"string\">/tmp</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span> <span class=\"string\">tmp-dir</span></span><br><span class=\"line\">      <span class=\"attr\">nodeSelector:</span></span><br><span class=\"line\">        <span class=\"attr\">kubernetes.io/os:</span> <span class=\"string\">linux</span></span><br><span class=\"line\">      <span class=\"attr\">priorityClassName:</span> <span class=\"string\">system-cluster-critical</span></span><br><span class=\"line\">      <span class=\"attr\">serviceAccountName:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">      <span class=\"attr\">volumes:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">emptyDir:</span> &#123;&#125;</span><br><span class=\"line\">        <span class=\"attr\">name:</span> <span class=\"string\">tmp-dir</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apiregistration.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">APIService</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">v1beta1.metrics.k8s.io</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">group:</span> <span class=\"string\">metrics.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">groupPriorityMinimum:</span> <span class=\"number\">100</span></span><br><span class=\"line\">  <span class=\"attr\">insecureSkipTLSVerify:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">service:</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">    <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\">  <span class=\"attr\">version:</span> <span class=\"string\">v1beta1</span></span><br><span class=\"line\">  <span class=\"attr\">versionPriority:</span> <span class=\"number\">100</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f metrics-server.yaml</span><br></pre></td></tr></table></figure>","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>使用kubectl top命名需要安装metrics-server,否则会报错: error: Metrics API not available<br>使用如下yaml文件安装metrics-server:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">    <span class=\"attr\">rbac.authorization.k8s.io/aggregate-to-admin:</span> <span class=\"string\">&quot;true&quot;</span></span><br><span class=\"line\">    <span class=\"attr\">rbac.authorization.k8s.io/aggregate-to-edit:</span> <span class=\"string\">&quot;true&quot;</span></span><br><span class=\"line\">    <span class=\"attr\">rbac.authorization.k8s.io/aggregate-to-view:</span> <span class=\"string\">&quot;true&quot;</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:aggregated-metrics-reader</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">metrics.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">resources:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">pods</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">nodes</span></span><br><span class=\"line\">  <span class=\"attr\">verbs:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">get</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">list</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">watch</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:metrics-server</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">  <span class=\"attr\">resources:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">nodes/metrics</span></span><br><span class=\"line\">  <span class=\"attr\">verbs:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">get</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">  <span class=\"attr\">resources:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">pods</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">nodes</span></span><br><span class=\"line\">  <span class=\"attr\">verbs:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">get</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">list</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">watch</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">RoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server-auth-reader</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">Role</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">extension-apiserver-authentication-reader</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server:system:auth-delegator</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:auth-delegator</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:metrics-server</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:metrics-server</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">ports:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">https</span></span><br><span class=\"line\">    <span class=\"attr\">port:</span> <span class=\"number\">443</span></span><br><span class=\"line\">    <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">    <span class=\"attr\">targetPort:</span> <span class=\"string\">https</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">strategy:</span></span><br><span class=\"line\">    <span class=\"attr\">rollingUpdate:</span></span><br><span class=\"line\">      <span class=\"attr\">maxUnavailable:</span> <span class=\"number\">0</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">args:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--cert-dir=/tmp</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--secure-port=4443</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--kubelet-use-node-status-port</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--metric-resolution=15s</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--kubelet-insecure-tls</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.6.4</span></span><br><span class=\"line\">        <span class=\"attr\">imagePullPolicy:</span> <span class=\"string\">IfNotPresent</span></span><br><span class=\"line\">        <span class=\"attr\">livenessProbe:</span></span><br><span class=\"line\">          <span class=\"attr\">failureThreshold:</span> <span class=\"number\">3</span></span><br><span class=\"line\">          <span class=\"attr\">httpGet:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/livez</span></span><br><span class=\"line\">            <span class=\"attr\">port:</span> <span class=\"string\">https</span></span><br><span class=\"line\">            <span class=\"attr\">scheme:</span> <span class=\"string\">HTTPS</span></span><br><span class=\"line\">          <span class=\"attr\">periodSeconds:</span> <span class=\"number\">10</span></span><br><span class=\"line\">        <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">4443</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span> <span class=\"string\">https</span></span><br><span class=\"line\">          <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">        <span class=\"attr\">readinessProbe:</span></span><br><span class=\"line\">          <span class=\"attr\">failureThreshold:</span> <span class=\"number\">3</span></span><br><span class=\"line\">          <span class=\"attr\">httpGet:</span></span><br><span class=\"line\">            <span class=\"attr\">path:</span> <span class=\"string\">/readyz</span></span><br><span class=\"line\">            <span class=\"attr\">port:</span> <span class=\"string\">https</span></span><br><span class=\"line\">            <span class=\"attr\">scheme:</span> <span class=\"string\">HTTPS</span></span><br><span class=\"line\">          <span class=\"attr\">initialDelaySeconds:</span> <span class=\"number\">20</span></span><br><span class=\"line\">          <span class=\"attr\">periodSeconds:</span> <span class=\"number\">10</span></span><br><span class=\"line\">        <span class=\"attr\">resources:</span></span><br><span class=\"line\">          <span class=\"attr\">requests:</span></span><br><span class=\"line\">            <span class=\"attr\">cpu:</span> <span class=\"string\">100m</span></span><br><span class=\"line\">            <span class=\"attr\">memory:</span> <span class=\"string\">200Mi</span></span><br><span class=\"line\">        <span class=\"attr\">securityContext:</span></span><br><span class=\"line\">          <span class=\"attr\">allowPrivilegeEscalation:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">          <span class=\"attr\">readOnlyRootFilesystem:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">          <span class=\"attr\">runAsNonRoot:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">          <span class=\"attr\">runAsUser:</span> <span class=\"number\">1000</span></span><br><span class=\"line\">        <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">mountPath:</span> <span class=\"string\">/tmp</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span> <span class=\"string\">tmp-dir</span></span><br><span class=\"line\">      <span class=\"attr\">nodeSelector:</span></span><br><span class=\"line\">        <span class=\"attr\">kubernetes.io/os:</span> <span class=\"string\">linux</span></span><br><span class=\"line\">      <span class=\"attr\">priorityClassName:</span> <span class=\"string\">system-cluster-critical</span></span><br><span class=\"line\">      <span class=\"attr\">serviceAccountName:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">      <span class=\"attr\">volumes:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">emptyDir:</span> &#123;&#125;</span><br><span class=\"line\">        <span class=\"attr\">name:</span> <span class=\"string\">tmp-dir</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apiregistration.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">APIService</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">k8s-app:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">v1beta1.metrics.k8s.io</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">group:</span> <span class=\"string\">metrics.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">groupPriorityMinimum:</span> <span class=\"number\">100</span></span><br><span class=\"line\">  <span class=\"attr\">insecureSkipTLSVerify:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">service:</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">metrics-server</span></span><br><span class=\"line\">    <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\">  <span class=\"attr\">version:</span> <span class=\"string\">v1beta1</span></span><br><span class=\"line\">  <span class=\"attr\">versionPriority:</span> <span class=\"number\">100</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f metrics-server.yaml</span><br></pre></td></tr></table></figure>"},{"title":"PromQL全解析","date":"2023-11-09T02:15:00.000Z","_content":"PromQL（Prometheus Query Language）为Prometheus tsdb的查询语言。是结合grafana进行数据展示和告警规则的配置的关键部分。\n本文默认您已了解Prometheus的四种指标类型：\n* counter（计数器）\n* gauge （仪表类型）\n* histogram（直方图类型）\n* summary （摘要类型）\n便于读者实践，本文大部分样本数据target：\n* Prometheus\n* node_exporter\n\n## 表达式数据类型\nPromQL查询语句即表达式，实现的四种数据类型：\n### Instant vector\nInstance vector（瞬时向量）表示一个时间序列的集合，但是每个时序只有最近的一个点，而不是线。\n![Alt text](image-132.png)\n### Range vector\nRange vector（范围向量）表示一段时间范围里的时序，每个时序可包含多个点\n![Alt text](image-133.png)\nsources：[Understanding Prometheus Range Vectors](https://satyanash.net/software/2021/01/04/understanding-prometheus-range-vectors.html)\n### Scalar\nScalar（标量）通常为数值，可以将只有一个时序的Instance vector转换成Scalar。\n### String\n简单字符串值，目前未被使用。\n## 选择器\n### 标签选择器\n查询Prometheus http状态码为400的请求数量。\n```\nprometheus_http_requests_total{code=\"400\"}\n```\n标签匹配运算符:\n\n* = ：与字符串匹配\n* != ：与字符串不匹配\n* =~ ：与正则匹配\n* !~ ：与正则不匹配\n\n查询Prometheus http状态码为4xx或5xx并且handler为/api/v1/query的请求数量\n```\nprometheus_http_requests_total{code=~\"4.*|5.*\",handler=\"/api/v1/query\"}\n```\n\n内部标签__name__用来匹配指标名称，下面的表达式与上一条等价\n```\n{code=~\"4.*|5.*\",handler=\"/api/v1/query\",__name__=\"prometheus_http_requests_total\"}\n```\n### 范围选择器\n\n查询过去5分钟Prometheus健康检查的采样记录。\n```\nprometheus_http_requests_total{code=\"200\",handler=\"/-/healthy\"}[5m]\n```\n单位：ms、s、m、h、d、w、y\n\n时间串联：[1h5m]一小时5分钟\n\n## 时间偏移\n### 通过offset\n\n通过offset将时间倒退5分钟，即查询5分钟之前的数据。\n```\nprometheus_http_requests_total{code=\"200\"} offset 5m \n```\n同样支持查询range vector\n```\nprometheus_http_requests_total{code=\"200\"}[3m] offset 5m\n```\n### @修饰符\n还可以通过@ 直接跳转到某个uinx时间戳，需开启启动参数--enable-feature=promql-at-modifier\n```\nprometheus_http_requests_total{code=\"200\"} @ 1646089826\n```\n## 运算符\nPrometheus中的运算符与各类编程语言中的基本一致。\n### 数学运算符\nPrometheus 中存在以下数学运算符：\n\n* +（加法）\n* -（减法）\n* *（乘法）\n* /（除法）\n* %（取模）\n* ^（幂）\n两个标量之间的计算\n```\n10/3\n```\n瞬时向量与标量计算，由于计算后值意义与原指标名有差异，Prometheus很贴心的帮我们移除了指标名称。\n```\nprometheus_http_response_size_bytes_sum / 1024\n```\n两个瞬时向量间的计算，如下计算node的内存使用率\n```\n(\n1 -\nnode_memory_MemAvailable_bytes{job=\"node\",instance=\"localhost:9100\"} \n/ node_memory_MemTotal_bytes{job=\"node\",instance=\"localhost:9100\"}\n)\n* 100\n```\n如果两个瞬时向量标签不一致可通过ignoring忽略多余标签\n输入示例：\n```\nmethod_code:http_errors:rate5m{method=\"get\", code=\"500\"}  24\nmethod_code:http_errors:rate5m{method=\"post\", code=\"500\"} 6\n\nmethod:http_requests:rate5m{method=\"get\"}  600\nmethod:http_requests:rate5m{method=\"post\"} 120\n```\n查询示例：\n```\nmethod_code:http_errors:rate5m{code=\"500\"} / ignoring(code) method:http_requests:rate5m\n```\n结果示例：\n```\n{method=\"get\"}  0.04            //  24 / 600\n{method=\"post\"} 0.05            //   6 / 120\n```\n如果两个瞬时向量数量不一致时可通过group_left、group_right指定以那一侧为准\n输入示例：\n```\nmethod_code:http_errors:rate5m{method=\"get\", code=\"500\"}  24\nmethod_code:http_errors:rate5m{method=\"get\", code=\"404\"}  30\nmethod_code:http_errors:rate5m{method=\"put\", code=\"501\"}  3\nmethod_code:http_errors:rate5m{method=\"post\", code=\"500\"} 6\nmethod_code:http_errors:rate5m{method=\"post\", code=\"404\"} 21\n\nmethod:http_requests:rate5m{method=\"get\"}  600\nmethod:http_requests:rate5m{method=\"del\"}  34\nmethod:http_requests:rate5m{method=\"post\"} 120\n```\n查询示例：\n\ngroup_left以左侧为准\n```\nmethod_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m\n```\n结果示例：\n```\n{method=\"get\", code=\"500\"}  0.04            //  24 / 600\n{method=\"get\", code=\"404\"}  0.05            //  30 / 600\n{method=\"post\", code=\"500\"} 0.05            //   6 / 120\n{method=\"post\", code=\"404\"} 0.175           //  21 / 120\n```\n\n### 比较运算符\n\nPrometheus 中存在以下比较运算符：\n\n* ==（相等）\n* !=（不相等）\n* \\>（大于）\n* <（小于）\n* \\>=（大于或等于）\n* <=（小于或等于）\n\n两个标量之间比较，在运算符后跟bool修饰，结果0( false) 或1 ( true)\n```\n10 < bool 5\n```\n![Alt text](image-134.png)\n瞬时向量与标量比较，查询node状态\n```\nup{job=\"node\"} ==  bool 1\n```\n两个瞬时向量比较，查看消息队列容量状态\n```\nprometheus_notifications_queue_length < bool prometheus_notifications_queue_capacity\n```\n![Alt text](image-135.png)\n### 逻辑运算符\n\nPrometheus 中存在以下逻辑运算符：\n\n* and（与）\n* or（或）\n* unless（非）\n  \n逻辑运算仅适用于向量\n\n如下我们有4个target，进行相应的逻辑运算，实现和标签选择相似效果。\n![Alt text](image-136.png)\n```\nup{instance!=\"192.168.1.123:9091\"} and up{job!=\"alertmanager\"}\n```\n![Alt text](image-137.png)\n```\nup{instance=\"192.168.1.123:9091\"} or up{job=\"alertmanager\"} \n```\n![Alt text](image-138.png)\n```\nup unless up{job=\"alertmanager\"} \n```\n![Alt text](image-139.png)\nPrometheus 中二元运算符的优先级，从高到低。\n\n1. ^\n2. *, /, %,atan2\n3. +,-\n4. ==, !=, <=, <, >=,>\n5. and,unless\n6. or\n\n\n相同优先级的运算符是左结合的\n相同优先级的运算符（+ 和 -）是左结合的。这意味着在表达式中，加法和减法运算将按照从左到右的顺序进行。\n\n例如，考虑以下PromQL表达式：\n```\na + b - c\n```\n在这个表达式中，加法运算符（+）和减法运算符（-）具有相同的优先级。根据左结合的规则，这个表达式将首先执行加法运算，然后再执行减法运算。换句话说，计算顺序将是先计算\"a + b\"，然后将结果与\"c\"相减。\n\nPromQL中的atan2函数用于计算两个数值的反正切值。它接受两个参数，并返回一个介于-π/2和π/2之间的值，表示从原点到点(y, x)的角度。\n\n具体来说，atan2(y, x)返回的角度是满足以下条件的唯一角度θ：\n\nθ在-π/2和π/2之间；\n点(x, y)位于以原点为圆心、半径为1的圆上；\n点(x, y)与极坐标中的点(1, θ)对应。\n与atan函数不同的是，atan2考虑了y和x的值之间的比例关系，因此能够更准确地描述角度的变化。在处理二维空间中的角度计算时，atan2函数通常比atan函数更常用。\n\n以下是一个PromQL中使用atan2函数的示例：\n\n```\nsum(rate(vector_field[1m])) * 100 / atan2(1, 1)\n```\n这个示例中，使用rate函数计算了一个名为vector_field的时间序列的1分钟平均值，并将其乘以100。然后，通过使用atan2函数将结果除以1和1之间的反正切值，得到一个归一化的结果。\n### 聚合运算符\nPrometheus 支持以下内置聚合运算符，可用于聚合单个瞬时向量，生成新的向量：\n\n* sum（总和）\n* min（最小）\n* max（最大）\n* avg（平均值）\n* group（分组）\n* stddev（标准偏差）\n* stdvar（标准方差）\n* count（计算向量中的元素个数）\n* count_values（计算具有相同值的元素个数）\n* bottomk（样本值的最小 k 个元素）\n* topk（按样本值计算的最大 k 个元素）\n* quantile（分位数计算 φ-quantile (0 ≤ φ ≤ 1)\n\n\n聚合运算符可通过 without、by 根据标签扩展\n\nsum、min、max、avg：\n\n计算http请求的总和，最大、最小请求的url的数量，平均数量\n```\nsum(prometheus_http_requests_total)\n```\n![Alt text](image-140.png)\n通过状态码分别统计\n![Alt text](image-141.png)\ngroup:\n\n类uniq的用法\n![Alt text](image-142.png)\n\nstddev、stdvar：\n\n反映一组数据离散程度，用以衡量数据值偏离算术平均值的程度。标准偏差为方差的开平方，标准偏差越小，这些值偏离平均值就越少，反之亦然。\n\n通过标准差来反映网络波动\n```\nstddev(rate(node_network_transmit_bytes_total[5m]))\n```\nrate计算某段时间的速率\n![Alt text](image-143.png)\ncount、count_values:\n\n统计总共有几个时序\n```\ncount(prometheus_http_requests_total)\n```\n![Alt text](image-144.png)\n计算每个value的数量\n```\ncount_values(\"value\",prometheus_http_requests_total)\n```\n![Alt text](image-145.png)\n\nbottomk、topk\n\n计算value中最小的5个时序\n```\nbottomk(5,prometheus_http_requests_total)\n```\n![Alt text](image-146.png)\n\nquantile:求数据的分位数\n\n我们现在要找出K8s集群中所有node节点的内存使用率的分布情况:\n```\nquantile\n(0.8,\n(\n1 -\nnode_memory_MemAvailable_bytes{job=\"kubernetes-service-endpoints\"} \n/ node_memory_MemTotal_bytes{job=\"kubernetes-service-endpoints\"}\n)\n* 100\n)\n```\n![Alt text](image-147.png)\n\n直接可以看出80%的节点内存使用率在68%以下\n\n## 函数\n### 值取整\n#### ceil()\nceil(v instant-vector)样本数据向上取整。\n```\nceil(node_load1)  #1.2-->2\n```\n#### floor()\nfloor(v instant-vector)与ceil()相反，floor()样本值向下取整。\n#### round()\nround(v instant-vector, to_nearest=1 scalar) 对样本值四舍五入取整。to_nearest参数是可选的,默认为 1,表示样本返回的是最接近 1 的整数倍的值，参数可以为分数。\n\n取整\n```\nround(prometheus_engine_query_duration_seconds_sum)\n```\n取整到最近的5的倍数\n```\nround(prometheus_engine_query_duration_seconds_sum,5)\n```\n### 值截取\n#### clamp()\n\nclamp(v instant-vector, min scalar, max scalar) 截取所有元素的样本值在 [min,max]集合内的样本,如果min>max返回NaN\n\n放回样本值在10到20的样本\n```\nclamp(prometheus_http_requests_total,10,20)\n```\n#### clamp_max()\n\nclamp_max(v instant-vector, max scalar) 同clamp()，不过只限定样本最大值\n\n#### clamp_min()\n\nclamp_min(v instant-vector, min scalar) 同clamp()，不过只限定样本最小值\n### 值变化统计\n#### changes()\n\nchanges(v range-vector)返回某段时间内样本值改变的次数\n```\nchanges(node_load1[1m])\n```\n### 复位统计\n#### resets()\n\nresets(v range-vector) 返回样本范围时间内的复位次数。与counter使用，两个连续样本之间值如有减少则被视为计数器复位。\n\n查看上下文交换次数计数器在5分钟内复位次数\n```\nresets(node_context_switches_total[5m])\n```\n### 日期与时间管理\n#### day_of_month()\n\nday_of_month(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份中的日期（1-31）\n\nv=vector(time()) 为默认参数\n```\nday_of_month(node_boot_time_seconds)\n```\n#### day_of_week()\n\nday_of_week(v=vector(time()) instant-vector)同上，如果样本值是utc时间，则返回这个时间所属星期几（0-6）\n\n#### days_in_month()\n\ndays_in_month(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份的天数（28-31）\n\n#### hour()\n\nhour(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属一天中的第几个小时（1-13）\n\n#### minute()\n\nminute(v=vector(time()) instant-vector) 如果样本值是utc时间，则返回这个时间所属小时中的第几分钟（1-59）\n\n#### month()\n\nmonth(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的月份（1-12）\n\n#### year()\n\nyear(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的年份\n\n#### time()\n\n返回自1970 年 1 月 1 日 UTC 以来的秒数，不是系统时间，而是表达式计算时那一刻的时间。\n\n#### timestamp()\n\ntimestamp(v instant-vector)返回每个样本值的时间戳，自 1970 年 1 月 1 日 UTC 以来的秒数。\n\n### 直方图分位数\n#### histogram_quantile()\n\nhistogram_quantile(φ float, b instant-vector) 从 bucket 类型的向量 b 中计算 φ (0 ≤ φ ≤ 1) 分位数的样本的最大值，与聚合运算符quantile相似。\n\n计算80%请求的持续时间最大值。\n```\nhistogram_quantile(0.8,rate(prometheus_http_request_duration_seconds_bucket[1d]))\n```\n### 差异与增长率\n#### delta()\n\ndelta(v range-vector)计算范围向量中每个时间序列元素的第一个值和最后一个值之间的差。与指标类型gauge一起使用\n\n计算一天内内存可用量的变化\n\ndelta(node_memory_MemAvailable_bytes[1d])\n#### idelta()\n\nidelta(v range-vector)计算范围向量中最后两个样本之间的差异。与指标类型gauge一起使用\n\nidelta(node_memory_MemAvailable_bytes[1m])\n#### increase()\n\nincrease(v range-vector) 计算时间范围内的增量，与counter一起使用。它是速率rate(v)乘以时间范围内秒数的语法糖，主要用于人类可读性。\n\n计算10分钟内请求增长量\n```\nincrease(prometheus_http_requests_total[10m])\n```\n#### rate()\n\nrate(v range-vector)计算范围向量中时间序列的平均每秒增长率。\n\n过去10分钟请求平均每秒增长率，与counter一起使用。\n```\nrate(prometheus_http_requests_total[10m])\n```\n#### irate()\n\nirate(v range-vector) 通过时间范围的最后两个点来计算每秒瞬时增长率。\n```\nirate(prometheus_http_requests_total[10m])\n```\n### label管理\n#### label_join()\n\nlabel_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, ...)为每个时间序列添加一个label，值为指定旧label的value连接\n```\nlabel_join(up{instance=\"localhost:9100\", job=\"node\"},\"new_label\",\"-\",\"instance\",\"job\")\n```\n结果：\n```\nup{instance=\"localhost:9100\", job=\"node\", new_label=\"localhost:9100-node\"}   1\n```\n#### label_replace()\n\nlabel_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string)从源label中获取value元素用于添加新的label\n\n$1 获取正则匹配，匹配值添加到hello标签中\n```\nlabel_replace(up{instance=\"localhost:9100\", job=\"node\"},\"hello\",\"$1\",\"job\",\"(.*)\")\n```\n结果：\n```\nup{hello=\"node\", instance=\"localhost:9100\", job=\"node\"}       1\n```\n\n### 预测\n#### predict_linear()\n\npredict_linear(v range-vector, t scalar) 通过简单线性回归预测t秒后的样本值，与gauge一起使用。\n\n根据过去1小时的文件系统剩余空间量，预测1小时之后的剩余空间\n```\npredict_linear(node_filesystem_free_bytes[1h],3600)\n```\n### 转换\n#### absent()\n\nabsent(v instant-vector)如果向量有元素，则返回一个空向量；如果向量没有元素，则返回值为 1。\n\n设置如下告警表达式：\n```\nabsent(up{job=\"node\"} == 1)\n```\n由于up{job=\"node\"}不存在或值不为1则告警表达式的值为1 产生告警\n\n#### absent_over_time()\n\nabsent_over_time(v range-vector)如果范围向量有元素，则返回一个空向量；如果范围向量没有元素，则返回值为 1。\n\n如果up{job=\"node1\"}在某段时间不存在则返回1\n```\nabsent_over_time(up{job=\"node1\"}[1h])\n```\n#### scalar()\n\nscalar(v instant-vector)以标量形式返回该单元素的样本值,如果输入向量不是正好一个元素，scalar将返回NaN.\n\n#### vector()\n\nvector(s scalar)将标量作为没有标签的向量返回。\n\n#### sgn()\n\nsgn(v instant-vector)返回一个向量，其中所有样本值都转换为1或-1或0\n\n定义如下：\n\n如果 v 为正，则为 1\n\n如果 v 为负，则为 -1\n\n如果 v 等于 0，则为 0。\n\n### 排序\n#### sort()\n\nsort(v instant-vector)返回按样本值升序排序的向量元素。\n\n#### sort_desc()\n\n与sort()相反，按降序排序。\n\n#### _over_time()\n下面的函数列表允许传入一个范围向量，返回一个带有聚合的瞬时向量：\n\n* avg_over_time(range-vector): 区间向量内每个度量指标的平均值。\n* min_over_time(range-vector): 区间向量内每个度量指标的最小值。\n* max_over_time(range-vector): 区间向量内每个度量指标的最大值。\n* sum_over_time(range-vector): 区间向量内每个度量指标的求和值。\n* count_over_time(range-vector): 区间向量内每个度量指标的样本数据个数。\n* quantile_over_time(scalar, range-vector): 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)\n* stddev_over_time(range-vector): 区间向量内每个度量指标的总体标准偏差。\n* stdvar_over_time(range-vector): 区间向量内每个度量指标的总体标准方差\n\n### 数学函数\n#### abs()\n\nabs(v instant-vector)返回样本的绝对值。\n\n#### sqrt()\n\nsqrt(v instant-vector)计算样本值的平方根。\n\n#### deriv()\n\nderiv(v range-vector) 使用简单线性回归计算时间序列在范围向量中的每秒导数。与指标类型gauge一起使用\n\n#### exp()\n\nexp(v instant-vector)计算样本值的指数函数。\n\n特殊情况：\n\n* Exp(+Inf) = +Inf\n* Exp(NaN) = NaN\n#### ln()、log2()、log10()\n\nln/log2/log10(v instant-vector) 计算样本值对数\n\n特殊情况（同适用于log2/log10）：\n\n* ln(+Inf) = +Inf\n* ln(0) = -Inf\n* ln(x < 0) = NaN\n* ln(NaN) = NaN\n\n\n#### holt_winters()\n\nholt_winters(v range-vector, sf scalar, tf scalar)基于访问向量v，生成时间序列数据平滑数据值。平滑因子sf越低, 对旧数据越重要。趋势因子tf越高，更关心趋势数据。0<sf,tf<=1。 与gauge一起使用\n\n### 三角函数、弧度\n\n* acos(v instant-vector)\n* acosh(v instant-vector)\n* asin(v instant-vector)\n* asinh(v instant-vector)\n* atan(v instant-vector)\n* atanh(v instant-vector)\n* cos(v instant-vector)\n* cosh(v instant-vector)\n* sin(v instant-vector)\n* sinh(v instant-vector)\n* tan(v instant-vector)\n* tanh(v instant-vector)\n\n### 角度、弧度转化\n\n* deg(v instant-vector)\n* pi()\n* rad(v instant-vector)\n\n原文地址: https://zhuanlan.zhihu.com/p/477177336","source":"_posts/kubernetes/promql.md","raw":"---\ntitle: PromQL全解析\ndate: 2023-11-09 10:15:00\ncategories:\n  - [kubernetes]\ntags: PromQL\n---\nPromQL（Prometheus Query Language）为Prometheus tsdb的查询语言。是结合grafana进行数据展示和告警规则的配置的关键部分。\n本文默认您已了解Prometheus的四种指标类型：\n* counter（计数器）\n* gauge （仪表类型）\n* histogram（直方图类型）\n* summary （摘要类型）\n便于读者实践，本文大部分样本数据target：\n* Prometheus\n* node_exporter\n\n## 表达式数据类型\nPromQL查询语句即表达式，实现的四种数据类型：\n### Instant vector\nInstance vector（瞬时向量）表示一个时间序列的集合，但是每个时序只有最近的一个点，而不是线。\n![Alt text](image-132.png)\n### Range vector\nRange vector（范围向量）表示一段时间范围里的时序，每个时序可包含多个点\n![Alt text](image-133.png)\nsources：[Understanding Prometheus Range Vectors](https://satyanash.net/software/2021/01/04/understanding-prometheus-range-vectors.html)\n### Scalar\nScalar（标量）通常为数值，可以将只有一个时序的Instance vector转换成Scalar。\n### String\n简单字符串值，目前未被使用。\n## 选择器\n### 标签选择器\n查询Prometheus http状态码为400的请求数量。\n```\nprometheus_http_requests_total{code=\"400\"}\n```\n标签匹配运算符:\n\n* = ：与字符串匹配\n* != ：与字符串不匹配\n* =~ ：与正则匹配\n* !~ ：与正则不匹配\n\n查询Prometheus http状态码为4xx或5xx并且handler为/api/v1/query的请求数量\n```\nprometheus_http_requests_total{code=~\"4.*|5.*\",handler=\"/api/v1/query\"}\n```\n\n内部标签__name__用来匹配指标名称，下面的表达式与上一条等价\n```\n{code=~\"4.*|5.*\",handler=\"/api/v1/query\",__name__=\"prometheus_http_requests_total\"}\n```\n### 范围选择器\n\n查询过去5分钟Prometheus健康检查的采样记录。\n```\nprometheus_http_requests_total{code=\"200\",handler=\"/-/healthy\"}[5m]\n```\n单位：ms、s、m、h、d、w、y\n\n时间串联：[1h5m]一小时5分钟\n\n## 时间偏移\n### 通过offset\n\n通过offset将时间倒退5分钟，即查询5分钟之前的数据。\n```\nprometheus_http_requests_total{code=\"200\"} offset 5m \n```\n同样支持查询range vector\n```\nprometheus_http_requests_total{code=\"200\"}[3m] offset 5m\n```\n### @修饰符\n还可以通过@ 直接跳转到某个uinx时间戳，需开启启动参数--enable-feature=promql-at-modifier\n```\nprometheus_http_requests_total{code=\"200\"} @ 1646089826\n```\n## 运算符\nPrometheus中的运算符与各类编程语言中的基本一致。\n### 数学运算符\nPrometheus 中存在以下数学运算符：\n\n* +（加法）\n* -（减法）\n* *（乘法）\n* /（除法）\n* %（取模）\n* ^（幂）\n两个标量之间的计算\n```\n10/3\n```\n瞬时向量与标量计算，由于计算后值意义与原指标名有差异，Prometheus很贴心的帮我们移除了指标名称。\n```\nprometheus_http_response_size_bytes_sum / 1024\n```\n两个瞬时向量间的计算，如下计算node的内存使用率\n```\n(\n1 -\nnode_memory_MemAvailable_bytes{job=\"node\",instance=\"localhost:9100\"} \n/ node_memory_MemTotal_bytes{job=\"node\",instance=\"localhost:9100\"}\n)\n* 100\n```\n如果两个瞬时向量标签不一致可通过ignoring忽略多余标签\n输入示例：\n```\nmethod_code:http_errors:rate5m{method=\"get\", code=\"500\"}  24\nmethod_code:http_errors:rate5m{method=\"post\", code=\"500\"} 6\n\nmethod:http_requests:rate5m{method=\"get\"}  600\nmethod:http_requests:rate5m{method=\"post\"} 120\n```\n查询示例：\n```\nmethod_code:http_errors:rate5m{code=\"500\"} / ignoring(code) method:http_requests:rate5m\n```\n结果示例：\n```\n{method=\"get\"}  0.04            //  24 / 600\n{method=\"post\"} 0.05            //   6 / 120\n```\n如果两个瞬时向量数量不一致时可通过group_left、group_right指定以那一侧为准\n输入示例：\n```\nmethod_code:http_errors:rate5m{method=\"get\", code=\"500\"}  24\nmethod_code:http_errors:rate5m{method=\"get\", code=\"404\"}  30\nmethod_code:http_errors:rate5m{method=\"put\", code=\"501\"}  3\nmethod_code:http_errors:rate5m{method=\"post\", code=\"500\"} 6\nmethod_code:http_errors:rate5m{method=\"post\", code=\"404\"} 21\n\nmethod:http_requests:rate5m{method=\"get\"}  600\nmethod:http_requests:rate5m{method=\"del\"}  34\nmethod:http_requests:rate5m{method=\"post\"} 120\n```\n查询示例：\n\ngroup_left以左侧为准\n```\nmethod_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m\n```\n结果示例：\n```\n{method=\"get\", code=\"500\"}  0.04            //  24 / 600\n{method=\"get\", code=\"404\"}  0.05            //  30 / 600\n{method=\"post\", code=\"500\"} 0.05            //   6 / 120\n{method=\"post\", code=\"404\"} 0.175           //  21 / 120\n```\n\n### 比较运算符\n\nPrometheus 中存在以下比较运算符：\n\n* ==（相等）\n* !=（不相等）\n* \\>（大于）\n* <（小于）\n* \\>=（大于或等于）\n* <=（小于或等于）\n\n两个标量之间比较，在运算符后跟bool修饰，结果0( false) 或1 ( true)\n```\n10 < bool 5\n```\n![Alt text](image-134.png)\n瞬时向量与标量比较，查询node状态\n```\nup{job=\"node\"} ==  bool 1\n```\n两个瞬时向量比较，查看消息队列容量状态\n```\nprometheus_notifications_queue_length < bool prometheus_notifications_queue_capacity\n```\n![Alt text](image-135.png)\n### 逻辑运算符\n\nPrometheus 中存在以下逻辑运算符：\n\n* and（与）\n* or（或）\n* unless（非）\n  \n逻辑运算仅适用于向量\n\n如下我们有4个target，进行相应的逻辑运算，实现和标签选择相似效果。\n![Alt text](image-136.png)\n```\nup{instance!=\"192.168.1.123:9091\"} and up{job!=\"alertmanager\"}\n```\n![Alt text](image-137.png)\n```\nup{instance=\"192.168.1.123:9091\"} or up{job=\"alertmanager\"} \n```\n![Alt text](image-138.png)\n```\nup unless up{job=\"alertmanager\"} \n```\n![Alt text](image-139.png)\nPrometheus 中二元运算符的优先级，从高到低。\n\n1. ^\n2. *, /, %,atan2\n3. +,-\n4. ==, !=, <=, <, >=,>\n5. and,unless\n6. or\n\n\n相同优先级的运算符是左结合的\n相同优先级的运算符（+ 和 -）是左结合的。这意味着在表达式中，加法和减法运算将按照从左到右的顺序进行。\n\n例如，考虑以下PromQL表达式：\n```\na + b - c\n```\n在这个表达式中，加法运算符（+）和减法运算符（-）具有相同的优先级。根据左结合的规则，这个表达式将首先执行加法运算，然后再执行减法运算。换句话说，计算顺序将是先计算\"a + b\"，然后将结果与\"c\"相减。\n\nPromQL中的atan2函数用于计算两个数值的反正切值。它接受两个参数，并返回一个介于-π/2和π/2之间的值，表示从原点到点(y, x)的角度。\n\n具体来说，atan2(y, x)返回的角度是满足以下条件的唯一角度θ：\n\nθ在-π/2和π/2之间；\n点(x, y)位于以原点为圆心、半径为1的圆上；\n点(x, y)与极坐标中的点(1, θ)对应。\n与atan函数不同的是，atan2考虑了y和x的值之间的比例关系，因此能够更准确地描述角度的变化。在处理二维空间中的角度计算时，atan2函数通常比atan函数更常用。\n\n以下是一个PromQL中使用atan2函数的示例：\n\n```\nsum(rate(vector_field[1m])) * 100 / atan2(1, 1)\n```\n这个示例中，使用rate函数计算了一个名为vector_field的时间序列的1分钟平均值，并将其乘以100。然后，通过使用atan2函数将结果除以1和1之间的反正切值，得到一个归一化的结果。\n### 聚合运算符\nPrometheus 支持以下内置聚合运算符，可用于聚合单个瞬时向量，生成新的向量：\n\n* sum（总和）\n* min（最小）\n* max（最大）\n* avg（平均值）\n* group（分组）\n* stddev（标准偏差）\n* stdvar（标准方差）\n* count（计算向量中的元素个数）\n* count_values（计算具有相同值的元素个数）\n* bottomk（样本值的最小 k 个元素）\n* topk（按样本值计算的最大 k 个元素）\n* quantile（分位数计算 φ-quantile (0 ≤ φ ≤ 1)\n\n\n聚合运算符可通过 without、by 根据标签扩展\n\nsum、min、max、avg：\n\n计算http请求的总和，最大、最小请求的url的数量，平均数量\n```\nsum(prometheus_http_requests_total)\n```\n![Alt text](image-140.png)\n通过状态码分别统计\n![Alt text](image-141.png)\ngroup:\n\n类uniq的用法\n![Alt text](image-142.png)\n\nstddev、stdvar：\n\n反映一组数据离散程度，用以衡量数据值偏离算术平均值的程度。标准偏差为方差的开平方，标准偏差越小，这些值偏离平均值就越少，反之亦然。\n\n通过标准差来反映网络波动\n```\nstddev(rate(node_network_transmit_bytes_total[5m]))\n```\nrate计算某段时间的速率\n![Alt text](image-143.png)\ncount、count_values:\n\n统计总共有几个时序\n```\ncount(prometheus_http_requests_total)\n```\n![Alt text](image-144.png)\n计算每个value的数量\n```\ncount_values(\"value\",prometheus_http_requests_total)\n```\n![Alt text](image-145.png)\n\nbottomk、topk\n\n计算value中最小的5个时序\n```\nbottomk(5,prometheus_http_requests_total)\n```\n![Alt text](image-146.png)\n\nquantile:求数据的分位数\n\n我们现在要找出K8s集群中所有node节点的内存使用率的分布情况:\n```\nquantile\n(0.8,\n(\n1 -\nnode_memory_MemAvailable_bytes{job=\"kubernetes-service-endpoints\"} \n/ node_memory_MemTotal_bytes{job=\"kubernetes-service-endpoints\"}\n)\n* 100\n)\n```\n![Alt text](image-147.png)\n\n直接可以看出80%的节点内存使用率在68%以下\n\n## 函数\n### 值取整\n#### ceil()\nceil(v instant-vector)样本数据向上取整。\n```\nceil(node_load1)  #1.2-->2\n```\n#### floor()\nfloor(v instant-vector)与ceil()相反，floor()样本值向下取整。\n#### round()\nround(v instant-vector, to_nearest=1 scalar) 对样本值四舍五入取整。to_nearest参数是可选的,默认为 1,表示样本返回的是最接近 1 的整数倍的值，参数可以为分数。\n\n取整\n```\nround(prometheus_engine_query_duration_seconds_sum)\n```\n取整到最近的5的倍数\n```\nround(prometheus_engine_query_duration_seconds_sum,5)\n```\n### 值截取\n#### clamp()\n\nclamp(v instant-vector, min scalar, max scalar) 截取所有元素的样本值在 [min,max]集合内的样本,如果min>max返回NaN\n\n放回样本值在10到20的样本\n```\nclamp(prometheus_http_requests_total,10,20)\n```\n#### clamp_max()\n\nclamp_max(v instant-vector, max scalar) 同clamp()，不过只限定样本最大值\n\n#### clamp_min()\n\nclamp_min(v instant-vector, min scalar) 同clamp()，不过只限定样本最小值\n### 值变化统计\n#### changes()\n\nchanges(v range-vector)返回某段时间内样本值改变的次数\n```\nchanges(node_load1[1m])\n```\n### 复位统计\n#### resets()\n\nresets(v range-vector) 返回样本范围时间内的复位次数。与counter使用，两个连续样本之间值如有减少则被视为计数器复位。\n\n查看上下文交换次数计数器在5分钟内复位次数\n```\nresets(node_context_switches_total[5m])\n```\n### 日期与时间管理\n#### day_of_month()\n\nday_of_month(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份中的日期（1-31）\n\nv=vector(time()) 为默认参数\n```\nday_of_month(node_boot_time_seconds)\n```\n#### day_of_week()\n\nday_of_week(v=vector(time()) instant-vector)同上，如果样本值是utc时间，则返回这个时间所属星期几（0-6）\n\n#### days_in_month()\n\ndays_in_month(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份的天数（28-31）\n\n#### hour()\n\nhour(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属一天中的第几个小时（1-13）\n\n#### minute()\n\nminute(v=vector(time()) instant-vector) 如果样本值是utc时间，则返回这个时间所属小时中的第几分钟（1-59）\n\n#### month()\n\nmonth(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的月份（1-12）\n\n#### year()\n\nyear(v=vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的年份\n\n#### time()\n\n返回自1970 年 1 月 1 日 UTC 以来的秒数，不是系统时间，而是表达式计算时那一刻的时间。\n\n#### timestamp()\n\ntimestamp(v instant-vector)返回每个样本值的时间戳，自 1970 年 1 月 1 日 UTC 以来的秒数。\n\n### 直方图分位数\n#### histogram_quantile()\n\nhistogram_quantile(φ float, b instant-vector) 从 bucket 类型的向量 b 中计算 φ (0 ≤ φ ≤ 1) 分位数的样本的最大值，与聚合运算符quantile相似。\n\n计算80%请求的持续时间最大值。\n```\nhistogram_quantile(0.8,rate(prometheus_http_request_duration_seconds_bucket[1d]))\n```\n### 差异与增长率\n#### delta()\n\ndelta(v range-vector)计算范围向量中每个时间序列元素的第一个值和最后一个值之间的差。与指标类型gauge一起使用\n\n计算一天内内存可用量的变化\n\ndelta(node_memory_MemAvailable_bytes[1d])\n#### idelta()\n\nidelta(v range-vector)计算范围向量中最后两个样本之间的差异。与指标类型gauge一起使用\n\nidelta(node_memory_MemAvailable_bytes[1m])\n#### increase()\n\nincrease(v range-vector) 计算时间范围内的增量，与counter一起使用。它是速率rate(v)乘以时间范围内秒数的语法糖，主要用于人类可读性。\n\n计算10分钟内请求增长量\n```\nincrease(prometheus_http_requests_total[10m])\n```\n#### rate()\n\nrate(v range-vector)计算范围向量中时间序列的平均每秒增长率。\n\n过去10分钟请求平均每秒增长率，与counter一起使用。\n```\nrate(prometheus_http_requests_total[10m])\n```\n#### irate()\n\nirate(v range-vector) 通过时间范围的最后两个点来计算每秒瞬时增长率。\n```\nirate(prometheus_http_requests_total[10m])\n```\n### label管理\n#### label_join()\n\nlabel_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, ...)为每个时间序列添加一个label，值为指定旧label的value连接\n```\nlabel_join(up{instance=\"localhost:9100\", job=\"node\"},\"new_label\",\"-\",\"instance\",\"job\")\n```\n结果：\n```\nup{instance=\"localhost:9100\", job=\"node\", new_label=\"localhost:9100-node\"}   1\n```\n#### label_replace()\n\nlabel_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string)从源label中获取value元素用于添加新的label\n\n$1 获取正则匹配，匹配值添加到hello标签中\n```\nlabel_replace(up{instance=\"localhost:9100\", job=\"node\"},\"hello\",\"$1\",\"job\",\"(.*)\")\n```\n结果：\n```\nup{hello=\"node\", instance=\"localhost:9100\", job=\"node\"}       1\n```\n\n### 预测\n#### predict_linear()\n\npredict_linear(v range-vector, t scalar) 通过简单线性回归预测t秒后的样本值，与gauge一起使用。\n\n根据过去1小时的文件系统剩余空间量，预测1小时之后的剩余空间\n```\npredict_linear(node_filesystem_free_bytes[1h],3600)\n```\n### 转换\n#### absent()\n\nabsent(v instant-vector)如果向量有元素，则返回一个空向量；如果向量没有元素，则返回值为 1。\n\n设置如下告警表达式：\n```\nabsent(up{job=\"node\"} == 1)\n```\n由于up{job=\"node\"}不存在或值不为1则告警表达式的值为1 产生告警\n\n#### absent_over_time()\n\nabsent_over_time(v range-vector)如果范围向量有元素，则返回一个空向量；如果范围向量没有元素，则返回值为 1。\n\n如果up{job=\"node1\"}在某段时间不存在则返回1\n```\nabsent_over_time(up{job=\"node1\"}[1h])\n```\n#### scalar()\n\nscalar(v instant-vector)以标量形式返回该单元素的样本值,如果输入向量不是正好一个元素，scalar将返回NaN.\n\n#### vector()\n\nvector(s scalar)将标量作为没有标签的向量返回。\n\n#### sgn()\n\nsgn(v instant-vector)返回一个向量，其中所有样本值都转换为1或-1或0\n\n定义如下：\n\n如果 v 为正，则为 1\n\n如果 v 为负，则为 -1\n\n如果 v 等于 0，则为 0。\n\n### 排序\n#### sort()\n\nsort(v instant-vector)返回按样本值升序排序的向量元素。\n\n#### sort_desc()\n\n与sort()相反，按降序排序。\n\n#### _over_time()\n下面的函数列表允许传入一个范围向量，返回一个带有聚合的瞬时向量：\n\n* avg_over_time(range-vector): 区间向量内每个度量指标的平均值。\n* min_over_time(range-vector): 区间向量内每个度量指标的最小值。\n* max_over_time(range-vector): 区间向量内每个度量指标的最大值。\n* sum_over_time(range-vector): 区间向量内每个度量指标的求和值。\n* count_over_time(range-vector): 区间向量内每个度量指标的样本数据个数。\n* quantile_over_time(scalar, range-vector): 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)\n* stddev_over_time(range-vector): 区间向量内每个度量指标的总体标准偏差。\n* stdvar_over_time(range-vector): 区间向量内每个度量指标的总体标准方差\n\n### 数学函数\n#### abs()\n\nabs(v instant-vector)返回样本的绝对值。\n\n#### sqrt()\n\nsqrt(v instant-vector)计算样本值的平方根。\n\n#### deriv()\n\nderiv(v range-vector) 使用简单线性回归计算时间序列在范围向量中的每秒导数。与指标类型gauge一起使用\n\n#### exp()\n\nexp(v instant-vector)计算样本值的指数函数。\n\n特殊情况：\n\n* Exp(+Inf) = +Inf\n* Exp(NaN) = NaN\n#### ln()、log2()、log10()\n\nln/log2/log10(v instant-vector) 计算样本值对数\n\n特殊情况（同适用于log2/log10）：\n\n* ln(+Inf) = +Inf\n* ln(0) = -Inf\n* ln(x < 0) = NaN\n* ln(NaN) = NaN\n\n\n#### holt_winters()\n\nholt_winters(v range-vector, sf scalar, tf scalar)基于访问向量v，生成时间序列数据平滑数据值。平滑因子sf越低, 对旧数据越重要。趋势因子tf越高，更关心趋势数据。0<sf,tf<=1。 与gauge一起使用\n\n### 三角函数、弧度\n\n* acos(v instant-vector)\n* acosh(v instant-vector)\n* asin(v instant-vector)\n* asinh(v instant-vector)\n* atan(v instant-vector)\n* atanh(v instant-vector)\n* cos(v instant-vector)\n* cosh(v instant-vector)\n* sin(v instant-vector)\n* sinh(v instant-vector)\n* tan(v instant-vector)\n* tanh(v instant-vector)\n\n### 角度、弧度转化\n\n* deg(v instant-vector)\n* pi()\n* rad(v instant-vector)\n\n原文地址: https://zhuanlan.zhihu.com/p/477177336","slug":"kubernetes/promql","published":1,"updated":"2023-11-10T03:22:53.697Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0cd0019fmjxe2nnf235","content":"<p>PromQL（Prometheus Query Language）为Prometheus tsdb的查询语言。是结合grafana进行数据展示和告警规则的配置的关键部分。<br>本文默认您已了解Prometheus的四种指标类型：</p>\n<ul>\n<li>counter（计数器）</li>\n<li>gauge （仪表类型）</li>\n<li>histogram（直方图类型）</li>\n<li>summary （摘要类型）<br>便于读者实践，本文大部分样本数据target：</li>\n<li>Prometheus</li>\n<li>node_exporter</li>\n</ul>\n<h2 id=\"表达式数据类型\"><a href=\"#表达式数据类型\" class=\"headerlink\" title=\"表达式数据类型\"></a>表达式数据类型</h2><p>PromQL查询语句即表达式，实现的四种数据类型：</p>\n<h3 id=\"Instant-vector\"><a href=\"#Instant-vector\" class=\"headerlink\" title=\"Instant vector\"></a>Instant vector</h3><p>Instance vector（瞬时向量）表示一个时间序列的集合，但是每个时序只有最近的一个点，而不是线。<br><img src=\"/image-132.png\" alt=\"Alt text\"></p>\n<h3 id=\"Range-vector\"><a href=\"#Range-vector\" class=\"headerlink\" title=\"Range vector\"></a>Range vector</h3><p>Range vector（范围向量）表示一段时间范围里的时序，每个时序可包含多个点<br><img src=\"/image-133.png\" alt=\"Alt text\"><br>sources：<a href=\"https://satyanash.net/software/2021/01/04/understanding-prometheus-range-vectors.html\">Understanding Prometheus Range Vectors</a></p>\n<h3 id=\"Scalar\"><a href=\"#Scalar\" class=\"headerlink\" title=\"Scalar\"></a>Scalar</h3><p>Scalar（标量）通常为数值，可以将只有一个时序的Instance vector转换成Scalar。</p>\n<h3 id=\"String\"><a href=\"#String\" class=\"headerlink\" title=\"String\"></a>String</h3><p>简单字符串值，目前未被使用。</p>\n<h2 id=\"选择器\"><a href=\"#选择器\" class=\"headerlink\" title=\"选择器\"></a>选择器</h2><h3 id=\"标签选择器\"><a href=\"#标签选择器\" class=\"headerlink\" title=\"标签选择器\"></a>标签选择器</h3><p>查询Prometheus http状态码为400的请求数量。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;400&quot;&#125;</span><br></pre></td></tr></table></figure>\n<p>标签匹配运算符:</p>\n<ul>\n<li>&#x3D; ：与字符串匹配</li>\n<li>!&#x3D; ：与字符串不匹配</li>\n<li>&#x3D;~ ：与正则匹配</li>\n<li>!~ ：与正则不匹配</li>\n</ul>\n<p>查询Prometheus http状态码为4xx或5xx并且handler为&#x2F;api&#x2F;v1&#x2F;query的请求数量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=~&quot;4.*|5.*&quot;,handler=&quot;/api/v1/query&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>内部标签__name__用来匹配指标名称，下面的表达式与上一条等价</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;code=~&quot;4.*|5.*&quot;,handler=&quot;/api/v1/query&quot;,__name__=&quot;prometheus_http_requests_total&quot;&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"范围选择器\"><a href=\"#范围选择器\" class=\"headerlink\" title=\"范围选择器\"></a>范围选择器</h3><p>查询过去5分钟Prometheus健康检查的采样记录。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;,handler=&quot;/-/healthy&quot;&#125;[5m]</span><br></pre></td></tr></table></figure>\n<p>单位：ms、s、m、h、d、w、y</p>\n<p>时间串联：[1h5m]一小时5分钟</p>\n<h2 id=\"时间偏移\"><a href=\"#时间偏移\" class=\"headerlink\" title=\"时间偏移\"></a>时间偏移</h2><h3 id=\"通过offset\"><a href=\"#通过offset\" class=\"headerlink\" title=\"通过offset\"></a>通过offset</h3><p>通过offset将时间倒退5分钟，即查询5分钟之前的数据。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125; offset 5m </span><br></pre></td></tr></table></figure>\n<p>同样支持查询range vector</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125;[3m] offset 5m</span><br></pre></td></tr></table></figure>\n<h3 id=\"修饰符\"><a href=\"#修饰符\" class=\"headerlink\" title=\"@修饰符\"></a>@修饰符</h3><p>还可以通过@ 直接跳转到某个uinx时间戳，需开启启动参数–enable-feature&#x3D;promql-at-modifier</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125; @ 1646089826</span><br></pre></td></tr></table></figure>\n<h2 id=\"运算符\"><a href=\"#运算符\" class=\"headerlink\" title=\"运算符\"></a>运算符</h2><p>Prometheus中的运算符与各类编程语言中的基本一致。</p>\n<h3 id=\"数学运算符\"><a href=\"#数学运算符\" class=\"headerlink\" title=\"数学运算符\"></a>数学运算符</h3><p>Prometheus 中存在以下数学运算符：</p>\n<ul>\n<li>+（加法）</li>\n<li>-（减法）</li>\n<li>*（乘法）</li>\n<li>&#x2F;（除法）</li>\n<li>%（取模）</li>\n<li>^（幂）<br>两个标量之间的计算<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10/3</span><br></pre></td></tr></table></figure>\n瞬时向量与标量计算，由于计算后值意义与原指标名有差异，Prometheus很贴心的帮我们移除了指标名称。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_response_size_bytes_sum / 1024</span><br></pre></td></tr></table></figure>\n两个瞬时向量间的计算，如下计算node的内存使用率<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(</span><br><span class=\"line\">1 -</span><br><span class=\"line\">node_memory_MemAvailable_bytes&#123;job=&quot;node&quot;,instance=&quot;localhost:9100&quot;&#125; </span><br><span class=\"line\">/ node_memory_MemTotal_bytes&#123;job=&quot;node&quot;,instance=&quot;localhost:9100&quot;&#125;</span><br><span class=\"line\">)</span><br><span class=\"line\">* 100</span><br></pre></td></tr></table></figure>\n如果两个瞬时向量标签不一致可通过ignoring忽略多余标签<br>输入示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  24</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6</span><br><span class=\"line\"></span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;get&quot;&#125;  600</span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120</span><br></pre></td></tr></table></figure>\n查询示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m&#123;code=&quot;500&quot;&#125; / ignoring(code) method:http_requests:rate5m</span><br></pre></td></tr></table></figure>\n结果示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;method=&quot;get&quot;&#125;  0.04            //  24 / 600</span><br><span class=\"line\">&#123;method=&quot;post&quot;&#125; 0.05            //   6 / 120</span><br></pre></td></tr></table></figure>\n如果两个瞬时向量数量不一致时可通过group_left、group_right指定以那一侧为准<br>输入示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  24</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125;  30</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;put&quot;, code=&quot;501&quot;&#125;  3</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 21</span><br><span class=\"line\"></span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;get&quot;&#125;  600</span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;del&quot;&#125;  34</span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120</span><br></pre></td></tr></table></figure>\n查询示例：</li>\n</ul>\n<p>group_left以左侧为准</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m</span><br></pre></td></tr></table></figure>\n<p>结果示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  0.04            //  24 / 600</span><br><span class=\"line\">&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125;  0.05            //  30 / 600</span><br><span class=\"line\">&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 0.05            //   6 / 120</span><br><span class=\"line\">&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 0.175           //  21 / 120</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"比较运算符\"><a href=\"#比较运算符\" class=\"headerlink\" title=\"比较运算符\"></a>比较运算符</h3><p>Prometheus 中存在以下比较运算符：</p>\n<ul>\n<li>&#x3D;&#x3D;（相等）</li>\n<li>!&#x3D;（不相等）</li>\n<li>&gt;（大于）</li>\n<li>&lt;（小于）</li>\n<li>&gt;&#x3D;（大于或等于）</li>\n<li>&lt;&#x3D;（小于或等于）</li>\n</ul>\n<p>两个标量之间比较，在运算符后跟bool修饰，结果0( false) 或1 ( true)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10 &lt; bool 5</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-134.png\" alt=\"Alt text\"><br>瞬时向量与标量比较，查询node状态</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;job=&quot;node&quot;&#125; ==  bool 1</span><br></pre></td></tr></table></figure>\n<p>两个瞬时向量比较，查看消息队列容量状态</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_notifications_queue_length &lt; bool prometheus_notifications_queue_capacity</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-135.png\" alt=\"Alt text\"></p>\n<h3 id=\"逻辑运算符\"><a href=\"#逻辑运算符\" class=\"headerlink\" title=\"逻辑运算符\"></a>逻辑运算符</h3><p>Prometheus 中存在以下逻辑运算符：</p>\n<ul>\n<li>and（与）</li>\n<li>or（或）</li>\n<li>unless（非）</li>\n</ul>\n<p>逻辑运算仅适用于向量</p>\n<p>如下我们有4个target，进行相应的逻辑运算，实现和标签选择相似效果。<br><img src=\"/image-136.png\" alt=\"Alt text\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;instance!=&quot;192.168.1.123:9091&quot;&#125; and up&#123;job!=&quot;alertmanager&quot;&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-137.png\" alt=\"Alt text\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;instance=&quot;192.168.1.123:9091&quot;&#125; or up&#123;job=&quot;alertmanager&quot;&#125; </span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-138.png\" alt=\"Alt text\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up unless up&#123;job=&quot;alertmanager&quot;&#125; </span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-139.png\" alt=\"Alt text\"><br>Prometheus 中二元运算符的优先级，从高到低。</p>\n<ol>\n<li>^</li>\n<li>*, &#x2F;, %,atan2</li>\n<li>+,-</li>\n<li>&#x3D;&#x3D;, !&#x3D;, &lt;&#x3D;, &lt;, &gt;&#x3D;,&gt;</li>\n<li>and,unless</li>\n<li>or</li>\n</ol>\n<p>相同优先级的运算符是左结合的<br>相同优先级的运算符（+ 和 -）是左结合的。这意味着在表达式中，加法和减法运算将按照从左到右的顺序进行。</p>\n<p>例如，考虑以下PromQL表达式：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a + b - c</span><br></pre></td></tr></table></figure>\n<p>在这个表达式中，加法运算符（+）和减法运算符（-）具有相同的优先级。根据左结合的规则，这个表达式将首先执行加法运算，然后再执行减法运算。换句话说，计算顺序将是先计算”a + b”，然后将结果与”c”相减。</p>\n<p>PromQL中的atan2函数用于计算两个数值的反正切值。它接受两个参数，并返回一个介于-π&#x2F;2和π&#x2F;2之间的值，表示从原点到点(y, x)的角度。</p>\n<p>具体来说，atan2(y, x)返回的角度是满足以下条件的唯一角度θ：</p>\n<p>θ在-π&#x2F;2和π&#x2F;2之间；<br>点(x, y)位于以原点为圆心、半径为1的圆上；<br>点(x, y)与极坐标中的点(1, θ)对应。<br>与atan函数不同的是，atan2考虑了y和x的值之间的比例关系，因此能够更准确地描述角度的变化。在处理二维空间中的角度计算时，atan2函数通常比atan函数更常用。</p>\n<p>以下是一个PromQL中使用atan2函数的示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum(rate(vector_field[1m])) * 100 / atan2(1, 1)</span><br></pre></td></tr></table></figure>\n<p>这个示例中，使用rate函数计算了一个名为vector_field的时间序列的1分钟平均值，并将其乘以100。然后，通过使用atan2函数将结果除以1和1之间的反正切值，得到一个归一化的结果。</p>\n<h3 id=\"聚合运算符\"><a href=\"#聚合运算符\" class=\"headerlink\" title=\"聚合运算符\"></a>聚合运算符</h3><p>Prometheus 支持以下内置聚合运算符，可用于聚合单个瞬时向量，生成新的向量：</p>\n<ul>\n<li>sum（总和）</li>\n<li>min（最小）</li>\n<li>max（最大）</li>\n<li>avg（平均值）</li>\n<li>group（分组）</li>\n<li>stddev（标准偏差）</li>\n<li>stdvar（标准方差）</li>\n<li>count（计算向量中的元素个数）</li>\n<li>count_values（计算具有相同值的元素个数）</li>\n<li>bottomk（样本值的最小 k 个元素）</li>\n<li>topk（按样本值计算的最大 k 个元素）</li>\n<li>quantile（分位数计算 φ-quantile (0 ≤ φ ≤ 1)</li>\n</ul>\n<p>聚合运算符可通过 without、by 根据标签扩展</p>\n<p>sum、min、max、avg：</p>\n<p>计算http请求的总和，最大、最小请求的url的数量，平均数量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum(prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-140.png\" alt=\"Alt text\"><br>通过状态码分别统计<br><img src=\"/image-141.png\" alt=\"Alt text\"><br>group:</p>\n<p>类uniq的用法<br><img src=\"/image-142.png\" alt=\"Alt text\"></p>\n<p>stddev、stdvar：</p>\n<p>反映一组数据离散程度，用以衡量数据值偏离算术平均值的程度。标准偏差为方差的开平方，标准偏差越小，这些值偏离平均值就越少，反之亦然。</p>\n<p>通过标准差来反映网络波动</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stddev(rate(node_network_transmit_bytes_total[5m]))</span><br></pre></td></tr></table></figure>\n<p>rate计算某段时间的速率<br><img src=\"/image-143.png\" alt=\"Alt text\"><br>count、count_values:</p>\n<p>统计总共有几个时序</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">count(prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-144.png\" alt=\"Alt text\"><br>计算每个value的数量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">count_values(&quot;value&quot;,prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-145.png\" alt=\"Alt text\"></p>\n<p>bottomk、topk</p>\n<p>计算value中最小的5个时序</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bottomk(5,prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-146.png\" alt=\"Alt text\"></p>\n<p>quantile:求数据的分位数</p>\n<p>我们现在要找出K8s集群中所有node节点的内存使用率的分布情况:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">quantile</span><br><span class=\"line\">(0.8,</span><br><span class=\"line\">(</span><br><span class=\"line\">1 -</span><br><span class=\"line\">node_memory_MemAvailable_bytes&#123;job=&quot;kubernetes-service-endpoints&quot;&#125; </span><br><span class=\"line\">/ node_memory_MemTotal_bytes&#123;job=&quot;kubernetes-service-endpoints&quot;&#125;</span><br><span class=\"line\">)</span><br><span class=\"line\">* 100</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-147.png\" alt=\"Alt text\"></p>\n<p>直接可以看出80%的节点内存使用率在68%以下</p>\n<h2 id=\"函数\"><a href=\"#函数\" class=\"headerlink\" title=\"函数\"></a>函数</h2><h3 id=\"值取整\"><a href=\"#值取整\" class=\"headerlink\" title=\"值取整\"></a>值取整</h3><h4 id=\"ceil\"><a href=\"#ceil\" class=\"headerlink\" title=\"ceil()\"></a>ceil()</h4><p>ceil(v instant-vector)样本数据向上取整。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceil(node_load1)  #1.2--&gt;2</span><br></pre></td></tr></table></figure>\n<h4 id=\"floor\"><a href=\"#floor\" class=\"headerlink\" title=\"floor()\"></a>floor()</h4><p>floor(v instant-vector)与ceil()相反，floor()样本值向下取整。</p>\n<h4 id=\"round\"><a href=\"#round\" class=\"headerlink\" title=\"round()\"></a>round()</h4><p>round(v instant-vector, to_nearest&#x3D;1 scalar) 对样本值四舍五入取整。to_nearest参数是可选的,默认为 1,表示样本返回的是最接近 1 的整数倍的值，参数可以为分数。</p>\n<p>取整</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">round(prometheus_engine_query_duration_seconds_sum)</span><br></pre></td></tr></table></figure>\n<p>取整到最近的5的倍数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">round(prometheus_engine_query_duration_seconds_sum,5)</span><br></pre></td></tr></table></figure>\n<h3 id=\"值截取\"><a href=\"#值截取\" class=\"headerlink\" title=\"值截取\"></a>值截取</h3><h4 id=\"clamp\"><a href=\"#clamp\" class=\"headerlink\" title=\"clamp()\"></a>clamp()</h4><p>clamp(v instant-vector, min scalar, max scalar) 截取所有元素的样本值在 [min,max]集合内的样本,如果min&gt;max返回NaN</p>\n<p>放回样本值在10到20的样本</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">clamp(prometheus_http_requests_total,10,20)</span><br></pre></td></tr></table></figure>\n<h4 id=\"clamp-max\"><a href=\"#clamp-max\" class=\"headerlink\" title=\"clamp_max()\"></a>clamp_max()</h4><p>clamp_max(v instant-vector, max scalar) 同clamp()，不过只限定样本最大值</p>\n<h4 id=\"clamp-min\"><a href=\"#clamp-min\" class=\"headerlink\" title=\"clamp_min()\"></a>clamp_min()</h4><p>clamp_min(v instant-vector, min scalar) 同clamp()，不过只限定样本最小值</p>\n<h3 id=\"值变化统计\"><a href=\"#值变化统计\" class=\"headerlink\" title=\"值变化统计\"></a>值变化统计</h3><h4 id=\"changes\"><a href=\"#changes\" class=\"headerlink\" title=\"changes()\"></a>changes()</h4><p>changes(v range-vector)返回某段时间内样本值改变的次数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">changes(node_load1[1m])</span><br></pre></td></tr></table></figure>\n<h3 id=\"复位统计\"><a href=\"#复位统计\" class=\"headerlink\" title=\"复位统计\"></a>复位统计</h3><h4 id=\"resets\"><a href=\"#resets\" class=\"headerlink\" title=\"resets()\"></a>resets()</h4><p>resets(v range-vector) 返回样本范围时间内的复位次数。与counter使用，两个连续样本之间值如有减少则被视为计数器复位。</p>\n<p>查看上下文交换次数计数器在5分钟内复位次数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">resets(node_context_switches_total[5m])</span><br></pre></td></tr></table></figure>\n<h3 id=\"日期与时间管理\"><a href=\"#日期与时间管理\" class=\"headerlink\" title=\"日期与时间管理\"></a>日期与时间管理</h3><h4 id=\"day-of-month\"><a href=\"#day-of-month\" class=\"headerlink\" title=\"day_of_month()\"></a>day_of_month()</h4><p>day_of_month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份中的日期（1-31）</p>\n<p>v&#x3D;vector(time()) 为默认参数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">day_of_month(node_boot_time_seconds)</span><br></pre></td></tr></table></figure>\n<h4 id=\"day-of-week\"><a href=\"#day-of-week\" class=\"headerlink\" title=\"day_of_week()\"></a>day_of_week()</h4><p>day_of_week(v&#x3D;vector(time()) instant-vector)同上，如果样本值是utc时间，则返回这个时间所属星期几（0-6）</p>\n<h4 id=\"days-in-month\"><a href=\"#days-in-month\" class=\"headerlink\" title=\"days_in_month()\"></a>days_in_month()</h4><p>days_in_month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份的天数（28-31）</p>\n<h4 id=\"hour\"><a href=\"#hour\" class=\"headerlink\" title=\"hour()\"></a>hour()</h4><p>hour(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属一天中的第几个小时（1-13）</p>\n<h4 id=\"minute\"><a href=\"#minute\" class=\"headerlink\" title=\"minute()\"></a>minute()</h4><p>minute(v&#x3D;vector(time()) instant-vector) 如果样本值是utc时间，则返回这个时间所属小时中的第几分钟（1-59）</p>\n<h4 id=\"month\"><a href=\"#month\" class=\"headerlink\" title=\"month()\"></a>month()</h4><p>month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的月份（1-12）</p>\n<h4 id=\"year\"><a href=\"#year\" class=\"headerlink\" title=\"year()\"></a>year()</h4><p>year(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的年份</p>\n<h4 id=\"time\"><a href=\"#time\" class=\"headerlink\" title=\"time()\"></a>time()</h4><p>返回自1970 年 1 月 1 日 UTC 以来的秒数，不是系统时间，而是表达式计算时那一刻的时间。</p>\n<h4 id=\"timestamp\"><a href=\"#timestamp\" class=\"headerlink\" title=\"timestamp()\"></a>timestamp()</h4><p>timestamp(v instant-vector)返回每个样本值的时间戳，自 1970 年 1 月 1 日 UTC 以来的秒数。</p>\n<h3 id=\"直方图分位数\"><a href=\"#直方图分位数\" class=\"headerlink\" title=\"直方图分位数\"></a>直方图分位数</h3><h4 id=\"histogram-quantile\"><a href=\"#histogram-quantile\" class=\"headerlink\" title=\"histogram_quantile()\"></a>histogram_quantile()</h4><p>histogram_quantile(φ float, b instant-vector) 从 bucket 类型的向量 b 中计算 φ (0 ≤ φ ≤ 1) 分位数的样本的最大值，与聚合运算符quantile相似。</p>\n<p>计算80%请求的持续时间最大值。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">histogram_quantile(0.8,rate(prometheus_http_request_duration_seconds_bucket[1d]))</span><br></pre></td></tr></table></figure>\n<h3 id=\"差异与增长率\"><a href=\"#差异与增长率\" class=\"headerlink\" title=\"差异与增长率\"></a>差异与增长率</h3><h4 id=\"delta\"><a href=\"#delta\" class=\"headerlink\" title=\"delta()\"></a>delta()</h4><p>delta(v range-vector)计算范围向量中每个时间序列元素的第一个值和最后一个值之间的差。与指标类型gauge一起使用</p>\n<p>计算一天内内存可用量的变化</p>\n<p>delta(node_memory_MemAvailable_bytes[1d])</p>\n<h4 id=\"idelta\"><a href=\"#idelta\" class=\"headerlink\" title=\"idelta()\"></a>idelta()</h4><p>idelta(v range-vector)计算范围向量中最后两个样本之间的差异。与指标类型gauge一起使用</p>\n<p>idelta(node_memory_MemAvailable_bytes[1m])</p>\n<h4 id=\"increase\"><a href=\"#increase\" class=\"headerlink\" title=\"increase()\"></a>increase()</h4><p>increase(v range-vector) 计算时间范围内的增量，与counter一起使用。它是速率rate(v)乘以时间范围内秒数的语法糖，主要用于人类可读性。</p>\n<p>计算10分钟内请求增长量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">increase(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure>\n<h4 id=\"rate\"><a href=\"#rate\" class=\"headerlink\" title=\"rate()\"></a>rate()</h4><p>rate(v range-vector)计算范围向量中时间序列的平均每秒增长率。</p>\n<p>过去10分钟请求平均每秒增长率，与counter一起使用。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rate(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure>\n<h4 id=\"irate\"><a href=\"#irate\" class=\"headerlink\" title=\"irate()\"></a>irate()</h4><p>irate(v range-vector) 通过时间范围的最后两个点来计算每秒瞬时增长率。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">irate(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure>\n<h3 id=\"label管理\"><a href=\"#label管理\" class=\"headerlink\" title=\"label管理\"></a>label管理</h3><h4 id=\"label-join\"><a href=\"#label-join\" class=\"headerlink\" title=\"label_join()\"></a>label_join()</h4><p>label_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, …)为每个时间序列添加一个label，值为指定旧label的value连接</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">label_join(up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;,&quot;new_label&quot;,&quot;-&quot;,&quot;instance&quot;,&quot;job&quot;)</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;, new_label=&quot;localhost:9100-node&quot;&#125;   1</span><br></pre></td></tr></table></figure>\n<h4 id=\"label-replace\"><a href=\"#label-replace\" class=\"headerlink\" title=\"label_replace()\"></a>label_replace()</h4><p>label_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string)从源label中获取value元素用于添加新的label</p>\n<p>$1 获取正则匹配，匹配值添加到hello标签中</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">label_replace(up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;,&quot;hello&quot;,&quot;$1&quot;,&quot;job&quot;,&quot;(.*)&quot;)</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;hello=&quot;node&quot;, instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;       1</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"预测\"><a href=\"#预测\" class=\"headerlink\" title=\"预测\"></a>预测</h3><h4 id=\"predict-linear\"><a href=\"#predict-linear\" class=\"headerlink\" title=\"predict_linear()\"></a>predict_linear()</h4><p>predict_linear(v range-vector, t scalar) 通过简单线性回归预测t秒后的样本值，与gauge一起使用。</p>\n<p>根据过去1小时的文件系统剩余空间量，预测1小时之后的剩余空间</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predict_linear(node_filesystem_free_bytes[1h],3600)</span><br></pre></td></tr></table></figure>\n<h3 id=\"转换\"><a href=\"#转换\" class=\"headerlink\" title=\"转换\"></a>转换</h3><h4 id=\"absent\"><a href=\"#absent\" class=\"headerlink\" title=\"absent()\"></a>absent()</h4><p>absent(v instant-vector)如果向量有元素，则返回一个空向量；如果向量没有元素，则返回值为 1。</p>\n<p>设置如下告警表达式：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">absent(up&#123;job=&quot;node&quot;&#125; == 1)</span><br></pre></td></tr></table></figure>\n<p>由于up{job&#x3D;”node”}不存在或值不为1则告警表达式的值为1 产生告警</p>\n<h4 id=\"absent-over-time\"><a href=\"#absent-over-time\" class=\"headerlink\" title=\"absent_over_time()\"></a>absent_over_time()</h4><p>absent_over_time(v range-vector)如果范围向量有元素，则返回一个空向量；如果范围向量没有元素，则返回值为 1。</p>\n<p>如果up{job&#x3D;”node1”}在某段时间不存在则返回1</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">absent_over_time(up&#123;job=&quot;node1&quot;&#125;[1h])</span><br></pre></td></tr></table></figure>\n<h4 id=\"scalar\"><a href=\"#scalar\" class=\"headerlink\" title=\"scalar()\"></a>scalar()</h4><p>scalar(v instant-vector)以标量形式返回该单元素的样本值,如果输入向量不是正好一个元素，scalar将返回NaN.</p>\n<h4 id=\"vector\"><a href=\"#vector\" class=\"headerlink\" title=\"vector()\"></a>vector()</h4><p>vector(s scalar)将标量作为没有标签的向量返回。</p>\n<h4 id=\"sgn\"><a href=\"#sgn\" class=\"headerlink\" title=\"sgn()\"></a>sgn()</h4><p>sgn(v instant-vector)返回一个向量，其中所有样本值都转换为1或-1或0</p>\n<p>定义如下：</p>\n<p>如果 v 为正，则为 1</p>\n<p>如果 v 为负，则为 -1</p>\n<p>如果 v 等于 0，则为 0。</p>\n<h3 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h3><h4 id=\"sort\"><a href=\"#sort\" class=\"headerlink\" title=\"sort()\"></a>sort()</h4><p>sort(v instant-vector)返回按样本值升序排序的向量元素。</p>\n<h4 id=\"sort-desc\"><a href=\"#sort-desc\" class=\"headerlink\" title=\"sort_desc()\"></a>sort_desc()</h4><p>与sort()相反，按降序排序。</p>\n<h4 id=\"over-time\"><a href=\"#over-time\" class=\"headerlink\" title=\"_over_time()\"></a>_over_time()</h4><p>下面的函数列表允许传入一个范围向量，返回一个带有聚合的瞬时向量：</p>\n<ul>\n<li>avg_over_time(range-vector): 区间向量内每个度量指标的平均值。</li>\n<li>min_over_time(range-vector): 区间向量内每个度量指标的最小值。</li>\n<li>max_over_time(range-vector): 区间向量内每个度量指标的最大值。</li>\n<li>sum_over_time(range-vector): 区间向量内每个度量指标的求和值。</li>\n<li>count_over_time(range-vector): 区间向量内每个度量指标的样本数据个数。</li>\n<li>quantile_over_time(scalar, range-vector): 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)</li>\n<li>stddev_over_time(range-vector): 区间向量内每个度量指标的总体标准偏差。</li>\n<li>stdvar_over_time(range-vector): 区间向量内每个度量指标的总体标准方差</li>\n</ul>\n<h3 id=\"数学函数\"><a href=\"#数学函数\" class=\"headerlink\" title=\"数学函数\"></a>数学函数</h3><h4 id=\"abs\"><a href=\"#abs\" class=\"headerlink\" title=\"abs()\"></a>abs()</h4><p>abs(v instant-vector)返回样本的绝对值。</p>\n<h4 id=\"sqrt\"><a href=\"#sqrt\" class=\"headerlink\" title=\"sqrt()\"></a>sqrt()</h4><p>sqrt(v instant-vector)计算样本值的平方根。</p>\n<h4 id=\"deriv\"><a href=\"#deriv\" class=\"headerlink\" title=\"deriv()\"></a>deriv()</h4><p>deriv(v range-vector) 使用简单线性回归计算时间序列在范围向量中的每秒导数。与指标类型gauge一起使用</p>\n<h4 id=\"exp\"><a href=\"#exp\" class=\"headerlink\" title=\"exp()\"></a>exp()</h4><p>exp(v instant-vector)计算样本值的指数函数。</p>\n<p>特殊情况：</p>\n<ul>\n<li>Exp(+Inf) &#x3D; +Inf</li>\n<li>Exp(NaN) &#x3D; NaN</li>\n</ul>\n<h4 id=\"ln-、log2-、log10\"><a href=\"#ln-、log2-、log10\" class=\"headerlink\" title=\"ln()、log2()、log10()\"></a>ln()、log2()、log10()</h4><p>ln&#x2F;log2&#x2F;log10(v instant-vector) 计算样本值对数</p>\n<p>特殊情况（同适用于log2&#x2F;log10）：</p>\n<ul>\n<li>ln(+Inf) &#x3D; +Inf</li>\n<li>ln(0) &#x3D; -Inf</li>\n<li>ln(x &lt; 0) &#x3D; NaN</li>\n<li>ln(NaN) &#x3D; NaN</li>\n</ul>\n<h4 id=\"holt-winters\"><a href=\"#holt-winters\" class=\"headerlink\" title=\"holt_winters()\"></a>holt_winters()</h4><p>holt_winters(v range-vector, sf scalar, tf scalar)基于访问向量v，生成时间序列数据平滑数据值。平滑因子sf越低, 对旧数据越重要。趋势因子tf越高，更关心趋势数据。0&lt;sf,tf&lt;&#x3D;1。 与gauge一起使用</p>\n<h3 id=\"三角函数、弧度\"><a href=\"#三角函数、弧度\" class=\"headerlink\" title=\"三角函数、弧度\"></a>三角函数、弧度</h3><ul>\n<li>acos(v instant-vector)</li>\n<li>acosh(v instant-vector)</li>\n<li>asin(v instant-vector)</li>\n<li>asinh(v instant-vector)</li>\n<li>atan(v instant-vector)</li>\n<li>atanh(v instant-vector)</li>\n<li>cos(v instant-vector)</li>\n<li>cosh(v instant-vector)</li>\n<li>sin(v instant-vector)</li>\n<li>sinh(v instant-vector)</li>\n<li>tan(v instant-vector)</li>\n<li>tanh(v instant-vector)</li>\n</ul>\n<h3 id=\"角度、弧度转化\"><a href=\"#角度、弧度转化\" class=\"headerlink\" title=\"角度、弧度转化\"></a>角度、弧度转化</h3><ul>\n<li>deg(v instant-vector)</li>\n<li>pi()</li>\n<li>rad(v instant-vector)</li>\n</ul>\n<p>原文地址: <a href=\"https://zhuanlan.zhihu.com/p/477177336\">https://zhuanlan.zhihu.com/p/477177336</a></p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>PromQL（Prometheus Query Language）为Prometheus tsdb的查询语言。是结合grafana进行数据展示和告警规则的配置的关键部分。<br>本文默认您已了解Prometheus的四种指标类型：</p>\n<ul>\n<li>counter（计数器）</li>\n<li>gauge （仪表类型）</li>\n<li>histogram（直方图类型）</li>\n<li>summary （摘要类型）<br>便于读者实践，本文大部分样本数据target：</li>\n<li>Prometheus</li>\n<li>node_exporter</li>\n</ul>\n<h2 id=\"表达式数据类型\"><a href=\"#表达式数据类型\" class=\"headerlink\" title=\"表达式数据类型\"></a>表达式数据类型</h2><p>PromQL查询语句即表达式，实现的四种数据类型：</p>\n<h3 id=\"Instant-vector\"><a href=\"#Instant-vector\" class=\"headerlink\" title=\"Instant vector\"></a>Instant vector</h3><p>Instance vector（瞬时向量）表示一个时间序列的集合，但是每个时序只有最近的一个点，而不是线。<br><img src=\"/image-132.png\" alt=\"Alt text\"></p>\n<h3 id=\"Range-vector\"><a href=\"#Range-vector\" class=\"headerlink\" title=\"Range vector\"></a>Range vector</h3><p>Range vector（范围向量）表示一段时间范围里的时序，每个时序可包含多个点<br><img src=\"/image-133.png\" alt=\"Alt text\"><br>sources：<a href=\"https://satyanash.net/software/2021/01/04/understanding-prometheus-range-vectors.html\">Understanding Prometheus Range Vectors</a></p>\n<h3 id=\"Scalar\"><a href=\"#Scalar\" class=\"headerlink\" title=\"Scalar\"></a>Scalar</h3><p>Scalar（标量）通常为数值，可以将只有一个时序的Instance vector转换成Scalar。</p>\n<h3 id=\"String\"><a href=\"#String\" class=\"headerlink\" title=\"String\"></a>String</h3><p>简单字符串值，目前未被使用。</p>\n<h2 id=\"选择器\"><a href=\"#选择器\" class=\"headerlink\" title=\"选择器\"></a>选择器</h2><h3 id=\"标签选择器\"><a href=\"#标签选择器\" class=\"headerlink\" title=\"标签选择器\"></a>标签选择器</h3><p>查询Prometheus http状态码为400的请求数量。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;400&quot;&#125;</span><br></pre></td></tr></table></figure>\n<p>标签匹配运算符:</p>\n<ul>\n<li>&#x3D; ：与字符串匹配</li>\n<li>!&#x3D; ：与字符串不匹配</li>\n<li>&#x3D;~ ：与正则匹配</li>\n<li>!~ ：与正则不匹配</li>\n</ul>\n<p>查询Prometheus http状态码为4xx或5xx并且handler为&#x2F;api&#x2F;v1&#x2F;query的请求数量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=~&quot;4.*|5.*&quot;,handler=&quot;/api/v1/query&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>内部标签__name__用来匹配指标名称，下面的表达式与上一条等价</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;code=~&quot;4.*|5.*&quot;,handler=&quot;/api/v1/query&quot;,__name__=&quot;prometheus_http_requests_total&quot;&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"范围选择器\"><a href=\"#范围选择器\" class=\"headerlink\" title=\"范围选择器\"></a>范围选择器</h3><p>查询过去5分钟Prometheus健康检查的采样记录。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;,handler=&quot;/-/healthy&quot;&#125;[5m]</span><br></pre></td></tr></table></figure>\n<p>单位：ms、s、m、h、d、w、y</p>\n<p>时间串联：[1h5m]一小时5分钟</p>\n<h2 id=\"时间偏移\"><a href=\"#时间偏移\" class=\"headerlink\" title=\"时间偏移\"></a>时间偏移</h2><h3 id=\"通过offset\"><a href=\"#通过offset\" class=\"headerlink\" title=\"通过offset\"></a>通过offset</h3><p>通过offset将时间倒退5分钟，即查询5分钟之前的数据。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125; offset 5m </span><br></pre></td></tr></table></figure>\n<p>同样支持查询range vector</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125;[3m] offset 5m</span><br></pre></td></tr></table></figure>\n<h3 id=\"修饰符\"><a href=\"#修饰符\" class=\"headerlink\" title=\"@修饰符\"></a>@修饰符</h3><p>还可以通过@ 直接跳转到某个uinx时间戳，需开启启动参数–enable-feature&#x3D;promql-at-modifier</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_requests_total&#123;code=&quot;200&quot;&#125; @ 1646089826</span><br></pre></td></tr></table></figure>\n<h2 id=\"运算符\"><a href=\"#运算符\" class=\"headerlink\" title=\"运算符\"></a>运算符</h2><p>Prometheus中的运算符与各类编程语言中的基本一致。</p>\n<h3 id=\"数学运算符\"><a href=\"#数学运算符\" class=\"headerlink\" title=\"数学运算符\"></a>数学运算符</h3><p>Prometheus 中存在以下数学运算符：</p>\n<ul>\n<li>+（加法）</li>\n<li>-（减法）</li>\n<li>*（乘法）</li>\n<li>&#x2F;（除法）</li>\n<li>%（取模）</li>\n<li>^（幂）<br>两个标量之间的计算<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10/3</span><br></pre></td></tr></table></figure>\n瞬时向量与标量计算，由于计算后值意义与原指标名有差异，Prometheus很贴心的帮我们移除了指标名称。<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_http_response_size_bytes_sum / 1024</span><br></pre></td></tr></table></figure>\n两个瞬时向量间的计算，如下计算node的内存使用率<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(</span><br><span class=\"line\">1 -</span><br><span class=\"line\">node_memory_MemAvailable_bytes&#123;job=&quot;node&quot;,instance=&quot;localhost:9100&quot;&#125; </span><br><span class=\"line\">/ node_memory_MemTotal_bytes&#123;job=&quot;node&quot;,instance=&quot;localhost:9100&quot;&#125;</span><br><span class=\"line\">)</span><br><span class=\"line\">* 100</span><br></pre></td></tr></table></figure>\n如果两个瞬时向量标签不一致可通过ignoring忽略多余标签<br>输入示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  24</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6</span><br><span class=\"line\"></span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;get&quot;&#125;  600</span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120</span><br></pre></td></tr></table></figure>\n查询示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m&#123;code=&quot;500&quot;&#125; / ignoring(code) method:http_requests:rate5m</span><br></pre></td></tr></table></figure>\n结果示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;method=&quot;get&quot;&#125;  0.04            //  24 / 600</span><br><span class=\"line\">&#123;method=&quot;post&quot;&#125; 0.05            //   6 / 120</span><br></pre></td></tr></table></figure>\n如果两个瞬时向量数量不一致时可通过group_left、group_right指定以那一侧为准<br>输入示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  24</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125;  30</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;put&quot;, code=&quot;501&quot;&#125;  3</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6</span><br><span class=\"line\">method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 21</span><br><span class=\"line\"></span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;get&quot;&#125;  600</span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;del&quot;&#125;  34</span><br><span class=\"line\">method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120</span><br></pre></td></tr></table></figure>\n查询示例：</li>\n</ul>\n<p>group_left以左侧为准</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m</span><br></pre></td></tr></table></figure>\n<p>结果示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125;  0.04            //  24 / 600</span><br><span class=\"line\">&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125;  0.05            //  30 / 600</span><br><span class=\"line\">&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 0.05            //   6 / 120</span><br><span class=\"line\">&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 0.175           //  21 / 120</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"比较运算符\"><a href=\"#比较运算符\" class=\"headerlink\" title=\"比较运算符\"></a>比较运算符</h3><p>Prometheus 中存在以下比较运算符：</p>\n<ul>\n<li>&#x3D;&#x3D;（相等）</li>\n<li>!&#x3D;（不相等）</li>\n<li>&gt;（大于）</li>\n<li>&lt;（小于）</li>\n<li>&gt;&#x3D;（大于或等于）</li>\n<li>&lt;&#x3D;（小于或等于）</li>\n</ul>\n<p>两个标量之间比较，在运算符后跟bool修饰，结果0( false) 或1 ( true)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10 &lt; bool 5</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-134.png\" alt=\"Alt text\"><br>瞬时向量与标量比较，查询node状态</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;job=&quot;node&quot;&#125; ==  bool 1</span><br></pre></td></tr></table></figure>\n<p>两个瞬时向量比较，查看消息队列容量状态</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">prometheus_notifications_queue_length &lt; bool prometheus_notifications_queue_capacity</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-135.png\" alt=\"Alt text\"></p>\n<h3 id=\"逻辑运算符\"><a href=\"#逻辑运算符\" class=\"headerlink\" title=\"逻辑运算符\"></a>逻辑运算符</h3><p>Prometheus 中存在以下逻辑运算符：</p>\n<ul>\n<li>and（与）</li>\n<li>or（或）</li>\n<li>unless（非）</li>\n</ul>\n<p>逻辑运算仅适用于向量</p>\n<p>如下我们有4个target，进行相应的逻辑运算，实现和标签选择相似效果。<br><img src=\"/image-136.png\" alt=\"Alt text\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;instance!=&quot;192.168.1.123:9091&quot;&#125; and up&#123;job!=&quot;alertmanager&quot;&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-137.png\" alt=\"Alt text\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;instance=&quot;192.168.1.123:9091&quot;&#125; or up&#123;job=&quot;alertmanager&quot;&#125; </span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-138.png\" alt=\"Alt text\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up unless up&#123;job=&quot;alertmanager&quot;&#125; </span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-139.png\" alt=\"Alt text\"><br>Prometheus 中二元运算符的优先级，从高到低。</p>\n<ol>\n<li>^</li>\n<li>*, &#x2F;, %,atan2</li>\n<li>+,-</li>\n<li>&#x3D;&#x3D;, !&#x3D;, &lt;&#x3D;, &lt;, &gt;&#x3D;,&gt;</li>\n<li>and,unless</li>\n<li>or</li>\n</ol>\n<p>相同优先级的运算符是左结合的<br>相同优先级的运算符（+ 和 -）是左结合的。这意味着在表达式中，加法和减法运算将按照从左到右的顺序进行。</p>\n<p>例如，考虑以下PromQL表达式：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a + b - c</span><br></pre></td></tr></table></figure>\n<p>在这个表达式中，加法运算符（+）和减法运算符（-）具有相同的优先级。根据左结合的规则，这个表达式将首先执行加法运算，然后再执行减法运算。换句话说，计算顺序将是先计算”a + b”，然后将结果与”c”相减。</p>\n<p>PromQL中的atan2函数用于计算两个数值的反正切值。它接受两个参数，并返回一个介于-π&#x2F;2和π&#x2F;2之间的值，表示从原点到点(y, x)的角度。</p>\n<p>具体来说，atan2(y, x)返回的角度是满足以下条件的唯一角度θ：</p>\n<p>θ在-π&#x2F;2和π&#x2F;2之间；<br>点(x, y)位于以原点为圆心、半径为1的圆上；<br>点(x, y)与极坐标中的点(1, θ)对应。<br>与atan函数不同的是，atan2考虑了y和x的值之间的比例关系，因此能够更准确地描述角度的变化。在处理二维空间中的角度计算时，atan2函数通常比atan函数更常用。</p>\n<p>以下是一个PromQL中使用atan2函数的示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum(rate(vector_field[1m])) * 100 / atan2(1, 1)</span><br></pre></td></tr></table></figure>\n<p>这个示例中，使用rate函数计算了一个名为vector_field的时间序列的1分钟平均值，并将其乘以100。然后，通过使用atan2函数将结果除以1和1之间的反正切值，得到一个归一化的结果。</p>\n<h3 id=\"聚合运算符\"><a href=\"#聚合运算符\" class=\"headerlink\" title=\"聚合运算符\"></a>聚合运算符</h3><p>Prometheus 支持以下内置聚合运算符，可用于聚合单个瞬时向量，生成新的向量：</p>\n<ul>\n<li>sum（总和）</li>\n<li>min（最小）</li>\n<li>max（最大）</li>\n<li>avg（平均值）</li>\n<li>group（分组）</li>\n<li>stddev（标准偏差）</li>\n<li>stdvar（标准方差）</li>\n<li>count（计算向量中的元素个数）</li>\n<li>count_values（计算具有相同值的元素个数）</li>\n<li>bottomk（样本值的最小 k 个元素）</li>\n<li>topk（按样本值计算的最大 k 个元素）</li>\n<li>quantile（分位数计算 φ-quantile (0 ≤ φ ≤ 1)</li>\n</ul>\n<p>聚合运算符可通过 without、by 根据标签扩展</p>\n<p>sum、min、max、avg：</p>\n<p>计算http请求的总和，最大、最小请求的url的数量，平均数量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum(prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-140.png\" alt=\"Alt text\"><br>通过状态码分别统计<br><img src=\"/image-141.png\" alt=\"Alt text\"><br>group:</p>\n<p>类uniq的用法<br><img src=\"/image-142.png\" alt=\"Alt text\"></p>\n<p>stddev、stdvar：</p>\n<p>反映一组数据离散程度，用以衡量数据值偏离算术平均值的程度。标准偏差为方差的开平方，标准偏差越小，这些值偏离平均值就越少，反之亦然。</p>\n<p>通过标准差来反映网络波动</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stddev(rate(node_network_transmit_bytes_total[5m]))</span><br></pre></td></tr></table></figure>\n<p>rate计算某段时间的速率<br><img src=\"/image-143.png\" alt=\"Alt text\"><br>count、count_values:</p>\n<p>统计总共有几个时序</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">count(prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-144.png\" alt=\"Alt text\"><br>计算每个value的数量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">count_values(&quot;value&quot;,prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-145.png\" alt=\"Alt text\"></p>\n<p>bottomk、topk</p>\n<p>计算value中最小的5个时序</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bottomk(5,prometheus_http_requests_total)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-146.png\" alt=\"Alt text\"></p>\n<p>quantile:求数据的分位数</p>\n<p>我们现在要找出K8s集群中所有node节点的内存使用率的分布情况:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">quantile</span><br><span class=\"line\">(0.8,</span><br><span class=\"line\">(</span><br><span class=\"line\">1 -</span><br><span class=\"line\">node_memory_MemAvailable_bytes&#123;job=&quot;kubernetes-service-endpoints&quot;&#125; </span><br><span class=\"line\">/ node_memory_MemTotal_bytes&#123;job=&quot;kubernetes-service-endpoints&quot;&#125;</span><br><span class=\"line\">)</span><br><span class=\"line\">* 100</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/image-147.png\" alt=\"Alt text\"></p>\n<p>直接可以看出80%的节点内存使用率在68%以下</p>\n<h2 id=\"函数\"><a href=\"#函数\" class=\"headerlink\" title=\"函数\"></a>函数</h2><h3 id=\"值取整\"><a href=\"#值取整\" class=\"headerlink\" title=\"值取整\"></a>值取整</h3><h4 id=\"ceil\"><a href=\"#ceil\" class=\"headerlink\" title=\"ceil()\"></a>ceil()</h4><p>ceil(v instant-vector)样本数据向上取整。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceil(node_load1)  #1.2--&gt;2</span><br></pre></td></tr></table></figure>\n<h4 id=\"floor\"><a href=\"#floor\" class=\"headerlink\" title=\"floor()\"></a>floor()</h4><p>floor(v instant-vector)与ceil()相反，floor()样本值向下取整。</p>\n<h4 id=\"round\"><a href=\"#round\" class=\"headerlink\" title=\"round()\"></a>round()</h4><p>round(v instant-vector, to_nearest&#x3D;1 scalar) 对样本值四舍五入取整。to_nearest参数是可选的,默认为 1,表示样本返回的是最接近 1 的整数倍的值，参数可以为分数。</p>\n<p>取整</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">round(prometheus_engine_query_duration_seconds_sum)</span><br></pre></td></tr></table></figure>\n<p>取整到最近的5的倍数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">round(prometheus_engine_query_duration_seconds_sum,5)</span><br></pre></td></tr></table></figure>\n<h3 id=\"值截取\"><a href=\"#值截取\" class=\"headerlink\" title=\"值截取\"></a>值截取</h3><h4 id=\"clamp\"><a href=\"#clamp\" class=\"headerlink\" title=\"clamp()\"></a>clamp()</h4><p>clamp(v instant-vector, min scalar, max scalar) 截取所有元素的样本值在 [min,max]集合内的样本,如果min&gt;max返回NaN</p>\n<p>放回样本值在10到20的样本</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">clamp(prometheus_http_requests_total,10,20)</span><br></pre></td></tr></table></figure>\n<h4 id=\"clamp-max\"><a href=\"#clamp-max\" class=\"headerlink\" title=\"clamp_max()\"></a>clamp_max()</h4><p>clamp_max(v instant-vector, max scalar) 同clamp()，不过只限定样本最大值</p>\n<h4 id=\"clamp-min\"><a href=\"#clamp-min\" class=\"headerlink\" title=\"clamp_min()\"></a>clamp_min()</h4><p>clamp_min(v instant-vector, min scalar) 同clamp()，不过只限定样本最小值</p>\n<h3 id=\"值变化统计\"><a href=\"#值变化统计\" class=\"headerlink\" title=\"值变化统计\"></a>值变化统计</h3><h4 id=\"changes\"><a href=\"#changes\" class=\"headerlink\" title=\"changes()\"></a>changes()</h4><p>changes(v range-vector)返回某段时间内样本值改变的次数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">changes(node_load1[1m])</span><br></pre></td></tr></table></figure>\n<h3 id=\"复位统计\"><a href=\"#复位统计\" class=\"headerlink\" title=\"复位统计\"></a>复位统计</h3><h4 id=\"resets\"><a href=\"#resets\" class=\"headerlink\" title=\"resets()\"></a>resets()</h4><p>resets(v range-vector) 返回样本范围时间内的复位次数。与counter使用，两个连续样本之间值如有减少则被视为计数器复位。</p>\n<p>查看上下文交换次数计数器在5分钟内复位次数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">resets(node_context_switches_total[5m])</span><br></pre></td></tr></table></figure>\n<h3 id=\"日期与时间管理\"><a href=\"#日期与时间管理\" class=\"headerlink\" title=\"日期与时间管理\"></a>日期与时间管理</h3><h4 id=\"day-of-month\"><a href=\"#day-of-month\" class=\"headerlink\" title=\"day_of_month()\"></a>day_of_month()</h4><p>day_of_month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份中的日期（1-31）</p>\n<p>v&#x3D;vector(time()) 为默认参数</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">day_of_month(node_boot_time_seconds)</span><br></pre></td></tr></table></figure>\n<h4 id=\"day-of-week\"><a href=\"#day-of-week\" class=\"headerlink\" title=\"day_of_week()\"></a>day_of_week()</h4><p>day_of_week(v&#x3D;vector(time()) instant-vector)同上，如果样本值是utc时间，则返回这个时间所属星期几（0-6）</p>\n<h4 id=\"days-in-month\"><a href=\"#days-in-month\" class=\"headerlink\" title=\"days_in_month()\"></a>days_in_month()</h4><p>days_in_month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属月份的天数（28-31）</p>\n<h4 id=\"hour\"><a href=\"#hour\" class=\"headerlink\" title=\"hour()\"></a>hour()</h4><p>hour(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属一天中的第几个小时（1-13）</p>\n<h4 id=\"minute\"><a href=\"#minute\" class=\"headerlink\" title=\"minute()\"></a>minute()</h4><p>minute(v&#x3D;vector(time()) instant-vector) 如果样本值是utc时间，则返回这个时间所属小时中的第几分钟（1-59）</p>\n<h4 id=\"month\"><a href=\"#month\" class=\"headerlink\" title=\"month()\"></a>month()</h4><p>month(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的月份（1-12）</p>\n<h4 id=\"year\"><a href=\"#year\" class=\"headerlink\" title=\"year()\"></a>year()</h4><p>year(v&#x3D;vector(time()) instant-vector)如果样本值是utc时间，则返回这个时间所属的年份</p>\n<h4 id=\"time\"><a href=\"#time\" class=\"headerlink\" title=\"time()\"></a>time()</h4><p>返回自1970 年 1 月 1 日 UTC 以来的秒数，不是系统时间，而是表达式计算时那一刻的时间。</p>\n<h4 id=\"timestamp\"><a href=\"#timestamp\" class=\"headerlink\" title=\"timestamp()\"></a>timestamp()</h4><p>timestamp(v instant-vector)返回每个样本值的时间戳，自 1970 年 1 月 1 日 UTC 以来的秒数。</p>\n<h3 id=\"直方图分位数\"><a href=\"#直方图分位数\" class=\"headerlink\" title=\"直方图分位数\"></a>直方图分位数</h3><h4 id=\"histogram-quantile\"><a href=\"#histogram-quantile\" class=\"headerlink\" title=\"histogram_quantile()\"></a>histogram_quantile()</h4><p>histogram_quantile(φ float, b instant-vector) 从 bucket 类型的向量 b 中计算 φ (0 ≤ φ ≤ 1) 分位数的样本的最大值，与聚合运算符quantile相似。</p>\n<p>计算80%请求的持续时间最大值。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">histogram_quantile(0.8,rate(prometheus_http_request_duration_seconds_bucket[1d]))</span><br></pre></td></tr></table></figure>\n<h3 id=\"差异与增长率\"><a href=\"#差异与增长率\" class=\"headerlink\" title=\"差异与增长率\"></a>差异与增长率</h3><h4 id=\"delta\"><a href=\"#delta\" class=\"headerlink\" title=\"delta()\"></a>delta()</h4><p>delta(v range-vector)计算范围向量中每个时间序列元素的第一个值和最后一个值之间的差。与指标类型gauge一起使用</p>\n<p>计算一天内内存可用量的变化</p>\n<p>delta(node_memory_MemAvailable_bytes[1d])</p>\n<h4 id=\"idelta\"><a href=\"#idelta\" class=\"headerlink\" title=\"idelta()\"></a>idelta()</h4><p>idelta(v range-vector)计算范围向量中最后两个样本之间的差异。与指标类型gauge一起使用</p>\n<p>idelta(node_memory_MemAvailable_bytes[1m])</p>\n<h4 id=\"increase\"><a href=\"#increase\" class=\"headerlink\" title=\"increase()\"></a>increase()</h4><p>increase(v range-vector) 计算时间范围内的增量，与counter一起使用。它是速率rate(v)乘以时间范围内秒数的语法糖，主要用于人类可读性。</p>\n<p>计算10分钟内请求增长量</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">increase(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure>\n<h4 id=\"rate\"><a href=\"#rate\" class=\"headerlink\" title=\"rate()\"></a>rate()</h4><p>rate(v range-vector)计算范围向量中时间序列的平均每秒增长率。</p>\n<p>过去10分钟请求平均每秒增长率，与counter一起使用。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rate(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure>\n<h4 id=\"irate\"><a href=\"#irate\" class=\"headerlink\" title=\"irate()\"></a>irate()</h4><p>irate(v range-vector) 通过时间范围的最后两个点来计算每秒瞬时增长率。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">irate(prometheus_http_requests_total[10m])</span><br></pre></td></tr></table></figure>\n<h3 id=\"label管理\"><a href=\"#label管理\" class=\"headerlink\" title=\"label管理\"></a>label管理</h3><h4 id=\"label-join\"><a href=\"#label-join\" class=\"headerlink\" title=\"label_join()\"></a>label_join()</h4><p>label_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, …)为每个时间序列添加一个label，值为指定旧label的value连接</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">label_join(up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;,&quot;new_label&quot;,&quot;-&quot;,&quot;instance&quot;,&quot;job&quot;)</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;, new_label=&quot;localhost:9100-node&quot;&#125;   1</span><br></pre></td></tr></table></figure>\n<h4 id=\"label-replace\"><a href=\"#label-replace\" class=\"headerlink\" title=\"label_replace()\"></a>label_replace()</h4><p>label_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string)从源label中获取value元素用于添加新的label</p>\n<p>$1 获取正则匹配，匹配值添加到hello标签中</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">label_replace(up&#123;instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;,&quot;hello&quot;,&quot;$1&quot;,&quot;job&quot;,&quot;(.*)&quot;)</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">up&#123;hello=&quot;node&quot;, instance=&quot;localhost:9100&quot;, job=&quot;node&quot;&#125;       1</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"预测\"><a href=\"#预测\" class=\"headerlink\" title=\"预测\"></a>预测</h3><h4 id=\"predict-linear\"><a href=\"#predict-linear\" class=\"headerlink\" title=\"predict_linear()\"></a>predict_linear()</h4><p>predict_linear(v range-vector, t scalar) 通过简单线性回归预测t秒后的样本值，与gauge一起使用。</p>\n<p>根据过去1小时的文件系统剩余空间量，预测1小时之后的剩余空间</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predict_linear(node_filesystem_free_bytes[1h],3600)</span><br></pre></td></tr></table></figure>\n<h3 id=\"转换\"><a href=\"#转换\" class=\"headerlink\" title=\"转换\"></a>转换</h3><h4 id=\"absent\"><a href=\"#absent\" class=\"headerlink\" title=\"absent()\"></a>absent()</h4><p>absent(v instant-vector)如果向量有元素，则返回一个空向量；如果向量没有元素，则返回值为 1。</p>\n<p>设置如下告警表达式：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">absent(up&#123;job=&quot;node&quot;&#125; == 1)</span><br></pre></td></tr></table></figure>\n<p>由于up{job&#x3D;”node”}不存在或值不为1则告警表达式的值为1 产生告警</p>\n<h4 id=\"absent-over-time\"><a href=\"#absent-over-time\" class=\"headerlink\" title=\"absent_over_time()\"></a>absent_over_time()</h4><p>absent_over_time(v range-vector)如果范围向量有元素，则返回一个空向量；如果范围向量没有元素，则返回值为 1。</p>\n<p>如果up{job&#x3D;”node1”}在某段时间不存在则返回1</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">absent_over_time(up&#123;job=&quot;node1&quot;&#125;[1h])</span><br></pre></td></tr></table></figure>\n<h4 id=\"scalar\"><a href=\"#scalar\" class=\"headerlink\" title=\"scalar()\"></a>scalar()</h4><p>scalar(v instant-vector)以标量形式返回该单元素的样本值,如果输入向量不是正好一个元素，scalar将返回NaN.</p>\n<h4 id=\"vector\"><a href=\"#vector\" class=\"headerlink\" title=\"vector()\"></a>vector()</h4><p>vector(s scalar)将标量作为没有标签的向量返回。</p>\n<h4 id=\"sgn\"><a href=\"#sgn\" class=\"headerlink\" title=\"sgn()\"></a>sgn()</h4><p>sgn(v instant-vector)返回一个向量，其中所有样本值都转换为1或-1或0</p>\n<p>定义如下：</p>\n<p>如果 v 为正，则为 1</p>\n<p>如果 v 为负，则为 -1</p>\n<p>如果 v 等于 0，则为 0。</p>\n<h3 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h3><h4 id=\"sort\"><a href=\"#sort\" class=\"headerlink\" title=\"sort()\"></a>sort()</h4><p>sort(v instant-vector)返回按样本值升序排序的向量元素。</p>\n<h4 id=\"sort-desc\"><a href=\"#sort-desc\" class=\"headerlink\" title=\"sort_desc()\"></a>sort_desc()</h4><p>与sort()相反，按降序排序。</p>\n<h4 id=\"over-time\"><a href=\"#over-time\" class=\"headerlink\" title=\"_over_time()\"></a>_over_time()</h4><p>下面的函数列表允许传入一个范围向量，返回一个带有聚合的瞬时向量：</p>\n<ul>\n<li>avg_over_time(range-vector): 区间向量内每个度量指标的平均值。</li>\n<li>min_over_time(range-vector): 区间向量内每个度量指标的最小值。</li>\n<li>max_over_time(range-vector): 区间向量内每个度量指标的最大值。</li>\n<li>sum_over_time(range-vector): 区间向量内每个度量指标的求和值。</li>\n<li>count_over_time(range-vector): 区间向量内每个度量指标的样本数据个数。</li>\n<li>quantile_over_time(scalar, range-vector): 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)</li>\n<li>stddev_over_time(range-vector): 区间向量内每个度量指标的总体标准偏差。</li>\n<li>stdvar_over_time(range-vector): 区间向量内每个度量指标的总体标准方差</li>\n</ul>\n<h3 id=\"数学函数\"><a href=\"#数学函数\" class=\"headerlink\" title=\"数学函数\"></a>数学函数</h3><h4 id=\"abs\"><a href=\"#abs\" class=\"headerlink\" title=\"abs()\"></a>abs()</h4><p>abs(v instant-vector)返回样本的绝对值。</p>\n<h4 id=\"sqrt\"><a href=\"#sqrt\" class=\"headerlink\" title=\"sqrt()\"></a>sqrt()</h4><p>sqrt(v instant-vector)计算样本值的平方根。</p>\n<h4 id=\"deriv\"><a href=\"#deriv\" class=\"headerlink\" title=\"deriv()\"></a>deriv()</h4><p>deriv(v range-vector) 使用简单线性回归计算时间序列在范围向量中的每秒导数。与指标类型gauge一起使用</p>\n<h4 id=\"exp\"><a href=\"#exp\" class=\"headerlink\" title=\"exp()\"></a>exp()</h4><p>exp(v instant-vector)计算样本值的指数函数。</p>\n<p>特殊情况：</p>\n<ul>\n<li>Exp(+Inf) &#x3D; +Inf</li>\n<li>Exp(NaN) &#x3D; NaN</li>\n</ul>\n<h4 id=\"ln-、log2-、log10\"><a href=\"#ln-、log2-、log10\" class=\"headerlink\" title=\"ln()、log2()、log10()\"></a>ln()、log2()、log10()</h4><p>ln&#x2F;log2&#x2F;log10(v instant-vector) 计算样本值对数</p>\n<p>特殊情况（同适用于log2&#x2F;log10）：</p>\n<ul>\n<li>ln(+Inf) &#x3D; +Inf</li>\n<li>ln(0) &#x3D; -Inf</li>\n<li>ln(x &lt; 0) &#x3D; NaN</li>\n<li>ln(NaN) &#x3D; NaN</li>\n</ul>\n<h4 id=\"holt-winters\"><a href=\"#holt-winters\" class=\"headerlink\" title=\"holt_winters()\"></a>holt_winters()</h4><p>holt_winters(v range-vector, sf scalar, tf scalar)基于访问向量v，生成时间序列数据平滑数据值。平滑因子sf越低, 对旧数据越重要。趋势因子tf越高，更关心趋势数据。0&lt;sf,tf&lt;&#x3D;1。 与gauge一起使用</p>\n<h3 id=\"三角函数、弧度\"><a href=\"#三角函数、弧度\" class=\"headerlink\" title=\"三角函数、弧度\"></a>三角函数、弧度</h3><ul>\n<li>acos(v instant-vector)</li>\n<li>acosh(v instant-vector)</li>\n<li>asin(v instant-vector)</li>\n<li>asinh(v instant-vector)</li>\n<li>atan(v instant-vector)</li>\n<li>atanh(v instant-vector)</li>\n<li>cos(v instant-vector)</li>\n<li>cosh(v instant-vector)</li>\n<li>sin(v instant-vector)</li>\n<li>sinh(v instant-vector)</li>\n<li>tan(v instant-vector)</li>\n<li>tanh(v instant-vector)</li>\n</ul>\n<h3 id=\"角度、弧度转化\"><a href=\"#角度、弧度转化\" class=\"headerlink\" title=\"角度、弧度转化\"></a>角度、弧度转化</h3><ul>\n<li>deg(v instant-vector)</li>\n<li>pi()</li>\n<li>rad(v instant-vector)</li>\n</ul>\n<p>原文地址: <a href=\"https://zhuanlan.zhihu.com/p/477177336\">https://zhuanlan.zhihu.com/p/477177336</a></p>\n"},{"title":"SNAT和DNAT","date":"2023-11-03T07:20:21.000Z","_content":"1.SNAT和DNAT都是网络地址转换技术，有什么不同？\nSNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。\nDNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。\n总的来说，SNAT和DNAT都是网络地址转换技术，但它们的作用不同。SNAT主要用于隐藏内部网络的真实IP地址，增强网络的安全性；DNAT主要用于将外部网络的请求路由到内部网络的某个主机上，实现网络服务的访问。\n\n2.SNAT也能解决路由的问题吧？例如源地址为内网ip，通过转换为外部ip，实现对外部资源的访问？\nSNAT也可以解决路由的问题。当内部网络的主机需要访问外部网络的资源时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就可以将数据包路由回内部网络的主机。通过这种方式，SNAT可以实现内部网络主机对外部资源的访问。\n在这种情况下，SNAT的作用类似于一个代理服务器。内部网络的主机将数据包发送到代理服务器，代理服务器将数据包的源IP地址修改为一个公共IP地址，然后将数据包发送到外部网络。外部网络将数据包路由回代理服务器，代理服务器再将数据包的源IP地址修改为内部网络的真实IP地址，最终将数据包发送到内部网络的主机。\n需要注意的是，SNAT只能实现单向的路由，即内部网络主机访问外部资源。如果外部网络的主机需要访问内部网络的资源，就需要使用DNAT技术将外部网络的请求路由到内部网络的某个主机上。\n\n3.DNAT也是可以解决访问的问题，作为回包路由转换？\nDNAT也可以解决访问的问题。当外部网络的主机需要访问内部网络的资源时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。通过这种方式，DNAT可以实现外部网络主机对内部资源的访问。\n在这种情况下，DNAT的作用类似于一个端口映射。外部网络的主机将数据包发送到DNAT设备，DNAT设备将数据包的目标IP地址修改为内部网络的某个主机的IP地址，然后将数据包发送到内部网络。内部网络将数据包的回复发送到DNAT设备，DNAT设备再将数据包的目标IP地址修改为外部网络的真实IP地址，最终将数据包发送到外部网络的主机。\n需要注意的是，DNAT只能实现单向的路由，即外部网络主机访问内部网络资源。如果内部网络的主机需要访问外部网络的资源，就需要使用SNAT技术将数据包的源IP地址修改为一个公共IP地址，从而实现数据包的路由。\n\n4.SNAT和DNAT，仅仅时转化ip的区别吗？\nSNAT和DNAT的区别不仅仅是转换IP地址的不同，它们的作用和应用场景也不同。\nSNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。同时，SNAT还可以实现负载均衡功能，将网络流量分配到多个服务器上，提高网络的性能和可靠性。\n\nDNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。同时，DNAT还可以实现端口映射功能，将外部网络的请求映射到内部网络的某个端口上，提高网络的灵活性和可扩展性。\n\n因此，虽然SNAT和DNAT都是网络地址转换技术，但它们的作用和应用场景不同，不能简单地认为它们只是转换IP地址的区别。\n————————————————\n版权声明：本文为CSDN博主「NTZ5bzZKdUw」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n原文链接：https://blog.csdn.net/qq_41152046/article/details/130029737","source":"_posts/kubernetes/snat-dnat.md","raw":"---\ntitle: SNAT和DNAT\ndate: 2023-11-03 15:20:21\ncategories:\n  - [kubernetes]\ntags: 计算机网络\n---\n1.SNAT和DNAT都是网络地址转换技术，有什么不同？\nSNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。\nDNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。\n总的来说，SNAT和DNAT都是网络地址转换技术，但它们的作用不同。SNAT主要用于隐藏内部网络的真实IP地址，增强网络的安全性；DNAT主要用于将外部网络的请求路由到内部网络的某个主机上，实现网络服务的访问。\n\n2.SNAT也能解决路由的问题吧？例如源地址为内网ip，通过转换为外部ip，实现对外部资源的访问？\nSNAT也可以解决路由的问题。当内部网络的主机需要访问外部网络的资源时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就可以将数据包路由回内部网络的主机。通过这种方式，SNAT可以实现内部网络主机对外部资源的访问。\n在这种情况下，SNAT的作用类似于一个代理服务器。内部网络的主机将数据包发送到代理服务器，代理服务器将数据包的源IP地址修改为一个公共IP地址，然后将数据包发送到外部网络。外部网络将数据包路由回代理服务器，代理服务器再将数据包的源IP地址修改为内部网络的真实IP地址，最终将数据包发送到内部网络的主机。\n需要注意的是，SNAT只能实现单向的路由，即内部网络主机访问外部资源。如果外部网络的主机需要访问内部网络的资源，就需要使用DNAT技术将外部网络的请求路由到内部网络的某个主机上。\n\n3.DNAT也是可以解决访问的问题，作为回包路由转换？\nDNAT也可以解决访问的问题。当外部网络的主机需要访问内部网络的资源时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。通过这种方式，DNAT可以实现外部网络主机对内部资源的访问。\n在这种情况下，DNAT的作用类似于一个端口映射。外部网络的主机将数据包发送到DNAT设备，DNAT设备将数据包的目标IP地址修改为内部网络的某个主机的IP地址，然后将数据包发送到内部网络。内部网络将数据包的回复发送到DNAT设备，DNAT设备再将数据包的目标IP地址修改为外部网络的真实IP地址，最终将数据包发送到外部网络的主机。\n需要注意的是，DNAT只能实现单向的路由，即外部网络主机访问内部网络资源。如果内部网络的主机需要访问外部网络的资源，就需要使用SNAT技术将数据包的源IP地址修改为一个公共IP地址，从而实现数据包的路由。\n\n4.SNAT和DNAT，仅仅时转化ip的区别吗？\nSNAT和DNAT的区别不仅仅是转换IP地址的不同，它们的作用和应用场景也不同。\nSNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。同时，SNAT还可以实现负载均衡功能，将网络流量分配到多个服务器上，提高网络的性能和可靠性。\n\nDNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。同时，DNAT还可以实现端口映射功能，将外部网络的请求映射到内部网络的某个端口上，提高网络的灵活性和可扩展性。\n\n因此，虽然SNAT和DNAT都是网络地址转换技术，但它们的作用和应用场景不同，不能简单地认为它们只是转换IP地址的区别。\n————————————————\n版权声明：本文为CSDN博主「NTZ5bzZKdUw」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n原文链接：https://blog.csdn.net/qq_41152046/article/details/130029737","slug":"kubernetes/snat-dnat","published":1,"updated":"2023-11-03T07:21:18.064Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0cf001cfmjxfh4qcr97","content":"<p>1.SNAT和DNAT都是网络地址转换技术，有什么不同？<br>SNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。<br>DNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。<br>总的来说，SNAT和DNAT都是网络地址转换技术，但它们的作用不同。SNAT主要用于隐藏内部网络的真实IP地址，增强网络的安全性；DNAT主要用于将外部网络的请求路由到内部网络的某个主机上，实现网络服务的访问。</p>\n<p>2.SNAT也能解决路由的问题吧？例如源地址为内网ip，通过转换为外部ip，实现对外部资源的访问？<br>SNAT也可以解决路由的问题。当内部网络的主机需要访问外部网络的资源时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就可以将数据包路由回内部网络的主机。通过这种方式，SNAT可以实现内部网络主机对外部资源的访问。<br>在这种情况下，SNAT的作用类似于一个代理服务器。内部网络的主机将数据包发送到代理服务器，代理服务器将数据包的源IP地址修改为一个公共IP地址，然后将数据包发送到外部网络。外部网络将数据包路由回代理服务器，代理服务器再将数据包的源IP地址修改为内部网络的真实IP地址，最终将数据包发送到内部网络的主机。<br>需要注意的是，SNAT只能实现单向的路由，即内部网络主机访问外部资源。如果外部网络的主机需要访问内部网络的资源，就需要使用DNAT技术将外部网络的请求路由到内部网络的某个主机上。</p>\n<p>3.DNAT也是可以解决访问的问题，作为回包路由转换？<br>DNAT也可以解决访问的问题。当外部网络的主机需要访问内部网络的资源时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。通过这种方式，DNAT可以实现外部网络主机对内部资源的访问。<br>在这种情况下，DNAT的作用类似于一个端口映射。外部网络的主机将数据包发送到DNAT设备，DNAT设备将数据包的目标IP地址修改为内部网络的某个主机的IP地址，然后将数据包发送到内部网络。内部网络将数据包的回复发送到DNAT设备，DNAT设备再将数据包的目标IP地址修改为外部网络的真实IP地址，最终将数据包发送到外部网络的主机。<br>需要注意的是，DNAT只能实现单向的路由，即外部网络主机访问内部网络资源。如果内部网络的主机需要访问外部网络的资源，就需要使用SNAT技术将数据包的源IP地址修改为一个公共IP地址，从而实现数据包的路由。</p>\n<p>4.SNAT和DNAT，仅仅时转化ip的区别吗？<br>SNAT和DNAT的区别不仅仅是转换IP地址的不同，它们的作用和应用场景也不同。<br>SNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。同时，SNAT还可以实现负载均衡功能，将网络流量分配到多个服务器上，提高网络的性能和可靠性。</p>\n<p>DNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。同时，DNAT还可以实现端口映射功能，将外部网络的请求映射到内部网络的某个端口上，提高网络的灵活性和可扩展性。</p>\n<p>因此，虽然SNAT和DNAT都是网络地址转换技术，但它们的作用和应用场景不同，不能简单地认为它们只是转换IP地址的区别。<br>————————————————<br>版权声明：本文为CSDN博主「NTZ5bzZKdUw」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href=\"https://blog.csdn.net/qq_41152046/article/details/130029737\">https://blog.csdn.net/qq_41152046/article/details/130029737</a></p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>1.SNAT和DNAT都是网络地址转换技术，有什么不同？<br>SNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。<br>DNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。<br>总的来说，SNAT和DNAT都是网络地址转换技术，但它们的作用不同。SNAT主要用于隐藏内部网络的真实IP地址，增强网络的安全性；DNAT主要用于将外部网络的请求路由到内部网络的某个主机上，实现网络服务的访问。</p>\n<p>2.SNAT也能解决路由的问题吧？例如源地址为内网ip，通过转换为外部ip，实现对外部资源的访问？<br>SNAT也可以解决路由的问题。当内部网络的主机需要访问外部网络的资源时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就可以将数据包路由回内部网络的主机。通过这种方式，SNAT可以实现内部网络主机对外部资源的访问。<br>在这种情况下，SNAT的作用类似于一个代理服务器。内部网络的主机将数据包发送到代理服务器，代理服务器将数据包的源IP地址修改为一个公共IP地址，然后将数据包发送到外部网络。外部网络将数据包路由回代理服务器，代理服务器再将数据包的源IP地址修改为内部网络的真实IP地址，最终将数据包发送到内部网络的主机。<br>需要注意的是，SNAT只能实现单向的路由，即内部网络主机访问外部资源。如果外部网络的主机需要访问内部网络的资源，就需要使用DNAT技术将外部网络的请求路由到内部网络的某个主机上。</p>\n<p>3.DNAT也是可以解决访问的问题，作为回包路由转换？<br>DNAT也可以解决访问的问题。当外部网络的主机需要访问内部网络的资源时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。通过这种方式，DNAT可以实现外部网络主机对内部资源的访问。<br>在这种情况下，DNAT的作用类似于一个端口映射。外部网络的主机将数据包发送到DNAT设备，DNAT设备将数据包的目标IP地址修改为内部网络的某个主机的IP地址，然后将数据包发送到内部网络。内部网络将数据包的回复发送到DNAT设备，DNAT设备再将数据包的目标IP地址修改为外部网络的真实IP地址，最终将数据包发送到外部网络的主机。<br>需要注意的是，DNAT只能实现单向的路由，即外部网络主机访问内部网络资源。如果内部网络的主机需要访问外部网络的资源，就需要使用SNAT技术将数据包的源IP地址修改为一个公共IP地址，从而实现数据包的路由。</p>\n<p>4.SNAT和DNAT，仅仅时转化ip的区别吗？<br>SNAT和DNAT的区别不仅仅是转换IP地址的不同，它们的作用和应用场景也不同。<br>SNAT是“Source Network Address Translation”的缩写，指的是一种将源IP地址转换为另一个IP地址的技术。在网络通信中，当内部网络的主机向外部网络发送数据包时，数据包的源IP地址会被修改为一个公共IP地址，这样外部网络就无法直接访问内部网络的真实IP地址。SNAT的主要作用是隐藏内部网络的真实IP地址，从而增强网络的安全性。同时，SNAT还可以实现负载均衡功能，将网络流量分配到多个服务器上，提高网络的性能和可靠性。</p>\n<p>DNAT是“Destination Network Address Translation”的缩写，指的是一种将目标IP地址转换为另一个IP地址的技术。在网络通信中，当外部网络的主机向内部网络发送数据包时，数据包的目标IP地址会被修改为内部网络的某个主机的IP地址，从而实现数据包的路由。DNAT的主要作用是将外部网络的请求路由到内部网络的某个主机上，从而实现网络服务的访问。同时，DNAT还可以实现端口映射功能，将外部网络的请求映射到内部网络的某个端口上，提高网络的灵活性和可扩展性。</p>\n<p>因此，虽然SNAT和DNAT都是网络地址转换技术，但它们的作用和应用场景不同，不能简单地认为它们只是转换IP地址的区别。<br>————————————————<br>版权声明：本文为CSDN博主「NTZ5bzZKdUw」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href=\"https://blog.csdn.net/qq_41152046/article/details/130029737\">https://blog.csdn.net/qq_41152046/article/details/130029737</a></p>\n"},{"title":"uninstall containerd","date":"2023-08-22T03:39:52.000Z","_content":"要彻底清除 Kubernetes 集群节点上的 containerd，可以按照以下步骤进行：\n\nStep 1: 停止并移除所有运行的容器\n```\n$ crictl ps -a | awk '{if(NR>1) print $1}' | xargs -I {} crictl rm {}\n```\n这将停止并删除节点上所有正在运行的容器。\n\nStep 2: 停止并禁用 containerd 服务\n```\n$ systemctl stop containerd\n$ systemctl disable containerd\n```\n这将停止并禁用 containerd 服务。\n\nStep 3: 卸载 containerd 软件包\n```\n$ yum remove containerd -y\n```\n根据你的系统，可能需要使用适当的软件包管理器（如apt、dnf）来移除 containerd 软件包。\n\nStep 4: 删除 containerd 配置目录\n```\n$ rm -rf /etc/containerd\n```\n这将删除 containerd 的配置文件。\n\nStep 5: 删除 containerd 数据目录\n```\n$ rm -rf /var/lib/containerd\n```\n这将删除 containerd 的数据目录。\n\nStep 6: 清理 containerd 相关的 iptables 规则\n```\n$ iptables -t nat -F\n$ iptables -t mangle -F\n```\n这将清除与 containerd 相关的 iptables 规则。\n\nStep 7: 检查是否有残留的 containerd 配置文件\n```\n$ ls /etc/systemd/system/containerd*\n```\n如果输出中有任何文件，则手动删除它们：\n```\n$ rm /etc/systemd/system/containerd*.service\n```\n\n现在，你的 Kubernetes 集群节点上的 containerd 已经彻底卸载。","source":"_posts/kubernetes/uninstall_cintainerd.md","raw":"---\ntitle: uninstall containerd\ndate: 2023-08-22 11:39:52\ncategories:\n  - [kubernetes]\ntags: containerd\n---\n要彻底清除 Kubernetes 集群节点上的 containerd，可以按照以下步骤进行：\n\nStep 1: 停止并移除所有运行的容器\n```\n$ crictl ps -a | awk '{if(NR>1) print $1}' | xargs -I {} crictl rm {}\n```\n这将停止并删除节点上所有正在运行的容器。\n\nStep 2: 停止并禁用 containerd 服务\n```\n$ systemctl stop containerd\n$ systemctl disable containerd\n```\n这将停止并禁用 containerd 服务。\n\nStep 3: 卸载 containerd 软件包\n```\n$ yum remove containerd -y\n```\n根据你的系统，可能需要使用适当的软件包管理器（如apt、dnf）来移除 containerd 软件包。\n\nStep 4: 删除 containerd 配置目录\n```\n$ rm -rf /etc/containerd\n```\n这将删除 containerd 的配置文件。\n\nStep 5: 删除 containerd 数据目录\n```\n$ rm -rf /var/lib/containerd\n```\n这将删除 containerd 的数据目录。\n\nStep 6: 清理 containerd 相关的 iptables 规则\n```\n$ iptables -t nat -F\n$ iptables -t mangle -F\n```\n这将清除与 containerd 相关的 iptables 规则。\n\nStep 7: 检查是否有残留的 containerd 配置文件\n```\n$ ls /etc/systemd/system/containerd*\n```\n如果输出中有任何文件，则手动删除它们：\n```\n$ rm /etc/systemd/system/containerd*.service\n```\n\n现在，你的 Kubernetes 集群节点上的 containerd 已经彻底卸载。","slug":"kubernetes/uninstall_cintainerd","published":1,"updated":"2023-08-22T07:29:52.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0ch001ffmjxcs7yg34l","content":"<p>要彻底清除 Kubernetes 集群节点上的 containerd，可以按照以下步骤进行：</p>\n<p>Step 1: 停止并移除所有运行的容器</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl ps -a | awk &#x27;&#123;if(NR&gt;1) print $1&#125;&#x27; | xargs -I &#123;&#125; crictl rm &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>这将停止并删除节点上所有正在运行的容器。</p>\n<p>Step 2: 停止并禁用 containerd 服务</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl stop containerd</span><br><span class=\"line\">$ systemctl disable containerd</span><br></pre></td></tr></table></figure>\n<p>这将停止并禁用 containerd 服务。</p>\n<p>Step 3: 卸载 containerd 软件包</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum remove containerd -y</span><br></pre></td></tr></table></figure>\n<p>根据你的系统，可能需要使用适当的软件包管理器（如apt、dnf）来移除 containerd 软件包。</p>\n<p>Step 4: 删除 containerd 配置目录</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf /etc/containerd</span><br></pre></td></tr></table></figure>\n<p>这将删除 containerd 的配置文件。</p>\n<p>Step 5: 删除 containerd 数据目录</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf /var/lib/containerd</span><br></pre></td></tr></table></figure>\n<p>这将删除 containerd 的数据目录。</p>\n<p>Step 6: 清理 containerd 相关的 iptables 规则</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ iptables -t nat -F</span><br><span class=\"line\">$ iptables -t mangle -F</span><br></pre></td></tr></table></figure>\n<p>这将清除与 containerd 相关的 iptables 规则。</p>\n<p>Step 7: 检查是否有残留的 containerd 配置文件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls /etc/systemd/system/containerd*</span><br></pre></td></tr></table></figure>\n<p>如果输出中有任何文件，则手动删除它们：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm /etc/systemd/system/containerd*.service</span><br></pre></td></tr></table></figure>\n\n<p>现在，你的 Kubernetes 集群节点上的 containerd 已经彻底卸载。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>要彻底清除 Kubernetes 集群节点上的 containerd，可以按照以下步骤进行：</p>\n<p>Step 1: 停止并移除所有运行的容器</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl ps -a | awk &#x27;&#123;if(NR&gt;1) print $1&#125;&#x27; | xargs -I &#123;&#125; crictl rm &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>这将停止并删除节点上所有正在运行的容器。</p>\n<p>Step 2: 停止并禁用 containerd 服务</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl stop containerd</span><br><span class=\"line\">$ systemctl disable containerd</span><br></pre></td></tr></table></figure>\n<p>这将停止并禁用 containerd 服务。</p>\n<p>Step 3: 卸载 containerd 软件包</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum remove containerd -y</span><br></pre></td></tr></table></figure>\n<p>根据你的系统，可能需要使用适当的软件包管理器（如apt、dnf）来移除 containerd 软件包。</p>\n<p>Step 4: 删除 containerd 配置目录</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf /etc/containerd</span><br></pre></td></tr></table></figure>\n<p>这将删除 containerd 的配置文件。</p>\n<p>Step 5: 删除 containerd 数据目录</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf /var/lib/containerd</span><br></pre></td></tr></table></figure>\n<p>这将删除 containerd 的数据目录。</p>\n<p>Step 6: 清理 containerd 相关的 iptables 规则</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ iptables -t nat -F</span><br><span class=\"line\">$ iptables -t mangle -F</span><br></pre></td></tr></table></figure>\n<p>这将清除与 containerd 相关的 iptables 规则。</p>\n<p>Step 7: 检查是否有残留的 containerd 配置文件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls /etc/systemd/system/containerd*</span><br></pre></td></tr></table></figure>\n<p>如果输出中有任何文件，则手动删除它们：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm /etc/systemd/system/containerd*.service</span><br></pre></td></tr></table></figure>\n\n<p>现在，你的 Kubernetes 集群节点上的 containerd 已经彻底卸载。</p>\n"},{"title":"VXLAN 基础教程：VXLAN 协议原理介绍","date":"2023-11-03T01:43:07.000Z","_content":"VXLAN（Virtual eXtensible Local Area Network，虚拟可扩展局域网），是一种虚拟化隧道通信技术。它是一种 Overlay（覆盖网络）技术，通过三层的网络来搭建虚拟的二层网络。\n\n简单来讲，VXLAN 是在底层物理网络（underlay）之上使用隧道技术，借助 UDP 层构建的 Overlay 的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。它对原有的网络架构几乎没有影响，不需要对原网络做任何改动，即可架设一层新的网络。也正是因为这个特性，很多 CNI 插件（Kubernetes 集群中的容器网络接口，这个大家应该都知道了吧，如果你不知道，现在你知道了）才会选择 VXLAN 作为通信网络。\n\nVXLAN 不仅支持一对一，也支持一对多，一个 VXLAN 设备能通过像网桥一样的学习方式学习到其他对端的 IP 地址，还可以直接配置静态转发表。\n\n一个典型的数据中心 VXLAN 网络拓扑图如图所示：\n\n![Alt text](image-114.png)\n其中 VM 指的是虚拟机，Hypervisor 指的是虚拟化管理器。\n## 1.  为什么需要 VXLAN？\n与 VLAN 相比，VXLAN 很明显要复杂很多，再加上 VLAN 的先发优势，已经得到了广泛的支持，那还要 VXLAN 干啥？\n\n### VLAN ID 数量限制\nVLAN tag 总共有 4 个字节，其中有 12 bit 用来标识不同的二层网络（即 LAN ID），故而最多只能支持 $2^{12}$，即 4096 个子网的划分。而虚拟化（虚拟机和容器）的兴起使得一个数据中心会有成千上万的机器需要通信，这时候 VLAN 就无法满足需求了。而 VXLAN 的报文 Header 预留了 24 bit 来标识不同的二层网络（即 VNI，VXLAN Network Identifier），即 3 个字节，可以支持 $2^{24}$ 个子网。\n\n### 交换机 MAC 地址表限制\n对于同网段主机的通信而言，报文到底交换机后都会查询 MAC 地址表进行二层转发。数据中心虚拟化之后，VM 的数量与原有的物理机相比呈数量级增长，而应用容器化之后，容器与 VM 相比也是呈数量级增长。。。而交换机的内存是有限的，因而 MAC 地址表也是有限的，随着虚拟机（或容器）网卡 MAC 地址数量的空前增加，交换机表示压力山大啊！\n\n而 VXLAN 就厉害了，它用 VTEP（后面会解释）将二层以太网帧封装在 UDP 中，一个 VTEP 可以被一个物理机上的所有 VM（或容器）共用，一个物理机对应一个 VTEP。从交换机的角度来看，只是不同的 VTEP 之间在传递 UDP 数据，只需要记录与物理机数量相当的 MAC 地址表条目就可以了，一切又回到了和从前一样。\n\n### 虚机或容器迁移范围受限\nVLAN 与物理网络融合在一起，不存在 Overlay 网络，带来的问题就是虚拟网络不能打破物理网络的限制。举个例子，如果要在 VLAN 100 部署虚拟机（或容器），那只能在支持 VLAN 100 的物理设备上部署。\n\nVLAN 其实也有解决办法，就是将所有的交换机 Trunk 连接起来，产生一个大的二层，这样带来的问题就是广播域过分扩大，也包括更多未知的单播和多播，即 BUM（Broadcast，Unknown Unicast，Multicast），同时交换机 MAC 地址表也会有承受不住的问题。\n\n而 VXLAN 将二层以太网帧封装在 UDP 中（上面说过了），相当于在三层网络上构建了二层网络。这样不管你物理网络是二层还是三层，都不影响虚拟机（或容器）的网络通信，也就无所谓部署在哪台物理设备上了，可以随意迁移。\n\n总的来说，传统二层和三层的网络在应对这些需求时变得力不从心，虽然很多改进型的技术比如堆叠、SVF、TRILL 等能够增加二层的范围，努力改进经典网络，但是要做到对网络改动尽可能小的同时保证灵活性却非常困难。为了解决这些问题，有很多方案被提出来，Overlay 就是其中之一，而 VXLAN 是 Overlay 的一种典型的技术方案。下面就对 Overlay 做一个简要的介绍。\n## 2. Overlay 是个啥？\nOverlay 在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于 IP 的基础网络技术为主。\n\nIETF 在 Overlay 技术领域提出 VXLAN、NVGRE、STT 三大技术方案。大体思路均是将以太网报文承载到某种隧道层面，差异性在于选择和构造隧道的不同，而底层均是 IP 转发。VXLAN 和 STT 对于现网设备而言对流量均衡要求较低，即负载链路负载分担适应性好，一般的网络设备都能对 L2-L4 的数据内容参数进行链路聚合或等价路由的流量均衡，而 NVGRE 则需要网络设备对 GRE 扩展头感知并对 flow ID 进行 HASH，需要硬件升级；STT 对于 TCP 有较大修改，隧道模式接近 UDP 性质，隧道构造技术属于革新性，且复杂度较高，而 VXLAN 利用了现有通用的 UDP 传输，成熟性极高。\n\n总体比较，VLXAN 技术具有更大优势，而且当前 VLXAN 也得到了更多厂家和客户的支持，已经成为 Overlay 技术的主流标准。\n## 3. VXLAN 协议原理\nVXLAN 有几个常见的术语：\n\n* VTEP（VXLAN Tunnel Endpoints，VXLAN 隧道端点）\n\nVXLAN 网络的边缘设备，用来进行 VXLAN 报文的处理（封包和解包）。VTEP 可以是网络设备（比如交换机），也可以是一台机器（比如虚拟化集群中的宿主机）。\n\n* VNI（VXLAN Network Identifier，VXLAN 网络标识符）\n\nVNI 是每个 VXLAN 段的标识，是个 24 位整数，一共有 $2^{24} = 16777216$（一千多万），一般每个 VNI 对应一个租户，也就是说使用 VXLAN 搭建的公有云可以理论上可以支撑千万级别的租户。\n\n* Tunnel（VXLAN 隧道）\n\n隧道是一个逻辑上的概念，在 VXLAN 模型中并没有具体的物理实体向对应。隧道可以看做是一种虚拟通道，VXLAN 通信双方认为自己是在直接通信，并不知道底层网络的存在。从整体来说，每个 VXLAN 网络像是为通信的虚拟机搭建了一个单独的通信通道，也就是隧道。\n![Alt text](image-115.png)\n上图所示为 VXLAN 的工作模型，它创建在原来的 IP 网络（三层）上，只要是三层可达（能够通过 IP 相互通信）的网络就能部署 VXLAN。在 VXLAN 网络的每个端点都有一个 VTEP 设备，负责 VXLAN 协议报文的解包和封包，也就是在虚拟报文上封装 VTEP 通信的报文头部。\n\n物理网络上可以创建多个 VXLAN 网络，可以将这些 VXLAN 网络看成一个隧道，不同节点上的虚拟机/容器能够通过隧道直连。通过 VNI 标识不同的 VXLAN 网络，使得不同的 VXLAN 可以相互隔离。\n\nVXLAN 的报文结构如下图所示：\n\n![Alt text](image-116.png)\n* VXLAN Header : 在原始二层帧的前面增加 8 字节的 VXLAN 的头部，其中最主要的是 VNID，占用 3 个字节（即 24 bit），类似 VLAN ID，可以具有 $2^{24}$ 个网段。\n\n* UDP Header : 在 VXLAN 和原始二层帧的前面使用 8 字节 UDP 头部进行封装（MAC IN UDP），目的端口号缺省使用 4789，源端口按流随机分配（通过 MAC，IP，四层端口号进行 hash 操作）， 这样可以更好的做 ECMP。\n\nIANA（Internet As-signed Numbers Autority）分配了 4789 作为 VXLAN 的默认目的端口号。\n\n在上面添加的二层封装之后，再添加底层网络的 IP 头部（20 字节）和 MAC 头部（14 字节），这里的 IP 和 MAC 是宿主机的 IP 地址和 MAC 地址。\n\n同时，这里需要注意 MTU 的问题，传统网络 MTU 一般为 1500，这里加上 VXLAN 的封装多出的（36+14/18，对于 14 的情况为 access 口，省去了 4 字节的 VLAN Tag）50 或 54 字节，需要调整 MTU 为 1550 或 1554，防止频繁分包。\n![Alt text](image-117.png)\n### VXLAN 的 Flood 与 Learn\n总的来说，VXLAN 报文的转发过程就是：原始报文经过 VTEP，被 Linux 内核添加上 VXLAN 头部以及外层的 UDP 头部，再发送出去，对端 VTEP 接收到 VXLAN 报文后拆除外层 UDP 头部，并根据 VXLAN 头部的 VNI 把原始报文发送到目的服务器。但这里有一个问题，第一次通信前双方如何知道所有的通信信息？这些信息包括：\n\n哪些 VTEP 需要加到一个相同的 VNI 组？\n发送方如何知道对方的 MAC 地址？\n如何知道目的服务器在哪个节点上（即目的 VTEP 的地址）？\n第一个问题简单，VTEP 通常由网络管理员来配置。要回答后面两个问题，还得回到 VXLAN 协议的报文上，看看一个完整的 VXLAN 报文需要哪些信息：\n\n* 内层报文 : 通信双方的 IP 地址已经明确，只需要 VXLAN 填充对方的 MAC 地址，因此需要一个机制来实现 ARP 功能。\n\n* VXLAN 头部 : 只需要知道 VNI。一般直接配置在 VTEP 上，要么提前规划，要么根据内层报文自动生成。\n\n* UDP 头部 : 需要知道源端口和目的端口，源端口由系统自动生成，目的端口默认是 4789。\n\n* IP 头部 : 需要知道对端 VTEP 的 IP 地址，这个是最关键的部分。\n\n实际上，VTEP 也会有自己的转发表，转发表通过泛洪和学习机制来维护，对于目标 MAC 地址在转发表中不存在的未知单播，广播流量，都会被泛洪给除源 VTEP 外所有的 VTEP，目标 VTEP 响应数据包后，源 VTEP 会从数据包中学习到 MAC，VNI 和 VTEP 的映射关系，并添加到转发表中，后续当再有数据包转发到这个 MAC 地址时，VTEP 会从转发表中直接获取到目标 VTEP 地址，从而发送单播数据到目标 VTEP。\n![Alt text](image-118.png)\n\nVTEP 转发表的学习可以通过以下两种方式：\n\n多播\n外部控制中心（如 Flannel、Cilium 等 CNI 插件）\n* MAC 头部 : 确定了 VTEP 的 IP 地址，后面就好办了，MAC 地址可以通过经典的 ARP 方式获取。\n\n## 4. Linux 的 VXLAN\nLinux 对 VXLAN 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，可能会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 VXLAN。\n\n到了 kernel 3.12 版本，Linux 对 VXLAN 的支持已经完备，支持单播和组播，IPv4 和 IPv6。利用 man 查看 ip 的 link 子命令，可以查看是否有 VXLAN type：\n```\n$ man ip-link\n```\n搜索 VXLAN，可以看到如下描述：\n![Alt text](image-119.png)\n### 管理 VXLAN 接口\n1. Linux VXLAN 接口的基本管理如下：\n创建点对点的 VXLAN 接口：\n```\n$ ip link add vxlan0 type vxlan id 4100 remote 192.168.1.101 local 192.168.1.100 dstport 4789 dev eth0\n```\n其中 id 为 VNI，remote 为远端主机的 IP，local 为你本地主机的 IP，dev 代表 VXLAN 数据从哪个接口传输。\n\n在 VXLAN 中，一般将 VXLAN 接口（本例中即 vxlan0）叫做 VTEP。\n2. 创建多播模式的 VXLAN 接口：\n```\n$ ip link add vxlan0 type vxlan id 4100 group 224.1.1.1 dstport 4789 dev eth0\n```\n多播组主要通过 ARP 泛洪来学习 MAC 地址，即在 VXLAN 子网内广播 ARP 请求，然后对应节点进行响应。group 指定多播组的地址。\n\n3. 查看 VXLAN 接口详细信息：\n```\n$ ip -d link show vxlan0\n```\n#### FDB 表\n\nFDB（Forwarding Database entry，即转发表）是 Linux 网桥维护的一个二层转发表，用于保存远端虚拟机/容器的 MAC地址，远端 VTEP IP，以及 VNI 的映射关系，可以通过 bridge fdb 命令来对 FDB 表进行操作：\n\n* 条目添加：\n```\n$ bridge fdb add <remote_host_mac> dev <vxlan_interface> dst <remote_host_ip>\n```\n* 条目删除：\n```\n$ bridge fdb del <remote_host_mac> dev <vxlan_interface>\n```\n* 条目更新：\n```\n$ bridge fdb replace <remote_host_mac> dev <vxlan_interface> dst <remote_host_ip>\n```\n* 条目查询：\n```\n$ bridge fdb show\n```\n## 5. 总结\n本文通过介绍 VXLAN 出现的时代背景、VXLAN 的概念和网络模型、VXLAN 报文结构，让你对 VXLAN 有了初步的认识；通过介绍 VXLAN 转发表的泛洪和学习，让你知道了通信双方如何感知对方；最后介绍了 Linux 中 VXLAN 的基本配置，让你进一步了解如何在 Linux 中玩转 VXLAN。下一篇文章将会通过实战来说明如何搭建基于 VXLAN 的 Overlay 网络，顺便展开解读上文提到的多播和外部控制中心的工作原理。\n\n原文地址: https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82","source":"_posts/kubernetes/vxlan.md","raw":"---\ntitle: VXLAN 基础教程：VXLAN 协议原理介绍\ndate: 2023-11-03 09:43:07\ncategories:\n  - [kubernetes]\ntags: VXLAN\n---\nVXLAN（Virtual eXtensible Local Area Network，虚拟可扩展局域网），是一种虚拟化隧道通信技术。它是一种 Overlay（覆盖网络）技术，通过三层的网络来搭建虚拟的二层网络。\n\n简单来讲，VXLAN 是在底层物理网络（underlay）之上使用隧道技术，借助 UDP 层构建的 Overlay 的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。它对原有的网络架构几乎没有影响，不需要对原网络做任何改动，即可架设一层新的网络。也正是因为这个特性，很多 CNI 插件（Kubernetes 集群中的容器网络接口，这个大家应该都知道了吧，如果你不知道，现在你知道了）才会选择 VXLAN 作为通信网络。\n\nVXLAN 不仅支持一对一，也支持一对多，一个 VXLAN 设备能通过像网桥一样的学习方式学习到其他对端的 IP 地址，还可以直接配置静态转发表。\n\n一个典型的数据中心 VXLAN 网络拓扑图如图所示：\n\n![Alt text](image-114.png)\n其中 VM 指的是虚拟机，Hypervisor 指的是虚拟化管理器。\n## 1.  为什么需要 VXLAN？\n与 VLAN 相比，VXLAN 很明显要复杂很多，再加上 VLAN 的先发优势，已经得到了广泛的支持，那还要 VXLAN 干啥？\n\n### VLAN ID 数量限制\nVLAN tag 总共有 4 个字节，其中有 12 bit 用来标识不同的二层网络（即 LAN ID），故而最多只能支持 $2^{12}$，即 4096 个子网的划分。而虚拟化（虚拟机和容器）的兴起使得一个数据中心会有成千上万的机器需要通信，这时候 VLAN 就无法满足需求了。而 VXLAN 的报文 Header 预留了 24 bit 来标识不同的二层网络（即 VNI，VXLAN Network Identifier），即 3 个字节，可以支持 $2^{24}$ 个子网。\n\n### 交换机 MAC 地址表限制\n对于同网段主机的通信而言，报文到底交换机后都会查询 MAC 地址表进行二层转发。数据中心虚拟化之后，VM 的数量与原有的物理机相比呈数量级增长，而应用容器化之后，容器与 VM 相比也是呈数量级增长。。。而交换机的内存是有限的，因而 MAC 地址表也是有限的，随着虚拟机（或容器）网卡 MAC 地址数量的空前增加，交换机表示压力山大啊！\n\n而 VXLAN 就厉害了，它用 VTEP（后面会解释）将二层以太网帧封装在 UDP 中，一个 VTEP 可以被一个物理机上的所有 VM（或容器）共用，一个物理机对应一个 VTEP。从交换机的角度来看，只是不同的 VTEP 之间在传递 UDP 数据，只需要记录与物理机数量相当的 MAC 地址表条目就可以了，一切又回到了和从前一样。\n\n### 虚机或容器迁移范围受限\nVLAN 与物理网络融合在一起，不存在 Overlay 网络，带来的问题就是虚拟网络不能打破物理网络的限制。举个例子，如果要在 VLAN 100 部署虚拟机（或容器），那只能在支持 VLAN 100 的物理设备上部署。\n\nVLAN 其实也有解决办法，就是将所有的交换机 Trunk 连接起来，产生一个大的二层，这样带来的问题就是广播域过分扩大，也包括更多未知的单播和多播，即 BUM（Broadcast，Unknown Unicast，Multicast），同时交换机 MAC 地址表也会有承受不住的问题。\n\n而 VXLAN 将二层以太网帧封装在 UDP 中（上面说过了），相当于在三层网络上构建了二层网络。这样不管你物理网络是二层还是三层，都不影响虚拟机（或容器）的网络通信，也就无所谓部署在哪台物理设备上了，可以随意迁移。\n\n总的来说，传统二层和三层的网络在应对这些需求时变得力不从心，虽然很多改进型的技术比如堆叠、SVF、TRILL 等能够增加二层的范围，努力改进经典网络，但是要做到对网络改动尽可能小的同时保证灵活性却非常困难。为了解决这些问题，有很多方案被提出来，Overlay 就是其中之一，而 VXLAN 是 Overlay 的一种典型的技术方案。下面就对 Overlay 做一个简要的介绍。\n## 2. Overlay 是个啥？\nOverlay 在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于 IP 的基础网络技术为主。\n\nIETF 在 Overlay 技术领域提出 VXLAN、NVGRE、STT 三大技术方案。大体思路均是将以太网报文承载到某种隧道层面，差异性在于选择和构造隧道的不同，而底层均是 IP 转发。VXLAN 和 STT 对于现网设备而言对流量均衡要求较低，即负载链路负载分担适应性好，一般的网络设备都能对 L2-L4 的数据内容参数进行链路聚合或等价路由的流量均衡，而 NVGRE 则需要网络设备对 GRE 扩展头感知并对 flow ID 进行 HASH，需要硬件升级；STT 对于 TCP 有较大修改，隧道模式接近 UDP 性质，隧道构造技术属于革新性，且复杂度较高，而 VXLAN 利用了现有通用的 UDP 传输，成熟性极高。\n\n总体比较，VLXAN 技术具有更大优势，而且当前 VLXAN 也得到了更多厂家和客户的支持，已经成为 Overlay 技术的主流标准。\n## 3. VXLAN 协议原理\nVXLAN 有几个常见的术语：\n\n* VTEP（VXLAN Tunnel Endpoints，VXLAN 隧道端点）\n\nVXLAN 网络的边缘设备，用来进行 VXLAN 报文的处理（封包和解包）。VTEP 可以是网络设备（比如交换机），也可以是一台机器（比如虚拟化集群中的宿主机）。\n\n* VNI（VXLAN Network Identifier，VXLAN 网络标识符）\n\nVNI 是每个 VXLAN 段的标识，是个 24 位整数，一共有 $2^{24} = 16777216$（一千多万），一般每个 VNI 对应一个租户，也就是说使用 VXLAN 搭建的公有云可以理论上可以支撑千万级别的租户。\n\n* Tunnel（VXLAN 隧道）\n\n隧道是一个逻辑上的概念，在 VXLAN 模型中并没有具体的物理实体向对应。隧道可以看做是一种虚拟通道，VXLAN 通信双方认为自己是在直接通信，并不知道底层网络的存在。从整体来说，每个 VXLAN 网络像是为通信的虚拟机搭建了一个单独的通信通道，也就是隧道。\n![Alt text](image-115.png)\n上图所示为 VXLAN 的工作模型，它创建在原来的 IP 网络（三层）上，只要是三层可达（能够通过 IP 相互通信）的网络就能部署 VXLAN。在 VXLAN 网络的每个端点都有一个 VTEP 设备，负责 VXLAN 协议报文的解包和封包，也就是在虚拟报文上封装 VTEP 通信的报文头部。\n\n物理网络上可以创建多个 VXLAN 网络，可以将这些 VXLAN 网络看成一个隧道，不同节点上的虚拟机/容器能够通过隧道直连。通过 VNI 标识不同的 VXLAN 网络，使得不同的 VXLAN 可以相互隔离。\n\nVXLAN 的报文结构如下图所示：\n\n![Alt text](image-116.png)\n* VXLAN Header : 在原始二层帧的前面增加 8 字节的 VXLAN 的头部，其中最主要的是 VNID，占用 3 个字节（即 24 bit），类似 VLAN ID，可以具有 $2^{24}$ 个网段。\n\n* UDP Header : 在 VXLAN 和原始二层帧的前面使用 8 字节 UDP 头部进行封装（MAC IN UDP），目的端口号缺省使用 4789，源端口按流随机分配（通过 MAC，IP，四层端口号进行 hash 操作）， 这样可以更好的做 ECMP。\n\nIANA（Internet As-signed Numbers Autority）分配了 4789 作为 VXLAN 的默认目的端口号。\n\n在上面添加的二层封装之后，再添加底层网络的 IP 头部（20 字节）和 MAC 头部（14 字节），这里的 IP 和 MAC 是宿主机的 IP 地址和 MAC 地址。\n\n同时，这里需要注意 MTU 的问题，传统网络 MTU 一般为 1500，这里加上 VXLAN 的封装多出的（36+14/18，对于 14 的情况为 access 口，省去了 4 字节的 VLAN Tag）50 或 54 字节，需要调整 MTU 为 1550 或 1554，防止频繁分包。\n![Alt text](image-117.png)\n### VXLAN 的 Flood 与 Learn\n总的来说，VXLAN 报文的转发过程就是：原始报文经过 VTEP，被 Linux 内核添加上 VXLAN 头部以及外层的 UDP 头部，再发送出去，对端 VTEP 接收到 VXLAN 报文后拆除外层 UDP 头部，并根据 VXLAN 头部的 VNI 把原始报文发送到目的服务器。但这里有一个问题，第一次通信前双方如何知道所有的通信信息？这些信息包括：\n\n哪些 VTEP 需要加到一个相同的 VNI 组？\n发送方如何知道对方的 MAC 地址？\n如何知道目的服务器在哪个节点上（即目的 VTEP 的地址）？\n第一个问题简单，VTEP 通常由网络管理员来配置。要回答后面两个问题，还得回到 VXLAN 协议的报文上，看看一个完整的 VXLAN 报文需要哪些信息：\n\n* 内层报文 : 通信双方的 IP 地址已经明确，只需要 VXLAN 填充对方的 MAC 地址，因此需要一个机制来实现 ARP 功能。\n\n* VXLAN 头部 : 只需要知道 VNI。一般直接配置在 VTEP 上，要么提前规划，要么根据内层报文自动生成。\n\n* UDP 头部 : 需要知道源端口和目的端口，源端口由系统自动生成，目的端口默认是 4789。\n\n* IP 头部 : 需要知道对端 VTEP 的 IP 地址，这个是最关键的部分。\n\n实际上，VTEP 也会有自己的转发表，转发表通过泛洪和学习机制来维护，对于目标 MAC 地址在转发表中不存在的未知单播，广播流量，都会被泛洪给除源 VTEP 外所有的 VTEP，目标 VTEP 响应数据包后，源 VTEP 会从数据包中学习到 MAC，VNI 和 VTEP 的映射关系，并添加到转发表中，后续当再有数据包转发到这个 MAC 地址时，VTEP 会从转发表中直接获取到目标 VTEP 地址，从而发送单播数据到目标 VTEP。\n![Alt text](image-118.png)\n\nVTEP 转发表的学习可以通过以下两种方式：\n\n多播\n外部控制中心（如 Flannel、Cilium 等 CNI 插件）\n* MAC 头部 : 确定了 VTEP 的 IP 地址，后面就好办了，MAC 地址可以通过经典的 ARP 方式获取。\n\n## 4. Linux 的 VXLAN\nLinux 对 VXLAN 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，可能会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 VXLAN。\n\n到了 kernel 3.12 版本，Linux 对 VXLAN 的支持已经完备，支持单播和组播，IPv4 和 IPv6。利用 man 查看 ip 的 link 子命令，可以查看是否有 VXLAN type：\n```\n$ man ip-link\n```\n搜索 VXLAN，可以看到如下描述：\n![Alt text](image-119.png)\n### 管理 VXLAN 接口\n1. Linux VXLAN 接口的基本管理如下：\n创建点对点的 VXLAN 接口：\n```\n$ ip link add vxlan0 type vxlan id 4100 remote 192.168.1.101 local 192.168.1.100 dstport 4789 dev eth0\n```\n其中 id 为 VNI，remote 为远端主机的 IP，local 为你本地主机的 IP，dev 代表 VXLAN 数据从哪个接口传输。\n\n在 VXLAN 中，一般将 VXLAN 接口（本例中即 vxlan0）叫做 VTEP。\n2. 创建多播模式的 VXLAN 接口：\n```\n$ ip link add vxlan0 type vxlan id 4100 group 224.1.1.1 dstport 4789 dev eth0\n```\n多播组主要通过 ARP 泛洪来学习 MAC 地址，即在 VXLAN 子网内广播 ARP 请求，然后对应节点进行响应。group 指定多播组的地址。\n\n3. 查看 VXLAN 接口详细信息：\n```\n$ ip -d link show vxlan0\n```\n#### FDB 表\n\nFDB（Forwarding Database entry，即转发表）是 Linux 网桥维护的一个二层转发表，用于保存远端虚拟机/容器的 MAC地址，远端 VTEP IP，以及 VNI 的映射关系，可以通过 bridge fdb 命令来对 FDB 表进行操作：\n\n* 条目添加：\n```\n$ bridge fdb add <remote_host_mac> dev <vxlan_interface> dst <remote_host_ip>\n```\n* 条目删除：\n```\n$ bridge fdb del <remote_host_mac> dev <vxlan_interface>\n```\n* 条目更新：\n```\n$ bridge fdb replace <remote_host_mac> dev <vxlan_interface> dst <remote_host_ip>\n```\n* 条目查询：\n```\n$ bridge fdb show\n```\n## 5. 总结\n本文通过介绍 VXLAN 出现的时代背景、VXLAN 的概念和网络模型、VXLAN 报文结构，让你对 VXLAN 有了初步的认识；通过介绍 VXLAN 转发表的泛洪和学习，让你知道了通信双方如何感知对方；最后介绍了 Linux 中 VXLAN 的基本配置，让你进一步了解如何在 Linux 中玩转 VXLAN。下一篇文章将会通过实战来说明如何搭建基于 VXLAN 的 Overlay 网络，顺便展开解读上文提到的多播和外部控制中心的工作原理。\n\n原文地址: https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82","slug":"kubernetes/vxlan","published":1,"updated":"2023-11-03T02:02:04.789Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0cs002efmjxfhuef7ow","content":"<p>VXLAN（Virtual eXtensible Local Area Network，虚拟可扩展局域网），是一种虚拟化隧道通信技术。它是一种 Overlay（覆盖网络）技术，通过三层的网络来搭建虚拟的二层网络。</p>\n<p>简单来讲，VXLAN 是在底层物理网络（underlay）之上使用隧道技术，借助 UDP 层构建的 Overlay 的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。它对原有的网络架构几乎没有影响，不需要对原网络做任何改动，即可架设一层新的网络。也正是因为这个特性，很多 CNI 插件（Kubernetes 集群中的容器网络接口，这个大家应该都知道了吧，如果你不知道，现在你知道了）才会选择 VXLAN 作为通信网络。</p>\n<p>VXLAN 不仅支持一对一，也支持一对多，一个 VXLAN 设备能通过像网桥一样的学习方式学习到其他对端的 IP 地址，还可以直接配置静态转发表。</p>\n<p>一个典型的数据中心 VXLAN 网络拓扑图如图所示：</p>\n<p><img src=\"/image-114.png\" alt=\"Alt text\"><br>其中 VM 指的是虚拟机，Hypervisor 指的是虚拟化管理器。</p>\n<h2 id=\"1-为什么需要-VXLAN？\"><a href=\"#1-为什么需要-VXLAN？\" class=\"headerlink\" title=\"1.  为什么需要 VXLAN？\"></a>1.  为什么需要 VXLAN？</h2><p>与 VLAN 相比，VXLAN 很明显要复杂很多，再加上 VLAN 的先发优势，已经得到了广泛的支持，那还要 VXLAN 干啥？</p>\n<h3 id=\"VLAN-ID-数量限制\"><a href=\"#VLAN-ID-数量限制\" class=\"headerlink\" title=\"VLAN ID 数量限制\"></a>VLAN ID 数量限制</h3><p>VLAN tag 总共有 4 个字节，其中有 12 bit 用来标识不同的二层网络（即 LAN ID），故而最多只能支持 $2^{12}$，即 4096 个子网的划分。而虚拟化（虚拟机和容器）的兴起使得一个数据中心会有成千上万的机器需要通信，这时候 VLAN 就无法满足需求了。而 VXLAN 的报文 Header 预留了 24 bit 来标识不同的二层网络（即 VNI，VXLAN Network Identifier），即 3 个字节，可以支持 $2^{24}$ 个子网。</p>\n<h3 id=\"交换机-MAC-地址表限制\"><a href=\"#交换机-MAC-地址表限制\" class=\"headerlink\" title=\"交换机 MAC 地址表限制\"></a>交换机 MAC 地址表限制</h3><p>对于同网段主机的通信而言，报文到底交换机后都会查询 MAC 地址表进行二层转发。数据中心虚拟化之后，VM 的数量与原有的物理机相比呈数量级增长，而应用容器化之后，容器与 VM 相比也是呈数量级增长。。。而交换机的内存是有限的，因而 MAC 地址表也是有限的，随着虚拟机（或容器）网卡 MAC 地址数量的空前增加，交换机表示压力山大啊！</p>\n<p>而 VXLAN 就厉害了，它用 VTEP（后面会解释）将二层以太网帧封装在 UDP 中，一个 VTEP 可以被一个物理机上的所有 VM（或容器）共用，一个物理机对应一个 VTEP。从交换机的角度来看，只是不同的 VTEP 之间在传递 UDP 数据，只需要记录与物理机数量相当的 MAC 地址表条目就可以了，一切又回到了和从前一样。</p>\n<h3 id=\"虚机或容器迁移范围受限\"><a href=\"#虚机或容器迁移范围受限\" class=\"headerlink\" title=\"虚机或容器迁移范围受限\"></a>虚机或容器迁移范围受限</h3><p>VLAN 与物理网络融合在一起，不存在 Overlay 网络，带来的问题就是虚拟网络不能打破物理网络的限制。举个例子，如果要在 VLAN 100 部署虚拟机（或容器），那只能在支持 VLAN 100 的物理设备上部署。</p>\n<p>VLAN 其实也有解决办法，就是将所有的交换机 Trunk 连接起来，产生一个大的二层，这样带来的问题就是广播域过分扩大，也包括更多未知的单播和多播，即 BUM（Broadcast，Unknown Unicast，Multicast），同时交换机 MAC 地址表也会有承受不住的问题。</p>\n<p>而 VXLAN 将二层以太网帧封装在 UDP 中（上面说过了），相当于在三层网络上构建了二层网络。这样不管你物理网络是二层还是三层，都不影响虚拟机（或容器）的网络通信，也就无所谓部署在哪台物理设备上了，可以随意迁移。</p>\n<p>总的来说，传统二层和三层的网络在应对这些需求时变得力不从心，虽然很多改进型的技术比如堆叠、SVF、TRILL 等能够增加二层的范围，努力改进经典网络，但是要做到对网络改动尽可能小的同时保证灵活性却非常困难。为了解决这些问题，有很多方案被提出来，Overlay 就是其中之一，而 VXLAN 是 Overlay 的一种典型的技术方案。下面就对 Overlay 做一个简要的介绍。</p>\n<h2 id=\"2-Overlay-是个啥？\"><a href=\"#2-Overlay-是个啥？\" class=\"headerlink\" title=\"2. Overlay 是个啥？\"></a>2. Overlay 是个啥？</h2><p>Overlay 在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于 IP 的基础网络技术为主。</p>\n<p>IETF 在 Overlay 技术领域提出 VXLAN、NVGRE、STT 三大技术方案。大体思路均是将以太网报文承载到某种隧道层面，差异性在于选择和构造隧道的不同，而底层均是 IP 转发。VXLAN 和 STT 对于现网设备而言对流量均衡要求较低，即负载链路负载分担适应性好，一般的网络设备都能对 L2-L4 的数据内容参数进行链路聚合或等价路由的流量均衡，而 NVGRE 则需要网络设备对 GRE 扩展头感知并对 flow ID 进行 HASH，需要硬件升级；STT 对于 TCP 有较大修改，隧道模式接近 UDP 性质，隧道构造技术属于革新性，且复杂度较高，而 VXLAN 利用了现有通用的 UDP 传输，成熟性极高。</p>\n<p>总体比较，VLXAN 技术具有更大优势，而且当前 VLXAN 也得到了更多厂家和客户的支持，已经成为 Overlay 技术的主流标准。</p>\n<h2 id=\"3-VXLAN-协议原理\"><a href=\"#3-VXLAN-协议原理\" class=\"headerlink\" title=\"3. VXLAN 协议原理\"></a>3. VXLAN 协议原理</h2><p>VXLAN 有几个常见的术语：</p>\n<ul>\n<li>VTEP（VXLAN Tunnel Endpoints，VXLAN 隧道端点）</li>\n</ul>\n<p>VXLAN 网络的边缘设备，用来进行 VXLAN 报文的处理（封包和解包）。VTEP 可以是网络设备（比如交换机），也可以是一台机器（比如虚拟化集群中的宿主机）。</p>\n<ul>\n<li>VNI（VXLAN Network Identifier，VXLAN 网络标识符）</li>\n</ul>\n<p>VNI 是每个 VXLAN 段的标识，是个 24 位整数，一共有 $2^{24} &#x3D; 16777216$（一千多万），一般每个 VNI 对应一个租户，也就是说使用 VXLAN 搭建的公有云可以理论上可以支撑千万级别的租户。</p>\n<ul>\n<li>Tunnel（VXLAN 隧道）</li>\n</ul>\n<p>隧道是一个逻辑上的概念，在 VXLAN 模型中并没有具体的物理实体向对应。隧道可以看做是一种虚拟通道，VXLAN 通信双方认为自己是在直接通信，并不知道底层网络的存在。从整体来说，每个 VXLAN 网络像是为通信的虚拟机搭建了一个单独的通信通道，也就是隧道。<br><img src=\"/image-115.png\" alt=\"Alt text\"><br>上图所示为 VXLAN 的工作模型，它创建在原来的 IP 网络（三层）上，只要是三层可达（能够通过 IP 相互通信）的网络就能部署 VXLAN。在 VXLAN 网络的每个端点都有一个 VTEP 设备，负责 VXLAN 协议报文的解包和封包，也就是在虚拟报文上封装 VTEP 通信的报文头部。</p>\n<p>物理网络上可以创建多个 VXLAN 网络，可以将这些 VXLAN 网络看成一个隧道，不同节点上的虚拟机&#x2F;容器能够通过隧道直连。通过 VNI 标识不同的 VXLAN 网络，使得不同的 VXLAN 可以相互隔离。</p>\n<p>VXLAN 的报文结构如下图所示：</p>\n<p><img src=\"/image-116.png\" alt=\"Alt text\"></p>\n<ul>\n<li><p>VXLAN Header : 在原始二层帧的前面增加 8 字节的 VXLAN 的头部，其中最主要的是 VNID，占用 3 个字节（即 24 bit），类似 VLAN ID，可以具有 $2^{24}$ 个网段。</p>\n</li>\n<li><p>UDP Header : 在 VXLAN 和原始二层帧的前面使用 8 字节 UDP 头部进行封装（MAC IN UDP），目的端口号缺省使用 4789，源端口按流随机分配（通过 MAC，IP，四层端口号进行 hash 操作）， 这样可以更好的做 ECMP。</p>\n</li>\n</ul>\n<p>IANA（Internet As-signed Numbers Autority）分配了 4789 作为 VXLAN 的默认目的端口号。</p>\n<p>在上面添加的二层封装之后，再添加底层网络的 IP 头部（20 字节）和 MAC 头部（14 字节），这里的 IP 和 MAC 是宿主机的 IP 地址和 MAC 地址。</p>\n<p>同时，这里需要注意 MTU 的问题，传统网络 MTU 一般为 1500，这里加上 VXLAN 的封装多出的（36+14&#x2F;18，对于 14 的情况为 access 口，省去了 4 字节的 VLAN Tag）50 或 54 字节，需要调整 MTU 为 1550 或 1554，防止频繁分包。<br><img src=\"/image-117.png\" alt=\"Alt text\"></p>\n<h3 id=\"VXLAN-的-Flood-与-Learn\"><a href=\"#VXLAN-的-Flood-与-Learn\" class=\"headerlink\" title=\"VXLAN 的 Flood 与 Learn\"></a>VXLAN 的 Flood 与 Learn</h3><p>总的来说，VXLAN 报文的转发过程就是：原始报文经过 VTEP，被 Linux 内核添加上 VXLAN 头部以及外层的 UDP 头部，再发送出去，对端 VTEP 接收到 VXLAN 报文后拆除外层 UDP 头部，并根据 VXLAN 头部的 VNI 把原始报文发送到目的服务器。但这里有一个问题，第一次通信前双方如何知道所有的通信信息？这些信息包括：</p>\n<p>哪些 VTEP 需要加到一个相同的 VNI 组？<br>发送方如何知道对方的 MAC 地址？<br>如何知道目的服务器在哪个节点上（即目的 VTEP 的地址）？<br>第一个问题简单，VTEP 通常由网络管理员来配置。要回答后面两个问题，还得回到 VXLAN 协议的报文上，看看一个完整的 VXLAN 报文需要哪些信息：</p>\n<ul>\n<li><p>内层报文 : 通信双方的 IP 地址已经明确，只需要 VXLAN 填充对方的 MAC 地址，因此需要一个机制来实现 ARP 功能。</p>\n</li>\n<li><p>VXLAN 头部 : 只需要知道 VNI。一般直接配置在 VTEP 上，要么提前规划，要么根据内层报文自动生成。</p>\n</li>\n<li><p>UDP 头部 : 需要知道源端口和目的端口，源端口由系统自动生成，目的端口默认是 4789。</p>\n</li>\n<li><p>IP 头部 : 需要知道对端 VTEP 的 IP 地址，这个是最关键的部分。</p>\n</li>\n</ul>\n<p>实际上，VTEP 也会有自己的转发表，转发表通过泛洪和学习机制来维护，对于目标 MAC 地址在转发表中不存在的未知单播，广播流量，都会被泛洪给除源 VTEP 外所有的 VTEP，目标 VTEP 响应数据包后，源 VTEP 会从数据包中学习到 MAC，VNI 和 VTEP 的映射关系，并添加到转发表中，后续当再有数据包转发到这个 MAC 地址时，VTEP 会从转发表中直接获取到目标 VTEP 地址，从而发送单播数据到目标 VTEP。<br><img src=\"/image-118.png\" alt=\"Alt text\"></p>\n<p>VTEP 转发表的学习可以通过以下两种方式：</p>\n<p>多播<br>外部控制中心（如 Flannel、Cilium 等 CNI 插件）</p>\n<ul>\n<li>MAC 头部 : 确定了 VTEP 的 IP 地址，后面就好办了，MAC 地址可以通过经典的 ARP 方式获取。</li>\n</ul>\n<h2 id=\"4-Linux-的-VXLAN\"><a href=\"#4-Linux-的-VXLAN\" class=\"headerlink\" title=\"4. Linux 的 VXLAN\"></a>4. Linux 的 VXLAN</h2><p>Linux 对 VXLAN 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，可能会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 VXLAN。</p>\n<p>到了 kernel 3.12 版本，Linux 对 VXLAN 的支持已经完备，支持单播和组播，IPv4 和 IPv6。利用 man 查看 ip 的 link 子命令，可以查看是否有 VXLAN type：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ man ip-link</span><br></pre></td></tr></table></figure>\n<p>搜索 VXLAN，可以看到如下描述：<br><img src=\"/image-119.png\" alt=\"Alt text\"></p>\n<h3 id=\"管理-VXLAN-接口\"><a href=\"#管理-VXLAN-接口\" class=\"headerlink\" title=\"管理 VXLAN 接口\"></a>管理 VXLAN 接口</h3><ol>\n<li>Linux VXLAN 接口的基本管理如下：<br>创建点对点的 VXLAN 接口：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link add vxlan0 type vxlan id 4100 remote 192.168.1.101 local 192.168.1.100 dstport 4789 dev eth0</span><br></pre></td></tr></table></figure>\n其中 id 为 VNI，remote 为远端主机的 IP，local 为你本地主机的 IP，dev 代表 VXLAN 数据从哪个接口传输。</li>\n</ol>\n<p>在 VXLAN 中，一般将 VXLAN 接口（本例中即 vxlan0）叫做 VTEP。<br>2. 创建多播模式的 VXLAN 接口：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link add vxlan0 type vxlan id 4100 group 224.1.1.1 dstport 4789 dev eth0</span><br></pre></td></tr></table></figure>\n<p>多播组主要通过 ARP 泛洪来学习 MAC 地址，即在 VXLAN 子网内广播 ARP 请求，然后对应节点进行响应。group 指定多播组的地址。</p>\n<ol start=\"3\">\n<li>查看 VXLAN 接口详细信息：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip -d link show vxlan0</span><br></pre></td></tr></table></figure></li>\n</ol>\n<h4 id=\"FDB-表\"><a href=\"#FDB-表\" class=\"headerlink\" title=\"FDB 表\"></a>FDB 表</h4><p>FDB（Forwarding Database entry，即转发表）是 Linux 网桥维护的一个二层转发表，用于保存远端虚拟机&#x2F;容器的 MAC地址，远端 VTEP IP，以及 VNI 的映射关系，可以通过 bridge fdb 命令来对 FDB 表进行操作：</p>\n<ul>\n<li>条目添加：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb add &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt; dst &lt;remote_host_ip&gt;</span><br></pre></td></tr></table></figure></li>\n<li>条目删除：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb del &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt;</span><br></pre></td></tr></table></figure></li>\n<li>条目更新：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb replace &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt; dst &lt;remote_host_ip&gt;</span><br></pre></td></tr></table></figure></li>\n<li>条目查询：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb show</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a>5. 总结</h2><p>本文通过介绍 VXLAN 出现的时代背景、VXLAN 的概念和网络模型、VXLAN 报文结构，让你对 VXLAN 有了初步的认识；通过介绍 VXLAN 转发表的泛洪和学习，让你知道了通信双方如何感知对方；最后介绍了 Linux 中 VXLAN 的基本配置，让你进一步了解如何在 Linux 中玩转 VXLAN。下一篇文章将会通过实战来说明如何搭建基于 VXLAN 的 Overlay 网络，顺便展开解读上文提到的多播和外部控制中心的工作原理。</p>\n<p>原文地址: <a href=\"https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82\">https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82</a></p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>VXLAN（Virtual eXtensible Local Area Network，虚拟可扩展局域网），是一种虚拟化隧道通信技术。它是一种 Overlay（覆盖网络）技术，通过三层的网络来搭建虚拟的二层网络。</p>\n<p>简单来讲，VXLAN 是在底层物理网络（underlay）之上使用隧道技术，借助 UDP 层构建的 Overlay 的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。它对原有的网络架构几乎没有影响，不需要对原网络做任何改动，即可架设一层新的网络。也正是因为这个特性，很多 CNI 插件（Kubernetes 集群中的容器网络接口，这个大家应该都知道了吧，如果你不知道，现在你知道了）才会选择 VXLAN 作为通信网络。</p>\n<p>VXLAN 不仅支持一对一，也支持一对多，一个 VXLAN 设备能通过像网桥一样的学习方式学习到其他对端的 IP 地址，还可以直接配置静态转发表。</p>\n<p>一个典型的数据中心 VXLAN 网络拓扑图如图所示：</p>\n<p><img src=\"/image-114.png\" alt=\"Alt text\"><br>其中 VM 指的是虚拟机，Hypervisor 指的是虚拟化管理器。</p>\n<h2 id=\"1-为什么需要-VXLAN？\"><a href=\"#1-为什么需要-VXLAN？\" class=\"headerlink\" title=\"1.  为什么需要 VXLAN？\"></a>1.  为什么需要 VXLAN？</h2><p>与 VLAN 相比，VXLAN 很明显要复杂很多，再加上 VLAN 的先发优势，已经得到了广泛的支持，那还要 VXLAN 干啥？</p>\n<h3 id=\"VLAN-ID-数量限制\"><a href=\"#VLAN-ID-数量限制\" class=\"headerlink\" title=\"VLAN ID 数量限制\"></a>VLAN ID 数量限制</h3><p>VLAN tag 总共有 4 个字节，其中有 12 bit 用来标识不同的二层网络（即 LAN ID），故而最多只能支持 $2^{12}$，即 4096 个子网的划分。而虚拟化（虚拟机和容器）的兴起使得一个数据中心会有成千上万的机器需要通信，这时候 VLAN 就无法满足需求了。而 VXLAN 的报文 Header 预留了 24 bit 来标识不同的二层网络（即 VNI，VXLAN Network Identifier），即 3 个字节，可以支持 $2^{24}$ 个子网。</p>\n<h3 id=\"交换机-MAC-地址表限制\"><a href=\"#交换机-MAC-地址表限制\" class=\"headerlink\" title=\"交换机 MAC 地址表限制\"></a>交换机 MAC 地址表限制</h3><p>对于同网段主机的通信而言，报文到底交换机后都会查询 MAC 地址表进行二层转发。数据中心虚拟化之后，VM 的数量与原有的物理机相比呈数量级增长，而应用容器化之后，容器与 VM 相比也是呈数量级增长。。。而交换机的内存是有限的，因而 MAC 地址表也是有限的，随着虚拟机（或容器）网卡 MAC 地址数量的空前增加，交换机表示压力山大啊！</p>\n<p>而 VXLAN 就厉害了，它用 VTEP（后面会解释）将二层以太网帧封装在 UDP 中，一个 VTEP 可以被一个物理机上的所有 VM（或容器）共用，一个物理机对应一个 VTEP。从交换机的角度来看，只是不同的 VTEP 之间在传递 UDP 数据，只需要记录与物理机数量相当的 MAC 地址表条目就可以了，一切又回到了和从前一样。</p>\n<h3 id=\"虚机或容器迁移范围受限\"><a href=\"#虚机或容器迁移范围受限\" class=\"headerlink\" title=\"虚机或容器迁移范围受限\"></a>虚机或容器迁移范围受限</h3><p>VLAN 与物理网络融合在一起，不存在 Overlay 网络，带来的问题就是虚拟网络不能打破物理网络的限制。举个例子，如果要在 VLAN 100 部署虚拟机（或容器），那只能在支持 VLAN 100 的物理设备上部署。</p>\n<p>VLAN 其实也有解决办法，就是将所有的交换机 Trunk 连接起来，产生一个大的二层，这样带来的问题就是广播域过分扩大，也包括更多未知的单播和多播，即 BUM（Broadcast，Unknown Unicast，Multicast），同时交换机 MAC 地址表也会有承受不住的问题。</p>\n<p>而 VXLAN 将二层以太网帧封装在 UDP 中（上面说过了），相当于在三层网络上构建了二层网络。这样不管你物理网络是二层还是三层，都不影响虚拟机（或容器）的网络通信，也就无所谓部署在哪台物理设备上了，可以随意迁移。</p>\n<p>总的来说，传统二层和三层的网络在应对这些需求时变得力不从心，虽然很多改进型的技术比如堆叠、SVF、TRILL 等能够增加二层的范围，努力改进经典网络，但是要做到对网络改动尽可能小的同时保证灵活性却非常困难。为了解决这些问题，有很多方案被提出来，Overlay 就是其中之一，而 VXLAN 是 Overlay 的一种典型的技术方案。下面就对 Overlay 做一个简要的介绍。</p>\n<h2 id=\"2-Overlay-是个啥？\"><a href=\"#2-Overlay-是个啥？\" class=\"headerlink\" title=\"2. Overlay 是个啥？\"></a>2. Overlay 是个啥？</h2><p>Overlay 在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于 IP 的基础网络技术为主。</p>\n<p>IETF 在 Overlay 技术领域提出 VXLAN、NVGRE、STT 三大技术方案。大体思路均是将以太网报文承载到某种隧道层面，差异性在于选择和构造隧道的不同，而底层均是 IP 转发。VXLAN 和 STT 对于现网设备而言对流量均衡要求较低，即负载链路负载分担适应性好，一般的网络设备都能对 L2-L4 的数据内容参数进行链路聚合或等价路由的流量均衡，而 NVGRE 则需要网络设备对 GRE 扩展头感知并对 flow ID 进行 HASH，需要硬件升级；STT 对于 TCP 有较大修改，隧道模式接近 UDP 性质，隧道构造技术属于革新性，且复杂度较高，而 VXLAN 利用了现有通用的 UDP 传输，成熟性极高。</p>\n<p>总体比较，VLXAN 技术具有更大优势，而且当前 VLXAN 也得到了更多厂家和客户的支持，已经成为 Overlay 技术的主流标准。</p>\n<h2 id=\"3-VXLAN-协议原理\"><a href=\"#3-VXLAN-协议原理\" class=\"headerlink\" title=\"3. VXLAN 协议原理\"></a>3. VXLAN 协议原理</h2><p>VXLAN 有几个常见的术语：</p>\n<ul>\n<li>VTEP（VXLAN Tunnel Endpoints，VXLAN 隧道端点）</li>\n</ul>\n<p>VXLAN 网络的边缘设备，用来进行 VXLAN 报文的处理（封包和解包）。VTEP 可以是网络设备（比如交换机），也可以是一台机器（比如虚拟化集群中的宿主机）。</p>\n<ul>\n<li>VNI（VXLAN Network Identifier，VXLAN 网络标识符）</li>\n</ul>\n<p>VNI 是每个 VXLAN 段的标识，是个 24 位整数，一共有 $2^{24} &#x3D; 16777216$（一千多万），一般每个 VNI 对应一个租户，也就是说使用 VXLAN 搭建的公有云可以理论上可以支撑千万级别的租户。</p>\n<ul>\n<li>Tunnel（VXLAN 隧道）</li>\n</ul>\n<p>隧道是一个逻辑上的概念，在 VXLAN 模型中并没有具体的物理实体向对应。隧道可以看做是一种虚拟通道，VXLAN 通信双方认为自己是在直接通信，并不知道底层网络的存在。从整体来说，每个 VXLAN 网络像是为通信的虚拟机搭建了一个单独的通信通道，也就是隧道。<br><img src=\"/image-115.png\" alt=\"Alt text\"><br>上图所示为 VXLAN 的工作模型，它创建在原来的 IP 网络（三层）上，只要是三层可达（能够通过 IP 相互通信）的网络就能部署 VXLAN。在 VXLAN 网络的每个端点都有一个 VTEP 设备，负责 VXLAN 协议报文的解包和封包，也就是在虚拟报文上封装 VTEP 通信的报文头部。</p>\n<p>物理网络上可以创建多个 VXLAN 网络，可以将这些 VXLAN 网络看成一个隧道，不同节点上的虚拟机&#x2F;容器能够通过隧道直连。通过 VNI 标识不同的 VXLAN 网络，使得不同的 VXLAN 可以相互隔离。</p>\n<p>VXLAN 的报文结构如下图所示：</p>\n<p><img src=\"/image-116.png\" alt=\"Alt text\"></p>\n<ul>\n<li><p>VXLAN Header : 在原始二层帧的前面增加 8 字节的 VXLAN 的头部，其中最主要的是 VNID，占用 3 个字节（即 24 bit），类似 VLAN ID，可以具有 $2^{24}$ 个网段。</p>\n</li>\n<li><p>UDP Header : 在 VXLAN 和原始二层帧的前面使用 8 字节 UDP 头部进行封装（MAC IN UDP），目的端口号缺省使用 4789，源端口按流随机分配（通过 MAC，IP，四层端口号进行 hash 操作）， 这样可以更好的做 ECMP。</p>\n</li>\n</ul>\n<p>IANA（Internet As-signed Numbers Autority）分配了 4789 作为 VXLAN 的默认目的端口号。</p>\n<p>在上面添加的二层封装之后，再添加底层网络的 IP 头部（20 字节）和 MAC 头部（14 字节），这里的 IP 和 MAC 是宿主机的 IP 地址和 MAC 地址。</p>\n<p>同时，这里需要注意 MTU 的问题，传统网络 MTU 一般为 1500，这里加上 VXLAN 的封装多出的（36+14&#x2F;18，对于 14 的情况为 access 口，省去了 4 字节的 VLAN Tag）50 或 54 字节，需要调整 MTU 为 1550 或 1554，防止频繁分包。<br><img src=\"/image-117.png\" alt=\"Alt text\"></p>\n<h3 id=\"VXLAN-的-Flood-与-Learn\"><a href=\"#VXLAN-的-Flood-与-Learn\" class=\"headerlink\" title=\"VXLAN 的 Flood 与 Learn\"></a>VXLAN 的 Flood 与 Learn</h3><p>总的来说，VXLAN 报文的转发过程就是：原始报文经过 VTEP，被 Linux 内核添加上 VXLAN 头部以及外层的 UDP 头部，再发送出去，对端 VTEP 接收到 VXLAN 报文后拆除外层 UDP 头部，并根据 VXLAN 头部的 VNI 把原始报文发送到目的服务器。但这里有一个问题，第一次通信前双方如何知道所有的通信信息？这些信息包括：</p>\n<p>哪些 VTEP 需要加到一个相同的 VNI 组？<br>发送方如何知道对方的 MAC 地址？<br>如何知道目的服务器在哪个节点上（即目的 VTEP 的地址）？<br>第一个问题简单，VTEP 通常由网络管理员来配置。要回答后面两个问题，还得回到 VXLAN 协议的报文上，看看一个完整的 VXLAN 报文需要哪些信息：</p>\n<ul>\n<li><p>内层报文 : 通信双方的 IP 地址已经明确，只需要 VXLAN 填充对方的 MAC 地址，因此需要一个机制来实现 ARP 功能。</p>\n</li>\n<li><p>VXLAN 头部 : 只需要知道 VNI。一般直接配置在 VTEP 上，要么提前规划，要么根据内层报文自动生成。</p>\n</li>\n<li><p>UDP 头部 : 需要知道源端口和目的端口，源端口由系统自动生成，目的端口默认是 4789。</p>\n</li>\n<li><p>IP 头部 : 需要知道对端 VTEP 的 IP 地址，这个是最关键的部分。</p>\n</li>\n</ul>\n<p>实际上，VTEP 也会有自己的转发表，转发表通过泛洪和学习机制来维护，对于目标 MAC 地址在转发表中不存在的未知单播，广播流量，都会被泛洪给除源 VTEP 外所有的 VTEP，目标 VTEP 响应数据包后，源 VTEP 会从数据包中学习到 MAC，VNI 和 VTEP 的映射关系，并添加到转发表中，后续当再有数据包转发到这个 MAC 地址时，VTEP 会从转发表中直接获取到目标 VTEP 地址，从而发送单播数据到目标 VTEP。<br><img src=\"/image-118.png\" alt=\"Alt text\"></p>\n<p>VTEP 转发表的学习可以通过以下两种方式：</p>\n<p>多播<br>外部控制中心（如 Flannel、Cilium 等 CNI 插件）</p>\n<ul>\n<li>MAC 头部 : 确定了 VTEP 的 IP 地址，后面就好办了，MAC 地址可以通过经典的 ARP 方式获取。</li>\n</ul>\n<h2 id=\"4-Linux-的-VXLAN\"><a href=\"#4-Linux-的-VXLAN\" class=\"headerlink\" title=\"4. Linux 的 VXLAN\"></a>4. Linux 的 VXLAN</h2><p>Linux 对 VXLAN 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，可能会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 VXLAN。</p>\n<p>到了 kernel 3.12 版本，Linux 对 VXLAN 的支持已经完备，支持单播和组播，IPv4 和 IPv6。利用 man 查看 ip 的 link 子命令，可以查看是否有 VXLAN type：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ man ip-link</span><br></pre></td></tr></table></figure>\n<p>搜索 VXLAN，可以看到如下描述：<br><img src=\"/image-119.png\" alt=\"Alt text\"></p>\n<h3 id=\"管理-VXLAN-接口\"><a href=\"#管理-VXLAN-接口\" class=\"headerlink\" title=\"管理 VXLAN 接口\"></a>管理 VXLAN 接口</h3><ol>\n<li>Linux VXLAN 接口的基本管理如下：<br>创建点对点的 VXLAN 接口：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link add vxlan0 type vxlan id 4100 remote 192.168.1.101 local 192.168.1.100 dstport 4789 dev eth0</span><br></pre></td></tr></table></figure>\n其中 id 为 VNI，remote 为远端主机的 IP，local 为你本地主机的 IP，dev 代表 VXLAN 数据从哪个接口传输。</li>\n</ol>\n<p>在 VXLAN 中，一般将 VXLAN 接口（本例中即 vxlan0）叫做 VTEP。<br>2. 创建多播模式的 VXLAN 接口：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link add vxlan0 type vxlan id 4100 group 224.1.1.1 dstport 4789 dev eth0</span><br></pre></td></tr></table></figure>\n<p>多播组主要通过 ARP 泛洪来学习 MAC 地址，即在 VXLAN 子网内广播 ARP 请求，然后对应节点进行响应。group 指定多播组的地址。</p>\n<ol start=\"3\">\n<li>查看 VXLAN 接口详细信息：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip -d link show vxlan0</span><br></pre></td></tr></table></figure></li>\n</ol>\n<h4 id=\"FDB-表\"><a href=\"#FDB-表\" class=\"headerlink\" title=\"FDB 表\"></a>FDB 表</h4><p>FDB（Forwarding Database entry，即转发表）是 Linux 网桥维护的一个二层转发表，用于保存远端虚拟机&#x2F;容器的 MAC地址，远端 VTEP IP，以及 VNI 的映射关系，可以通过 bridge fdb 命令来对 FDB 表进行操作：</p>\n<ul>\n<li>条目添加：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb add &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt; dst &lt;remote_host_ip&gt;</span><br></pre></td></tr></table></figure></li>\n<li>条目删除：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb del &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt;</span><br></pre></td></tr></table></figure></li>\n<li>条目更新：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb replace &lt;remote_host_mac&gt; dev &lt;vxlan_interface&gt; dst &lt;remote_host_ip&gt;</span><br></pre></td></tr></table></figure></li>\n<li>条目查询：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bridge fdb show</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a>5. 总结</h2><p>本文通过介绍 VXLAN 出现的时代背景、VXLAN 的概念和网络模型、VXLAN 报文结构，让你对 VXLAN 有了初步的认识；通过介绍 VXLAN 转发表的泛洪和学习，让你知道了通信双方如何感知对方；最后介绍了 Linux 中 VXLAN 的基本配置，让你进一步了解如何在 Linux 中玩转 VXLAN。下一篇文章将会通过实战来说明如何搭建基于 VXLAN 的 Overlay 网络，顺便展开解读上文提到的多播和外部控制中心的工作原理。</p>\n<p>原文地址: <a href=\"https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82\">https://zhuanlan.zhihu.com/p/130277008#:~:text=%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AE%B2%EF%BC%8C%20VXLAN%20%E6%98%AF,%E4%B8%80%E5%B1%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%BB%9C%E3%80%82</a></p>\n"},{"title":"chrony参数及常用命令介绍","date":"2023-10-27T06:38:29.000Z","_content":"​\n# 1. 背景\n在Kubernetes集群中，如果各节点的时间不一致，可能会带来以下影响：\n\n资源调度问题：Kubernetes使用资源调度器来分配任务和计算资源。如果各个节点的时间不一致，可能会导致调度器无法准确判断任务的截止时间，从而影响任务的执行和资源的分配。\n服务一致性问题：对于有状态的服务（如数据库），如果各个节点的时间不一致，可能会导致数据一致性问题。例如，如果在某个节点上写入了一条数据，然后在另一个时间不一致的节点上读取数据，可能会读取到过期的数据。\n日志分析问题：在Kubernetes集群中，所有的日志都是按照时间顺序排列的。如果各个节点的时间不一致，可能会导致日志分析出现问题，如时间戳不匹配、事件顺序错误等。\n容器同步问题：Kubernetes使用容器来运行任务。如果各个节点的时间不一致，可能会导致容器同步出现问题，如容器启动和停止的时间不一致等。\n网络通信问题：Kubernetes集群中的各个节点通过网络进行通信。如果节点之间的时间不一致，可能会导致网络通信出现问题，如消息延迟、丢包等。\n监控和报警问题：如果各个节点的时间不一致，可能会导致监控和报警系统出现问题。例如，报警阈值设置错误、监控数据不准确等。\n采用chrony进行集群节点间时间同步。\n\n#2. chrony配置文件介绍\nubuntu系统下chrony配置文件路径为/etc/chrony/chrony.conf ，内容如下：\n```\n# Welcome to the chrony configuration file. See chrony.conf(5) for more\nserver 192.168.0.206 iburst  #选择集群中一个节点作为服务器，这在集群无法连接外网是保证所有节点时间一直，其余所有节点从该节点获取时间同步。\nserver ntp.aliyun.com iburst #外网ntp server\nserver time1.cloud.tencent.com iburst\n# information about usuable directives.\n\n# This will use (up to):\n# - 4 sources from ntp.ubuntu.com which some are ipv6 enabled\n# - 2 sources from 2.ubuntu.pool.ntp.org which is ipv6 enabled as well\n# - 1 source from [01].ubuntu.pool.ntp.org each (ipv4 only atm)\n# This means by default, up to 6 dual-stack and up to 2 additional IPv4-only\n# sources will be used.\n# At the same time it retains some protection against one of the entries being\n# down (compare to just using one of the lines). See (LP: #1754358) for the\n# discussion.\n#\n# About using servers from the NTP Pool Project in general see (LP: #104525).\n# Approved by Ubuntu Technical Board on 2011-02-08.\n# See http://www.pool.ntp.org/join.html for more information.\npool ntp.ubuntu.com        iburst maxsources 4\npool 0.ubuntu.pool.ntp.org iburst maxsources 1\npool 1.ubuntu.pool.ntp.org iburst maxsources 1\npool 2.ubuntu.pool.ntp.org iburst maxsources 2\n\n# This directive specify the location of the file containing ID/key pairs for\n# NTP authentication.\nkeyfile /etc/chrony/chrony.keys\n\n# This directive specify the file into which chronyd will store the rate\n# information.\ndriftfile /var/lib/chrony/chrony.drift\n\n# Uncomment the following line to turn logging on.\n#log tracking measurements statistics\n\n# Log files location.\nlogdir /var/log/chrony\n\n# Stop bad estimates upsetting machine clock.\nmaxupdateskew 100.0\n\n# This directive enables kernel synchronisation (every 11 minutes) of the\n# real-time clock. Note that it can’t be used along with the 'rtcfile' directive.\nrtcsync\n\n# Step the system clock instead of slewing it if the adjustment is larger than\n# one second, but only in the first three clock updates.\nmakestep 1 3 #此出可以设置为：makestep 3 -1 当误差大于三秒时执行步进调整，而不用等待微调\n\nallow all #允许所有ip访问本时间服务器\n\nlocal stratum 10 #即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端\n```\n# 3. 常用命令\n\ntimedatectl set-time \"2023-10-27 12:30:50\" ：修改时间\nchronyc tracking： 服务当前同步状态的快照\nchronyc sources -v：查看时间同步源\nchronyc makestep：立即执行步进调整\nsystemctl status chronyd： 查看chronyd服务状态\nsystemctl restart chronyd: 重启chronyd服务\n\n​","source":"_posts/linux/chrony.md","raw":"---\ntitle: chrony参数及常用命令介绍\ndate: 2023-10-27 14:38:29\ncategories:\n  - [linux]\ntags: chrony\n---\n​\n# 1. 背景\n在Kubernetes集群中，如果各节点的时间不一致，可能会带来以下影响：\n\n资源调度问题：Kubernetes使用资源调度器来分配任务和计算资源。如果各个节点的时间不一致，可能会导致调度器无法准确判断任务的截止时间，从而影响任务的执行和资源的分配。\n服务一致性问题：对于有状态的服务（如数据库），如果各个节点的时间不一致，可能会导致数据一致性问题。例如，如果在某个节点上写入了一条数据，然后在另一个时间不一致的节点上读取数据，可能会读取到过期的数据。\n日志分析问题：在Kubernetes集群中，所有的日志都是按照时间顺序排列的。如果各个节点的时间不一致，可能会导致日志分析出现问题，如时间戳不匹配、事件顺序错误等。\n容器同步问题：Kubernetes使用容器来运行任务。如果各个节点的时间不一致，可能会导致容器同步出现问题，如容器启动和停止的时间不一致等。\n网络通信问题：Kubernetes集群中的各个节点通过网络进行通信。如果节点之间的时间不一致，可能会导致网络通信出现问题，如消息延迟、丢包等。\n监控和报警问题：如果各个节点的时间不一致，可能会导致监控和报警系统出现问题。例如，报警阈值设置错误、监控数据不准确等。\n采用chrony进行集群节点间时间同步。\n\n#2. chrony配置文件介绍\nubuntu系统下chrony配置文件路径为/etc/chrony/chrony.conf ，内容如下：\n```\n# Welcome to the chrony configuration file. See chrony.conf(5) for more\nserver 192.168.0.206 iburst  #选择集群中一个节点作为服务器，这在集群无法连接外网是保证所有节点时间一直，其余所有节点从该节点获取时间同步。\nserver ntp.aliyun.com iburst #外网ntp server\nserver time1.cloud.tencent.com iburst\n# information about usuable directives.\n\n# This will use (up to):\n# - 4 sources from ntp.ubuntu.com which some are ipv6 enabled\n# - 2 sources from 2.ubuntu.pool.ntp.org which is ipv6 enabled as well\n# - 1 source from [01].ubuntu.pool.ntp.org each (ipv4 only atm)\n# This means by default, up to 6 dual-stack and up to 2 additional IPv4-only\n# sources will be used.\n# At the same time it retains some protection against one of the entries being\n# down (compare to just using one of the lines). See (LP: #1754358) for the\n# discussion.\n#\n# About using servers from the NTP Pool Project in general see (LP: #104525).\n# Approved by Ubuntu Technical Board on 2011-02-08.\n# See http://www.pool.ntp.org/join.html for more information.\npool ntp.ubuntu.com        iburst maxsources 4\npool 0.ubuntu.pool.ntp.org iburst maxsources 1\npool 1.ubuntu.pool.ntp.org iburst maxsources 1\npool 2.ubuntu.pool.ntp.org iburst maxsources 2\n\n# This directive specify the location of the file containing ID/key pairs for\n# NTP authentication.\nkeyfile /etc/chrony/chrony.keys\n\n# This directive specify the file into which chronyd will store the rate\n# information.\ndriftfile /var/lib/chrony/chrony.drift\n\n# Uncomment the following line to turn logging on.\n#log tracking measurements statistics\n\n# Log files location.\nlogdir /var/log/chrony\n\n# Stop bad estimates upsetting machine clock.\nmaxupdateskew 100.0\n\n# This directive enables kernel synchronisation (every 11 minutes) of the\n# real-time clock. Note that it can’t be used along with the 'rtcfile' directive.\nrtcsync\n\n# Step the system clock instead of slewing it if the adjustment is larger than\n# one second, but only in the first three clock updates.\nmakestep 1 3 #此出可以设置为：makestep 3 -1 当误差大于三秒时执行步进调整，而不用等待微调\n\nallow all #允许所有ip访问本时间服务器\n\nlocal stratum 10 #即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端\n```\n# 3. 常用命令\n\ntimedatectl set-time \"2023-10-27 12:30:50\" ：修改时间\nchronyc tracking： 服务当前同步状态的快照\nchronyc sources -v：查看时间同步源\nchronyc makestep：立即执行步进调整\nsystemctl status chronyd： 查看chronyd服务状态\nsystemctl restart chronyd: 重启chronyd服务\n\n​","slug":"linux/chrony","published":1,"updated":"2023-10-27T07:08:31.967Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0ct002ffmjx7b3v1sty","content":"<p>​</p>\n<h1 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h1><p>在Kubernetes集群中，如果各节点的时间不一致，可能会带来以下影响：</p>\n<p>资源调度问题：Kubernetes使用资源调度器来分配任务和计算资源。如果各个节点的时间不一致，可能会导致调度器无法准确判断任务的截止时间，从而影响任务的执行和资源的分配。<br>服务一致性问题：对于有状态的服务（如数据库），如果各个节点的时间不一致，可能会导致数据一致性问题。例如，如果在某个节点上写入了一条数据，然后在另一个时间不一致的节点上读取数据，可能会读取到过期的数据。<br>日志分析问题：在Kubernetes集群中，所有的日志都是按照时间顺序排列的。如果各个节点的时间不一致，可能会导致日志分析出现问题，如时间戳不匹配、事件顺序错误等。<br>容器同步问题：Kubernetes使用容器来运行任务。如果各个节点的时间不一致，可能会导致容器同步出现问题，如容器启动和停止的时间不一致等。<br>网络通信问题：Kubernetes集群中的各个节点通过网络进行通信。如果节点之间的时间不一致，可能会导致网络通信出现问题，如消息延迟、丢包等。<br>监控和报警问题：如果各个节点的时间不一致，可能会导致监控和报警系统出现问题。例如，报警阈值设置错误、监控数据不准确等。<br>采用chrony进行集群节点间时间同步。</p>\n<p>#2. chrony配置文件介绍<br>ubuntu系统下chrony配置文件路径为&#x2F;etc&#x2F;chrony&#x2F;chrony.conf ，内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Welcome to the chrony configuration file. See chrony.conf(5) for more</span><br><span class=\"line\">server 192.168.0.206 iburst  #选择集群中一个节点作为服务器，这在集群无法连接外网是保证所有节点时间一直，其余所有节点从该节点获取时间同步。</span><br><span class=\"line\">server ntp.aliyun.com iburst #外网ntp server</span><br><span class=\"line\">server time1.cloud.tencent.com iburst</span><br><span class=\"line\"># information about usuable directives.</span><br><span class=\"line\"></span><br><span class=\"line\"># This will use (up to):</span><br><span class=\"line\"># - 4 sources from ntp.ubuntu.com which some are ipv6 enabled</span><br><span class=\"line\"># - 2 sources from 2.ubuntu.pool.ntp.org which is ipv6 enabled as well</span><br><span class=\"line\"># - 1 source from [01].ubuntu.pool.ntp.org each (ipv4 only atm)</span><br><span class=\"line\"># This means by default, up to 6 dual-stack and up to 2 additional IPv4-only</span><br><span class=\"line\"># sources will be used.</span><br><span class=\"line\"># At the same time it retains some protection against one of the entries being</span><br><span class=\"line\"># down (compare to just using one of the lines). See (LP: #1754358) for the</span><br><span class=\"line\"># discussion.</span><br><span class=\"line\">#</span><br><span class=\"line\"># About using servers from the NTP Pool Project in general see (LP: #104525).</span><br><span class=\"line\"># Approved by Ubuntu Technical Board on 2011-02-08.</span><br><span class=\"line\"># See http://www.pool.ntp.org/join.html for more information.</span><br><span class=\"line\">pool ntp.ubuntu.com        iburst maxsources 4</span><br><span class=\"line\">pool 0.ubuntu.pool.ntp.org iburst maxsources 1</span><br><span class=\"line\">pool 1.ubuntu.pool.ntp.org iburst maxsources 1</span><br><span class=\"line\">pool 2.ubuntu.pool.ntp.org iburst maxsources 2</span><br><span class=\"line\"></span><br><span class=\"line\"># This directive specify the location of the file containing ID/key pairs for</span><br><span class=\"line\"># NTP authentication.</span><br><span class=\"line\">keyfile /etc/chrony/chrony.keys</span><br><span class=\"line\"></span><br><span class=\"line\"># This directive specify the file into which chronyd will store the rate</span><br><span class=\"line\"># information.</span><br><span class=\"line\">driftfile /var/lib/chrony/chrony.drift</span><br><span class=\"line\"></span><br><span class=\"line\"># Uncomment the following line to turn logging on.</span><br><span class=\"line\">#log tracking measurements statistics</span><br><span class=\"line\"></span><br><span class=\"line\"># Log files location.</span><br><span class=\"line\">logdir /var/log/chrony</span><br><span class=\"line\"></span><br><span class=\"line\"># Stop bad estimates upsetting machine clock.</span><br><span class=\"line\">maxupdateskew 100.0</span><br><span class=\"line\"></span><br><span class=\"line\"># This directive enables kernel synchronisation (every 11 minutes) of the</span><br><span class=\"line\"># real-time clock. Note that it can’t be used along with the &#x27;rtcfile&#x27; directive.</span><br><span class=\"line\">rtcsync</span><br><span class=\"line\"></span><br><span class=\"line\"># Step the system clock instead of slewing it if the adjustment is larger than</span><br><span class=\"line\"># one second, but only in the first three clock updates.</span><br><span class=\"line\">makestep 1 3 #此出可以设置为：makestep 3 -1 当误差大于三秒时执行步进调整，而不用等待微调</span><br><span class=\"line\"></span><br><span class=\"line\">allow all #允许所有ip访问本时间服务器</span><br><span class=\"line\"></span><br><span class=\"line\">local stratum 10 #即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端</span><br></pre></td></tr></table></figure>\n<h1 id=\"3-常用命令\"><a href=\"#3-常用命令\" class=\"headerlink\" title=\"3. 常用命令\"></a>3. 常用命令</h1><p>timedatectl set-time “2023-10-27 12:30:50” ：修改时间<br>chronyc tracking： 服务当前同步状态的快照<br>chronyc sources -v：查看时间同步源<br>chronyc makestep：立即执行步进调整<br>systemctl status chronyd： 查看chronyd服务状态<br>systemctl restart chronyd: 重启chronyd服务</p>\n<p>​</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>​</p>\n<h1 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h1><p>在Kubernetes集群中，如果各节点的时间不一致，可能会带来以下影响：</p>\n<p>资源调度问题：Kubernetes使用资源调度器来分配任务和计算资源。如果各个节点的时间不一致，可能会导致调度器无法准确判断任务的截止时间，从而影响任务的执行和资源的分配。<br>服务一致性问题：对于有状态的服务（如数据库），如果各个节点的时间不一致，可能会导致数据一致性问题。例如，如果在某个节点上写入了一条数据，然后在另一个时间不一致的节点上读取数据，可能会读取到过期的数据。<br>日志分析问题：在Kubernetes集群中，所有的日志都是按照时间顺序排列的。如果各个节点的时间不一致，可能会导致日志分析出现问题，如时间戳不匹配、事件顺序错误等。<br>容器同步问题：Kubernetes使用容器来运行任务。如果各个节点的时间不一致，可能会导致容器同步出现问题，如容器启动和停止的时间不一致等。<br>网络通信问题：Kubernetes集群中的各个节点通过网络进行通信。如果节点之间的时间不一致，可能会导致网络通信出现问题，如消息延迟、丢包等。<br>监控和报警问题：如果各个节点的时间不一致，可能会导致监控和报警系统出现问题。例如，报警阈值设置错误、监控数据不准确等。<br>采用chrony进行集群节点间时间同步。</p>\n<p>#2. chrony配置文件介绍<br>ubuntu系统下chrony配置文件路径为&#x2F;etc&#x2F;chrony&#x2F;chrony.conf ，内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Welcome to the chrony configuration file. See chrony.conf(5) for more</span><br><span class=\"line\">server 192.168.0.206 iburst  #选择集群中一个节点作为服务器，这在集群无法连接外网是保证所有节点时间一直，其余所有节点从该节点获取时间同步。</span><br><span class=\"line\">server ntp.aliyun.com iburst #外网ntp server</span><br><span class=\"line\">server time1.cloud.tencent.com iburst</span><br><span class=\"line\"># information about usuable directives.</span><br><span class=\"line\"></span><br><span class=\"line\"># This will use (up to):</span><br><span class=\"line\"># - 4 sources from ntp.ubuntu.com which some are ipv6 enabled</span><br><span class=\"line\"># - 2 sources from 2.ubuntu.pool.ntp.org which is ipv6 enabled as well</span><br><span class=\"line\"># - 1 source from [01].ubuntu.pool.ntp.org each (ipv4 only atm)</span><br><span class=\"line\"># This means by default, up to 6 dual-stack and up to 2 additional IPv4-only</span><br><span class=\"line\"># sources will be used.</span><br><span class=\"line\"># At the same time it retains some protection against one of the entries being</span><br><span class=\"line\"># down (compare to just using one of the lines). See (LP: #1754358) for the</span><br><span class=\"line\"># discussion.</span><br><span class=\"line\">#</span><br><span class=\"line\"># About using servers from the NTP Pool Project in general see (LP: #104525).</span><br><span class=\"line\"># Approved by Ubuntu Technical Board on 2011-02-08.</span><br><span class=\"line\"># See http://www.pool.ntp.org/join.html for more information.</span><br><span class=\"line\">pool ntp.ubuntu.com        iburst maxsources 4</span><br><span class=\"line\">pool 0.ubuntu.pool.ntp.org iburst maxsources 1</span><br><span class=\"line\">pool 1.ubuntu.pool.ntp.org iburst maxsources 1</span><br><span class=\"line\">pool 2.ubuntu.pool.ntp.org iburst maxsources 2</span><br><span class=\"line\"></span><br><span class=\"line\"># This directive specify the location of the file containing ID/key pairs for</span><br><span class=\"line\"># NTP authentication.</span><br><span class=\"line\">keyfile /etc/chrony/chrony.keys</span><br><span class=\"line\"></span><br><span class=\"line\"># This directive specify the file into which chronyd will store the rate</span><br><span class=\"line\"># information.</span><br><span class=\"line\">driftfile /var/lib/chrony/chrony.drift</span><br><span class=\"line\"></span><br><span class=\"line\"># Uncomment the following line to turn logging on.</span><br><span class=\"line\">#log tracking measurements statistics</span><br><span class=\"line\"></span><br><span class=\"line\"># Log files location.</span><br><span class=\"line\">logdir /var/log/chrony</span><br><span class=\"line\"></span><br><span class=\"line\"># Stop bad estimates upsetting machine clock.</span><br><span class=\"line\">maxupdateskew 100.0</span><br><span class=\"line\"></span><br><span class=\"line\"># This directive enables kernel synchronisation (every 11 minutes) of the</span><br><span class=\"line\"># real-time clock. Note that it can’t be used along with the &#x27;rtcfile&#x27; directive.</span><br><span class=\"line\">rtcsync</span><br><span class=\"line\"></span><br><span class=\"line\"># Step the system clock instead of slewing it if the adjustment is larger than</span><br><span class=\"line\"># one second, but only in the first three clock updates.</span><br><span class=\"line\">makestep 1 3 #此出可以设置为：makestep 3 -1 当误差大于三秒时执行步进调整，而不用等待微调</span><br><span class=\"line\"></span><br><span class=\"line\">allow all #允许所有ip访问本时间服务器</span><br><span class=\"line\"></span><br><span class=\"line\">local stratum 10 #即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端</span><br></pre></td></tr></table></figure>\n<h1 id=\"3-常用命令\"><a href=\"#3-常用命令\" class=\"headerlink\" title=\"3. 常用命令\"></a>3. 常用命令</h1><p>timedatectl set-time “2023-10-27 12:30:50” ：修改时间<br>chronyc tracking： 服务当前同步状态的快照<br>chronyc sources -v：查看时间同步源<br>chronyc makestep：立即执行步进调整<br>systemctl status chronyd： 查看chronyd服务状态<br>systemctl restart chronyd: 重启chronyd服务</p>\n<p>​</p>\n"},{"title":"install nodejs","date":"2023-08-22T08:35:17.000Z","_content":"要在Ubuntu上安装Node.js和NPM，你可以按照以下步骤进行操作：\n\n1. 首先，打开终端。\n\n2. 更新系统软件包列表：\n\n   ```\n   sudo apt update\n   ```\n\n3. 安装Node.js：\n\n   ```\n   sudo apt install nodejs\n   ```\n\n   这将安装最新版本的Node.js。\n\n4. 安装npm：\n\n   ```\n   sudo apt install npm\n   ```\n\n   这将安装最新版本的npm。\n\n5. 检查Node.js和npm的安装版本：\n\n   ```\n   nodejs --version\n   npm --version\n   ```\n\n   在命令行上将显示Node.js和npm的版本号。\n\n如果你希望安装特定版本的Node.js和npm，可以使用nvm（Node Version Manager）工具。\n\n1. 安装nvm：\n\n   ```\n   curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash\n   ```\n\n   这将下载并运行nvm的安装脚本。\n\n2. 重新打开终端，或者在当前终端中运行以下命令以启用nvm：\n\n   ```\n   source ~/.bashrc\n   ```\n\n3. 安装所需版本的Node.js：\n\n   ```\n   nvm install 18.17.1\n   ```\n\n   这将安装Node.js v18.17.1。\n\n4. 使用所需版本的Node.js：\n\n   ```\n   nvm use 18.17.1\n   ```\n\n   这将在当前终端会话中使用Node.js v18.17.1。\n\n5. 安装所需版本的npm：\n\n   ```\n   npm install -g npm@9.6.7\n   ```\n\n   这将安装npm v9.6.7。\n\n6. 检查Node.js和npm的安装版本：\n\n   ```\n   node --version\n   npm --version\n   ```\n\n   在命令行上将显示Node.js v18.17.1和npm v9.6.7的版本号。\n\n请注意，使用nvm安装的Node.js版本仅在您的当前终端会话中有效。如果您希望在其他终端会话中使用相同的Node.js版本，您需要运行相应的`nvm use`命令。","source":"_posts/nodejs/install_nodejs.md","raw":"---\ntitle: install nodejs\ndate: 2023-08-22 16:35:17\ntags: nodejs\n---\n要在Ubuntu上安装Node.js和NPM，你可以按照以下步骤进行操作：\n\n1. 首先，打开终端。\n\n2. 更新系统软件包列表：\n\n   ```\n   sudo apt update\n   ```\n\n3. 安装Node.js：\n\n   ```\n   sudo apt install nodejs\n   ```\n\n   这将安装最新版本的Node.js。\n\n4. 安装npm：\n\n   ```\n   sudo apt install npm\n   ```\n\n   这将安装最新版本的npm。\n\n5. 检查Node.js和npm的安装版本：\n\n   ```\n   nodejs --version\n   npm --version\n   ```\n\n   在命令行上将显示Node.js和npm的版本号。\n\n如果你希望安装特定版本的Node.js和npm，可以使用nvm（Node Version Manager）工具。\n\n1. 安装nvm：\n\n   ```\n   curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash\n   ```\n\n   这将下载并运行nvm的安装脚本。\n\n2. 重新打开终端，或者在当前终端中运行以下命令以启用nvm：\n\n   ```\n   source ~/.bashrc\n   ```\n\n3. 安装所需版本的Node.js：\n\n   ```\n   nvm install 18.17.1\n   ```\n\n   这将安装Node.js v18.17.1。\n\n4. 使用所需版本的Node.js：\n\n   ```\n   nvm use 18.17.1\n   ```\n\n   这将在当前终端会话中使用Node.js v18.17.1。\n\n5. 安装所需版本的npm：\n\n   ```\n   npm install -g npm@9.6.7\n   ```\n\n   这将安装npm v9.6.7。\n\n6. 检查Node.js和npm的安装版本：\n\n   ```\n   node --version\n   npm --version\n   ```\n\n   在命令行上将显示Node.js v18.17.1和npm v9.6.7的版本号。\n\n请注意，使用nvm安装的Node.js版本仅在您的当前终端会话中有效。如果您希望在其他终端会话中使用相同的Node.js版本，您需要运行相应的`nvm use`命令。","slug":"nodejs/install_nodejs","published":1,"updated":"2023-08-22T08:36:07.375Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clos1z0cu002hfmjxbbg00b9p","content":"<p>要在Ubuntu上安装Node.js和NPM，你可以按照以下步骤进行操作：</p>\n<ol>\n<li><p>首先，打开终端。</p>\n</li>\n<li><p>更新系统软件包列表：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt update</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装Node.js：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install nodejs</span><br></pre></td></tr></table></figure>\n\n<p>这将安装最新版本的Node.js。</p>\n</li>\n<li><p>安装npm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install npm</span><br></pre></td></tr></table></figure>\n\n<p>这将安装最新版本的npm。</p>\n</li>\n<li><p>检查Node.js和npm的安装版本：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nodejs --version</span><br><span class=\"line\">npm --version</span><br></pre></td></tr></table></figure>\n\n<p>在命令行上将显示Node.js和npm的版本号。</p>\n</li>\n</ol>\n<p>如果你希望安装特定版本的Node.js和npm，可以使用nvm（Node Version Manager）工具。</p>\n<ol>\n<li><p>安装nvm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash</span><br></pre></td></tr></table></figure>\n\n<p>这将下载并运行nvm的安装脚本。</p>\n</li>\n<li><p>重新打开终端，或者在当前终端中运行以下命令以启用nvm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装所需版本的Node.js：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvm install 18.17.1</span><br></pre></td></tr></table></figure>\n\n<p>这将安装Node.js v18.17.1。</p>\n</li>\n<li><p>使用所需版本的Node.js：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvm use 18.17.1</span><br></pre></td></tr></table></figure>\n\n<p>这将在当前终端会话中使用Node.js v18.17.1。</p>\n</li>\n<li><p>安装所需版本的npm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g npm@9.6.7</span><br></pre></td></tr></table></figure>\n\n<p>这将安装npm v9.6.7。</p>\n</li>\n<li><p>检查Node.js和npm的安装版本：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node --version</span><br><span class=\"line\">npm --version</span><br></pre></td></tr></table></figure>\n\n<p>在命令行上将显示Node.js v18.17.1和npm v9.6.7的版本号。</p>\n</li>\n</ol>\n<p>请注意，使用nvm安装的Node.js版本仅在您的当前终端会话中有效。如果您希望在其他终端会话中使用相同的Node.js版本，您需要运行相应的<code>nvm use</code>命令。</p>\n","site":{"data":{"link":[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]}},"cover":false,"excerpt":"","more":"<p>要在Ubuntu上安装Node.js和NPM，你可以按照以下步骤进行操作：</p>\n<ol>\n<li><p>首先，打开终端。</p>\n</li>\n<li><p>更新系统软件包列表：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt update</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装Node.js：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install nodejs</span><br></pre></td></tr></table></figure>\n\n<p>这将安装最新版本的Node.js。</p>\n</li>\n<li><p>安装npm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install npm</span><br></pre></td></tr></table></figure>\n\n<p>这将安装最新版本的npm。</p>\n</li>\n<li><p>检查Node.js和npm的安装版本：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nodejs --version</span><br><span class=\"line\">npm --version</span><br></pre></td></tr></table></figure>\n\n<p>在命令行上将显示Node.js和npm的版本号。</p>\n</li>\n</ol>\n<p>如果你希望安装特定版本的Node.js和npm，可以使用nvm（Node Version Manager）工具。</p>\n<ol>\n<li><p>安装nvm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash</span><br></pre></td></tr></table></figure>\n\n<p>这将下载并运行nvm的安装脚本。</p>\n</li>\n<li><p>重新打开终端，或者在当前终端中运行以下命令以启用nvm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装所需版本的Node.js：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvm install 18.17.1</span><br></pre></td></tr></table></figure>\n\n<p>这将安装Node.js v18.17.1。</p>\n</li>\n<li><p>使用所需版本的Node.js：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvm use 18.17.1</span><br></pre></td></tr></table></figure>\n\n<p>这将在当前终端会话中使用Node.js v18.17.1。</p>\n</li>\n<li><p>安装所需版本的npm：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g npm@9.6.7</span><br></pre></td></tr></table></figure>\n\n<p>这将安装npm v9.6.7。</p>\n</li>\n<li><p>检查Node.js和npm的安装版本：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node --version</span><br><span class=\"line\">npm --version</span><br></pre></td></tr></table></figure>\n\n<p>在命令行上将显示Node.js v18.17.1和npm v9.6.7的版本号。</p>\n</li>\n</ol>\n<p>请注意，使用nvm安装的Node.js版本仅在您的当前终端会话中有效。如果您希望在其他终端会话中使用相同的Node.js版本，您需要运行相应的<code>nvm use</code>命令。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"clos1z0bg0005fmjxdcmccx9m","category_id":"clos1z0bo000afmjx6ny3eboi","_id":"clos1z0c2000lfmjxc1p9fc3k"},{"post_id":"clos1z0bj0007fmjxhg1v1idl","category_id":"clos1z0bt000efmjxhek798cc","_id":"clos1z0c7000sfmjx5pm1687s"},{"post_id":"clos1z0bn0009fmjx7r4n7y30","category_id":"clos1z0bt000efmjxhek798cc","_id":"clos1z0c9000xfmjx5indc5x8"},{"post_id":"clos1z0c6000qfmjx3x5h7s26","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cb0013fmjxeyfe212n"},{"post_id":"clos1z0bq000bfmjx3h2d9mqb","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cc0016fmjxfuam2n6a"},{"post_id":"clos1z0c7000tfmjx4o9g38rw","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0ce001afmjxee035bkl"},{"post_id":"clos1z0br000cfmjx6ab0e5hz","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cg001dfmjx2vpr1qdv"},{"post_id":"clos1z0c9000zfmjx4z944fss","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0ci001gfmjxgeypfhjg"},{"post_id":"clos1z0ca0012fmjx0wi23y24","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cj001jfmjx39mqhbkr"},{"post_id":"clos1z0bu000gfmjx2x7xh5nv","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0ck001lfmjxa0663lle"},{"post_id":"clos1z0cb0015fmjxcmni16wm","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cl001nfmjx7s80h0hu"},{"post_id":"clos1z0cd0019fmjxe2nnf235","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cl001pfmjxhak0gapl"},{"post_id":"clos1z0bv000hfmjx6sl11d6z","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cm001rfmjx1zkf6niq"},{"post_id":"clos1z0cf001cfmjxfh4qcr97","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cm001tfmjx4gbx61ml"},{"post_id":"clos1z0ch001ffmjxcs7yg34l","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cn001vfmjx85qkcb8r"},{"post_id":"clos1z0c0000kfmjxfeov3bw1","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cn001xfmjxauk0ceng"},{"post_id":"clos1z0c3000nfmjx68w48ht6","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0co001zfmjx1gcs90al"},{"post_id":"clos1z0cs002efmjxfhuef7ow","category_id":"clos1z0c5000pfmjxgtv023al","_id":"clos1z0cv002jfmjx9l64b8cv"},{"post_id":"clos1z0ct002ffmjx7b3v1sty","category_id":"clos1z0cu002ifmjx8vruegtu","_id":"clos1z0cv002ofmjxcidog4o0"}],"PostTag":[{"post_id":"clos1z0bg0005fmjxdcmccx9m","tag_id":"clos1z0bl0008fmjx3u384gje","_id":"clos1z0bu000ffmjx06pxdq9j"},{"post_id":"clos1z0bj0007fmjxhg1v1idl","tag_id":"clos1z0bs000dfmjxe3vx5jso","_id":"clos1z0c2000mfmjx5fvbh9m9"},{"post_id":"clos1z0bn0009fmjx7r4n7y30","tag_id":"clos1z0bs000dfmjxe3vx5jso","_id":"clos1z0c7000rfmjx54mg3r4k"},{"post_id":"clos1z0bq000bfmjx3h2d9mqb","tag_id":"clos1z0c5000ofmjx2s94863w","_id":"clos1z0c9000yfmjxaewi9w5i"},{"post_id":"clos1z0br000cfmjx6ab0e5hz","tag_id":"clos1z0c8000ufmjxeyhgef44","_id":"clos1z0cb0014fmjx5hpi500m"},{"post_id":"clos1z0bu000gfmjx2x7xh5nv","tag_id":"clos1z0c5000ofmjx2s94863w","_id":"clos1z0cf001bfmjx6e3m5asm"},{"post_id":"clos1z0bv000hfmjx6sl11d6z","tag_id":"clos1z0cc0018fmjx8sgu44a8","_id":"clos1z0cj001ifmjx68z389ao"},{"post_id":"clos1z0c0000kfmjxfeov3bw1","tag_id":"clos1z0ci001hfmjxbn828nq6","_id":"clos1z0cl001ofmjx4vqz1e82"},{"post_id":"clos1z0c3000nfmjx68w48ht6","tag_id":"clos1z0ck001mfmjxcx0y89nu","_id":"clos1z0cm001sfmjx06mneh4j"},{"post_id":"clos1z0c6000qfmjx3x5h7s26","tag_id":"clos1z0cc0018fmjx8sgu44a8","_id":"clos1z0cn001wfmjxbk0o2jri"},{"post_id":"clos1z0c7000tfmjx4o9g38rw","tag_id":"clos1z0cm001ufmjxbv5u7rb0","_id":"clos1z0co0020fmjxhmf615wt"},{"post_id":"clos1z0c8000wfmjx0acj7l1m","tag_id":"clos1z0cn001yfmjxbw3o3ef8","_id":"clos1z0co0022fmjx324o1uty"},{"post_id":"clos1z0c9000zfmjx4z944fss","tag_id":"clos1z0co0021fmjxg34herdi","_id":"clos1z0cp0024fmjx32vyc8pd"},{"post_id":"clos1z0ca0012fmjx0wi23y24","tag_id":"clos1z0cp0023fmjx3u2r81lq","_id":"clos1z0cp0026fmjx046w8l8f"},{"post_id":"clos1z0cb0015fmjxcmni16wm","tag_id":"clos1z0cp0023fmjx3u2r81lq","_id":"clos1z0cq0028fmjx4w3maukf"},{"post_id":"clos1z0cd0019fmjxe2nnf235","tag_id":"clos1z0cq0027fmjx4b7i3heg","_id":"clos1z0cq002afmjxag9s6hot"},{"post_id":"clos1z0cf001cfmjxfh4qcr97","tag_id":"clos1z0ck001mfmjxcx0y89nu","_id":"clos1z0cr002cfmjxf91i5rhu"},{"post_id":"clos1z0ch001ffmjxcs7yg34l","tag_id":"clos1z0cr002bfmjx02tge7fl","_id":"clos1z0cr002dfmjx470wb1tx"},{"post_id":"clos1z0cs002efmjxfhuef7ow","tag_id":"clos1z0ct002gfmjx6vyr8k8g","_id":"clos1z0cv002lfmjxb2hb8xpk"},{"post_id":"clos1z0ct002ffmjx7b3v1sty","tag_id":"clos1z0cv002kfmjxb31m10qm","_id":"clos1z0cv002nfmjxa3muek6u"},{"post_id":"clos1z0cu002hfmjxbbg00b9p","tag_id":"clos1z0cv002mfmjxbjtv73ys","_id":"clos1z0cv002pfmjxa8qoe43e"}],"Tag":[{"name":"docker","_id":"clos1z0bl0008fmjx3u384gje"},{"name":"golang","_id":"clos1z0bs000dfmjxe3vx5jso"},{"name":"logging","_id":"clos1z0c5000ofmjx2s94863w"},{"name":"deepflow","_id":"clos1z0c8000ufmjxeyhgef44"},{"name":"grafana","_id":"clos1z0cc0018fmjx8sgu44a8"},{"name":"gateway","_id":"clos1z0ci001hfmjxbn828nq6"},{"name":"计算机网络","_id":"clos1z0ck001mfmjxcx0y89nu"},{"name":"kibana","_id":"clos1z0cm001ufmjxbv5u7rb0"},{"name":"kubeovn","_id":"clos1z0cn001yfmjxbw3o3ef8"},{"name":"kubevirt","_id":"clos1z0co0021fmjxg34herdi"},{"name":"kubernetes","_id":"clos1z0cp0023fmjx3u2r81lq"},{"name":"PromQL","_id":"clos1z0cq0027fmjx4b7i3heg"},{"name":"containerd","_id":"clos1z0cr002bfmjx02tge7fl"},{"name":"VXLAN","_id":"clos1z0ct002gfmjx6vyr8k8g"},{"name":"chrony","_id":"clos1z0cv002kfmjxb31m10qm"},{"name":"nodejs","_id":"clos1z0cv002mfmjxbjtv73ys"}]}}