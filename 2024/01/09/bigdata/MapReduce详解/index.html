<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>MapReduce详解 | Earl Wong</title><meta name="author" content="Earl Wong"><meta name="copyright" content="Earl Wong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="第1章 MapReduce入门1.1 MapReduce定义Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。 Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。 1.2 MapReduce优缺点1.2.1 优点1．MapReduce 易于编程 它简单的实现一些">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce详解">
<meta property="og:url" content="https://wongearl.github.io/2024/01/09/bigdata/MapReduce%E8%AF%A6%E8%A7%A3/index.html">
<meta property="og:site_name" content="Earl Wong">
<meta property="og:description" content="第1章 MapReduce入门1.1 MapReduce定义Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。 Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。 1.2 MapReduce优缺点1.2.1 优点1．MapReduce 易于编程 它简单的实现一些">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wongearl.github.io/img/20230818103122.jpg">
<meta property="article:published_time" content="2024-01-09T09:11:07.000Z">
<meta property="article:modified_time" content="2024-01-09T09:20:41.135Z">
<meta property="article:author" content="Earl Wong">
<meta property="article:tag" content="mapreduce">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wongearl.github.io/img/20230818103122.jpg"><link rel="shortcut icon" href="/img/20230823160932.png"><link rel="canonical" href="https://wongearl.github.io/2024/01/09/bigdata/MapReduce%E8%AF%A6%E8%A7%A3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MapReduce详解',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-01-09 17:20:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/20230818103122.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/thumbbig-1221433.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Earl Wong"><span class="site-name">Earl Wong</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MapReduce详解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-09T09:11:07.000Z" title="发表于 2024-01-09 17:11:07">2024-01-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-09T09:20:41.135Z" title="更新于 2024-01-09 17:20:41">2024-01-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/bigdata/">bigdata</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="MapReduce详解"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>第1章 MapReduce入门<br>1.1 MapReduce定义<br>Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。</p>
<p>Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。</p>
<p>1.2 MapReduce优缺点<br>1.2.1 优点<br>1．MapReduce 易于编程</p>
<p>它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。就是因为这个特点使得MapReduce编程变得非常流行。</p>
<p>2．良好的扩展性</p>
<p>当计算资源不能得到满足的时候，可以通过简单的增加机器来扩展它的计算能力。</p>
<p>3．高容错性</p>
<p>MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</p>
<p>4．适合PB级以上海量数据的离线处理</p>
<p>它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。</p>
<p>1.2.2 缺点<br>MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。</p>
<ol>
<li>实时计算</li>
</ol>
<p>MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。</p>
<ol start="2">
<li>流式计算</li>
</ol>
<p>流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。</p>
<ol start="3">
<li>DAG（有向图）计算</li>
</ol>
<p>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</p>
<p>1.3 MapReduce核心思想<br>MapReduce核心思想，如图<br><img src="/image-1.png" alt="Alt text"></p>
<p>1）分布式的运算程序往往需要分成至少2个阶段。</p>
<p>2）第一个阶段的maptask并发实例，完全并行运行，互不相干。</p>
<p>3）第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。</p>
<p>4）MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行。</p>
<p>1.4 MapReduce进程（MR）<br>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p>
<p>1）MrAppMaster：负责整个程序的过程调度及状态协调。</p>
<p>2）MapTask：负责map阶段的整个数据处理流程。</p>
<p>3）ReduceTask：负责reduce阶段的整个数据处理流程。</p>
<p>1.5 MapReduce编程规范<br>用户编写的程序分成三个部分：Mapper、Reducer和Driver。</p>
<p>1．Mapper阶段</p>
<p>（1）用户自定义的Mapper继承Mapper</p>
<p>（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）</p>
<p>（3）Mapper中的业务逻辑写在map()方法中</p>
<p>（4）Mapper的输出数据是KV对的形式（KV的类型可自定义）</p>
<p>（5）map()方法（maptask进程）对每一个&lt;K,V&gt;调用一次</p>
<p>2．Reducer阶段</p>
<p>（1）用户自定义的Reducer继承Reducer</p>
<p>（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</p>
<p>（3）Reducer的业务逻辑写在reduce()方法中</p>
<p>（4）Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</p>
<p>3．Driver阶段(关联Mapper和Reducer，并且提交任务到集群)</p>
<p>相当于yarn集群的客户端，用于提交我们整个程序到yarn集群，提交的是封装了mapreduce程序相关运行参数的job对象</p>
<p>第2章 Hadoop序列化<br>2.1 序列化概述<br>2.1.1 什么是序列化<br>序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储（持久化）和网络传输。 </p>
<p>反序列化就是将收到字节序列（或其他数据传输协议）或者是硬盘的持久化数据，转换成内存中的对象。</p>
<p>2.1.2 为什么要序列化<br>        一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。</p>
<p>2.1.3 为什么不用Java的序列化 serilazable<br> Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系等），不便于在网络中高效传输。所以，hadoop自己开发了一套序列化机制（Writable），特点如下：</p>
<p>1．紧凑</p>
<p>紧凑的格式能让我们充分利用网络带宽，而带宽是数据中心最稀缺的资源</p>
<p>2．快速</p>
<p>进程通信形成了分布式系统的骨架，所以需要尽量减少序列化和反序列化的性能开销，这是基本的；</p>
<p>3．可扩展</p>
<p>协议为了满足新的需求变化，所以控制客户端和服务器过程中，需要直接引进相应的协议，这些是新协议，原序列化方式能支持新的协议报文；</p>
<p>4．互操作</p>
<p>能支持不同语言写的客户端和服务端进行交互； </p>
<p>2.2 常用数据序列化类型<br>表4-1 常用的数据类型对应的hadoop数据序列化类型</p>
<p><img src="/image-2.png" alt="Alt text"><br>2.3 自定义bean对象实现序列化接口（Writable）<br>自定义bean对象要想序列化传输，必须实现序列化接口，需要注意以下7项。</p>
<p>（1）必须实现Writable接口</p>
<p>（2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public FlowBean() &#123;</span><br><span class="line"></span><br><span class="line">super();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）重写序列化方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line"></span><br><span class="line">public void write(DataOutput out) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">out.writeLong(upFlow);</span><br><span class="line"></span><br><span class="line">out.writeLong(downFlow);</span><br><span class="line"></span><br><span class="line">out.writeLong(sumFlow);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（4）重写反序列化方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line"></span><br><span class="line">public void readFields(DataInput in) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">upFlow = in.readLong();</span><br><span class="line"></span><br><span class="line">downFlow = in.readLong();</span><br><span class="line"></span><br><span class="line">sumFlow = in.readLong();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（5）注意反序列化的顺序和序列化的顺序完全一致</p>
<p>（6）要想把结果显示在文件中，需要重写toString()，可用”\t”分开，方便后续用。</p>
<p>第3章 MapReduce框架原理<br>3.1 MapReduce工作流程<br>1．流程示意图，如图所示</p>
<p><img src="/image-3.png" alt="Alt text"></p>
<p>2．流程详解</p>
<p>上面的流程是整个mapreduce工作流程，但是shuffle过程只是从第7步开始到第16步结束，具体shuffle过程详解，如下：</p>
<p>1）maptask收集我们的map()方法输出的kv对，放到内存缓冲区中</p>
<p>2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p>
<p>3）多个溢出文件会被合并成大的溢出文件</p>
<p>4）在溢出过程中，及合并的过程中，都要调用partitioner进行分区和针对key进行排序</p>
<p>5）reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据</p>
<p>6）reducetask会取到同一个分区的来自不同maptask的结果文件，reducetask会将这些文件再进行合并（归并排序）</p>
<p>7）合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）</p>
<p>3．注意</p>
<p>Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。</p>
<p>缓冲区的大小可以通过参数调整，参数：io.sort.mb  默认100M。</p>
<p>3.2 InputFormat数据输入<br>2．FileInputFormat操作流程</p>
<p>（1）找到你数据存储的目录。</p>
<p>（2）开始遍历处理（规划切片）目录下的每一个文件</p>
<p>（3）遍历第一个文件xx.txt</p>
<p>a）获取文件大小fs.sizeOf(xx.txt)</p>
<p>b）默认情况下，切片大小&#x3D;blocksize</p>
<p>c）开始切，形成第1个切片：ss.txt—0:128M 第2个切片ss.txt—128:256M 第3个切片ss.txt—256M:300M（每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片）  剩下部分大于128m但是小于140m</p>
<p>e）将切片信息写到一个切片规划文件中</p>
<p>f）数据切片只是在逻辑上对输入数据进行分片，并不会再磁盘上将其切分成分片进行存储。使用InputSplit只记录了分片的元数据信息，比如起始位置、长度以及所在的节点列表等</p>
<p>h）注意：block是HDFS物理上存储的数据，切片是对数据逻辑上的划分</p>
<p>（4）提交切片规划文件到yarn上，yarn上的MrAppMaster就可以根据切片规划文件计算开启maptask个数。</p>
<p>3.2.2 FileInputFormat切片机制<br>1．FileInputFormat中默认的切片机制</p>
<p>（1）简单地按照文件的内容长度进行切片</p>
<p>（2）切片大小，默认等于block大小</p>
<p>（3）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</p>
<p>比如待处理数据有两个文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">file1.txt    320M</span><br><span class="line"></span><br><span class="line">file2.txt    10M</span><br></pre></td></tr></table></figure>
<p>经过FileInputFormat的切片机制运算后，形成的切片信息如下：  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">file1.txt.split1--  0~128</span><br><span class="line"></span><br><span class="line">file1.txt.split2--  128~256</span><br><span class="line"></span><br><span class="line">file1.txt.split3--  256~320</span><br><span class="line"></span><br><span class="line">file2.txt.split1--  0~10M</span><br></pre></td></tr></table></figure>
<p>3.2.3 CombineTextInputFormat切片机制<br>关于大量小文件的优化策略</p>
<p>默认情况下TextInputformat对任务的切片机制是按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个maptask，这样如果有大量小文件，就会产生大量的maptask，处理效率极其低下。</p>
<p>1．优化策略</p>
<p>（1）最好的办法，在数据处理系统的最前端（预处理&#x2F;采集），将小文件先合并成大文件，再上传到HDFS做后续分析。</p>
<p>（2）补救措施：如果已经是大量小文件在HDFS中了，可以使用另一种InputFormat来做切片（CombineTextInputFormat），它的切片逻辑跟TextFileInputFormat不同：它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个maptask。</p>
<p>（3）优先满足最小切片大小，不超过最大切片大小</p>
<p>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304); &#x2F;&#x2F; 4m  </p>
<p>CombineTextInputFormat.setMinInputSplitSize(job, 2097152); &#x2F;&#x2F; 2m   </p>
<p>举例：0.5m+1m+0.3m+5m&#x3D;2m + 4.8m&#x3D;2m + 4m + 0.8m</p>
<p>2．具体实现步骤</p>
<p>&#x2F;&#x2F;  如果不设置InputFormat,它默认用的是TextInputFormat.class</p>
<p>job.setInputFormatClass(CombineTextInputFormat.class)</p>
<p>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);&#x2F;&#x2F; 4m</p>
<p>CombineTextInputFormat.setMinInputSplitSize(job, 2097152);&#x2F;&#x2F; 2m</p>
<p>3.3 MapTask工作机制<br>3.3.1 并行度决定机制<br>1．问题引出</p>
<p>maptask的并行度决定map阶段的任务处理并发度，进而影响到整个job的处理速度。那么，mapTask并行任务是否越多越好呢？</p>
<p>2．MapTask并行度决定机制</p>
<p>一个job的map阶段MapTask并行度（个数），由客户端提交job时的切片个数决定，如图所示。</p>
<p><img src="/image-4.png" alt="Alt text"></p>
<p>3.3.2 MapTask工作机制<br>MapTask工作机制如图所示<br><img src="/image-5.png" alt="Alt text"></p>
<p>（1）Read阶段：Map Task通过用户编写的RecordReader，从输入InputSplit中解析出一个个key&#x2F;value。</p>
<p>（2）Map阶段：该节点主要是将解析出的key&#x2F;value交给用户编写map()函数处理，并产生一系列新的key&#x2F;value。</p>
<p>（3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用context.write，context.write底层 OutputCollector.collect()输出结果。在该函数内部，它会将生成的key&#x2F;value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p>
<p>（4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并等操作。</p>
<p>（5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p>
<p>在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并io.sort.factor（默认100）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p>
<p>3.4 Shuffle机制<br>3.4.1 Shuffle机制(洗牌)<br>Mapreduce确保每个reducer的输入都是按key排序的。系统执行排序的过程（即将mapper输出作为输入传给reducer）称为shuffle，如图所示。<br><img src="/image-6.png" alt="Alt text"></p>
<p>3.4.2 Partition分区<br>分区：把数据扎堆存放</p>
<p>问题引出：要求将统计结果按照条件输出到不同文件中（分区）。比如：将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p>
<p>默认partition分区 hello–&gt;hash%reducetask数量–2 ；0，1</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class HashPartitioner&lt;K, V&gt; extends Partitioner&lt;K, V&gt; &#123;</span><br><span class="line"></span><br><span class="line">  public int getPartition(K key, V value, int numReduceTasks) &#123;</span><br><span class="line"></span><br><span class="line">    return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>默认分区是根据key的hashCode对reduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。</p>
<p>2．自定义Partitioner步骤</p>
<p>（1）自定义类继承Partitioner，重写getPartition()方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public class ProvincePartitioner extends Partitioner&lt;Text, FlowBean&gt; &#123;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line"></span><br><span class="line">public int getPartition(Text key, FlowBean value, int numPartitions) &#123;</span><br><span class="line"></span><br><span class="line">// 1 获取电话号码的前三位</span><br><span class="line"></span><br><span class="line">String preNum = key.toString().substring(0, 3);</span><br><span class="line"></span><br><span class="line">int partition = 4;</span><br><span class="line"></span><br><span class="line">// 2 判断是哪个省</span><br><span class="line"></span><br><span class="line">if (&quot;136&quot;.equals(preNum)) &#123;</span><br><span class="line"></span><br><span class="line">partition = 0;</span><br><span class="line"></span><br><span class="line">&#125;else if (&quot;137&quot;.equals(preNum)) &#123;</span><br><span class="line"></span><br><span class="line">partition = 1;</span><br><span class="line"></span><br><span class="line">&#125;else if (&quot;138&quot;.equals(preNum)) &#123;</span><br><span class="line"></span><br><span class="line">partition = 2;</span><br><span class="line"></span><br><span class="line">&#125;else if (&quot;139&quot;.equals(preNum)) &#123;</span><br><span class="line"></span><br><span class="line">partition = 3;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return partition;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）在job驱动中，设置自定义partitioner：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionerClass(CustomPartitioner.class);</span><br></pre></td></tr></table></figure>
<p>（3）自定义partition后，要根据自定义partitioner的逻辑设置相应数量的reduce task</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(5);</span><br></pre></td></tr></table></figure>
<p>注意<br>reduceTask的个数决定了有几个文件！！</p>
<p>如果reduceTask的数量&gt; getPartition的结果数，则会多产生几个空的输出文件part-r-000xx；</p>
<p>如果1&lt;reduceTask的数量&lt;getPartition的结果数，则有一部分分区数据无处安放，会Exception；</p>
<p>如果reduceTask的数量&#x3D;1，则不管mapTask端输出多少个分区文件，最终结果都交给这一个reduceTask，最终也就只会产生一个结果文件 part-r-00000；</p>
<p>例如：假设自定义分区数为5，则</p>
<p>（1）job.setNumReduceTasks(1);会正常运行，只不过会产生一个输出文件</p>
<p>（2）job.setNumReduceTasks(2);会报错</p>
<p>（3）job.setNumReduceTasks(6);大于5，程序会正常运行，会产生空文件</p>
<p>3.4.3 WritableComparable排序<br>排序是MapReduce框架中最重要的操作之一。Map Task和Reduce Task均会对数据（按照key）进行排序。该操作属于Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。默认排序是按照字典顺序排序。</p>
<p>对于Map Task，它会将处理的结果暂时放到一个缓冲区中，当缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次排序，并将这些有序数据写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行一次合并，以将这些文件合并成一个大的有序文件。</p>
<p>对于Reduce Task，它从每个Map Task上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则放到磁盘上，否则放到内存中。如果磁盘上文件数目达到一定阈值，则进行一次合并以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据写到磁盘上。当所有数据拷贝完毕后，Reduce Task统一对内存和磁盘上的所有数据进行一次合并。</p>
<p>每个阶段的默认排序</p>
<p>1．排序的分类</p>
<p>（1）部分排序：</p>
<p>MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部排序。</p>
<p>（2）全排序：</p>
<p>如何用Hadoop产生一个全局排序的文件？最简单的方法是使用一个分区。但该方法在处理大型文件时效率极低，因为一台机器必须处理所有输出文件，从而完全丧失了MapReduce所提供的并行架构。</p>
<p>替代方案：首先创建一系列排好序的文件；其次，串联这些文件；最后，生成一个全局排序的文件。主要思路是使用一个分区来描述输出的全局排序。例如：可以为上述文件创建3个分区，在第一分区中，记录的单词首字母a-g，第二分区记录单词首字母h-n, 第三分区记录单词首字母o-z。</p>
<p>2．自定义排序WritableComparable</p>
<p>（1）原理分析</p>
<p>bean对象实现WritableComparable接口重写compareTo方法，就可以实现排序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line"></span><br><span class="line">public int compareTo(FlowBean o) &#123;</span><br><span class="line"></span><br><span class="line">// 倒序排列，从大到小</span><br><span class="line"></span><br><span class="line">return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;</span><br><span class="line"></span><br><span class="line">if(this.sumFlow==o.getSumFlow())&#123;</span><br><span class="line"></span><br><span class="line">This.downFlow&gt;o.getDownFlow() ? -1 :1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3.5 ReduceTask工作机制</p>
<p><img src="/image-7.png" alt="Alt text"><br>1．设置ReduceTask并行度（个数）</p>
<p>reducetask的并行度同样影响整个job的执行并发度和执行效率，但与maptask的并发数由切片数决定不同，Reducetask数量的决定是可以直接手动设置：</p>
<p>&#x2F;&#x2F;默认值是1，手动设置为4</p>
<p>job.setNumReduceTasks(4);</p>
<p>2．注意</p>
<p>（1）reducetask&#x3D;0 ，表示没有reduce阶段，输出文件个数和map个数一致。</p>
<p>（2）reducetask默认值就是1，所以输出文件个数为一个。</p>
<p>（3）如果数据分布不均匀，就有可能在reduce阶段产生数据倾斜</p>
<p>（4）reducetask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个reducetask。</p>
<p>（5）具体多少个reducetask，需要根据集群性能而定。</p>
<p>（6）如果分区数不是1，但是reducetask为1，是否执行分区过程。答案是：不执行分区过程。因为在maptask的源码中，执行分区的前提是先判断reduceNum个数是否大于1。不大于1肯定不执行。</p>
<p>3．实验：测试reducetask多少合适。</p>
<p>（1）实验环境：1个master节点，16个slave节点：CPU:8GHZ，内存: 2G</p>
<p>（2）实验结论：</p>
<p>表4-3 改变reduce task （数据量为1GB）</p>
<p><img src="/image.png" alt="Alt text"></p>
<p>4．ReduceTask工作机制</p>
<p>（1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>
<p>（2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p>
<p>（3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p>
<p>（4）Reduce阶段：reduce()函数将计算结果写到HDFS上。<br>————————————————<br>版权声明：本文为CSDN博主「叫我阿呆就好了」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44868502/article/details/102827774">https://blog.csdn.net/qq_44868502/article/details/102827774</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://wongearl.github.io">Earl Wong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wongearl.github.io/2024/01/09/bigdata/MapReduce%E8%AF%A6%E8%A7%A3/">https://wongearl.github.io/2024/01/09/bigdata/MapReduce%E8%AF%A6%E8%A7%A3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://wongearl.github.io" target="_blank">Earl Wong</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/mapreduce/">mapreduce</a></div><div class="post_share"><div class="social-share" data-image="/img/20230818103122.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/01/09/kubernetes/kube-ovn-underlay/" title="kubeovn underlay 相关概念"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">kubeovn underlay 相关概念</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/20230818103122.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Earl Wong</div><div class="author-info__description">Share everything</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wongearl"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/wongearl" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:earlwong368@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/09/bigdata/MapReduce%E8%AF%A6%E8%A7%A3/" title="MapReduce详解">MapReduce详解</a><time datetime="2024-01-09T09:11:07.000Z" title="发表于 2024-01-09 17:11:07">2024-01-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/09/kubernetes/kube-ovn-underlay/" title="kubeovn underlay 相关概念">kubeovn underlay 相关概念</a><time datetime="2024-01-09T03:34:41.595Z" title="发表于 2024-01-09 11:34:41">2024-01-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/09/hello-world/" title="Hello World">Hello World</a><time datetime="2024-01-09T03:34:41.327Z" title="发表于 2024-01-09 11:34:41">2024-01-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/02/kubernetes/buildx/" title="使用buildx构建多架构镜像">使用buildx构建多架构镜像</a><time datetime="2024-01-02T07:52:06.000Z" title="发表于 2024-01-02 15:52:06">2024-01-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/17/gitops/argo-cd-guide/" title="argo-cd-guide">argo-cd-guide</a><time datetime="2023-11-17T01:39:03.000Z" title="发表于 2023-11-17 09:39:03">2023-11-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Earl Wong</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>